{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import uncertainty_toolbox as uct\n",
    "import uncertainty_toolbox.metrics as umetrics\n",
    "from uncertainty_toolbox.metrics_calibration import (\n",
    "    get_proportion_lists_vectorized,\n",
    ")\n",
    "import uncertainty_toolbox.viz as uviz\n",
    "from uncertainty_toolbox.recalibration import iso_recal\n",
    "\n",
    "from data import data_preprocess\n",
    "from evaluation import metrics\n",
    "from model import end2end_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = data_preprocess.data_preprocess('kin8nm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss:  7.2912068367004395\n",
      "nllk loss:  tensor(0.6150, grad_fn=<MeanBackward0>) kernel loss: tensor(2.2254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1991, grad_fn=<MeanBackward0>) kernel loss: tensor(16.1952, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.0542, grad_fn=<MeanBackward0>) kernel loss: tensor(73.1851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.8139, grad_fn=<MeanBackward0>) kernel loss: tensor(76.1749, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.3491, grad_fn=<MeanBackward0>) kernel loss: tensor(35.3163, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.1500, grad_fn=<MeanBackward0>) kernel loss: tensor(29.0084, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.0385, grad_fn=<MeanBackward0>) kernel loss: tensor(40.5155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.2763, grad_fn=<MeanBackward0>) kernel loss: tensor(23.6513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.3084, grad_fn=<MeanBackward0>) kernel loss: tensor(24.2492, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.7075, grad_fn=<MeanBackward0>) kernel loss: tensor(16.2851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6116, grad_fn=<MeanBackward0>) kernel loss: tensor(15.8630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6740, grad_fn=<MeanBackward0>) kernel loss: tensor(15.2491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.7275, grad_fn=<MeanBackward0>) kernel loss: tensor(7.7433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.8607, grad_fn=<MeanBackward0>) kernel loss: tensor(11.2996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.8825, grad_fn=<MeanBackward0>) kernel loss: tensor(6.4482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9578, grad_fn=<MeanBackward0>) kernel loss: tensor(5.1063, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9586, grad_fn=<MeanBackward0>) kernel loss: tensor(8.9046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.8361, grad_fn=<MeanBackward0>) kernel loss: tensor(9.2775, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9879, grad_fn=<MeanBackward0>) kernel loss: tensor(8.4541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.0071, grad_fn=<MeanBackward0>) kernel loss: tensor(3.9842, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1167, grad_fn=<MeanBackward0>) kernel loss: tensor(6.5587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.2457, grad_fn=<MeanBackward0>) kernel loss: tensor(3.0596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.2913, grad_fn=<MeanBackward0>) kernel loss: tensor(7.2443, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3283, grad_fn=<MeanBackward0>) kernel loss: tensor(4.5567, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3808, grad_fn=<MeanBackward0>) kernel loss: tensor(3.0850, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4397, grad_fn=<MeanBackward0>) kernel loss: tensor(3.3677, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3927, grad_fn=<MeanBackward0>) kernel loss: tensor(3.1060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4007, grad_fn=<MeanBackward0>) kernel loss: tensor(5.4100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4468, grad_fn=<MeanBackward0>) kernel loss: tensor(4.4704, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5086, grad_fn=<MeanBackward0>) kernel loss: tensor(2.7209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5291, grad_fn=<MeanBackward0>) kernel loss: tensor(2.8613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4791, grad_fn=<MeanBackward0>) kernel loss: tensor(4.3457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4696, grad_fn=<MeanBackward0>) kernel loss: tensor(3.6056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5193, grad_fn=<MeanBackward0>) kernel loss: tensor(2.2657, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5219, grad_fn=<MeanBackward0>) kernel loss: tensor(4.3892, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5423, grad_fn=<MeanBackward0>) kernel loss: tensor(2.9148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5899, grad_fn=<MeanBackward0>) kernel loss: tensor(3.2534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6070, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6471, grad_fn=<MeanBackward0>) kernel loss: tensor(2.5024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6626, grad_fn=<MeanBackward0>) kernel loss: tensor(3.0868, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6567, grad_fn=<MeanBackward0>) kernel loss: tensor(3.4202, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6507, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6792, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3133, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7124, grad_fn=<MeanBackward0>) kernel loss: tensor(2.7008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7336, grad_fn=<MeanBackward0>) kernel loss: tensor(4.2786, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7392, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6515, grad_fn=<MeanBackward0>) kernel loss: tensor(2.7523, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6117, grad_fn=<MeanBackward0>) kernel loss: tensor(3.1574, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6870, grad_fn=<MeanBackward0>) kernel loss: tensor(3.3775, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7445, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5592, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7987, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8185, grad_fn=<MeanBackward0>) kernel loss: tensor(2.2701, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8158, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7682, grad_fn=<MeanBackward0>) kernel loss: tensor(3.3846, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7828, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0537, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8512, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8490, grad_fn=<MeanBackward0>) kernel loss: tensor(2.2448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8305, grad_fn=<MeanBackward0>) kernel loss: tensor(3.8818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8459, grad_fn=<MeanBackward0>) kernel loss: tensor(2.9072, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8825, grad_fn=<MeanBackward0>) kernel loss: tensor(2.5600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8263, grad_fn=<MeanBackward0>) kernel loss: tensor(2.8483, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9005, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3887, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9231, grad_fn=<MeanBackward0>) kernel loss: tensor(2.4237, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8593, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0663, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9413, grad_fn=<MeanBackward0>) kernel loss: tensor(3.2146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9219, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8656, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9102, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0758, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9548, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8392, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9771, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9642, grad_fn=<MeanBackward0>) kernel loss: tensor(2.4945, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9709, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1966, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9770, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3833, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8342, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9499, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3345, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0051, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6152, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9844, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6447, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0134, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1326, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0250, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0157, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5101, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9838, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6807, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0225, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0075, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0256, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8715, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0274, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9651, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0091, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7343, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.0155, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0330, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4985, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0197, grad_fn=<MeanBackward0>) kernel loss: tensor(2.6490, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9740, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9920, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3233, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8142, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0490, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0472, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9137, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0756, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0507, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0821, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6478, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0533, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1978, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0561, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0684, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8594, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0916, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0296, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0577, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4968, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0744, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0615, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0882, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0730, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3400, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0589, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9677, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9836, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0225, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0834, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0604, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3421, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0508, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9425, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6862, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1047, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2419, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1346, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1201, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2591, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3934, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1225, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0966, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1395, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9369, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1372, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1174, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8480, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0544, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0511, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1026, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1014, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1402, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1270, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7137, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0991, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1264, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1413, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1718, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1891, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1519, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0575, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0284, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1087, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8747, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1719, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1964, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0523, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2058, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1521, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1821, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8709, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1734, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4246, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1669, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3766, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1715, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5959, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1448, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1397, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1870, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1593, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3950, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1810, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0017, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1746, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1783, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1891, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1232, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7394, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1676, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9797, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1726, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1601, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1289, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6986, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1635, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1321, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1450, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0884, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1785, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1755, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4058, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1636, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4578, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.1522, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5370, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1771, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5135, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7572, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8325, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6834, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1704, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4184, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1931, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1937, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7019, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5575, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1985, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4795, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2123, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2246, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2968, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2428, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2323, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2251, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2164, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2285, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2919, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2494, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4762, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2554, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3698, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2285, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1979, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2323, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6399, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2425, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1055, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2263, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5384, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2259, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0105, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2364, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2129, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7731, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2050, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4791, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2234, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0091, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3028, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1715, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0951, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8546, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1797, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0842, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7096, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1754, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3530, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7961, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2257, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2531, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7220, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2399, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5958, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2510, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5783, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8144, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2351, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2446, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8439, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2560, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2600, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7256, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2505, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8795, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7527, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7368, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2698, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6841, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2904, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2895, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2878, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7832, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2584, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7180, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9369, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8268, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2958, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8283, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3020, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3089, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2270, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2563, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6459, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3108, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3113, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9667, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3041, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5987, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3087, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6041, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3210, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6125, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3098, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5015, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9573, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.2443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6001, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2952, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3200, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1909, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5764, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3196, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3323, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3215, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3255, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2619, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4692, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3283, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2923, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7543, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3043, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7764, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2993, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3226, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3203, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3195, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4662, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3317, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2078, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6843, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7716, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2116, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1846, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2192, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2680, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2966, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2948, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3159, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3490, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3140, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3350, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8663, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3243, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5967, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5562, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2291, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8074, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3229, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8628, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3476, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7357, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3183, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3583, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5399, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8450, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2753, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5909, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3851, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1413, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3915, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4303, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2865, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7747, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3243, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3339, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3223, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3323, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3523, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2957, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3648, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3385, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6896, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3586, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7320, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3639, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3611, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3194, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3294, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5842, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3800, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3383, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8496, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2716, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2686, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4531, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5891, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3824, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3588, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0150, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3448, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8308, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3577, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3702, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1937, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4576, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8106, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.3691, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4791, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3423, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3189, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5260, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3408, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1987, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3637, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2822, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4054, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4070, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4108, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7294, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3841, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6334, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3477, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5240, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3708, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6645, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8957, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4065, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3615, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5989, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3714, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4825, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3907, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0891, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3388, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3540, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4170, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4961, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4043, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4282, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4205, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8886, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6133, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3186, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4155, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3758, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2948, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4483, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1970, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3031, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9228, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4494, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4323, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4570, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4682, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3535, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4197, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5225, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4203, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5133, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2873, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4587, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4492, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3704, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7286, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4723, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1824, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4751, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3374, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4878, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4667, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5787, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5098, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3059, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4853, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3608, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4345, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5072, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1824, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5066, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6753, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4906, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0320, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4612, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4455, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5056, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3018, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4726, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5126, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4776, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5455, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5141, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3881, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7505, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4679, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2428, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2823, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4821, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1960, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5033, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4353, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.4992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2960, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5309, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2645, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4708, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0215, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5598, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2406, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9995, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3842, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5599, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1248, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5157, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4280, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4805, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9954, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4437, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4425, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4693, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5774, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4719, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6845, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4706, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4840, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4900, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3030, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6092, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3043, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5429, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5107, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3845, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4591, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3336, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4786, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3778, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4615, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2967, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5273, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2915, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5451, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5400, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5288, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3789, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4862, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5369, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3011, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1516, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8484, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8569, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3745, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4971, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3274, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5217, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5261, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3182, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5439, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5542, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5124, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5460, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2864, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5543, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5545, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7302, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5428, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5432, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5784, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1846, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5705, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2743, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5829, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5917, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4831, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5686, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3439, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2616, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5722, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5328, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4545, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6309, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4852, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6096, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5659, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3208, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6232, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4753, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6281, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6333, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5659, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4209, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3174, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3906, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3907, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2258, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1338, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5570, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6116, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4293, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2796, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.5290, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8987, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5606, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5177, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4642, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5321, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4356, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6359, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2002, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6384, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3285, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6203, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4663, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4168, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5703, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4148, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3505, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6638, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2570, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6581, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5715, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7106, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3530, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6231, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2570, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7499, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3579, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4252, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7585, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4091, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6782, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2348, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7426, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2576, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8407, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7138, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5551, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7537, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7585, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7352, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7514, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1995, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7363, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7589, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7444, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3250, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6048, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3528, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0662, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3948, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5952, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7269, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4047, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5152, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7155, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3546, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7513, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6160, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7365, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4922, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1965, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6222, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3518, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5822, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2481, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3091, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7845, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5544, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7880, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3877, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8666, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1374, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8492, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1951, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7698, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7991, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3079, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7476, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4250, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4265, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4936, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3643, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2561, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6439, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2877, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3897, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.7544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8452, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9083, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8686, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3803, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8857, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8904, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2931, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7066, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3602, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2811, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3784, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8686, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3610, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9373, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9594, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3407, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1660, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3244, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6324, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7782, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4184, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3870, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2328, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8858, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5528, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2326, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9086, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9279, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1588, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9038, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9601, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5310, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9604, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3868, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9160, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3997, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8061, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4495, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3594, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3949, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3082, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0417, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1866, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8388, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9020, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9364, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9524, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3572, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9619, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4806, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8862, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3738, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9697, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4820, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0351, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6699, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9799, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0206, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1473, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0205, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8816, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5856, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3518, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1896, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8632, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1434, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3567, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8382, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3828, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2841, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5047, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9097, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0221, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2695, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9862, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2645, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0281, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3994, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0017, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3570, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2917, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0289, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3777, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2577, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0378, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3930, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9651, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0317, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2800, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0493, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2788, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9270, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9408, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9062, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4140, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9540, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3774, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9523, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1047, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.0068, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5603, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9607, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2285, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9991, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8582, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1365, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2834, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3826, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0060, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2682, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0478, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0359, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3579, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0099, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5122, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0822, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1373, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1012, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3352, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5530, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9557, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0551, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1997, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8785, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3093, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4017, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0413, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4170, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0274, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9861, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2224, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0312, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2033, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6444, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3102, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5194, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3180, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3602, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2962, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1430, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0391, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3820, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0885, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1698, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1571, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1436, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1011, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1714, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4243, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1574, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1480, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1548, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1520, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2492, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1298, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2502, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3264, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1248, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0190, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6092, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7313, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7634, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2967, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3030, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1653, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4695, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3501, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1381, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3437, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4522, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2809, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1808, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2762, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4644, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1250, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3275, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2404, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0090, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5401, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3364, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1715, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2187, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0098, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3913, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1069, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1058, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2619, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0827, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3485, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2142, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1708, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4366, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1973, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1816, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2274, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2198, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2373, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0797, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4153, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.8476, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1160, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2642, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0708, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2679, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4937, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7455, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5963, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8587, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9121, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2182, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1174, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1677, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1066, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4515, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5011, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2373, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2431, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2719, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3208, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2543, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4272, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1598, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4348, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2718, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3849, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1795, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2924, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2088, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1685, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2217, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1142, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2090, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3955, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3141, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2285, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3027, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3853, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2796, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3200, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3518, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2140, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3366, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2239, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0543, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2358, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4586, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2495, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2827, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3994, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2599, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2221, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3402, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2555, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2702, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3058, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2500, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2932, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4050, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7794, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5396, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8291, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2540, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1753, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2932, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3012, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2775, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2802, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3265, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2949, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4271, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3673, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3738, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2651, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3442, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3448, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3059, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3322, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1079, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6913, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4101, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1020, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1619, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4067, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.3844, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4121, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2774, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4331, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2709, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5002, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4121, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2619, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2364, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1718, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6580, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2633, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.0053, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4964, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2231, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3295, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2633, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4342, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3635, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2220, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4086, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3955, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1810, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3910, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2821, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2113, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2878, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2695, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3843, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1548, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0214, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5333, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1513, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3702, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1270, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2645, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1615, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0558, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4506, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8615, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2240, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9575, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2428, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2939, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3844, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3045, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4053, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2250, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4693, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1835, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4160, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4434, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3364, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3980, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1104, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9628, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1801, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0621, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1997, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9123, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1892, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0272, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8198, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3122, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2301, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1421, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4284, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4558, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4827, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3551, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4641, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3825, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3649, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3400, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0714, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0852, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4537, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1481, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2710, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0061, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2916, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9749, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2549, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2907, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4216, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.4849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2014, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5019, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4243, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1969, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3291, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1219, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2944, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9285, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3386, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4674, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3163, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3692, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4231, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3849, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4528, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2577, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4782, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2336, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5469, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3419, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5162, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3227, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3612, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1388, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5869, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2960, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5487, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3600, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3469, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1653, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0531, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6971, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0325, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5071, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4676, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5289, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5224, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2561, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2907, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2186, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5216, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1932, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5754, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2194, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2422, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3121, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3314, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1225, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4699, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2696, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2395, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6611, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3765, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4176, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0468, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3788, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3643, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1588, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4542, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5182, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5065, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5041, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2593, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5091, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4971, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2694, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5947, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2138, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6062, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5823, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4012, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2333, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2479, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3401, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2278, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2425, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7802, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3171, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0336, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0403, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2372, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4373, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3799, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5527, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3315, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.5649, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6088, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2180, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6102, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5198, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1920, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1030, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0511, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0446, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3888, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2736, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1258, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3641, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2210, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5599, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6116, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6396, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6512, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6305, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1354, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6068, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4678, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0620, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0492, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1865, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2273, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4823, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5705, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6421, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2638, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6473, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1920, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6317, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6294, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2352, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3199, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3827, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1726, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2137, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2378, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2512, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0850, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3797, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1644, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6234, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6301, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1936, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1749, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5433, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5510, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1574, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4765, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5115, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2801, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1298, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9459, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1895, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1425, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1829, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3540, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5147, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5867, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2314, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2566, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5841, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1020, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4390, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2413, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3835, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2018, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2696, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0437, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4246, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2570, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.1779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4246, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4587, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4208, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5676, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6211, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2359, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5350, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1971, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6239, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5035, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3193, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3565, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5365, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5693, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2738, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6350, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2934, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4950, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1740, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2381, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5005, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0648, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6229, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6231, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1878, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1360, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6589, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4251, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7166, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7437, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7652, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7416, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1834, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7193, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2601, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6279, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1747, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3075, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6416, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2380, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7059, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1386, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4252, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1998, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7002, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0566, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7462, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7618, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7703, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1648, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2594, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5148, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1463, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6115, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1423, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0437, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6522, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1543, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7122, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2777, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7319, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7531, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5358, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7571, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2210, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7810, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7996, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2591, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2332, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1969, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8112, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8152, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7569, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6659, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1942, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0754, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2922, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0019, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3269, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1434, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6721, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6093, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6733, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1638, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.6960, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1753, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7309, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3408, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7276, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1654, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7546, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7405, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1061, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7556, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7421, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7915, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3604, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8130, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1175, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8368, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2699, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8046, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3295, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6179, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4439, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2645, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3915, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1257, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1549, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0896, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1867, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1733, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5690, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1916, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6576, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6846, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7216, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3413, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7496, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1011, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0504, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8143, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8191, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1948, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8394, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3425, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7318, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2888, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5778, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1604, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7253, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1782, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4596, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0248, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7221, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2150, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7341, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1934, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8002, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1693, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7285, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1290, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5996, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7323, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7645, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1530, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7999, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1338, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7909, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1927, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7681, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1271, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4778, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4995, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1092, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2249, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1097, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3693, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2555, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3646, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2192, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3190, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1903, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1965, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1435, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1712, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6768, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7807, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7564, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7685, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2150, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7641, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7405, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1572, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4138, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3531, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1102, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3384, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1918, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2126, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6061, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2227, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2562, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2083, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8498, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0310, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8693, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3656, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8123, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4495, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7185, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1799, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1728, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.7080, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2647, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1313, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6533, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2784, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1835, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4500, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1205, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2710, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1167, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3733, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7568, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1870, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8219, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1220, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8471, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8509, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8662, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1561, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8533, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2473, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5599, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0679, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2389, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1217, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2838, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3252, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1662, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6072, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0502, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6906, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0598, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8230, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2370, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7645, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1592, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0998, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7257, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3709, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1304, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6935, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7495, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7608, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1231, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1422, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6838, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1576, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7498, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7499, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7263, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6658, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5807, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1982, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4795, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2881, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4014, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5077, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6046, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3410, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7456, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2353, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8295, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2711, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8201, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1616, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7897, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8390, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8596, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0425, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9309, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9433, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2487, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9660, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9741, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9677, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3489, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2954, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9756, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1745, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4646, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1688, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2123, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2180, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2451, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3909, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2644, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8519, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8770, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2921, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.8760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0237, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9627, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0538, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9696, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1913, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9472, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8120, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1866, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4319, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2663, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2142, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9996, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1087, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1390, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1030, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3775, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8552, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9632, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2744, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9612, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1488, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9845, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0452, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2575, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9857, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2192, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9617, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1813, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7088, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0659, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3722, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7785, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7687, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0489, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8201, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1038, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9047, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9469, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9479, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9587, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9838, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0607, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9389, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0657, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9079, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1081, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2732, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9641, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9069, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8718, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1217, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7600, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3549, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5676, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0557, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6949, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3266, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2982, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8854, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1753, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8548, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8586, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1592, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3224, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9013, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9636, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1823, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2722, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9690, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3035, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8508, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7428, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1728, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7157, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7602, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1948, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8022, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1824, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7602, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8033, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2805, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0389, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1485, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9250, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8435, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8234, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2662, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8857, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1556, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5975, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2489, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5714, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5654, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1895, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.6422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2559, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1806, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2567, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2814, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9293, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9168, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8864, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1273, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9119, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9626, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1835, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9187, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1591, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8485, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2928, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9059, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0654, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9155, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2901, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9186, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8674, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3107, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7416, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8253, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8834, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8424, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1271, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9197, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1167, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9456, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9819, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9505, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9755, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9784, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9556, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9005, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7556, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5442, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5677, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1273, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5897, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6988, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8463, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1273, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8503, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8421, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2295, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0391, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9454, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9507, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9087, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1962, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1388, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9459, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3163, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0046, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0043, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1452, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0336, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1992, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9752, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9494, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9143, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8623, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7250, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5086, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2558, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6808, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2257, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8136, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8523, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1968, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9152, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1886, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8573, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0014, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9929, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1862, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9425, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1986, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.9779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1856, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1314, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9190, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2707, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7363, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1138, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8167, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7332, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1394, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7784, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7550, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7404, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1840, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8621, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8437, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1167, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1734, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9445, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1029, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0220, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1831, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0402, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1655, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0010, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1354, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3359, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9576, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0305, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8936, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8618, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7561, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6582, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1129, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8194, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0419, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1240, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9568, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3109, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9641, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9861, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2228, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0234, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2595, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0489, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1805, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0535, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2001, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0776, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1811, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1138, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1353, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1213, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0502, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1258, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1062, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1797, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0607, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0250, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1688, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8794, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8411, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1138, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5003, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1944, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9071, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1304, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0761, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1121, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1031, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1407, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1072, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0313, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1697, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1295, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2771, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1093, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1266, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1656, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0840, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0571, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9182, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2515, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8450, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6190, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4857, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1538, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7424, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1152, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8092, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2430, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9294, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9505, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2113, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0199, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2231, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0880, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1661, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1165, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-4.0999, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1302, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3282, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1210, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1169, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1200, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2496, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0643, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0596, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2402, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1272, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3302, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8501, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6638, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2747, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7908, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1177, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7663, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9120, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0050, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9778, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0172, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0695, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1689, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1197, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0623, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1253, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1324, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1127, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1298, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1714, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2459, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8404, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0659, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8353, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1251, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9067, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2931, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9520, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0558, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9935, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9723, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0255, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1595, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0426, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0262, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3275, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1352, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0295, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1364, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0019, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9622, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9705, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2304, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1523, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8643, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6549, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8283, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1080, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9668, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0608, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1079, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0734, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2260, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1288, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1468, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1472, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2665, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1339, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1127, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1097, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0870, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1526, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1064, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1601, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1041, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0485, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9480, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1696, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8975, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8481, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7869, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2463, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2686, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9368, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0183, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0691, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1012, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1186, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2961, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-4.1591, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1503, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1176, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1602, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1403, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0661, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1052, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0934, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3145, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1835, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1058, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1852, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1105, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2248, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1804, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1331, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1722, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0390, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2104, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1288, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0660, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6275, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0064, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2011, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1216, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2075, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1542, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1775, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1598, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1647, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3274, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2689, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1834, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0849, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1796, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1854, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2019, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1226, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0785, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0059, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9768, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2336, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8390, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8556, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9855, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0054, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0904, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1439, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1435, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2969, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1631, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2746, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1016, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2762, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1671, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8017, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9050, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8784, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0447, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1833, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2760, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0491, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0409, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1307, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0332, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1416, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1874, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0661, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1543, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1369, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1667, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1106, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1692, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1321, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1270, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1483, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0992, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1293, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0371, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8185, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1411, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2052, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0222, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2717, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-4.0792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2317, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2368, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2281, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2443, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2194, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1518, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2053, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2558, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2020, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1489, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1771, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1480, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9827, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1487, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9467, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9640, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0765, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1599, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0881, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1528, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1609, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1654, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2083, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1733, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2133, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2266, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2099, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1484, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1014, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1279, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9239, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7845, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1390, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5994, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1510, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8318, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1229, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1537, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2273, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2016, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2468, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2475, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1455, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2635, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1653, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2652, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0777, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2486, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0734, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2569, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1842, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2395, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2223, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1501, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1755, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2758, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1796, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0502, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1846, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1593, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1088, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6101, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8965, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1011, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1974, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1341, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0736, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1563, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2178, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2089, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2673, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2795, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1345, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2785, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0599, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2633, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2501, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2535, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2363, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1913, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1820, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1677, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0147, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1718, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.8855, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0282, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6517, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5050, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0701, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9749, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1720, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1399, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1334, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2402, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1238, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1814, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2520, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2226, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2682, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2876, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0256, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1965, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1044, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2670, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1325, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2542, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1125, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2618, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2719, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2573, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0402, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2380, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1911, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2099, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1182, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0279, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6765, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0754, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9451, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1059, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1276, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1664, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1774, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1237, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1672, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1336, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0607, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2138, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1947, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2073, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0660, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1443, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1619, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0745, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1301, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1285, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1744, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1184, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1915, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1059, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1604, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1565, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1500, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0643, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1557, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0419, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1138, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1988, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1667, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1837, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1575, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0801, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1962, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1682, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1472, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1873, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1885, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2238, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1111, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1604, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2207, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2120, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1549, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1908, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0647, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1088, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1930, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0802, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0466, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0554, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1569, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2788, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0911, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1488, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2060, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0974, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1434, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1663, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1646, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0524, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-4.1700, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0944, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1020, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1507, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0830, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1841, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1837, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2089, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0579, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2190, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1995, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1475, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1366, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1822, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1803, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1461, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1677, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1685, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1579, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2195, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1593, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2305, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2334, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2123, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2305, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0556, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2444, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2854, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3096, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0259, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3193, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1985, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3261, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0496, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3174, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1238, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3228, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0257, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3186, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3223, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2691, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2383, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1878, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2473, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0929, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2770, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1440, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1106, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0579, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9706, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9828, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1252, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0330, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2072, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2444, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1074, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3244, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3292, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2120, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1547, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3476, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3444, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3553, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1895, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0169, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3584, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3619, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3550, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0995, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3582, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1598, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3324, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3372, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3416, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0592, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2836, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2402, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0400, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1872, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8158, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0496, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7752, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2321, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5695, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1655, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9653, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3066, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1950, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3083, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1606, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-4.3220, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3220, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3220, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3157, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0459, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3296, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1853, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3606, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1334, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3577, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2410, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3513, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3641, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0661, grad_fn=<AddBackward0>)\n",
      "final loss:  -4.371332168579102\n"
     ]
    }
   ],
   "source": [
    "end2end_model = end2end_kernel.train_model_kernel(x_train, y_train, n_epoch = 2000, hidden_layers = [100, 100, 100], learning_rate = 0.006, exp_decay = .999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End2end test MAPE:  0.12442542\n",
      "End2end test RMSE:  0.084976606\n",
      "End2end test NLLK:  -3.991264\n",
      "End2end test CRPS:  tensor(0.0465)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End2end test calibration error when step size is 0.001:  1.3030756025869281\n",
      "End2end test calibration error when step size is 0.01:  0.13028471386946164\n",
      "End2end test calibration error when step size is 0.1:  0.012192400074580745\n"
     ]
    }
   ],
   "source": [
    "mean_pred, var_pred, _ = end2end_model(x_test)\n",
    "mean_pred = mean_pred.detach().numpy()\n",
    "var_pred = var_pred.detach().numpy()\n",
    "sd_pred = np.sqrt(var_pred)\n",
    "\n",
    "print('End2end test MAPE: ', metrics.mape(y_test.detach().numpy(), mean_pred))\n",
    "print('End2end test RMSE: ', metrics.rmse(y_test.detach().numpy(), mean_pred))\n",
    "print('End2end test NLLK: ', metrics.nllk(y_test.detach().numpy(), mean_pred, var_pred))\n",
    "print('End2end test CRPS: ', metrics.CRPSMetric(x = y_test.squeeze(dim = 1), loc = torch.tensor(mean_pred).squeeze(dim = 1), scale = torch.tensor(sd_pred).squeeze(dim = 1)).gaussian_crps().mean())\n",
    "\n",
    "pcdf = metrics.pcdf(mean_pred.squeeze(1), var_pred.squeeze(1), y_test.detach().numpy().squeeze(1))\n",
    "metrics.draw_pcdf(pcdf)\n",
    "print('End2end test calibration error when step size is 0.001: ', metrics.calibration_error(pcdf, step = 0.001))\n",
    "print('End2end test calibration error when step size is 0.01: ', metrics.calibration_error(pcdf, step = 0.01))\n",
    "print('End2end test calibration error when step size is 0.1: ', metrics.calibration_error(pcdf, step = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:00<00:00, 10.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:01<00:00,  7.95it/s]\n",
      " 20%|████████▌                                  | 2/10 [00:00<00:00, 10.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:01<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           0.065\n",
      "  RMSE          0.085\n",
      "  MDAE          0.052\n",
      "  MARPD         11.298\n",
      "  R2            0.894\n",
      "  Correlation   0.946\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.033\n",
      "  Mean-absolute Calibration Error       0.031\n",
      "  Miscalibration Area                   0.031\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.052\n",
      "     Group Size: 0.56 -- Calibration Error: 0.040\n",
      "     Group Size: 1.00 -- Calibration Error: 0.031\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.065\n",
      "     Group Size: 0.56 -- Calibration Error: 0.043\n",
      "     Group Size: 1.00 -- Calibration Error: 0.033\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   0.073\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   -1.077\n",
      "  CRPS                      0.046\n",
      "  Check Score               0.023\n",
      "  Interval Score            0.232\n",
      "{'accuracy': {'mae': 0.06524888, 'rmse': 0.084976606, 'mdae': 0.05174476, 'marpd': 11.298354715108871, 'r2': 0.894096306741409, 'corr': 0.946114305855411}, 'avg_calibration': {'rms_cal': 0.03308407885567196, 'ma_cal': 0.03065965583174, 'miscal_area': 0.030969349324989855}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.41402525, 0.05167228, 0.05309508, 0.04531517, 0.04324223,\n",
      "       0.03983608, 0.0381854 , 0.03623663, 0.03372366, 0.03065966]), 'adv_group_cali_stderr': array([0.06461637, 0.01363123, 0.00856372, 0.00706932, 0.00627311,\n",
      "       0.00381597, 0.00233372, 0.00251918, 0.001244  , 0.        ])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.43208238, 0.06534501, 0.05625156, 0.04876958, 0.046546  ,\n",
      "       0.04288521, 0.04130548, 0.0377923 , 0.03677662, 0.03308408]), 'adv_group_cali_stderr': array([6.08667002e-02, 1.35695936e-02, 7.32036892e-03, 5.00344299e-03,\n",
      "       3.45687499e-03, 3.08587943e-03, 2.91433218e-03, 1.30674352e-03,\n",
      "       1.66594134e-03, 7.31423639e-18])}}, 'sharpness': {'sharp': 0.07318582}, 'scoring_rule': {'nll': -1.0766933990168785, 'crps': 0.04649843293282308, 'check': 0.0234776146942904, 'interval': 0.23195386846454796}}\n"
     ]
    }
   ],
   "source": [
    "print(uct.metrics.get_all_metrics(mean_pred.squeeze(1), sd_pred.squeeze(1), y_test.detach().numpy().squeeze(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lims is None. Setting lims now:\n",
      "min_max_true: (0.06322076, 1.4585207)\n",
      "min_max_pred: (0.16693403, 1.4766705)\n",
      "lims: (0.06322076, 1.4766705)\n",
      "lims_ext: (-0.0781242147088051, 1.6180154800415039)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = y_test.detach().numpy().squeeze(1)\n",
    "\n",
    "uviz.plot_intervals(mean_pred.squeeze(1), sd_pred.squeeze(1), y)\n",
    "uviz.plot_intervals_ordered(mean_pred.squeeze(1), sd_pred.squeeze(1), y)\n",
    "uviz.plot_parity(mean_pred.squeeze(1), y)\n",
    "uviz.plot_calibration(mean_pred.squeeze(1), sd_pred.squeeze(1), y)\n",
    "uviz.plot_sharpness(sd_pred.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
