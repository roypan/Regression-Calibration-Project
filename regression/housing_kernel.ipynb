{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import uncertainty_toolbox as uct\n",
    "import uncertainty_toolbox.metrics as umetrics\n",
    "from uncertainty_toolbox.metrics_calibration import (\n",
    "    get_proportion_lists_vectorized,\n",
    ")\n",
    "import uncertainty_toolbox.viz as uviz\n",
    "from uncertainty_toolbox.recalibration import iso_recal\n",
    "\n",
    "from data import data_preprocess\n",
    "from evaluation import metrics\n",
    "from model import end2end_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = data_preprocess.data_preprocess('housing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss:  751.9530639648438\n",
      "nllk loss:  tensor(747.7012, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(16.4009, grad_fn=<MeanBackward0>) kernel loss: tensor(273.8536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(296.9529, grad_fn=<MeanBackward0>) kernel loss: tensor(33.5707, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(10.6840, grad_fn=<MeanBackward0>) kernel loss: tensor(85.8267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(17.6758, grad_fn=<MeanBackward0>) kernel loss: tensor(121.1766, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(30.6052, grad_fn=<MeanBackward0>) kernel loss: tensor(34.0248, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(12.4866, grad_fn=<MeanBackward0>) kernel loss: tensor(17.8580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(15.0805, grad_fn=<MeanBackward0>) kernel loss: tensor(35.4547, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(7.2753, grad_fn=<MeanBackward0>) kernel loss: tensor(34.4120, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(8.6102, grad_fn=<MeanBackward0>) kernel loss: tensor(89.3060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(9.1017, grad_fn=<MeanBackward0>) kernel loss: tensor(23.3520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(9.3201, grad_fn=<MeanBackward0>) kernel loss: tensor(29.3006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(10.4084, grad_fn=<MeanBackward0>) kernel loss: tensor(19.5123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.5428, grad_fn=<MeanBackward0>) kernel loss: tensor(15.8618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(8.0254, grad_fn=<MeanBackward0>) kernel loss: tensor(22.9327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(7.1236, grad_fn=<MeanBackward0>) kernel loss: tensor(23.0613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.5987, grad_fn=<MeanBackward0>) kernel loss: tensor(7.9607, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.9850, grad_fn=<MeanBackward0>) kernel loss: tensor(8.4256, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.3049, grad_fn=<MeanBackward0>) kernel loss: tensor(4.0182, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.5243, grad_fn=<MeanBackward0>) kernel loss: tensor(5.4841, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.2104, grad_fn=<MeanBackward0>) kernel loss: tensor(6.9945, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.2180, grad_fn=<MeanBackward0>) kernel loss: tensor(8.9599, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.6689, grad_fn=<MeanBackward0>) kernel loss: tensor(6.4464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.7473, grad_fn=<MeanBackward0>) kernel loss: tensor(4.1798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.8943, grad_fn=<MeanBackward0>) kernel loss: tensor(5.3933, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.7566, grad_fn=<MeanBackward0>) kernel loss: tensor(4.7363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.5730, grad_fn=<MeanBackward0>) kernel loss: tensor(7.9763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.9587, grad_fn=<MeanBackward0>) kernel loss: tensor(7.0971, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.5660, grad_fn=<MeanBackward0>) kernel loss: tensor(9.1514, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.3358, grad_fn=<MeanBackward0>) kernel loss: tensor(3.1801, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.6729, grad_fn=<MeanBackward0>) kernel loss: tensor(8.8462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(8.1762, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0390, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.7115, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.0429, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1706, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.5166, grad_fn=<MeanBackward0>) kernel loss: tensor(5.5429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2761, grad_fn=<MeanBackward0>) kernel loss: tensor(3.1535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.6665, grad_fn=<MeanBackward0>) kernel loss: tensor(5.0821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.7025, grad_fn=<MeanBackward0>) kernel loss: tensor(6.1887, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.6917, grad_fn=<MeanBackward0>) kernel loss: tensor(2.6926, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.5030, grad_fn=<MeanBackward0>) kernel loss: tensor(3.3956, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.4321, grad_fn=<MeanBackward0>) kernel loss: tensor(3.6340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.7068, grad_fn=<MeanBackward0>) kernel loss: tensor(2.8815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1335, grad_fn=<MeanBackward0>) kernel loss: tensor(2.5125, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1634, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.8031, grad_fn=<MeanBackward0>) kernel loss: tensor(3.4108, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3101, grad_fn=<MeanBackward0>) kernel loss: tensor(2.2057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.4558, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3129, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.7536, grad_fn=<MeanBackward0>) kernel loss: tensor(3.4044, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3435, grad_fn=<MeanBackward0>) kernel loss: tensor(4.7361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.6180, grad_fn=<MeanBackward0>) kernel loss: tensor(4.0292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.4878, grad_fn=<MeanBackward0>) kernel loss: tensor(2.7634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3210, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.5935, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.5905, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1884, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9754, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3143, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9390, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0880, grad_fn=<MeanBackward0>) kernel loss: tensor(2.4586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3204, grad_fn=<MeanBackward0>) kernel loss: tensor(3.4766, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.5539, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5633, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.5044, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7927, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.5355, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3322, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.8299, grad_fn=<MeanBackward0>) kernel loss: tensor(3.6587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1474, grad_fn=<MeanBackward0>) kernel loss: tensor(4.0445, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3341, grad_fn=<MeanBackward0>) kernel loss: tensor(2.6219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.6266, grad_fn=<MeanBackward0>) kernel loss: tensor(3.1221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3125, grad_fn=<MeanBackward0>) kernel loss: tensor(3.2541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0446, grad_fn=<MeanBackward0>) kernel loss: tensor(3.5239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.0650, grad_fn=<MeanBackward0>) kernel loss: tensor(3.4835, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2793, grad_fn=<MeanBackward0>) kernel loss: tensor(4.4015, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.4604, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5812, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.6558, grad_fn=<MeanBackward0>) kernel loss: tensor(2.7026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2393, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9377, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3225, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3886, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2609, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0597, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7296, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.4040, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1392, grad_fn=<MeanBackward0>) kernel loss: tensor(3.1130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0615, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3484, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0191, grad_fn=<MeanBackward0>) kernel loss: tensor(3.7296, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.7538, grad_fn=<MeanBackward0>) kernel loss: tensor(3.4654, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0179, grad_fn=<MeanBackward0>) kernel loss: tensor(2.9935, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1372, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9849, grad_fn=<MeanBackward0>) kernel loss: tensor(2.7582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2876, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1151, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1045, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0850, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3080, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3436, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5736, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1904, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3972, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.4149, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2647, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4029, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.4028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2008, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5729, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1623, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5435, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0746, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1102, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1933, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2466, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6714, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1491, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0421, grad_fn=<MeanBackward0>) kernel loss: tensor(2.7475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.6313, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2191, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3903, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.0925, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4753, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1070, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0511, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1651, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3356, grad_fn=<MeanBackward0>) kernel loss: tensor(4.2966, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1223, grad_fn=<MeanBackward0>) kernel loss: tensor(2.4464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.4383, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8350, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0025, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3337, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3226, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2978, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4998, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1431, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1508, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2908, grad_fn=<MeanBackward0>) kernel loss: tensor(3.0030, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1880, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0665, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3961, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0012, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1806, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0623, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0845, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1325, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0531, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.6686, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4896, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3819, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0063, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2052, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1750, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1073, grad_fn=<MeanBackward0>) kernel loss: tensor(3.4014, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1765, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1093, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2519, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2485, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3374, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3867, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1657, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2418, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1058, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1284, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1932, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1206, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1214, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2638, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1623, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6740, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0500, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4926, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0903, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0487, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8184, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2861, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7638, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2153, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1322, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3089, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2012, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7373, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1908, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9113, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0232, grad_fn=<MeanBackward0>) kernel loss: tensor(2.6098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2468, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1934, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1039, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1054, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4669, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0097, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3841, grad_fn=<MeanBackward0>) kernel loss: tensor(2.2970, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0453, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0869, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4440, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1200, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1186, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9070, grad_fn=<MeanBackward0>) kernel loss: tensor(3.3978, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9542, grad_fn=<MeanBackward0>) kernel loss: tensor(2.9148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8176, grad_fn=<MeanBackward0>) kernel loss: tensor(3.9145, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7630, grad_fn=<MeanBackward0>) kernel loss: tensor(3.6307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9234, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4911, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8284, grad_fn=<MeanBackward0>) kernel loss: tensor(3.0709, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2758, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2553, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2057, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0784, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4945, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2261, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0962, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1312, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0293, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9619, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9491, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9381, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1071, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1160, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0267, grad_fn=<MeanBackward0>) kernel loss: tensor(2.8515, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0029, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2288, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9853, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6889, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8865, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6337, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8855, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0018, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1507, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0434, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2122, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2331, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7187, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0514, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0275, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0502, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3090, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0664, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8492, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9616, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0415, grad_fn=<MeanBackward0>) kernel loss: tensor(2.4335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1502, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0344, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8620, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1738, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2688, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0495, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0549, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5676, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0022, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6628, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9620, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3738, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0452, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5291, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9893, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0734, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9067, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8883, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9577, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0581, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0187, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9884, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1554, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.0341, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1598, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3384, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0364, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.4231, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8061, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1238, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0754, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1445, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0538, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0663, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6689, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0978, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3458, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0565, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6766, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0281, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1614, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1572, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0359, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1869, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1811, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0511, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9719, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0551, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1907, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1683, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2296, grad_fn=<MeanBackward0>) kernel loss: tensor(5.0149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9974, grad_fn=<MeanBackward0>) kernel loss: tensor(3.4581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1716, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7260, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0978, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2443, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0932, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1809, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1267, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1106, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6059, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2688, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8265, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2097, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6791, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2265, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4656, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3307, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5082, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1909, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5353, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5001, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1925, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1591, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3678, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1655, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1291, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3256, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1563, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0612, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1121, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2633, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0829, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9620, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0534, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3701, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4272, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1936, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0633, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0610, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0177, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1271, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1751, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0861, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7788, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1268, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3122, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2339, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2349, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6574, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1439, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5286, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0837, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2853, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1413, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0460, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1067, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1954, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2133, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2783, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1727, grad_fn=<MeanBackward0>) kernel loss: tensor(2.5119, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5913, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1974, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0492, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0676, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5805, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9953, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1685, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9158, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7305, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1828, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0729, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2570, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1813, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6933, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1698, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8982, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1975, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2909, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0105, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2144, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3445, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0717, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8850, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2563, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2485, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1268, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2096, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8669, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7102, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0715, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7667, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1039, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4694, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1162, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4167, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1701, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1415, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5747, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0679, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0578, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0305, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1091, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7282, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3706, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0798, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0961, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0022, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7427, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.2013, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5882, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2504, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0496, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0536, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0181, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2683, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0496, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5440, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0794, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6283, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9308, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1383, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2813, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1477, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9562, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1209, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4704, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1383, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3869, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1147, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0466, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3169, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0197, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4169, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3017, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0545, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1364, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0296, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0871, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5958, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0413, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9980, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9509, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8028, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1583, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7365, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0611, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0252, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0257, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2687, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5659, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0623, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5435, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1097, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4385, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0699, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0770, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2591, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4380, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4892, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0020, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0692, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4194, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0865, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1775, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2996, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2411, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1449, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5567, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1302, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0220, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0213, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6312, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0061, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9912, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0864, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2280, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1321, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0677, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7285, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1034, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1558, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5040, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4490, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0966, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7591, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0701, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0760, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0291, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4391, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0214, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0069, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8145, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0177, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0412, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3685, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0510, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2980, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0439, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0079, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9867, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2279, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9749, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2478, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7547, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9508, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0194, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0675, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1982, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0265, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2184, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1977, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0354, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1186, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5399, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0418, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0623, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0479, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9918, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9878, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0438, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5510, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0257, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0523, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1296, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0926, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0631, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1035, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5378, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.0478, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5923, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1803, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3081, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1628, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0499, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0450, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0823, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8171, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0756, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0263, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2005, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1522, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9999, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9904, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8956, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0494, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0659, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9505, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0880, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5727, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0125, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2592, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0901, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0399, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1133, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6694, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2801, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4150, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8306, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6557, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0501, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4711, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1331, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3461, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5478, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1178, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1632, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4345, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1164, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1557, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3972, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2339, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0903, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5997, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8878, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0446, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4404, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4364, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1273, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0973, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5413, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0626, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0670, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6233, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0192, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1183, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2478, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1062, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1985, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0708, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7962, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2313, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0870, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2557, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3559, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7303, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0855, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0375, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0788, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6956, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1135, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4200, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1183, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6251, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1006, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1229, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4113, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1176, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3325, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1540, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3588, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1317, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5377, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1646, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5017, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2067, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9156, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6740, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7271, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1555, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7825, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1460, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1854, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3927, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1175, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4096, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0999, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4071, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1306, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3215, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1652, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1705, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1235, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1265, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3879, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1124, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6869, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1301, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5090, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3988, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1547, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1417, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4514, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2548, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0436, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5341, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1257, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6566, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1317, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0685, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2012, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5061, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1557, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1502, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1489, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5358, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0581, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1181, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5589, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1479, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9079, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.1783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1522, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2548, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1041, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1532, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1819, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1208, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0961, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5768, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2189, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5711, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1252, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8199, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5577, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1411, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7963, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1677, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5399, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3803, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1608, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6711, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1458, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1226, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2158, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1295, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1377, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4626, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2211, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4965, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0738, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1341, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1356, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1394, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1666, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0265, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1684, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1939, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1599, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1590, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2337, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2132, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1380, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3244, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1786, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1092, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0808, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5109, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1296, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1139, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3460, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3385, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5837, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2092, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4377, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1480, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3719, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1476, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6227, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1491, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1219, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1427, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1225, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1222, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2336, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1297, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4110, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1270, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1486, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1840, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1814, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1459, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1632, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1520, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2835, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1643, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5963, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1484, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5930, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2222, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1350, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2386, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2661, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1949, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1265, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3495, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1080, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2227, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1199, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5641, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1498, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1582, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1404, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2777, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1442, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6726, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3385, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3413, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1174, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5293, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6597, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.3593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9422, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1585, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1267, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1697, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1503, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3998, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1665, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1569, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1693, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2443, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1563, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1598, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1526, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1644, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1923, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5490, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0973, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9813, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1507, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4208, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.1286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1633, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4814, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2229, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6896, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2280, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1129, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1698, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1691, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1864, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1603, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2410, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1400, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1560, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1217, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1923, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1706, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1801, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4592, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5038, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2268, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1894, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1709, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1949, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3764, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1298, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1585, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3432, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1953, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1350, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2466, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1351, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3694, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1765, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2949, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2090, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1662, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3774, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1502, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2745, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2365, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2547, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3144, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1707, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2810, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1621, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2118, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1784, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1238, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1813, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3368, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1457, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0460, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3868, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1395, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1741, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1419, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2701, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1723, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1652, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3225, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1481, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1854, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1421, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1542, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1272, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0852, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7572, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2079, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4495, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4354, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2325, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1209, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1559, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1563, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2205, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2136, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1864, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1020, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1675, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2371, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3853, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2025, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3079, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1481, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1090, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1289, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1359, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2374, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2066, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3833, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1382, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1683, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1538, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2883, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4167, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2515, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1529, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0631, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1852, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1873, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5631, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5783, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1565, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1523, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1761, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3055, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1896, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2654, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2299, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4350, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2199, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1450, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1809, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1690, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2140, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1951, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2127, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0944, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.1914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1645, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2969, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1951, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5544, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2002, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2928, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5594, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2543, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4550, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1852, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2319, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1507, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1611, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0338, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1581, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3175, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1878, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0416, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1215, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1448, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1565, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1581, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3619, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3119, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1709, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3951, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1224, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0544, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1383, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2782, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1663, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1489, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2896, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1733, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1952, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3097, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2509, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1692, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3152, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1468, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1936, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1809, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2017, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3040, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1705, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2123, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2039, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1638, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2328, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1615, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4656, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2309, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3615, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3139, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3575, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2056, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2231, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3290, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2002, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2101, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2005, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1638, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1983, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1849, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1951, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1880, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1795, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2529, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6917, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2251, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3140, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2140, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0605, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1804, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1741, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2809, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1768, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1795, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2033, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2067, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5139, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2641, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1705, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1663, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1675, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1282, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1695, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1517, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2982, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3328, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1467, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1600, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1771, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1594, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1799, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3288, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2198, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4088, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1971, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0982, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1808, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4093, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2077, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1662, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5661, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2371, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1657, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1604, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2318, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3688, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1751, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1072, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1667, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3035, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2122, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2495, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0216, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1741, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1377, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2883, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1518, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4967, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.2294, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1244, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2126, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2072, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2396, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2356, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1565, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1836, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1424, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1616, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1503, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4156, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1096, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4965, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2915, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1795, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1336, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1186, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0434, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1690, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2184, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1644, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0671, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1483, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4005, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0451, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1834, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2233, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2019, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2788, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1609, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1824, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1862, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1638, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2380, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1017, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3838, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1839, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1738, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1341, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1864, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1107, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1683, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1904, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1701, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1723, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1721, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2837, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1656, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2988, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1569, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2608, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2008, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1701, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2546, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2029, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2092, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1326, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1837, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1900, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1789, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1446, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1390, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1454, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2620, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1577, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2729, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1870, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2016, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0675, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1575, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1772, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2561, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1516, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1795, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3768, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2093, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1867, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2125, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2267, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1761, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0506, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1761, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1829, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0679, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1821, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3461, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1447, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1651, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0454, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1660, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1593, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1492, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4556, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2056, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1064, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1566, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3416, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1551, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1205, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1356, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4302, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1346, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1374, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1558, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1822, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1435, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1628, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1265, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2384, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0522, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2072, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1873, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1493, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2025, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1246, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1454, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0642, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1616, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1372, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1408, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1701, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0916, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2833, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.1433, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2075, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1610, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1823, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1991, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1749, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2120, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2054, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1216, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2641, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1997, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1896, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3678, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2315, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2096, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2128, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2298, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2078, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3900, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2283, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2525, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1999, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3742, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2234, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2111, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1462, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2686, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1805, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1814, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1546, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1894, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1922, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1871, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1698, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2803, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1976, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0601, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1436, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1655, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2378, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1676, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3192, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1635, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4005, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1611, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2886, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1722, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2020, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2003, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1906, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2313, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1659, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1666, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1622, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1719, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0605, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1741, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1581, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1225, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1585, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0332, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0605, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1645, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1349, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1678, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1901, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1506, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1748, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1199, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1160, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1546, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1237, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1643, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1718, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1559, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1190, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1688, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1670, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1600, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2357, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1556, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.2020, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1667, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1389, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1749, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2071, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1874, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2388, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1580, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1633, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1910, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1674, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1607, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1703, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0451, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0589, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1637, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0864, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1433, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3271, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1598, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1828, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1677, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1495, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0377, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1230, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2227, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1559, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1584, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1319, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1433, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1529, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2604, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.1439, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1860, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1338, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0375, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1215, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1257, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2846, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1808, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2115, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1578, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1158, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1831, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2001, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1461, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3093, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1548, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1802, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1520, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1692, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1576, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2050, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1755, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0545, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2443, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1413, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2503, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1505, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1346, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0225, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1256, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1836, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0202, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1733, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1991, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1570, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1707, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1896, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1517, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1519, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1683, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1926, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1936, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1552, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3320, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1706, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1438, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2559, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1494, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3833, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1541, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2495, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1308, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1888, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1590, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1704, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1530, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1315, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1247, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2104, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1283, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1658, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1490, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1174, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1489, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0648, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1561, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0410, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1064, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1676, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1294, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1391, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0616, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1489, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1199, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1586, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1641, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1222, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1521, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1175, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1352, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1203, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1557, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1456, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1434, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1321, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3607, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1265, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1253, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0622, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1415, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2106, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1193, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1216, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1856, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3165, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1056, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1181, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2903, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1384, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1424, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1293, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1182, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0332, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1380, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1702, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1078, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1515, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1472, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1688, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1341, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1142, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1047, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2007, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1280, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1155, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1219, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1156, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1147, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1978, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1175, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4714, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.1719, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0325, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1392, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1234, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1374, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2047, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1101, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1728, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1054, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1652, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1354, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1222, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2336, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0962, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1143, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1378, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0374, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1382, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0709, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1390, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1296, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1137, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0503, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1963, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0840, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2109, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0807, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0936, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1271, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1315, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1380, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0285, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1189, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1370, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2966, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1299, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1736, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1107, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0852, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0732, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0960, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0905, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2383, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1573, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2850, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1186, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0565, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1041, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2216, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1234, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1337, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1094, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2115, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6679, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1205, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1455, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1280, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2631, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1259, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1550, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0867, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0288, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0904, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0998, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0822, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2136, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0976, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0399, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1059, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1078, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1358, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0708, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1224, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1017, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0366, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1077, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1022, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1209, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0480, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1047, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0981, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1551, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0867, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1913, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0637, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0648, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2443, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0913, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1882, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0677, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1428, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0432, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1651, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0621, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1061, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1328, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4041, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0570, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3373, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0503, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1073, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0535, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0412, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0259, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1369, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0252, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2121, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(5.0700, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0558, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0517, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1553, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0672, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1045, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0816, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0496, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0765, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0903, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0456, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0726, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0322, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1787, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0613, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2526, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4980, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0518, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1806, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0770, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2345, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1841, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0617, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0784, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0386, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0288, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1257, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0615, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2852, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0476, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0412, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0660, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0637, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0434, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0428, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1790, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0221, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2504, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0810, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3142, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0337, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2828, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0349, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2956, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0069, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0753, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0138, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1303, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0099, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0438, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0322, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0239, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0171, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0069, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0171, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9966, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0395, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2252, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0600, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0531, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1125, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1304, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.1147, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0331, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0529, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2954, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0270, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1141, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0195, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0266, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0107, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1460, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1603, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0479, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1141, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9947, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9926, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0584, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2962, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0477, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1570, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2088, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0477, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1595, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0228, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3681, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0418, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2089, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0058, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1771, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0167, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1014, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2305, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0167, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2569, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0280, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1797, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2304, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0185, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0336, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0431, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0199, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9981, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2375, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2527, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0679, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0194, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9508, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0584, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9433, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9799, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1240, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9660, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1338, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9834, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3807, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9926, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1916, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0620, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(4.9584, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2092, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9867, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0437, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9705, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9753, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0227, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9799, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9884, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9736, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9546, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0207, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0046, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9503, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9668, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9675, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0192, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9512, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0380, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1478, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9366, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2527, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0069, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3736, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9501, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1231, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9511, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1714, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1407, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0402, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0106, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2602, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0370, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9353, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9073, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1483, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9337, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2133, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9177, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2096, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2012, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1710, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9436, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0887, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(5.0001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9632, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9685, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9621, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9412, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9417, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9480, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9612, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1495, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1930, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0747, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2770, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2819, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2109, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9561, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1328, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9407, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0644, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1762, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9508, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0336, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9022, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1375, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9353, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0878, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9210, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9458, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4998, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3492, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0099, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9508, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1256, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9098, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9223, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9301, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0342, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9263, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1873, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9204, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0354, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1392, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9086, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1167, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8785, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3900, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9016, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1994, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8580, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1879, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1681, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8675, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9284, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2093, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8770, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1199, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8649, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9292, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1522, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2758, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8780, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8631, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2422, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8611, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8545, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8542, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1048, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(4.9296, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9181, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1933, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9139, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9631, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9198, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8975, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0657, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8950, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0501, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8706, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4558, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8857, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2623, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9047, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0435, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9029, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8693, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1687, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8828, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0394, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8684, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1647, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8496, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9270, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8876, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1360, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8640, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0087, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8416, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8290, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1406, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2944, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8619, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0722, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8608, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8697, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2957, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1113, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8560, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8788, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8553, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1437, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8566, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8432, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8557, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1756, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8658, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2503, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8608, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8191, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1856, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8252, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8212, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0273, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8374, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2025, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.9021, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1776, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8541, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8466, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1396, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8291, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8594, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8008, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8010, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8354, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1823, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3028, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8121, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0832, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1737, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3988, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8126, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1312, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8238, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7978, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1953, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3610, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8366, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3214, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8140, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8092, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2055, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2169, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1789, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8060, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0525, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0615, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8091, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8313, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8143, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2257, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7641, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8050, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1603, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2043, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7432, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4169, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1645, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7071, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2771, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7466, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7988, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1998, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7678, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1321, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(4.7524, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1528, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7838, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4231, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8516, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1399, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8102, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1202, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1350, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8123, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1877, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8207, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8379, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5083, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7754, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7703, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7658, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1611, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7566, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7858, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0182, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7857, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7550, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7421, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1122, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.8369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2150, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7738, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7139, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1345, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7089, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2128, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7804, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0294, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1732, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7379, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7374, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7503, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1096, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7371, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1374, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2574, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7341, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0138, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7128, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2719, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7179, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7271, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7590, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1559, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7357, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1865, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7571, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1129, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7855, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1565, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7516, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1569, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7198, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7434, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2270, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2214, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6870, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7034, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7054, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1831, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6874, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1506, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6827, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1813, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7072, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7648, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7478, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7125, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2954, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7267, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1064, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7029, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3918, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6968, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1108, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6609, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6475, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6456, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0109, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6559, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0787, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6548, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4675, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1527, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7180, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1087, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6904, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7253, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6584, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1819, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1421, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6700, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6551, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3466, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7191, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6679, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6489, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6394, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1141, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6493, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0275, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0608, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6379, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6654, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6673, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5768, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7441, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2278, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0786, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6828, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4612, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2829, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2522, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2258, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(4.6813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1838, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6467, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0664, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6548, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1906, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6601, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1785, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6518, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6936, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1194, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6581, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2099, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6864, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1282, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.7070, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6601, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0659, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6456, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0988, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5978, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0518, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6406, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2044, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6276, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6548, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0676, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2368, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6612, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0548, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6417, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3296, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6217, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1911, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0949, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6127, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6068, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1704, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0744, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0775, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0306, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5599, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1826, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5834, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5708, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0082, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0835, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5492, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1726, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5380, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5320, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1694, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1050, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5658, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5976, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3163, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5788, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2240, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5804, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3018, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6396, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6155, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0496, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5754, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5359, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0308, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1294, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6067, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6303, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2693, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6603, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1919, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.6151, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4987, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1137, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1589, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5687, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5659, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5703, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5506, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1421, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5494, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5517, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5365, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3252, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5446, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5445, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5293, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5061, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5252, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5244, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5442, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0728, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5227, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5282, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5566, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5146, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5707, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3702, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2319, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5317, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5203, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1067, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1554, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5221, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5121, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2208, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4923, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3607, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5441, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0406, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5379, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4535, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2018, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1313, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5490, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2553, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5315, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1647, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(4.5082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4802, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4741, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1365, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4738, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1259, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4854, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0492, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4649, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1707, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2970, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4427, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2455, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1719, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5067, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1610, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1764, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5111, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4685, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0604, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4445, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4487, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2901, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4383, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2558, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4374, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3643, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4613, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4676, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2483, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5033, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3055, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4708, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1693, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4905, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0523, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4774, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1055, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1395, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4460, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3199, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4468, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4514, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2469, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4279, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2029, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5505, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4807, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4324, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0326, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4096, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1399, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4293, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4211, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4352, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4228, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2549, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3040, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4492, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2220, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4438, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0633, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2698, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2628, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4448, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0165, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4382, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4266, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4184, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3608, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4180, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4112, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4309, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4317, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2948, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1956, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0246, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3836, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0081, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3807, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3797, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3801, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4097, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0834, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3782, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4774, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2422, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0400, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3991, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3836, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3604, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2568, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3505, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1365, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1556, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3636, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3696, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3734, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3512, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1642, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3532, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3501, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3839, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3530, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2785, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3678, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2170, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3951, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2811, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3551, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2935, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1544, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4127, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2063, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4234, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4306, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3988, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(4.4189, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3885, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1489, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3594, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3473, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3434, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1825, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4003, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3677, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3315, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3552, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3122, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3575, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0375, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3580, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0067, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3392, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0110, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3230, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1928, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3371, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3022, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0641, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2752, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5562, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3646, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3538, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3187, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0444, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3088, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4050, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3513, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3366, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1716, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2828, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2728, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2170, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1653, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.4015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.5073, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3654, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3490, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1806, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3580, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3616, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1902, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3450, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0605, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3556, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3099, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1601, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3441, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2437, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3459, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3307, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0868, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2824, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2715, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3249, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1891, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2805, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2652, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2503, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2572, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2499, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0829, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3138, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3962, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3014, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1202, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2714, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1360, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2323, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2800, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1107, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1967, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1537, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2580, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2638, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3038, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2574, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2598, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3067, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1622, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2900, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2266, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2609, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2646, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2384, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1419, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2363, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2214, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2495, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1936, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2392, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2402, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3473, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2498, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3664, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3310, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2715, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2306, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0298, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2179, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1322, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2491, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2129, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3336, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2017, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1259, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2840, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2438, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2733, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2399, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2215, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2504, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2210, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(4.2519, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4288, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2293, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4099, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2808, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2012, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2194, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2183, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2988, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2097, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3165, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2070, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2526, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1084, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2282, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2027, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1333, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1435, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1820, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1321, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1568, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4665, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.3303, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2510, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0275, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2570, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1591, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1462, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0980, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1446, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1314, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1685, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1607, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0342, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1481, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3147, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1014, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5695, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2563, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1677, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1504, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1519, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1174, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1473, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0461, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1205, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2923, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1590, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1260, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0458, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4958, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1267, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1036, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1259, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1565, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1710, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1229, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1229, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1021, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1488, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1033, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2270, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1200, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1255, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1390, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1934, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1113, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0814, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0589, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4614, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1110, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0982, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1009, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2579, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0878, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2546, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0646, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1679, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0425, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2651, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0639, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0681, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1144, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1035, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0819, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2661, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1289, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5214, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0718, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0686, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0448, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4043, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0906, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0814, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0751, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(4.0725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0492, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0973, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2291, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0699, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2425, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0773, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1110, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5758, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0507, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0378, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0285, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2052, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0684, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0446, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2339, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.1003, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0549, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1430, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0500, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1737, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0614, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0048, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9835, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9643, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1336, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3140, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0159, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2107, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0611, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3995, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0167, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1259, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2041, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0283, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1556, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0635, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1265, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0594, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0803, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0409, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1500, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1881, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0502, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3341, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9991, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5237, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0186, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0294, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0312, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0307, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0180, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0626, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9966, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0966, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9696, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2133, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1266, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0615, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9594, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2305, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9683, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9578, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9328, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9431, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1939, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9448, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4305, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9497, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9557, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0631, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9570, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9496, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0323, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9410, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9448, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9284, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9324, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2283, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9378, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4985, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9299, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1786, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9695, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9412, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9667, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9427, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9574, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2348, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9379, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1919, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9315, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5177, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9753, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3272, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9429, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0612, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5275, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9672, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9283, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1647, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9092, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2265, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9658, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9365, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2017, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9228, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0605, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8983, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3033, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9220, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3867, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.9074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1615, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9021, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2386, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8770, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8936, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1238, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8747, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8900, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1953, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2696, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8999, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2174, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9039, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0404, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8862, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9346, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9279, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9139, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3396, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9521, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9317, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9522, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9546, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9469, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3873, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.0075, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9648, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0564, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1110, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9528, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9426, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0394, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9425, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9238, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0220, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9026, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8598, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1102, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8809, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9009, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9072, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8672, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8529, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3652, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8468, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3135, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8204, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8919, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8529, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8407, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8413, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1321, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3339, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8543, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2270, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8180, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8354, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8271, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2458, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9216, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1274, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8696, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3210, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9589, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2160, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8751, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1177, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8583, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8441, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3260, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8332, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0664, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8201, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8146, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1083, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3922, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8077, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3337, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8469, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1334, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8196, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0599, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8295, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8307, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0607, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8318, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2101, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8381, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8249, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1088, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4225, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.9137, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8296, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8275, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7906, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3917, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8018, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0119, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7805, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8353, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0537, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2978, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8092, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8159, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3312, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7950, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2800, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.8249, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2638, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1184, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7800, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1093, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7782, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4106, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7741, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1787, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2072, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7627, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1993, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7573, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7640, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2808, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8012, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7542, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1352, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7547, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7502, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7640, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7741, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7510, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1385, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7492, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7336, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7234, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7222, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3594, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1323, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0128, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7155, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0266, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7052, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0720, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7088, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0545, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7013, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7046, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0038, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6780, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3989, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6854, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4018, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7075, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1422, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7006, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1175, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7089, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7339, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7068, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1192, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1616, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7449, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7094, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7257, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2760, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6896, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2731, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6828, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6930, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2108, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6573, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2132, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6611, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3810, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6968, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1505, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6862, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0545, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0564, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0200, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0500, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3881, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1945, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7844, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5575, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.8205, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1163, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7274, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7130, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1805, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6994, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6901, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6801, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2265, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7112, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2080, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3697, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4891, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7223, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1274, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7034, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2500, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7078, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0332, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.6916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6824, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1874, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7185, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2813, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7010, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5659, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5942, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7435, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6853, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6911, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3226, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7086, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1102, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6904, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1667, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6805, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6664, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2506, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6878, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6691, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6617, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6537, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2548, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6685, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6697, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6626, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1760, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6407, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6322, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1458, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6466, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6390, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1917, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6529, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5722, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6564, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6520, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1364, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6102, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2052, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6137, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6269, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6146, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1202, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6098, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6054, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1544, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6175, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6180, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6075, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3285, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6016, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1147, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6102, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6269, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0733, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1326, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6062, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0306, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6179, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5853, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1141, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6097, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0434, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6119, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6417, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6270, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1702, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6186, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1922, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6107, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1743, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6137, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6115, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0274, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6078, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2391, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6138, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6014, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3747, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6050, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5991, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5951, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5968, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6224, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1969, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6102, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4029, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6058, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5950, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5748, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5622, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5577, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0437, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5493, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5617, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0831, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1964, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6035, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2150, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.7286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6395, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0614, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2648, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.6026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3278, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5611, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0437, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5484, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5502, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0664, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5471, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0391, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4122, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1123, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.5633, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5537, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1235, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5458, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5556, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5499, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5497, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5445, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0480, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5492, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5538, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5547, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0687, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5444, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0566, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5374, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1644, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5290, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5213, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5140, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5309, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1481, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5211, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5178, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5208, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3452, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5685, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3716, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5538, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5400, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0390, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5324, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1538, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5333, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1917, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5222, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1687, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5294, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5296, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5320, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5189, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5113, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5168, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3891, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5204, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0044, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5190, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5158, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2461, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5214, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2745, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4137, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5058, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5906, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5691, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5208, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5176, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2845, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0333, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5036, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1487, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0915, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4626, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0388, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0938, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3870, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4966, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1421, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4509, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4423, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4481, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4704, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2244, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1400, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4513, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4480, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4635, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4498, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0350, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4393, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2920, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1901, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4531, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0373, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4446, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2490, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0231, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4307, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4441, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1264, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4533, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1330, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4440, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3836, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5652, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4478, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4313, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4250, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3011, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4294, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2310, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0598, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4436, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4505, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2259, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1989, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4473, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3079, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4425, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2565, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4404, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1061, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4289, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3374, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4388, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0982, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1626, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4332, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1974, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0590, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.4149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1920, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4449, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4439, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4252, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4718, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1523, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3678, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4413, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2133, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5839, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2074, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5211, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3862, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5036, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1353, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2289, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.5030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0883, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4780, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0158, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4693, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2740, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4118, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4514, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4548, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0084, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4418, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2001, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2216, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4472, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4294, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4185, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1214, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4065, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4631, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4087, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4450, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4469, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4514, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3931, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4102, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0841, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4126, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2758, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4000, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4148, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3905, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4156, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4297, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4155, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0305, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2657, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4013, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1800, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3747, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4066, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4212, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3838, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4111, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4065, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1854, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0660, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3845, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3896, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1439, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2896, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2922, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1088, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3640, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1140, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3558, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3565, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3533, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1681, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3543, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1072, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3432, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3417, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3363, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3033, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3613, grad_fn=<MeanBackward0>) kernel loss: tensor(6.9857e-05, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3399, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3394, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0226, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3448, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3322, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3303, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2616, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3633, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3386, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2698, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3185, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1740, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3359, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1790, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3295, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3860, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3208, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4284, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1294, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3331, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4108, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3960, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3953, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3498, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3449, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3524, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2109, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2215, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3428, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0458, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3429, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3435, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3740, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.3798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3706, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0626, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3589, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1766, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3409, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4714, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3424, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2526, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3738, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3989, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1892, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3701, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3751, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1623, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.4816, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3935, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0466, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1810, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3801, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3810, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3719, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1874, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2995, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3563, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2391, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5705, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3656, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3665, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3456, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2983, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3692, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2510, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3537, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3286, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3487, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3465, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3388, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6430, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3965, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3533, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2928, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5834, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3328, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3256, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1545, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3364, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3349, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3262, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3231, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3199, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2508, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3511, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0082, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3247, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0350, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0383, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3216, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3971, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1479, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3590, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3680, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2991, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0483, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2874, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3865, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2897, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1111, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1968, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1575, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5970, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3402, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3580, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1322, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0377, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2947, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1959, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2855, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3466, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2250, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3073, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0496, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2744, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2684, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2696, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2882, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2080, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2805, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2662, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2664, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2637, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5233, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2755, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2651, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1699, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2684, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2618, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1283, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1633, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2600, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2494, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2455, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4338, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2706, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2726, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2434, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3537, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.2974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1288, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2683, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2558, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0311, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2445, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0809, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2507, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2271, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2474, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0380, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2552, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0147, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2484, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4108, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2450, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1030, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2521, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2424, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1602, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2402, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6443, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2627, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2637, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0791, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2400, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2350, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1993, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2301, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2141, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2155, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2143, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1783, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0888, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2366, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2262, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1764, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2262, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2326, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2286, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1907, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2217, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5111, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2673, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2400, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2354, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2842, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2312, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4487, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.3354, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0602, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2655, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2040, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2307, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1011, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2260, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1508, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2271, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2469, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0866, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2185, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2071, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2372, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2215, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0005, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2178, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2281, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4593, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0637, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2027, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1156, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1973, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4099, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2075, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2064, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2208, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0616, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2039, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2061, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0240, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2018, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3140, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2228, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1792, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2140, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2146, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3808, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2198, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1738, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2051, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1996, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2901, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1991, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2948, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2427, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3569, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2243, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1372, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2151, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1093, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4045, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2421, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2308, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2205, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0932, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2201, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2184, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1391, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3707, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1463, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1982, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2574, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1900, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1981, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3853, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2106, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1079, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2018, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1695, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0842, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1806, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4567, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1835, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1808, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2174, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1707, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1655, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.1912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2570, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2030, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1778, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1756, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2661, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0386, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1824, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2005, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2187, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0959, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1881, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1906, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1919, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1980, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1603, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1884, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3694, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1909, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1561, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1915, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2130, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4784, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0416, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2180, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3853, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1140, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2080, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3018, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2255, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2033, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1202, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0029, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2088, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1906, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4980, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0370, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2955, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2018, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1372, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1846, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1897, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0392, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1883, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2121, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2330, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2009, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1588, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3830, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1333, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1778, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1983, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1643, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2314, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2101, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2008, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1905, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1894, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1808, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0333, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1682, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1248, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1747, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2968, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1734, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1714, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1627, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2284, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1530, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2744, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1499, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1641, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1423, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1616, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3754, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4090, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.2191, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1869, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0411, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1676, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0930, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1583, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1689, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1560, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1546, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3041, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1455, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2481, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1423, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1913, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1322, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1378, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1318, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0408, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1394, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1202, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1265, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3635, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1307, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1290, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1226, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1230, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0052, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.1189, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1178, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1040, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1083, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1323, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1187, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1452, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1226, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1194, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1209, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1195, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1313, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1150, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1270, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1107, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1186, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1483, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1219, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1022, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1016, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1313, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1260, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1562, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1227, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1089, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1067, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0926, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0983, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1156, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6341, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1666, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4399, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1274, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2011, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1119, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1842, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0101, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3569, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1301, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0500, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1193, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2177, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1503, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3461, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1176, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0139, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1696, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3671, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1255, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1174, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1487, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1187, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1141, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1098, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1139, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1660, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1048, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1269, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1162, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2440, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1179, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0312, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1255, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2186, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1380, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2643, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1239, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2445, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1164, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1174, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1162, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2400, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1164, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1648, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0900, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1019, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2044, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0975, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0952, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0994, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1027, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0523, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0200, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1843, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0106, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2043, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2508, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0923, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0960, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0965, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4799, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0973, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0907, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6830, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1060, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2220, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1051, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1430, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2693, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1080, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1378, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2690, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1048, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2187, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3348, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3806, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0553, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0874, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3758, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0941, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0130, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.0936, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0862, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0864, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2091, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1119, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1478, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1359, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3830, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1201, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1522, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1113, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1060, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0228, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1014, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1469, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1165, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0652, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3478, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1046, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1749, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0995, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0873, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0976, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0553, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1408, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1013, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0989, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0678, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1214, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0989, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0404, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1090, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0915, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0444, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1319, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0826, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1576, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0910, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0828, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0787, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0547, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0716, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0722, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0770, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1737, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0738, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2113, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0651, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1814, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0752, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1311, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1690, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0824, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2298, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0785, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2766, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0650, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0810, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0708, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0687, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0774, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4811, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0768, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2514, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0824, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0814, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1656, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0699, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2052, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0659, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0679, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1696, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1715, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0694, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0693, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2593, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0718, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0807, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0664, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0295, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0822, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0380, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0780, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1093, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0905, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1199, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3279, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1087, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0808, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1505, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0715, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0684, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3268, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0753, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0081, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0656, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0697, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1950, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0686, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0672, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2090, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0748, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2419, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0698, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0774, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2637, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0194, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2327, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.0741, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1010, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0847, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3160, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1028, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0930, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0821, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2321, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0837, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0889, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1093, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0873, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2623, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0174, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0802, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0861, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0852, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0653, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0608, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2992, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0718, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0797, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1334, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0603, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0564, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0823, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2435, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0704, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0917, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1455, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0755, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0749, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0683, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6002, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0679, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2304, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1373, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0664, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3667, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0541, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4030, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0524, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1290, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0505, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0533, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0643, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3551, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0653, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0601, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3378, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0622, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1243, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0597, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1731, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0576, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0692, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0562, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0574, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0601, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1732, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0561, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3373, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0411, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0596, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2655, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0564, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0741, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0658, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0559, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1402, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0691, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0608, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0566, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0566, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3774, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1992, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1004, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0796, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0681, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4454, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0631, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0647, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2119, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0701, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1083, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0673, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0616, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1489, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0175, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0564, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1502, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0594, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0569, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1461, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0476, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0567, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0479, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0481, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0683, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1182, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0594, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1661, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0556, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0557, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1843, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0597, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1665, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0285, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0584, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0586, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6961, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0697, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0865, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0607, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1147, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0631, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0594, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1450, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3983, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0623, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2279, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.0644, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1216, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0577, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0604, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0578, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2830, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0552, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0565, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1264, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0537, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1685, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0493, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2308, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0484, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3614, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0563, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0448, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0394, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0955, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0386, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0319, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0363, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4040, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0400, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0318, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0431, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1911, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0359, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0458, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2787, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0656, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0558, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2888, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0668, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1473, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0532, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0328, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0567, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0568, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4097, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1729, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0552, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0479, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0519, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0507, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2019, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0532, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0643, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0614, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0565, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0608, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2938, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0597, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2553, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0535, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3345, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0527, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0462, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0843, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0372, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1298, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0321, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0289, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1522, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0108, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0332, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0303, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0517, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0456, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0135, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0170, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0954, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0222, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0210, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0166, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0206, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2637, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0384, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0147, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0160, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0502, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0705, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0115, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1935, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0101, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0159, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0126, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0129, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0091, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2589, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2960, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0141, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2141, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0121, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0998, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0136, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1548, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5755, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0380, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1248, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0250, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0207, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3771, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0206, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1373, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0217, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0121, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1104, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0094, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0121, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0096, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0008, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9966, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0845, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2478, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9976, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3551, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9999, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3064, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0806, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0027, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3113, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0061, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2353, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0053, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0612, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0006, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9981, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1508, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9995, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1222, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9980, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1828, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.0037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3235, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0067, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3128, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0046, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6559, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0281, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0243, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3576, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0252, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0227, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0224, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0190, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0213, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0247, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2082, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0256, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0200, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0178, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0138, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0545, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2279, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1384, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0160, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2734, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0195, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1937, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0195, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0077, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0166, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2411, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0087, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0094, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0097, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0054, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1459, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0138, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0565, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0100, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0255, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0244, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1092, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0525, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0203, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1706, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0243, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2091, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1830, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0090, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0620, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0108, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1999, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0090, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4808, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1451, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0245, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0213, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0183, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1642, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0298, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0220, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0182, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0958, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0177, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0136, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0151, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0070, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0048, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1930, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3093, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0065, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3837, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0106, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0090, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0101, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2953, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0022, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1756, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0038, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1370, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1102, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0157, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0131, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0075, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5518, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0108, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2108, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0083, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0078, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0073, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0035, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1597, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0059, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4122, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0145, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9999, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9989, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0060, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1931, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0644, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9995, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1688, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0689, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0697, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2289, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0041, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0310, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2504, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3020, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0528, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0080, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0005, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1963, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0029, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1783, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0016, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1076, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.0056, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0077, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0029, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0332, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0036, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9994, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3831, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0059, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1064, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9962, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9977, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9968, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2745, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0021, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0226, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9954, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9962, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0012, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9936, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2386, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9983, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2033, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9908, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4237, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9894, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0069, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1001, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9930, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9906, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1428, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9858, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3343, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1744, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9905, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1593, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9861, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9858, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1993, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3179, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0018, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1531, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0012, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2018, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2371, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9880, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0995, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9904, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9880, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2701, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9861, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2847, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9878, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9857, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3707, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0978, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9780, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9838, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9846, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9839, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1983, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9926, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1025, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9784, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0966, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1732, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9873, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9894, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5606, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0086, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2656, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0052, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9909, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0626, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9995, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1458, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9988, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1760, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9908, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0543, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1892, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0971, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9923, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0518, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3109, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1663, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2035, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1479, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9950, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3722, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1698, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9831, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0180, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9826, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9821, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9804, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1722, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(3.0005, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9954, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3133, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3943, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0651, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0097, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9977, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4483, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0133, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3383, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0010, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3246, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1350, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9909, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2016, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9891, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9870, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9835, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9864, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2572, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1785, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2656, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0283, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9910, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9855, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9828, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9821, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2105, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9834, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0579, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2150, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9840, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5518, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9838, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0503, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9853, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1787, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9874, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3216, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9814, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1074, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0389, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1005, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1503, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9831, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2908, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9824, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0481, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0260, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9780, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0447, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9759, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1685, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9710, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0601, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9788, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2812, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9707, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0588, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9699, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.0001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2556, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9826, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2348, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9829, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0755, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9831, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9857, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9804, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2469, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9831, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2332, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2245, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9835, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2043, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9756, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2389, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2413, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9734, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1246, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9654, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0606, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9658, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1394, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9656, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9646, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1709, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9644, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9625, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9617, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2972, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9601, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3629, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9631, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1742, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9649, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0937, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.9607, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3612, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9622, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1408, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9668, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9636, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9645, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4492, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9604, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4210, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9678, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0140, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9648, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1458, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9678, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0886, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9678, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9603, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1853, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9609, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9644, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9600, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9707, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9573, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1028, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5505, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9551, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9618, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9514, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9543, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1479, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9500, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2383, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9469, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4380, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9508, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9473, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9574, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9577, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1525, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9617, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1612, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9585, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9580, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1019, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1192, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1676, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0496, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9546, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1163, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9527, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9519, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2025, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9514, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1945, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9527, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9512, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0107, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9504, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9496, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0378, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9438, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9500, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9526, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3974, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9543, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7050, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9494, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9502, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9487, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9462, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9444, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9402, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9419, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9449, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1215, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0629, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9433, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9403, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9395, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1210, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9391, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9371, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2279, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9365, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5525, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9399, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1385, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9401, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0557, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0698, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0877, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9306, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2872, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9378, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3404, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1396, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4566, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9462, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9418, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0043, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0576, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9349, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2452, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9352, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1088, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9339, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9319, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9305, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9616, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9587, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9452, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1156, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9429, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9348, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9389, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9308, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3432, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2805, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.9306, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4136, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9338, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1365, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9333, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0853, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1727, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0360, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9331, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9333, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0337, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9321, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1932, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9336, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3872, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9346, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4074, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9341, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0296, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9352, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9322, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9431, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9381, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1864, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0303, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9339, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0568, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1831, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9348, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1745, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9349, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4790, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9359, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0681, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1278, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6558, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9392, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0225, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9382, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9378, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1809, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9394, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9410, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9386, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1868, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1235, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9383, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9368, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9373, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9366, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9356, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0485, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9353, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0504, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0083, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9312, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0184, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9331, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9323, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9305, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9308, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3696, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1442, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1825, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1138, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9328, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1954, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9337, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9351, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1538, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9349, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1812, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9328, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1312, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9320, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9313, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9402, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9370, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2101, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9425, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9339, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2137, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9322, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1548, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1836, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9285, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2142, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9299, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2595, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9350, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9435, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9406, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2895, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9386, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9332, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9351, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9354, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0483, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9306, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9284, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9291, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1732, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9279, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9274, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9275, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1969, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3569, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0615, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9329, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0488, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.9264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0365, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9243, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4007, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9255, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1764, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9237, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9223, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1653, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9379, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2450, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9328, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3296, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1359, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9558, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9479, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0909, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9458, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9432, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1631, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9419, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9363, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1642, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4238, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9412, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4215, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9388, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3545, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0167, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9298, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1224, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3167, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9297, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0311, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9303, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2089, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2025, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9332, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9319, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9312, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9280, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9261, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9221, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0439, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9187, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4959, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9313, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1394, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9195, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1622, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2483, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9234, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2268, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9209, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9249, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0186, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9226, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0200, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9212, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0928, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9212, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9198, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1800, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9184, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0743, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9192, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9183, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9177, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9195, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9192, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9187, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9148, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9139, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9222, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9239, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1035, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9260, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3869, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9204, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0592, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9197, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1285, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9203, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2378, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9255, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9235, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9253, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9224, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3233, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9180, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1031, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9177, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0667, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9160, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1864, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9169, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0106, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1960, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9158, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1058, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9157, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0550, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9157, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2136, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9158, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9146, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9152, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9127, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9116, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9124, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1878, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9148, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1421, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9109, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1454, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9106, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2187, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9169, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6531, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9178, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2608, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9180, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9191, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9137, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9127, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9158, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1556, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0319, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0718, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.9178, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9157, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2502, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9136, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3679, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4549, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9158, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2339, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9147, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2251, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9152, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9132, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1749, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1950, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9139, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0626, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0040, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9108, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9094, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2339, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9124, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0461, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1177, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9078, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1666, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9038, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9038, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3888, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9020, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0922, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0840, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9010, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3444, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9035, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3274, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9008, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0389, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8988, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8981, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1785, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2690, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2101, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8949, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8975, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1615, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8975, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8975, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1110, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8982, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2762, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8976, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8977, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3160, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1652, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8978, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0664, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1506, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8981, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1099, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8980, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8965, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8976, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2722, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8962, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8950, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8949, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0165, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8962, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2957, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8962, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8961, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3174, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8947, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2675, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2386, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0217, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8943, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1740, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1956, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2096, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0737, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1812, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2072, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1654, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1224, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8926, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3238, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1408, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0526, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0926, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4174, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1522, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8908, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3478, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8930, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3321, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8908, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1937, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.8927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0220, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4370, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1097, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8915, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1720, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9008, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9010, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1799, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8983, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2466, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2142, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2602, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1687, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8907, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1749, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8905, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0606, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8892, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8882, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3803, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8949, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4320, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8880, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1971, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2368, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1983, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2283, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1866, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1760, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1553, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0567, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5588, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0136, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8965, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1014, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0428, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1799, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8950, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8936, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1017, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8929, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8973, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8938, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0147, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9002, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3380, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3698, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3257, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9199, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4140, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9059, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1845, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4266, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0714, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1612, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8955, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3016, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8954, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0075, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3823, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8932, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8915, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0645, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8900, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8909, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2743, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8910, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5256, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0291, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8977, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8988, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0479, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8994, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0792, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3696, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0966, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8968, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2020, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8971, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2546, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2674, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2678, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9013, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9003, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1856, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9018, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8994, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0357, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8982, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2132, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8994, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9035, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2270, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0999, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8982, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2216, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.8997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0428, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0369, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8954, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0554, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8940, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8930, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1028, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0093, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8907, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0338, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8897, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2487, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2121, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2238, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8960, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1289, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2865, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8951, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8980, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8951, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2642, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8950, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1682, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8936, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8923, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8911, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1290, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8896, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8884, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8885, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2562, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1944, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8893, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0892, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2437, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0704, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8954, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0404, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1903, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1939, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1762, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8929, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1170, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8930, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2682, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0908, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3637, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3677, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3977, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8908, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1118, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8903, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2743, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8909, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2675, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1685, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8911, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2245, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1768, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1466, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8929, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3900, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1235, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1251, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1338, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0428, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8878, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0400, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1870, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8873, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2715, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1977, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8867, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5802, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8908, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3319, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8952, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8935, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9052, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3901, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9137, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9092, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9055, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9019, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1011, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9026, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9005, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0718, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9000, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8984, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1252, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8966, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0092, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.8943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0067, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8954, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8965, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1787, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0087, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8968, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0706, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8988, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3330, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0071, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8996, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0828, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8968, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8980, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0606, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8971, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2238, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0805, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8966, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8982, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8950, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2279, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8949, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0142, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8928, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0779, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9009, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8978, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9009, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9019, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9006, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0422, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.9023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8994, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1128, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0789, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8980, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8965, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0992, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1250, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8902, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0268, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8871, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8867, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8881, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8870, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1075, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8858, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8858, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2268, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2842, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3862, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6017, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8862, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2288, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8874, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8871, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0971, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0210, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8855, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0907, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1007, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8843, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0971, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8854, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2373, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8852, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1918, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8873, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8841, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6359, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8881, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1227, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0716, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8897, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2660, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8870, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3942, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1747, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2310, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8882, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8873, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8869, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8858, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1819, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8854, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2565, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8871, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1391, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8884, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8881, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8880, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3434, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0746, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8881, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2454, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.8876, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1273, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1987, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0987, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8871, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2514, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8876, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1615, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8894, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8905, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8885, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3293, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1481, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8871, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5210, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3402, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8900, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1348, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1746, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8996, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1136, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8929, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3662, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2220, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8952, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2454, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0354, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2072, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1231, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8876, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8897, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0331, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8911, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8896, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0432, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2939, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0550, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8873, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8867, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8852, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0536, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8847, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0611, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2979, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8840, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8850, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2677, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8836, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1368, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2485, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8829, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2325, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8814, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1576, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8810, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3319, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1891, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1626, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8819, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8795, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8800, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1971, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8795, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2313, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8797, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1200, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0742, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8801, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1956, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2736, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1286, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8765, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2270, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8770, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0796, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1490, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2554, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8778, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0205, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8761, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8754, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5129, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8768, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1777, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0643, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1175, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8747, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1989, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0111, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2629, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8719, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0235, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8718, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8720, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5025, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8719, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1113, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8721, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1196, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4045, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0228, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8753, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0305, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.8744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1846, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1787, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8741, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0808, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0948, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0822, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1407, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0428, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8765, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3498, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1040, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8774, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1254, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8801, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8796, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0803, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1766, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8785, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0339, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0266, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8756, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1158, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7869, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0334, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3626, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8776, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1937, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8778, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2246, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0652, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3311, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8776, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1557, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8770, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0257, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8747, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0629, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8755, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1501, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8761, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8747, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1175, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2515, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1158, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8761, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2330, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1226, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2038, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8751, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2935, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8751, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1350, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8735, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0481, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8731, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1252, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8722, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1962, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8721, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0953, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3835, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3322, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8747, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2977, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8756, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1002, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1488, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1784, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8731, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0105, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2308, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0597, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1306, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1967, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8728, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8722, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2227, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8733, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8723, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1895, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1419, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2275, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4608, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8742, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2570, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0428, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.8731, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2595, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8732, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8722, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8734, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8736, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1291, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2788, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8753, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0152, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8752, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1288, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2228, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0980, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4660, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8796, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8765, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1778, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8796, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3895, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3644, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8799, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0099, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8780, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1927, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8827, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8809, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8794, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8807, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8785, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2215, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8796, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8810, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1620, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8797, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3502, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8782, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1028, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1729, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2167, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3754, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2620, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8862, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8823, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2451, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8798, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2113, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0951, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8774, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0824, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8774, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2972, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1004, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8734, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1147, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8715, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3243, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0997, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1222, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8718, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1117, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1733, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8720, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8715, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1577, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8714, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3877, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4295, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8711, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8706, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1003, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8706, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8705, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8704, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2760, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8716, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8703, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0688, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8721, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2466, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1705, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8722, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1244, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8723, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1108, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1265, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8733, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6652, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8749, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8723, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8716, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3237, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4554, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8731, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2619, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8731, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4061, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8771, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2786, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1289, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(2.8783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4878, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8770, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0961, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2475, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1050, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8753, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1886, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8752, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8747, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0342, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8745, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8736, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0271, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0279, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0821, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8723, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2268, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8712, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8704, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2268, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0026, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8683, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0645, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1410, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8657, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2909, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0935, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8667, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4129, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8673, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0933, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8666, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1432, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2934, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8672, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0228, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8670, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8670, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1274, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.8670, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1617, grad_fn=<AddBackward0>)\n",
      "final loss:  2.866966724395752\n"
     ]
    }
   ],
   "source": [
    "end2end_model = end2end_kernel.train_model_kernel(x_train, y_train, n_epoch = 5000, hidden_layers = [30, 30, 30], learning_rate = 0.02, exp_decay = .999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End2end test MAPE:  0.13078105\n",
      "End2end test RMSE:  4.513759\n",
      "End2end test NLLK:  4.0757017\n",
      "End2end test CRPS:  tensor(2.1840)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End2end test calibration error when step size is 0.001:  1.9970925925925933\n",
      "End2end test calibration error when step size is 0.01:  0.20105442176870755\n",
      "End2end test calibration error when step size is 0.1:  0.021227009322247435\n"
     ]
    }
   ],
   "source": [
    "mean_pred, var_pred, _ = end2end_model(x_test)\n",
    "mean_pred = mean_pred.detach().numpy()\n",
    "var_pred = var_pred.detach().numpy()\n",
    "sd_pred = np.sqrt(var_pred)\n",
    "\n",
    "print('End2end test MAPE: ', metrics.mape(y_test.detach().numpy(), mean_pred))\n",
    "print('End2end test RMSE: ', metrics.rmse(y_test.detach().numpy(), mean_pred))\n",
    "print('End2end test NLLK: ', metrics.nllk(y_test.detach().numpy(), mean_pred, var_pred))\n",
    "print('End2end test CRPS: ', metrics.CRPSMetric(x = y_test.squeeze(dim = 1), loc = torch.tensor(mean_pred).squeeze(dim = 1), scale = torch.tensor(sd_pred).squeeze(dim = 1)).gaussian_crps().mean())\n",
    "\n",
    "pcdf = metrics.pcdf(mean_pred.squeeze(1), var_pred.squeeze(1), y_test.detach().numpy().squeeze(1))\n",
    "metrics.draw_pcdf(pcdf)\n",
    "print('End2end test calibration error when step size is 0.001: ', metrics.calibration_error(pcdf, step = 0.001))\n",
    "print('End2end test calibration error when step size is 0.01: ', metrics.calibration_error(pcdf, step = 0.01))\n",
    "print('End2end test calibration error when step size is 0.1: ', metrics.calibration_error(pcdf, step = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:00<00:00, 11.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 11.37it/s]\n",
      " 20%|████████▌                                  | 2/10 [00:00<00:00, 11.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 11.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           2.880\n",
      "  RMSE          4.514\n",
      "  MDAE          1.797\n",
      "  MARPD         13.243\n",
      "  R2            0.779\n",
      "  Correlation   0.887\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.050\n",
      "  Mean-absolute Calibration Error       0.040\n",
      "  Miscalibration Area                   0.040\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.151\n",
      "     Group Size: 0.56 -- Calibration Error: 0.075\n",
      "     Group Size: 1.00 -- Calibration Error: 0.040\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.191\n",
      "     Group Size: 0.56 -- Calibration Error: 0.085\n",
      "     Group Size: 1.00 -- Calibration Error: 0.050\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   2.921\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   2.957\n",
      "  CRPS                      2.184\n",
      "  Check Score               1.102\n",
      "  Interval Score            12.701\n",
      "{'accuracy': {'mae': 2.880309, 'rmse': 4.513759, 'mdae': 1.7965856, 'marpd': 13.243435323238373, 'r2': 0.7789720127285789, 'corr': 0.8871032565316469}, 'avg_calibration': {'rms_cal': 0.0499220629898721, 'ma_cal': 0.039617604617604635, 'miscal_area': 0.03994423689494703}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.40764646, 0.15092713, 0.11808658, 0.0932684 , 0.08419823,\n",
      "       0.07537302, 0.05835281, 0.05787642, 0.04863681, 0.0396176 ]), 'adv_group_cali_stderr': array([4.71804956e-02, 2.25151108e-02, 2.57570532e-02, 1.78381193e-02,\n",
      "       1.79182615e-02, 1.29107043e-02, 8.43291386e-03, 1.02627342e-02,\n",
      "       2.62875218e-03, 7.31423639e-18])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.48203208, 0.19107783, 0.1392089 , 0.11860345, 0.08684538,\n",
      "       0.08540456, 0.07888064, 0.06779053, 0.06086229, 0.04992206]), 'adv_group_cali_stderr': array([3.76838922e-02, 3.23431796e-02, 3.39132548e-02, 3.08633668e-02,\n",
      "       1.34169017e-02, 9.21133406e-03, 9.84959560e-03, 6.91092417e-03,\n",
      "       3.26129434e-03, 7.31423639e-18])}}, 'sharpness': {'sharp': 2.9214017}, 'scoring_rule': {'nll': 2.956789586409217, 'crps': 2.1839950815431535, 'check': 1.1016188798762254, 'interval': 12.700823872128629}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(uct.metrics.get_all_metrics(mean_pred.squeeze(1), sd_pred.squeeze(1), y_test.detach().numpy().squeeze(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lims is None. Setting lims now:\n",
      "min_max_true: (7.0, 50.0)\n",
      "min_max_pred: (8.845348, 48.441334)\n",
      "lims: (7.0, 50.0)\n",
      "lims_ext: (2.7, 54.3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = y_test.detach().numpy().squeeze(1)\n",
    "\n",
    "uviz.plot_intervals(mean_pred.squeeze(1), sd_pred.squeeze(1), y)\n",
    "uviz.plot_intervals_ordered(mean_pred.squeeze(1), sd_pred.squeeze(1), y)\n",
    "uviz.plot_parity(mean_pred.squeeze(1), y)\n",
    "uviz.plot_calibration(mean_pred.squeeze(1), sd_pred.squeeze(1), y)\n",
    "uviz.plot_sharpness(sd_pred.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
