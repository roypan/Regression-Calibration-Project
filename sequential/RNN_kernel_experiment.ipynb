{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbdf3498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import random\n",
    "\n",
    "from dataset import get_dataset\n",
    "from metrics import Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5942cdaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, data_np = get_dataset(name=\"electricity\", window_len=1, cxt_len=1, pred_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6b183a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b9482b8b310>]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(data_np[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0681172",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_len = 100\n",
    "window_len = 400\n",
    "sample_len = 800\n",
    "\n",
    "# only train with the first few observations of each time series\n",
    "train_ds = torch.tensor(data_np[:, :sample_len-pred_len])\n",
    "test_ds = torch.tensor(data_np[:, sample_len-pred_len-window_len:sample_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e49e917c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = []\n",
    "train_sd = []\n",
    "for i in range(train_ds.shape[0]):\n",
    "    sample_mean = torch.mean(train_ds[i])\n",
    "    sample_sd = torch.std(train_ds[i], unbiased = True)\n",
    "    train_mean.append(sample_mean)\n",
    "    train_sd.append(sample_sd)\n",
    "    train_ds[i] = (train_ds[i] - sample_mean) / sample_sd\n",
    "    test_ds[i] = (test_ds[i] - sample_mean) / sample_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf1fd38f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2b94816fb490>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_ds[0].detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1322bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_inout_sequences(input_data, window_len, pred_len = 1):\n",
    "    L = len(input_data)\n",
    "    x = torch.empty([L-window_len, window_len ,1])\n",
    "    y = torch.empty([L-window_len ,1])\n",
    "    for i in range(L-window_len):\n",
    "        x[i, :, 0] = input_data[i:i+window_len]\n",
    "        y[i, 0] = input_data[i+window_len:i+window_len+pred_len]\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7796a8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, num_outputs = 2, input_size = 1, hidden_size = 50, num_layers = 1):\n",
    "        super(LSTM, self).__init__()\n",
    "        \n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_layers = num_layers\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True, dropout=.5)\n",
    "        \n",
    "        self.fc = nn.Linear(hidden_size, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h_0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).cuda()\n",
    "        c_0 = torch.zeros(self.num_layers, x.shape[0], self.hidden_size).cuda()\n",
    "        # Propagate input through LSTM\n",
    "        output, (h_out, _) = self.lstm(x, (h_0, c_0))\n",
    "        output = output[:, -1, :]\n",
    "        out = self.fc(output)\n",
    "        out[:, 1] = torch.log(1 + torch.exp(out[:, 1])) # variance\n",
    "        \n",
    "        return out, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67a7ef87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NLLloss(y, mean, var):\n",
    "    \"\"\" Negative log-likelihood loss function. \"\"\"\n",
    "    return (torch.log(var) + torch.pow(y - mean, 2)/var).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "16cf3832",
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(x, feature):\n",
    "    \"\"\"\n",
    "    x: k by 3 by d tensor\n",
    "    \"\"\"\n",
    "    m = nn.ReLU()\n",
    "    k = x.shape[0]\n",
    "    d = x.shape[2]\n",
    "    weight = torch.from_numpy(1/np.sqrt(np.arange(d,0,-1))).repeat([k, 1]).cuda()\n",
    "    distance_x01 = ((x[:, 0, :] - x[:, 1, :]) * weight).norm(dim = 1)\n",
    "    distance_x02 = ((x[:, 0, :] - x[:, 2, :]) * weight).norm(dim = 1)\n",
    "    distance_f01 = (feature[:, 0, :] - feature[:, 1, :]).norm(dim = 1)\n",
    "    distance_f02 = (feature[:, 0, :] - feature[:, 2, :]).norm(dim = 1)\n",
    "    loss = torch.sum((distance_x01 - distance_x02 < 0) * m(distance_f01 - distance_f02)) + torch.sum((distance_x02 - distance_x01 < 0) * m(distance_f02 - distance_f01))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b877c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kernel_sequences(input_data, index, start, window_len):\n",
    "    n = len(index) * 3\n",
    "    x = torch.empty([n, window_len,1])\n",
    "    for i in range(len(index)):\n",
    "        for j in range(3):\n",
    "            x[i*3 + j, :, 0] = input_data[index[i][j], start[i][j]:start[i][j]+window_len]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8e406fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, series: 0, nllk loss: 1.02879, kernel loss: 0.47145\n",
      "Epoch: 0, series: 1, nllk loss: 0.74155, kernel loss: 0.19170\n",
      "Epoch: 0, series: 2, nllk loss: 1.21650, kernel loss: 0.47468\n",
      "Epoch: 0, series: 3, nllk loss: 1.01623, kernel loss: 0.13728\n",
      "Epoch: 0, series: 4, nllk loss: 1.08677, kernel loss: 0.19101\n",
      "Epoch: 0, series: 5, nllk loss: 1.04421, kernel loss: 0.31109\n",
      "Epoch: 0, series: 6, nllk loss: 1.21238, kernel loss: 0.45881\n",
      "Epoch: 0, series: 7, nllk loss: 0.97882, kernel loss: 0.44067\n",
      "Epoch: 0, series: 8, nllk loss: 0.96377, kernel loss: 0.48107\n",
      "Epoch: 0, series: 9, nllk loss: 0.84289, kernel loss: 0.32376\n",
      "Epoch: 0, series: 10, nllk loss: 0.96300, kernel loss: 0.63226\n",
      "Epoch: 0, series: 11, nllk loss: 1.00510, kernel loss: 0.50541\n",
      "Epoch: 0, series: 12, nllk loss: 0.92294, kernel loss: 0.47395\n",
      "Epoch: 0, series: 13, nllk loss: 0.96609, kernel loss: 0.40311\n",
      "Epoch: 0, series: 14, nllk loss: 0.95978, kernel loss: 0.34559\n",
      "Epoch: 0, series: 15, nllk loss: 0.93255, kernel loss: 0.50938\n",
      "Epoch: 0, series: 16, nllk loss: 0.98505, kernel loss: 0.39439\n",
      "Epoch: 0, series: 17, nllk loss: 0.91599, kernel loss: 0.42562\n",
      "Epoch: 0, series: 18, nllk loss: 1.01970, kernel loss: 0.34986\n",
      "Epoch: 0, series: 19, nllk loss: 1.06554, kernel loss: 0.20030\n",
      "Epoch: 0, series: 20, nllk loss: 0.92000, kernel loss: 0.24440\n",
      "Epoch: 0, series: 21, nllk loss: 1.08414, kernel loss: 0.26863\n",
      "Epoch: 0, series: 22, nllk loss: 0.93411, kernel loss: 0.32668\n",
      "Epoch: 0, series: 23, nllk loss: 0.96162, kernel loss: 0.19887\n",
      "Epoch: 0, series: 24, nllk loss: 0.97883, kernel loss: 0.22941\n",
      "Epoch: 0, series: 25, nllk loss: 0.86786, kernel loss: 0.24133\n",
      "Epoch: 0, series: 26, nllk loss: 1.00724, kernel loss: 0.25270\n",
      "Epoch: 0, series: 27, nllk loss: 0.81499, kernel loss: 0.31456\n",
      "Epoch: 0, series: 28, nllk loss: 0.68572, kernel loss: 0.24280\n",
      "Epoch: 0, series: 29, nllk loss: 1.03561, kernel loss: 0.30668\n",
      "Epoch: 0, series: 30, nllk loss: 1.13225, kernel loss: 0.21417\n",
      "Epoch: 0, series: 31, nllk loss: 0.94190, kernel loss: 0.18402\n",
      "Epoch: 0, series: 32, nllk loss: 1.07273, kernel loss: 0.18269\n",
      "Epoch: 0, series: 33, nllk loss: 0.92319, kernel loss: 0.22498\n",
      "Epoch: 0, series: 34, nllk loss: 0.87925, kernel loss: 0.29431\n",
      "Epoch: 0, series: 35, nllk loss: 0.89547, kernel loss: 0.17830\n",
      "Epoch: 0, series: 36, nllk loss: 0.91645, kernel loss: 0.29564\n",
      "Epoch: 0, series: 37, nllk loss: 0.93064, kernel loss: 0.22604\n",
      "Epoch: 0, series: 38, nllk loss: 0.93327, kernel loss: 0.30848\n",
      "Epoch: 0, series: 39, nllk loss: 1.08214, kernel loss: 0.22830\n",
      "Epoch: 0, series: 40, nllk loss: 0.92372, kernel loss: 0.36180\n",
      "Epoch: 0, series: 41, nllk loss: 0.88275, kernel loss: 0.18371\n",
      "Epoch: 0, series: 42, nllk loss: 0.86900, kernel loss: 0.11512\n",
      "Epoch: 0, series: 43, nllk loss: 1.02973, kernel loss: 0.15051\n",
      "Epoch: 0, series: 44, nllk loss: 0.93814, kernel loss: 0.07414\n",
      "Epoch: 0, series: 45, nllk loss: 0.93059, kernel loss: 0.24882\n",
      "Epoch: 0, series: 46, nllk loss: 0.90934, kernel loss: 0.22198\n",
      "Epoch: 0, series: 47, nllk loss: 0.96873, kernel loss: 0.19163\n",
      "Epoch: 0, series: 48, nllk loss: 0.95713, kernel loss: 0.19108\n",
      "Epoch: 0, series: 49, nllk loss: 0.89501, kernel loss: 0.26775\n",
      "Epoch: 0, series: 50, nllk loss: 0.94752, kernel loss: 0.21940\n",
      "Epoch: 0, series: 51, nllk loss: 0.91604, kernel loss: 0.25128\n",
      "Epoch: 0, series: 52, nllk loss: 1.02960, kernel loss: 0.29609\n",
      "Epoch: 0, series: 53, nllk loss: 0.91442, kernel loss: 0.11492\n",
      "Epoch: 0, series: 54, nllk loss: 0.91799, kernel loss: 0.28316\n",
      "Epoch: 0, series: 55, nllk loss: 0.84246, kernel loss: 0.18600\n",
      "Epoch: 0, series: 56, nllk loss: 0.85001, kernel loss: 0.13972\n",
      "Epoch: 0, series: 57, nllk loss: 0.91913, kernel loss: 0.26466\n",
      "Epoch: 0, series: 58, nllk loss: 0.93192, kernel loss: 0.29453\n",
      "Epoch: 0, series: 59, nllk loss: 1.07533, kernel loss: 0.17808\n",
      "Epoch: 0, series: 60, nllk loss: 0.78490, kernel loss: 0.18385\n",
      "Epoch: 0, series: 61, nllk loss: 0.92205, kernel loss: 0.25832\n",
      "Epoch: 0, series: 62, nllk loss: 0.90818, kernel loss: 0.26905\n",
      "Epoch: 0, series: 63, nllk loss: 0.82805, kernel loss: 0.14293\n",
      "Epoch: 0, series: 64, nllk loss: 1.00580, kernel loss: 0.20894\n",
      "Epoch: 0, series: 65, nllk loss: 0.86445, kernel loss: 0.27702\n",
      "Epoch: 0, series: 66, nllk loss: 0.76365, kernel loss: 0.12601\n",
      "Epoch: 0, series: 67, nllk loss: 0.90854, kernel loss: 0.22050\n",
      "Epoch: 0, series: 68, nllk loss: 0.89791, kernel loss: 0.14039\n",
      "Epoch: 0, series: 69, nllk loss: 0.75680, kernel loss: 0.08456\n",
      "Epoch: 0, series: 70, nllk loss: 0.77015, kernel loss: 0.22150\n",
      "Epoch: 0, series: 71, nllk loss: 0.83602, kernel loss: 0.19406\n",
      "Epoch: 0, series: 72, nllk loss: 0.76276, kernel loss: 0.20085\n",
      "Epoch: 0, series: 73, nllk loss: 0.90842, kernel loss: 0.24277\n",
      "Epoch: 0, series: 74, nllk loss: 0.81999, kernel loss: 0.19340\n",
      "Epoch: 0, series: 75, nllk loss: 0.70826, kernel loss: 0.29176\n",
      "Epoch: 0, series: 76, nllk loss: 0.74040, kernel loss: 0.38585\n",
      "Epoch: 0, series: 77, nllk loss: 0.81633, kernel loss: 0.21535\n",
      "Epoch: 0, series: 78, nllk loss: 0.74584, kernel loss: 0.10147\n",
      "Epoch: 0, series: 79, nllk loss: 0.60694, kernel loss: 0.19696\n",
      "Epoch: 0, series: 80, nllk loss: 0.63421, kernel loss: 0.24370\n",
      "Epoch: 0, series: 81, nllk loss: 0.67914, kernel loss: 0.23727\n",
      "Epoch: 0, series: 82, nllk loss: 0.72363, kernel loss: 0.16195\n",
      "Epoch: 0, series: 83, nllk loss: 0.53932, kernel loss: 0.35623\n",
      "Epoch: 0, series: 84, nllk loss: 0.16115, kernel loss: 0.16282\n",
      "Epoch: 0, series: 85, nllk loss: 0.54870, kernel loss: 0.68957\n",
      "Epoch: 0, series: 86, nllk loss: 0.66245, kernel loss: 0.22484\n",
      "Epoch: 0, series: 87, nllk loss: 0.41635, kernel loss: 0.36292\n",
      "Epoch: 0, series: 88, nllk loss: 0.40927, kernel loss: 0.34591\n",
      "Epoch: 0, series: 89, nllk loss: 0.30177, kernel loss: 0.27878\n",
      "Epoch: 0, series: 90, nllk loss: 0.29555, kernel loss: 0.23495\n",
      "Epoch: 0, series: 91, nllk loss: 0.15100, kernel loss: 0.73746\n",
      "Epoch: 0, series: 92, nllk loss: 0.33322, kernel loss: 0.35686\n",
      "Epoch: 0, series: 93, nllk loss: 0.12150, kernel loss: 0.71773\n",
      "Epoch: 0, series: 94, nllk loss: -0.00330, kernel loss: 0.67226\n",
      "Epoch: 0, series: 95, nllk loss: -0.31954, kernel loss: 0.90273\n",
      "Epoch: 0, series: 96, nllk loss: 0.09213, kernel loss: 0.52323\n",
      "Epoch: 0, series: 97, nllk loss: -0.15423, kernel loss: 0.96340\n",
      "Epoch: 0, series: 98, nllk loss: 0.36137, kernel loss: 0.87476\n",
      "Epoch: 0, series: 99, nllk loss: 0.30239, kernel loss: 0.53478\n",
      "Epoch: 0, series: 100, nllk loss: 0.17118, kernel loss: 0.39049\n",
      "Epoch: 0, series: 101, nllk loss: 0.20011, kernel loss: 0.35517\n",
      "Epoch: 0, series: 102, nllk loss: 0.07034, kernel loss: 0.28493\n",
      "Epoch: 0, series: 103, nllk loss: 0.11567, kernel loss: 0.73524\n",
      "Epoch: 0, series: 104, nllk loss: 0.54347, kernel loss: 0.73037\n",
      "Epoch: 0, series: 105, nllk loss: 0.15164, kernel loss: 0.70735\n",
      "Epoch: 0, series: 106, nllk loss: -0.10826, kernel loss: 0.82652\n",
      "Epoch: 0, series: 107, nllk loss: -0.14373, kernel loss: 0.59401\n",
      "Epoch: 0, series: 108, nllk loss: 0.22757, kernel loss: 0.82942\n",
      "Epoch: 0, series: 109, nllk loss: 0.74604, kernel loss: 0.35163\n",
      "Epoch: 0, series: 110, nllk loss: 0.10268, kernel loss: 0.38131\n",
      "Epoch: 0, series: 111, nllk loss: -0.08724, kernel loss: 0.34155\n",
      "Epoch: 0, series: 112, nllk loss: 0.17319, kernel loss: 0.67084\n",
      "Epoch: 0, series: 113, nllk loss: -0.27218, kernel loss: 0.69737\n",
      "Epoch: 0, series: 114, nllk loss: 0.00154, kernel loss: 0.50590\n",
      "Epoch: 0, series: 115, nllk loss: 0.33245, kernel loss: 0.66493\n",
      "Epoch: 0, series: 116, nllk loss: -0.52114, kernel loss: 0.86853\n",
      "Epoch: 0, series: 117, nllk loss: -0.08158, kernel loss: 0.98464\n",
      "Epoch: 0, series: 118, nllk loss: -0.30462, kernel loss: 0.38393\n",
      "Epoch: 0, series: 119, nllk loss: -0.06213, kernel loss: 0.61822\n",
      "Epoch: 0, series: 120, nllk loss: -0.50700, kernel loss: 0.79399\n",
      "Epoch: 0, series: 121, nllk loss: -0.01766, kernel loss: 0.68170\n",
      "Epoch: 0, series: 122, nllk loss: 0.11891, kernel loss: 0.87653\n",
      "Epoch: 0, series: 123, nllk loss: -0.38275, kernel loss: 0.31352\n",
      "Epoch: 0, series: 124, nllk loss: -0.37477, kernel loss: 1.55418\n",
      "Epoch: 0, series: 125, nllk loss: -0.91040, kernel loss: 0.86668\n",
      "Epoch: 0, series: 126, nllk loss: -0.58618, kernel loss: 0.85412\n",
      "Epoch: 0, series: 127, nllk loss: -0.96622, kernel loss: 0.96170\n",
      "Epoch: 0, series: 128, nllk loss: -0.38447, kernel loss: 0.60983\n",
      "Epoch: 0, series: 129, nllk loss: -0.29688, kernel loss: 0.30004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, series: 130, nllk loss: -0.36636, kernel loss: 0.40662\n",
      "Epoch: 0, series: 131, nllk loss: 0.33142, kernel loss: 0.26222\n",
      "Epoch: 0, series: 132, nllk loss: 0.13939, kernel loss: 1.17935\n",
      "Epoch: 0, series: 133, nllk loss: -0.53598, kernel loss: 1.14025\n",
      "Epoch: 0, series: 134, nllk loss: -0.46590, kernel loss: 0.53955\n",
      "Epoch: 0, series: 135, nllk loss: -0.62925, kernel loss: 1.00118\n",
      "Epoch: 0, series: 136, nllk loss: -0.26913, kernel loss: 0.55973\n",
      "Epoch: 0, series: 137, nllk loss: -0.69976, kernel loss: 0.45681\n",
      "Epoch: 0, series: 138, nllk loss: -0.73359, kernel loss: 0.69714\n",
      "Epoch: 0, series: 139, nllk loss: -0.69255, kernel loss: 0.63773\n",
      "Epoch: 0, series: 140, nllk loss: -0.68181, kernel loss: 0.26949\n",
      "Epoch: 0, series: 141, nllk loss: -0.59760, kernel loss: 0.75234\n",
      "Epoch: 0, series: 142, nllk loss: -0.40873, kernel loss: 0.84215\n",
      "Epoch: 0, series: 143, nllk loss: -0.55753, kernel loss: 0.46994\n",
      "Epoch: 0, series: 144, nllk loss: -0.56452, kernel loss: 0.71186\n",
      "Epoch: 0, series: 145, nllk loss: -0.67419, kernel loss: 0.21315\n",
      "Epoch: 0, series: 146, nllk loss: 1.83836, kernel loss: 0.58622\n",
      "Epoch: 0, series: 147, nllk loss: -0.88942, kernel loss: 0.63428\n",
      "Epoch: 0, series: 148, nllk loss: -0.42775, kernel loss: 0.22856\n",
      "Epoch: 0, series: 149, nllk loss: -0.81294, kernel loss: 0.55979\n",
      "Epoch: 0, series: 150, nllk loss: -1.05477, kernel loss: 0.52185\n",
      "Epoch: 0, series: 151, nllk loss: -0.99807, kernel loss: 0.68333\n",
      "Epoch: 0, series: 152, nllk loss: -0.78042, kernel loss: 0.87569\n",
      "Epoch: 0, series: 153, nllk loss: -0.73996, kernel loss: 0.85852\n",
      "Epoch: 0, series: 154, nllk loss: -0.58041, kernel loss: 0.77817\n",
      "Epoch: 0, series: 155, nllk loss: -0.74272, kernel loss: 0.93746\n",
      "Epoch: 0, series: 156, nllk loss: -0.77219, kernel loss: 0.72851\n",
      "Epoch: 0, series: 157, nllk loss: -0.68579, kernel loss: 0.65441\n",
      "Epoch: 0, series: 158, nllk loss: -0.91223, kernel loss: 0.54897\n",
      "Epoch: 0, series: 159, nllk loss: -1.10376, kernel loss: 0.24765\n",
      "Epoch: 0, series: 160, nllk loss: -1.07442, kernel loss: 0.54825\n",
      "Epoch: 0, series: 161, nllk loss: -1.20806, kernel loss: 0.58596\n",
      "Epoch: 0, series: 162, nllk loss: -0.96699, kernel loss: 0.37829\n",
      "Epoch: 0, series: 163, nllk loss: -1.34098, kernel loss: 0.77785\n",
      "Epoch: 0, series: 164, nllk loss: -1.04450, kernel loss: 0.34078\n",
      "Epoch: 0, series: 165, nllk loss: -1.17936, kernel loss: 0.37101\n",
      "Epoch: 0, series: 166, nllk loss: -0.86845, kernel loss: 1.27146\n",
      "Epoch: 0, series: 167, nllk loss: -1.56246, kernel loss: 0.59238\n",
      "Epoch: 0, series: 168, nllk loss: -1.51291, kernel loss: 0.15560\n",
      "Epoch: 0, series: 169, nllk loss: -1.54997, kernel loss: 0.37982\n",
      "Epoch: 0, series: 170, nllk loss: -0.79110, kernel loss: 0.38298\n",
      "Epoch: 0, series: 171, nllk loss: -0.22948, kernel loss: 0.14535\n",
      "Epoch: 0, series: 172, nllk loss: -0.55967, kernel loss: 0.36459\n",
      "Epoch: 0, series: 173, nllk loss: -0.94101, kernel loss: 0.20599\n",
      "Epoch: 0, series: 174, nllk loss: -0.98929, kernel loss: 0.34648\n",
      "Epoch: 0, series: 175, nllk loss: -0.77278, kernel loss: 0.37535\n",
      "Epoch: 0, series: 176, nllk loss: -0.84372, kernel loss: 0.27560\n",
      "Epoch: 0, series: 177, nllk loss: -0.84194, kernel loss: 0.36197\n",
      "Epoch: 0, series: 178, nllk loss: -0.85377, kernel loss: 0.38869\n",
      "Epoch: 0, series: 179, nllk loss: -0.97178, kernel loss: 0.10281\n",
      "Epoch: 0, series: 180, nllk loss: -0.71838, kernel loss: 0.44406\n",
      "Epoch: 0, series: 181, nllk loss: -0.93544, kernel loss: 0.13732\n",
      "Epoch: 0, series: 182, nllk loss: -0.85182, kernel loss: 0.57575\n",
      "Epoch: 0, series: 183, nllk loss: -1.04292, kernel loss: 0.59278\n",
      "Epoch: 0, series: 184, nllk loss: -1.01495, kernel loss: 0.30277\n",
      "Epoch: 0, series: 185, nllk loss: -1.07581, kernel loss: 0.22123\n",
      "Epoch: 0, series: 186, nllk loss: -1.01471, kernel loss: 0.16401\n",
      "Epoch: 0, series: 187, nllk loss: -1.05926, kernel loss: 0.70278\n",
      "Epoch: 0, series: 188, nllk loss: -0.77605, kernel loss: 0.90862\n",
      "Epoch: 0, series: 189, nllk loss: -0.79199, kernel loss: 0.56840\n",
      "Epoch: 0, series: 190, nllk loss: -1.02282, kernel loss: 0.48889\n",
      "Epoch: 0, series: 191, nllk loss: -1.06439, kernel loss: 0.29443\n",
      "Epoch: 0, series: 192, nllk loss: -1.18326, kernel loss: 0.71057\n",
      "Epoch: 0, series: 193, nllk loss: -1.10456, kernel loss: 0.48535\n",
      "Epoch: 0, series: 194, nllk loss: -0.92087, kernel loss: 0.62551\n",
      "Epoch: 0, series: 195, nllk loss: -1.43843, kernel loss: 0.37669\n",
      "Epoch: 0, series: 196, nllk loss: -1.05586, kernel loss: 0.31831\n",
      "Epoch: 0, series: 197, nllk loss: -1.27446, kernel loss: 0.23927\n",
      "Epoch: 0, series: 198, nllk loss: -1.36813, kernel loss: 0.79595\n",
      "Epoch: 0, series: 199, nllk loss: -1.37118, kernel loss: 0.66257\n",
      "Epoch: 0, series: 200, nllk loss: -1.44240, kernel loss: 0.97551\n",
      "Epoch: 0, series: 201, nllk loss: -1.60963, kernel loss: 0.26933\n",
      "Epoch: 0, series: 202, nllk loss: -1.09427, kernel loss: 0.69482\n",
      "Epoch: 0, series: 203, nllk loss: -1.22464, kernel loss: 0.27396\n",
      "Epoch: 0, series: 204, nllk loss: -0.23100, kernel loss: 0.36998\n",
      "Epoch: 0, series: 205, nllk loss: -1.12263, kernel loss: 0.16266\n",
      "Epoch: 0, series: 206, nllk loss: -1.54009, kernel loss: 0.58968\n",
      "Epoch: 0, series: 207, nllk loss: -0.53224, kernel loss: 0.43995\n",
      "Epoch: 0, series: 208, nllk loss: -1.60845, kernel loss: 0.29438\n",
      "Epoch: 0, series: 209, nllk loss: -1.16023, kernel loss: 0.26545\n",
      "Epoch: 0, series: 210, nllk loss: -1.66710, kernel loss: 0.41943\n",
      "Epoch: 0, series: 211, nllk loss: -1.57556, kernel loss: 0.24738\n",
      "Epoch: 0, series: 212, nllk loss: -1.02776, kernel loss: 0.35701\n",
      "Epoch: 0, series: 213, nllk loss: -1.39870, kernel loss: 0.28348\n",
      "Epoch: 0, series: 214, nllk loss: -1.23905, kernel loss: 0.26457\n",
      "Epoch: 0, series: 215, nllk loss: -1.43066, kernel loss: 0.56113\n",
      "Epoch: 0, series: 216, nllk loss: -0.77672, kernel loss: 0.74483\n",
      "Epoch: 0, series: 217, nllk loss: -0.89703, kernel loss: 0.29915\n",
      "Epoch: 0, series: 218, nllk loss: -0.75032, kernel loss: 0.32099\n",
      "Epoch: 0, series: 219, nllk loss: -1.00341, kernel loss: 0.41769\n",
      "Epoch: 0, series: 220, nllk loss: -1.34980, kernel loss: 0.35067\n",
      "Epoch: 0, series: 221, nllk loss: -1.40452, kernel loss: 0.22966\n",
      "Epoch: 0, series: 222, nllk loss: -1.33967, kernel loss: 0.48513\n",
      "Epoch: 0, series: 223, nllk loss: -0.69285, kernel loss: 0.28666\n",
      "Epoch: 0, series: 224, nllk loss: -1.32885, kernel loss: 0.06781\n",
      "Epoch: 0, series: 225, nllk loss: -1.20417, kernel loss: 0.08136\n",
      "Epoch: 0, series: 226, nllk loss: -1.13204, kernel loss: 0.09937\n",
      "Epoch: 0, series: 227, nllk loss: -1.33417, kernel loss: 0.37379\n",
      "Epoch: 0, series: 228, nllk loss: -1.31681, kernel loss: 0.33637\n",
      "Epoch: 0, series: 229, nllk loss: -1.18678, kernel loss: 0.18955\n",
      "Epoch: 0, series: 230, nllk loss: -1.40150, kernel loss: 0.34779\n",
      "Epoch: 0, series: 231, nllk loss: -1.21317, kernel loss: 0.62801\n",
      "Epoch: 0, series: 232, nllk loss: -1.57841, kernel loss: 0.35775\n",
      "Epoch: 0, series: 233, nllk loss: -1.51360, kernel loss: 0.51107\n",
      "Epoch: 0, series: 234, nllk loss: -1.26040, kernel loss: 0.60865\n",
      "Epoch: 0, series: 235, nllk loss: -1.65006, kernel loss: 0.43160\n",
      "Epoch: 0, series: 236, nllk loss: -0.61898, kernel loss: 0.14401\n",
      "Epoch: 0, series: 237, nllk loss: -1.09636, kernel loss: 0.69539\n",
      "Epoch: 0, series: 238, nllk loss: -1.22939, kernel loss: 0.36075\n",
      "Epoch: 0, series: 239, nllk loss: -1.47409, kernel loss: 0.27531\n",
      "Epoch: 0, series: 240, nllk loss: -1.11085, kernel loss: 0.13657\n",
      "Epoch: 0, series: 241, nllk loss: -0.96484, kernel loss: 0.04921\n",
      "Epoch: 0, series: 242, nllk loss: -1.00806, kernel loss: 0.14046\n",
      "Epoch: 0, series: 243, nllk loss: -1.55918, kernel loss: 0.27930\n",
      "Epoch: 0, series: 244, nllk loss: -1.08902, kernel loss: 0.34352\n",
      "Epoch: 0, series: 245, nllk loss: -1.45809, kernel loss: 0.58847\n",
      "Epoch: 0, series: 246, nllk loss: -0.12551, kernel loss: 0.49325\n",
      "Epoch: 0, series: 247, nllk loss: -1.22110, kernel loss: 0.55490\n",
      "Epoch: 0, series: 248, nllk loss: -1.12007, kernel loss: 0.28881\n",
      "Epoch: 0, series: 249, nllk loss: -1.15472, kernel loss: 0.29368\n",
      "Epoch: 0, series: 250, nllk loss: -1.07810, kernel loss: 0.13485\n",
      "Epoch: 0, series: 251, nllk loss: -0.64896, kernel loss: 0.19383\n",
      "Epoch: 0, series: 252, nllk loss: -0.42594, kernel loss: 0.28033\n",
      "Epoch: 0, series: 253, nllk loss: -1.21834, kernel loss: 0.27627\n",
      "Epoch: 0, series: 254, nllk loss: -1.43944, kernel loss: 0.42043\n",
      "Epoch: 0, series: 255, nllk loss: -1.23766, kernel loss: 0.37349\n",
      "Epoch: 0, series: 256, nllk loss: -0.87706, kernel loss: 0.36057\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, series: 257, nllk loss: -1.36795, kernel loss: 0.11403\n",
      "Epoch: 0, series: 258, nllk loss: -1.36427, kernel loss: 0.46407\n",
      "Epoch: 0, series: 259, nllk loss: -0.94563, kernel loss: 0.17587\n",
      "Epoch: 0, series: 260, nllk loss: -1.19963, kernel loss: 0.24147\n",
      "Epoch: 0, series: 261, nllk loss: -1.49662, kernel loss: 0.23763\n",
      "Epoch: 0, series: 262, nllk loss: -1.59239, kernel loss: 0.23995\n",
      "Epoch: 0, series: 263, nllk loss: -0.38442, kernel loss: 0.59027\n",
      "Epoch: 0, series: 264, nllk loss: -1.37761, kernel loss: 0.37469\n",
      "Epoch: 0, series: 265, nllk loss: -1.50021, kernel loss: 0.33387\n",
      "Epoch: 0, series: 266, nllk loss: -1.44817, kernel loss: 0.11991\n",
      "Epoch: 0, series: 267, nllk loss: -1.56753, kernel loss: 0.35490\n",
      "Epoch: 0, series: 268, nllk loss: -1.48672, kernel loss: 0.21878\n",
      "Epoch: 0, series: 269, nllk loss: -0.88465, kernel loss: 0.12024\n",
      "Epoch: 0, series: 270, nllk loss: -1.16934, kernel loss: 0.14781\n",
      "Epoch: 0, series: 271, nllk loss: -1.32444, kernel loss: 0.19213\n",
      "Epoch: 0, series: 272, nllk loss: -1.37793, kernel loss: 0.24724\n",
      "Epoch: 0, series: 273, nllk loss: -1.48142, kernel loss: 0.32259\n",
      "Epoch: 0, series: 274, nllk loss: -1.20300, kernel loss: 0.50814\n",
      "Epoch: 0, series: 275, nllk loss: -1.47447, kernel loss: 0.21385\n",
      "Epoch: 0, series: 276, nllk loss: -0.40440, kernel loss: 0.43163\n",
      "Epoch: 0, series: 277, nllk loss: -1.49926, kernel loss: 0.37999\n",
      "Epoch: 0, series: 278, nllk loss: -1.28597, kernel loss: 0.40127\n",
      "Epoch: 0, series: 279, nllk loss: -1.66216, kernel loss: 0.47441\n",
      "Epoch: 0, series: 280, nllk loss: -1.55749, kernel loss: 0.57754\n",
      "Epoch: 0, series: 281, nllk loss: -1.54591, kernel loss: 0.50323\n",
      "Epoch: 0, series: 282, nllk loss: -1.69164, kernel loss: 0.34449\n",
      "Epoch: 0, series: 283, nllk loss: -1.05642, kernel loss: 0.28367\n",
      "Epoch: 0, series: 284, nllk loss: -1.29210, kernel loss: 0.15579\n",
      "Epoch: 0, series: 285, nllk loss: -1.31083, kernel loss: 0.94183\n",
      "Epoch: 0, series: 286, nllk loss: -1.39597, kernel loss: 0.40173\n",
      "Epoch: 0, series: 287, nllk loss: -1.86019, kernel loss: 0.20435\n",
      "Epoch: 0, series: 288, nllk loss: -0.58318, kernel loss: 0.31799\n",
      "Epoch: 0, series: 289, nllk loss: -0.53568, kernel loss: 0.23245\n",
      "Epoch: 0, series: 290, nllk loss: -1.58328, kernel loss: 0.26872\n",
      "Epoch: 0, series: 291, nllk loss: -1.62359, kernel loss: 0.27749\n",
      "Epoch: 0, series: 292, nllk loss: -1.65048, kernel loss: 0.23164\n",
      "Epoch: 0, series: 293, nllk loss: -1.64919, kernel loss: 0.28385\n",
      "Epoch: 0, series: 294, nllk loss: -1.12425, kernel loss: 0.21405\n",
      "Epoch: 0, series: 295, nllk loss: -1.05592, kernel loss: 0.43082\n",
      "Epoch: 0, series: 296, nllk loss: -1.85375, kernel loss: 0.33253\n",
      "Epoch: 0, series: 297, nllk loss: -1.78340, kernel loss: 0.41815\n",
      "Epoch: 0, series: 298, nllk loss: 4.15512, kernel loss: 0.29822\n",
      "Epoch: 0, series: 299, nllk loss: 1.44121, kernel loss: 0.57939\n",
      "Epoch: 0, series: 300, nllk loss: -1.13531, kernel loss: 0.15566\n",
      "Epoch: 0, series: 301, nllk loss: -1.08496, kernel loss: 0.13719\n",
      "Epoch: 0, series: 302, nllk loss: -1.18240, kernel loss: 0.24915\n",
      "Epoch: 0, series: 303, nllk loss: -1.09053, kernel loss: 0.25057\n",
      "Epoch: 0, series: 304, nllk loss: -0.90432, kernel loss: 0.17755\n",
      "Epoch: 0, series: 305, nllk loss: -0.66081, kernel loss: 0.07168\n",
      "Epoch: 0, series: 306, nllk loss: -1.09001, kernel loss: 0.21027\n",
      "Epoch: 0, series: 307, nllk loss: -0.78078, kernel loss: 0.07999\n",
      "Epoch: 0, series: 308, nllk loss: -1.03655, kernel loss: 0.55781\n",
      "Epoch: 0, series: 309, nllk loss: -1.01249, kernel loss: 0.26732\n",
      "Epoch: 0, series: 310, nllk loss: -1.10695, kernel loss: 0.47237\n",
      "Epoch: 0, series: 311, nllk loss: -0.97750, kernel loss: 0.19108\n",
      "Epoch: 0, series: 312, nllk loss: -1.14307, kernel loss: 0.47923\n",
      "Epoch: 0, series: 313, nllk loss: -1.25442, kernel loss: 0.24043\n",
      "Epoch: 0, series: 314, nllk loss: -1.36031, kernel loss: 0.29932\n",
      "Epoch: 0, series: 315, nllk loss: -0.66366, kernel loss: 0.21301\n",
      "Epoch: 0, series: 316, nllk loss: -0.91507, kernel loss: 0.33958\n",
      "Epoch: 0, series: 317, nllk loss: 0.50406, kernel loss: 0.37857\n",
      "Epoch: 0, series: 318, nllk loss: 0.96628, kernel loss: 0.22481\n",
      "Epoch: 0, series: 319, nllk loss: -0.37169, kernel loss: 0.39334\n",
      "Epoch: 0, series: 320, nllk loss: -0.63991, kernel loss: 0.26570\n",
      "Epoch: 0, total loss: 14.94444\n",
      "Epoch: 1, series: 0, nllk loss: 2.16009, kernel loss: 0.55839\n",
      "Epoch: 1, series: 1, nllk loss: -0.40960, kernel loss: 0.42291\n",
      "Epoch: 1, series: 2, nllk loss: 0.26834, kernel loss: 0.28801\n",
      "Epoch: 1, series: 3, nllk loss: -0.62128, kernel loss: 0.35108\n",
      "Epoch: 1, series: 4, nllk loss: -0.47657, kernel loss: 0.30703\n",
      "Epoch: 1, series: 5, nllk loss: -0.68797, kernel loss: 0.42162\n",
      "Epoch: 1, series: 6, nllk loss: -0.31077, kernel loss: 0.35765\n",
      "Epoch: 1, series: 7, nllk loss: -0.81483, kernel loss: 1.04476\n",
      "Epoch: 1, series: 8, nllk loss: -0.17987, kernel loss: 0.46908\n",
      "Epoch: 1, series: 9, nllk loss: -0.30022, kernel loss: 0.04970\n",
      "Epoch: 1, series: 10, nllk loss: -0.60266, kernel loss: 0.24233\n",
      "Epoch: 1, series: 11, nllk loss: -0.60606, kernel loss: 0.38806\n",
      "Epoch: 1, series: 12, nllk loss: -0.83331, kernel loss: 0.31225\n",
      "Epoch: 1, series: 13, nllk loss: -0.36080, kernel loss: 0.10807\n",
      "Epoch: 1, series: 14, nllk loss: -0.59950, kernel loss: 0.21641\n",
      "Epoch: 1, series: 15, nllk loss: -0.54161, kernel loss: 0.45540\n",
      "Epoch: 1, series: 16, nllk loss: -0.43101, kernel loss: 0.32104\n",
      "Epoch: 1, series: 17, nllk loss: -0.47784, kernel loss: 0.20747\n",
      "Epoch: 1, series: 18, nllk loss: -0.66171, kernel loss: 0.15783\n",
      "Epoch: 1, series: 19, nllk loss: -0.04789, kernel loss: 0.38593\n",
      "Epoch: 1, series: 20, nllk loss: -0.20608, kernel loss: 0.31900\n",
      "Epoch: 1, series: 21, nllk loss: -0.55163, kernel loss: 0.04515\n",
      "Epoch: 1, series: 22, nllk loss: -0.77137, kernel loss: 0.63721\n",
      "Epoch: 1, series: 23, nllk loss: -0.72386, kernel loss: 0.32104\n",
      "Epoch: 1, series: 24, nllk loss: -0.84310, kernel loss: 0.13456\n",
      "Epoch: 1, series: 25, nllk loss: -0.71319, kernel loss: 0.31409\n",
      "Epoch: 1, series: 26, nllk loss: -0.72371, kernel loss: 0.33377\n",
      "Epoch: 1, series: 27, nllk loss: -0.74223, kernel loss: 0.35433\n",
      "Epoch: 1, series: 28, nllk loss: -0.86363, kernel loss: 0.44172\n",
      "Epoch: 1, series: 29, nllk loss: -0.23671, kernel loss: 0.29412\n",
      "Epoch: 1, series: 30, nllk loss: -0.53881, kernel loss: 0.54615\n",
      "Epoch: 1, series: 31, nllk loss: -0.69537, kernel loss: 0.68176\n",
      "Epoch: 1, series: 32, nllk loss: -0.74014, kernel loss: 0.38599\n",
      "Epoch: 1, series: 33, nllk loss: -0.68583, kernel loss: 0.31402\n",
      "Epoch: 1, series: 34, nllk loss: -0.80386, kernel loss: 0.40371\n",
      "Epoch: 1, series: 35, nllk loss: -0.74516, kernel loss: 0.22388\n",
      "Epoch: 1, series: 36, nllk loss: -0.83685, kernel loss: 0.15206\n",
      "Epoch: 1, series: 37, nllk loss: -0.14878, kernel loss: 0.44585\n",
      "Epoch: 1, series: 38, nllk loss: -0.72324, kernel loss: 0.42887\n",
      "Epoch: 1, series: 39, nllk loss: -0.45288, kernel loss: 0.14780\n",
      "Epoch: 1, series: 40, nllk loss: -1.20416, kernel loss: 0.10961\n",
      "Epoch: 1, series: 41, nllk loss: -0.91209, kernel loss: 0.17330\n",
      "Epoch: 1, series: 42, nllk loss: -0.95418, kernel loss: 0.38583\n",
      "Epoch: 1, series: 43, nllk loss: -0.56548, kernel loss: 0.52707\n",
      "Epoch: 1, series: 44, nllk loss: -0.92395, kernel loss: 0.17031\n",
      "Epoch: 1, series: 45, nllk loss: -1.16633, kernel loss: 0.31450\n",
      "Epoch: 1, series: 46, nllk loss: -1.10555, kernel loss: 0.28002\n",
      "Epoch: 1, series: 47, nllk loss: -0.94215, kernel loss: 0.24636\n",
      "Epoch: 1, series: 48, nllk loss: -1.13556, kernel loss: 0.10802\n",
      "Epoch: 1, series: 49, nllk loss: -0.78105, kernel loss: 0.12927\n",
      "Epoch: 1, series: 50, nllk loss: -0.03817, kernel loss: 0.32141\n",
      "Epoch: 1, series: 51, nllk loss: -1.10694, kernel loss: 0.30795\n",
      "Epoch: 1, series: 52, nllk loss: -0.58789, kernel loss: 0.13359\n",
      "Epoch: 1, series: 53, nllk loss: -1.10379, kernel loss: 0.25643\n",
      "Epoch: 1, series: 54, nllk loss: -0.85233, kernel loss: 0.11289\n",
      "Epoch: 1, series: 55, nllk loss: -0.77099, kernel loss: 0.22879\n",
      "Epoch: 1, series: 56, nllk loss: -0.95739, kernel loss: 0.18073\n",
      "Epoch: 1, series: 57, nllk loss: -0.91594, kernel loss: 0.18249\n",
      "Epoch: 1, series: 58, nllk loss: -0.99817, kernel loss: 0.38506\n",
      "Epoch: 1, series: 59, nllk loss: -0.84055, kernel loss: 0.25958\n",
      "Epoch: 1, series: 60, nllk loss: -0.77206, kernel loss: 0.08233\n",
      "Epoch: 1, series: 61, nllk loss: -0.85329, kernel loss: 0.20983\n",
      "Epoch: 1, series: 62, nllk loss: -0.94679, kernel loss: 0.43859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, series: 63, nllk loss: -0.93152, kernel loss: 0.36238\n",
      "Epoch: 1, series: 64, nllk loss: -0.37974, kernel loss: 0.29336\n",
      "Epoch: 1, series: 65, nllk loss: -0.98028, kernel loss: 0.14448\n",
      "Epoch: 1, series: 66, nllk loss: -0.84709, kernel loss: 0.14229\n",
      "Epoch: 1, series: 67, nllk loss: -0.87392, kernel loss: 0.40331\n",
      "Epoch: 1, series: 68, nllk loss: -0.39398, kernel loss: 0.31988\n",
      "Epoch: 1, series: 69, nllk loss: -0.96881, kernel loss: 0.27238\n",
      "Epoch: 1, series: 70, nllk loss: -1.11533, kernel loss: 0.44956\n",
      "Epoch: 1, series: 71, nllk loss: -1.10394, kernel loss: 0.26993\n",
      "Epoch: 1, series: 72, nllk loss: -1.20119, kernel loss: 0.05096\n",
      "Epoch: 1, series: 73, nllk loss: -0.87102, kernel loss: 0.41421\n",
      "Epoch: 1, series: 74, nllk loss: -1.22664, kernel loss: 0.08854\n",
      "Epoch: 1, series: 75, nllk loss: -1.08643, kernel loss: 0.34546\n",
      "Epoch: 1, series: 76, nllk loss: -1.06928, kernel loss: 0.12194\n",
      "Epoch: 1, series: 77, nllk loss: -0.69710, kernel loss: 0.19118\n",
      "Epoch: 1, series: 78, nllk loss: -1.02841, kernel loss: 0.46483\n",
      "Epoch: 1, series: 79, nllk loss: -0.53481, kernel loss: 0.16686\n",
      "Epoch: 1, series: 80, nllk loss: -1.34446, kernel loss: 0.10491\n",
      "Epoch: 1, series: 81, nllk loss: -0.99528, kernel loss: 0.20886\n",
      "Epoch: 1, series: 82, nllk loss: -0.15166, kernel loss: 0.35981\n",
      "Epoch: 1, series: 83, nllk loss: -0.39758, kernel loss: 0.34152\n",
      "Epoch: 1, series: 84, nllk loss: -0.79815, kernel loss: 0.41068\n",
      "Epoch: 1, series: 85, nllk loss: -0.78535, kernel loss: 0.35633\n",
      "Epoch: 1, series: 86, nllk loss: -0.07263, kernel loss: 0.09297\n",
      "Epoch: 1, series: 87, nllk loss: -1.33995, kernel loss: 0.26631\n",
      "Epoch: 1, series: 88, nllk loss: -1.45394, kernel loss: 0.37452\n",
      "Epoch: 1, series: 89, nllk loss: -1.46734, kernel loss: 0.22694\n",
      "Epoch: 1, series: 90, nllk loss: -1.36220, kernel loss: 0.26018\n",
      "Epoch: 1, series: 91, nllk loss: -1.36669, kernel loss: 0.19634\n",
      "Epoch: 1, series: 92, nllk loss: -0.08839, kernel loss: 0.15880\n",
      "Epoch: 1, series: 93, nllk loss: -1.42324, kernel loss: 0.73432\n",
      "Epoch: 1, series: 94, nllk loss: -1.55611, kernel loss: 0.52186\n",
      "Epoch: 1, series: 95, nllk loss: -1.62045, kernel loss: 0.36973\n",
      "Epoch: 1, series: 96, nllk loss: -1.19028, kernel loss: 0.62203\n",
      "Epoch: 1, series: 97, nllk loss: -0.48780, kernel loss: 0.43120\n",
      "Epoch: 1, series: 98, nllk loss: -0.42307, kernel loss: 0.44019\n",
      "Epoch: 1, series: 99, nllk loss: -0.84233, kernel loss: 0.19378\n",
      "Epoch: 1, series: 100, nllk loss: -0.62317, kernel loss: 0.33831\n",
      "Epoch: 1, series: 101, nllk loss: -0.80286, kernel loss: 0.35670\n",
      "Epoch: 1, series: 102, nllk loss: -0.77950, kernel loss: 0.25721\n",
      "Epoch: 1, series: 103, nllk loss: -0.98653, kernel loss: 0.28713\n",
      "Epoch: 1, series: 104, nllk loss: 0.43871, kernel loss: 0.38060\n",
      "Epoch: 1, series: 105, nllk loss: 0.30443, kernel loss: 0.24242\n",
      "Epoch: 1, series: 106, nllk loss: -0.83845, kernel loss: 0.23367\n",
      "Epoch: 1, series: 107, nllk loss: -0.71161, kernel loss: 0.26844\n",
      "Epoch: 1, series: 108, nllk loss: -0.85628, kernel loss: 0.27275\n",
      "Epoch: 1, series: 109, nllk loss: -0.13488, kernel loss: 0.31719\n",
      "Epoch: 1, series: 110, nllk loss: -0.88188, kernel loss: 0.48396\n",
      "Epoch: 1, series: 111, nllk loss: -0.85312, kernel loss: 0.44064\n",
      "Epoch: 1, series: 112, nllk loss: -0.37945, kernel loss: 0.10520\n",
      "Epoch: 1, series: 113, nllk loss: -0.78618, kernel loss: 0.25840\n",
      "Epoch: 1, series: 114, nllk loss: -0.46226, kernel loss: 0.53784\n",
      "Epoch: 1, series: 115, nllk loss: -0.49157, kernel loss: 0.26610\n",
      "Epoch: 1, series: 116, nllk loss: -1.27594, kernel loss: 0.40229\n",
      "Epoch: 1, series: 117, nllk loss: -0.52200, kernel loss: 0.35269\n",
      "Epoch: 1, series: 118, nllk loss: -1.35051, kernel loss: 0.37830\n",
      "Epoch: 1, series: 119, nllk loss: -0.58568, kernel loss: 0.30411\n",
      "Epoch: 1, series: 120, nllk loss: -1.21538, kernel loss: 0.04412\n",
      "Epoch: 1, series: 121, nllk loss: -0.02055, kernel loss: 0.47746\n",
      "Epoch: 1, series: 122, nllk loss: -0.37724, kernel loss: 0.68886\n",
      "Epoch: 1, series: 123, nllk loss: -1.11215, kernel loss: 0.68453\n",
      "Epoch: 1, series: 124, nllk loss: -1.21124, kernel loss: 0.43372\n",
      "Epoch: 1, series: 125, nllk loss: -1.17818, kernel loss: 0.22373\n",
      "Epoch: 1, series: 126, nllk loss: -1.12105, kernel loss: 0.55546\n",
      "Epoch: 1, series: 127, nllk loss: -1.32227, kernel loss: 0.21943\n",
      "Epoch: 1, series: 128, nllk loss: -0.78241, kernel loss: 0.34335\n",
      "Epoch: 1, series: 129, nllk loss: -0.56346, kernel loss: 0.25474\n",
      "Epoch: 1, series: 130, nllk loss: -0.88191, kernel loss: 0.27539\n",
      "Epoch: 1, series: 131, nllk loss: 0.32004, kernel loss: 0.13841\n",
      "Epoch: 1, series: 132, nllk loss: -0.02311, kernel loss: 0.19261\n",
      "Epoch: 1, series: 133, nllk loss: -0.74533, kernel loss: 0.16996\n",
      "Epoch: 1, series: 134, nllk loss: -0.73287, kernel loss: 0.13296\n",
      "Epoch: 1, series: 135, nllk loss: -1.15817, kernel loss: 0.03535\n",
      "Epoch: 1, series: 136, nllk loss: -1.06403, kernel loss: 0.26899\n",
      "Epoch: 1, series: 137, nllk loss: -1.28825, kernel loss: 0.30098\n",
      "Epoch: 1, series: 138, nllk loss: -1.34751, kernel loss: 0.16785\n",
      "Epoch: 1, series: 139, nllk loss: -1.17912, kernel loss: 0.15779\n",
      "Epoch: 1, series: 140, nllk loss: -1.10892, kernel loss: 0.19215\n",
      "Epoch: 1, series: 141, nllk loss: -1.28898, kernel loss: 0.38813\n",
      "Epoch: 1, series: 142, nllk loss: -1.01157, kernel loss: 0.08789\n",
      "Epoch: 1, series: 143, nllk loss: -1.27316, kernel loss: 0.31511\n",
      "Epoch: 1, series: 144, nllk loss: -1.30173, kernel loss: 0.14528\n",
      "Epoch: 1, series: 145, nllk loss: -1.29386, kernel loss: 0.31078\n",
      "Epoch: 1, series: 146, nllk loss: 3.23175, kernel loss: 0.17858\n",
      "Epoch: 1, series: 147, nllk loss: -1.15530, kernel loss: 0.09910\n",
      "Epoch: 1, series: 148, nllk loss: -0.89008, kernel loss: 0.22305\n",
      "Epoch: 1, series: 149, nllk loss: -1.21190, kernel loss: 0.17049\n",
      "Epoch: 1, series: 150, nllk loss: -1.47572, kernel loss: 0.20810\n",
      "Epoch: 1, series: 151, nllk loss: -1.49535, kernel loss: 0.14371\n",
      "Epoch: 1, series: 152, nllk loss: -1.37997, kernel loss: 0.14411\n",
      "Epoch: 1, series: 153, nllk loss: -1.40297, kernel loss: 0.14390\n",
      "Epoch: 1, series: 154, nllk loss: -1.15288, kernel loss: 0.55242\n",
      "Epoch: 1, series: 155, nllk loss: -1.34661, kernel loss: 0.18498\n",
      "Epoch: 1, series: 156, nllk loss: -1.33168, kernel loss: 0.24771\n",
      "Epoch: 1, series: 157, nllk loss: -1.12826, kernel loss: 0.24481\n",
      "Epoch: 1, series: 158, nllk loss: -1.40195, kernel loss: 0.20685\n",
      "Epoch: 1, series: 159, nllk loss: -1.46434, kernel loss: 0.19241\n",
      "Epoch: 1, series: 160, nllk loss: -1.42264, kernel loss: 0.16334\n",
      "Epoch: 1, series: 161, nllk loss: -1.52596, kernel loss: 0.34755\n",
      "Epoch: 1, series: 162, nllk loss: -1.23434, kernel loss: 0.10002\n",
      "Epoch: 1, series: 163, nllk loss: -1.69881, kernel loss: 0.09120\n",
      "Epoch: 1, series: 164, nllk loss: -1.38727, kernel loss: 0.17108\n",
      "Epoch: 1, series: 165, nllk loss: -1.59347, kernel loss: 0.30219\n",
      "Epoch: 1, series: 166, nllk loss: -0.97884, kernel loss: 0.51692\n",
      "Epoch: 1, series: 167, nllk loss: -1.67885, kernel loss: 0.10224\n",
      "Epoch: 1, series: 168, nllk loss: -1.63550, kernel loss: 0.11853\n",
      "Epoch: 1, series: 169, nllk loss: -1.77453, kernel loss: 0.25871\n",
      "Epoch: 1, series: 170, nllk loss: -1.48157, kernel loss: 0.04768\n",
      "Epoch: 1, series: 171, nllk loss: -1.66653, kernel loss: 0.10102\n",
      "Epoch: 1, series: 172, nllk loss: -1.62952, kernel loss: 0.33078\n",
      "Epoch: 1, series: 173, nllk loss: -1.99573, kernel loss: 0.08391\n",
      "Epoch: 1, series: 174, nllk loss: -1.51234, kernel loss: 0.09559\n",
      "Epoch: 1, series: 175, nllk loss: -1.78912, kernel loss: 0.22069\n",
      "Epoch: 1, series: 176, nllk loss: -1.89814, kernel loss: 0.19668\n",
      "Epoch: 1, series: 177, nllk loss: -1.11958, kernel loss: 0.09038\n",
      "Epoch: 1, series: 178, nllk loss: -1.18452, kernel loss: 0.21229\n",
      "Epoch: 1, series: 179, nllk loss: -1.53610, kernel loss: 0.22345\n",
      "Epoch: 1, series: 180, nllk loss: -1.60890, kernel loss: 0.25534\n",
      "Epoch: 1, series: 181, nllk loss: -1.86820, kernel loss: 0.14976\n",
      "Epoch: 1, series: 182, nllk loss: -1.72034, kernel loss: 0.09494\n",
      "Epoch: 1, series: 183, nllk loss: -1.67139, kernel loss: 0.23479\n",
      "Epoch: 1, series: 184, nllk loss: -1.44951, kernel loss: 0.31762\n",
      "Epoch: 1, series: 185, nllk loss: -1.59657, kernel loss: 0.24552\n",
      "Epoch: 1, series: 186, nllk loss: -1.72542, kernel loss: 0.06657\n",
      "Epoch: 1, series: 187, nllk loss: -1.83413, kernel loss: 0.24575\n",
      "Epoch: 1, series: 188, nllk loss: -1.13156, kernel loss: 0.07833\n",
      "Epoch: 1, series: 189, nllk loss: -1.24937, kernel loss: 0.34145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, series: 190, nllk loss: -1.61778, kernel loss: 0.14060\n",
      "Epoch: 1, series: 191, nllk loss: -1.67327, kernel loss: 0.20001\n",
      "Epoch: 1, series: 192, nllk loss: -1.58131, kernel loss: 0.27935\n",
      "Epoch: 1, series: 193, nllk loss: -1.24695, kernel loss: 0.19415\n",
      "Epoch: 1, series: 194, nllk loss: -0.95943, kernel loss: 0.09121\n",
      "Epoch: 1, series: 195, nllk loss: -1.80704, kernel loss: 0.28123\n",
      "Epoch: 1, series: 196, nllk loss: -1.50130, kernel loss: 0.43272\n",
      "Epoch: 1, series: 197, nllk loss: -1.56265, kernel loss: 0.17646\n",
      "Epoch: 1, series: 198, nllk loss: -1.68981, kernel loss: 0.46544\n",
      "Epoch: 1, series: 199, nllk loss: -1.62898, kernel loss: 0.18592\n",
      "Epoch: 1, series: 200, nllk loss: -1.57837, kernel loss: 0.10284\n",
      "Epoch: 1, series: 201, nllk loss: -1.74762, kernel loss: 0.27062\n",
      "Epoch: 1, series: 202, nllk loss: -1.54053, kernel loss: 0.10139\n",
      "Epoch: 1, series: 203, nllk loss: -1.67652, kernel loss: 0.09341\n",
      "Epoch: 1, series: 204, nllk loss: -0.93435, kernel loss: 0.23675\n",
      "Epoch: 1, series: 205, nllk loss: -1.50690, kernel loss: 0.07651\n",
      "Epoch: 1, series: 206, nllk loss: -1.79845, kernel loss: 0.27813\n",
      "Epoch: 1, series: 207, nllk loss: -1.07396, kernel loss: 0.24414\n",
      "Epoch: 1, series: 208, nllk loss: -1.89606, kernel loss: 0.08520\n",
      "Epoch: 1, series: 209, nllk loss: -1.34898, kernel loss: 0.01557\n",
      "Epoch: 1, series: 210, nllk loss: -1.97813, kernel loss: 0.04324\n",
      "Epoch: 1, series: 211, nllk loss: -1.79928, kernel loss: 0.06639\n",
      "Epoch: 1, series: 212, nllk loss: -1.35935, kernel loss: 0.26268\n",
      "Epoch: 1, series: 213, nllk loss: -1.84826, kernel loss: 0.14556\n",
      "Epoch: 1, series: 214, nllk loss: -1.59613, kernel loss: 0.11326\n",
      "Epoch: 1, series: 215, nllk loss: -1.75748, kernel loss: 0.09117\n",
      "Epoch: 1, series: 216, nllk loss: -0.95672, kernel loss: 0.27833\n",
      "Epoch: 1, series: 217, nllk loss: -1.25383, kernel loss: 0.29950\n",
      "Epoch: 1, series: 218, nllk loss: -1.26038, kernel loss: 0.11575\n",
      "Epoch: 1, series: 219, nllk loss: -1.45956, kernel loss: 0.10341\n",
      "Epoch: 1, series: 220, nllk loss: -1.69027, kernel loss: 0.04137\n",
      "Epoch: 1, series: 221, nllk loss: -1.85877, kernel loss: 0.12405\n",
      "Epoch: 1, series: 222, nllk loss: -1.47804, kernel loss: 0.33988\n",
      "Epoch: 1, series: 223, nllk loss: -1.41432, kernel loss: 0.33285\n",
      "Epoch: 1, series: 224, nllk loss: -1.67101, kernel loss: 0.19693\n",
      "Epoch: 1, series: 225, nllk loss: -1.62458, kernel loss: 0.25932\n",
      "Epoch: 1, series: 226, nllk loss: -1.34014, kernel loss: 0.23519\n",
      "Epoch: 1, series: 227, nllk loss: -1.33382, kernel loss: 0.19784\n",
      "Epoch: 1, series: 228, nllk loss: -1.58668, kernel loss: 0.55299\n",
      "Epoch: 1, series: 229, nllk loss: -1.39933, kernel loss: 0.27911\n",
      "Epoch: 1, series: 230, nllk loss: -1.77690, kernel loss: 0.29119\n",
      "Epoch: 1, series: 231, nllk loss: -1.36684, kernel loss: 0.18364\n",
      "Epoch: 1, series: 232, nllk loss: -1.84032, kernel loss: 0.19751\n",
      "Epoch: 1, series: 233, nllk loss: -1.94501, kernel loss: 0.29791\n",
      "Epoch: 1, series: 234, nllk loss: -1.63649, kernel loss: 0.04277\n",
      "Epoch: 1, series: 235, nllk loss: -1.92530, kernel loss: 0.25022\n",
      "Epoch: 1, series: 236, nllk loss: -0.99522, kernel loss: 0.13412\n",
      "Epoch: 1, series: 237, nllk loss: -1.55042, kernel loss: 0.02336\n",
      "Epoch: 1, series: 238, nllk loss: -1.43969, kernel loss: 0.11384\n",
      "Epoch: 1, series: 239, nllk loss: -1.55309, kernel loss: 0.22637\n",
      "Epoch: 1, series: 240, nllk loss: -1.46737, kernel loss: 0.11129\n",
      "Epoch: 1, series: 241, nllk loss: -1.51433, kernel loss: 0.30496\n",
      "Epoch: 1, series: 242, nllk loss: -1.47126, kernel loss: 0.23082\n",
      "Epoch: 1, series: 243, nllk loss: -2.09331, kernel loss: 0.17861\n",
      "Epoch: 1, series: 244, nllk loss: -1.46768, kernel loss: 0.41258\n",
      "Epoch: 1, series: 245, nllk loss: -1.86183, kernel loss: 0.12174\n",
      "Epoch: 1, series: 246, nllk loss: -0.19467, kernel loss: 0.16616\n",
      "Epoch: 1, series: 247, nllk loss: -1.59546, kernel loss: 0.27368\n",
      "Epoch: 1, series: 248, nllk loss: -1.63718, kernel loss: 0.32057\n",
      "Epoch: 1, series: 249, nllk loss: -1.67025, kernel loss: 0.09679\n",
      "Epoch: 1, series: 250, nllk loss: -1.53617, kernel loss: 0.13984\n",
      "Epoch: 1, series: 251, nllk loss: -0.85631, kernel loss: 0.05901\n",
      "Epoch: 1, series: 252, nllk loss: -0.46494, kernel loss: 0.11514\n",
      "Epoch: 1, series: 253, nllk loss: -1.51508, kernel loss: 0.03210\n",
      "Epoch: 1, series: 254, nllk loss: -1.90394, kernel loss: 0.22645\n",
      "Epoch: 1, series: 255, nllk loss: -1.68907, kernel loss: 0.37026\n",
      "Epoch: 1, series: 256, nllk loss: -1.24078, kernel loss: 0.16947\n",
      "Epoch: 1, series: 257, nllk loss: -1.68346, kernel loss: 0.20088\n",
      "Epoch: 1, series: 258, nllk loss: -1.69295, kernel loss: 0.06042\n",
      "Epoch: 1, series: 259, nllk loss: -1.17396, kernel loss: 0.09317\n",
      "Epoch: 1, series: 260, nllk loss: -1.55637, kernel loss: 0.17751\n",
      "Epoch: 1, series: 261, nllk loss: -1.82178, kernel loss: 0.13857\n",
      "Epoch: 1, series: 262, nllk loss: -1.97745, kernel loss: 0.14689\n",
      "Epoch: 1, series: 263, nllk loss: -0.52748, kernel loss: 0.01767\n",
      "Epoch: 1, series: 264, nllk loss: -1.66426, kernel loss: 0.04221\n",
      "Epoch: 1, series: 265, nllk loss: -1.69154, kernel loss: 0.33476\n",
      "Epoch: 1, series: 266, nllk loss: -1.74352, kernel loss: 0.33056\n",
      "Epoch: 1, series: 267, nllk loss: -1.77811, kernel loss: 0.07284\n",
      "Epoch: 1, series: 268, nllk loss: -1.82784, kernel loss: 0.30723\n",
      "Epoch: 1, series: 269, nllk loss: -1.14641, kernel loss: 0.17856\n",
      "Epoch: 1, series: 270, nllk loss: -1.38869, kernel loss: 0.11207\n",
      "Epoch: 1, series: 271, nllk loss: -1.38975, kernel loss: 0.38571\n",
      "Epoch: 1, series: 272, nllk loss: -1.74182, kernel loss: 0.01230\n",
      "Epoch: 1, series: 273, nllk loss: -1.69857, kernel loss: 0.14054\n",
      "Epoch: 1, series: 274, nllk loss: -1.12382, kernel loss: 0.24904\n",
      "Epoch: 1, series: 275, nllk loss: -1.46099, kernel loss: 0.07320\n",
      "Epoch: 1, series: 276, nllk loss: -0.73468, kernel loss: 0.05380\n",
      "Epoch: 1, series: 277, nllk loss: -1.83881, kernel loss: 0.23864\n",
      "Epoch: 1, series: 278, nllk loss: -1.55950, kernel loss: 0.25219\n",
      "Epoch: 1, series: 279, nllk loss: -1.86141, kernel loss: 0.29146\n",
      "Epoch: 1, series: 280, nllk loss: -1.72787, kernel loss: 0.25346\n",
      "Epoch: 1, series: 281, nllk loss: -1.86084, kernel loss: 0.18303\n",
      "Epoch: 1, series: 282, nllk loss: -1.79329, kernel loss: 0.00000\n",
      "Epoch: 1, series: 283, nllk loss: -1.68904, kernel loss: 0.06752\n",
      "Epoch: 1, series: 284, nllk loss: -1.60284, kernel loss: 0.06163\n",
      "Epoch: 1, series: 285, nllk loss: -1.66138, kernel loss: 0.29938\n",
      "Epoch: 1, series: 286, nllk loss: -1.76542, kernel loss: 0.29404\n",
      "Epoch: 1, series: 287, nllk loss: -2.07421, kernel loss: 0.06679\n",
      "Epoch: 1, series: 288, nllk loss: -0.89014, kernel loss: 0.21960\n",
      "Epoch: 1, series: 289, nllk loss: -0.72237, kernel loss: 0.22338\n",
      "Epoch: 1, series: 290, nllk loss: -1.86467, kernel loss: 0.42508\n",
      "Epoch: 1, series: 291, nllk loss: -1.96279, kernel loss: 0.29528\n",
      "Epoch: 1, series: 292, nllk loss: -2.13384, kernel loss: 0.05950\n",
      "Epoch: 1, series: 293, nllk loss: -2.04385, kernel loss: 0.31063\n",
      "Epoch: 1, series: 294, nllk loss: -1.29625, kernel loss: 0.22258\n",
      "Epoch: 1, series: 295, nllk loss: -1.08000, kernel loss: 0.17132\n",
      "Epoch: 1, series: 296, nllk loss: -2.14830, kernel loss: 0.02230\n",
      "Epoch: 1, series: 297, nllk loss: -2.07895, kernel loss: 0.09599\n",
      "Epoch: 1, series: 298, nllk loss: 4.44449, kernel loss: 0.29930\n",
      "Epoch: 1, series: 299, nllk loss: 5.07777, kernel loss: 0.63972\n",
      "Epoch: 1, series: 300, nllk loss: -1.07839, kernel loss: 0.34817\n",
      "Epoch: 1, series: 301, nllk loss: -0.84629, kernel loss: 0.26409\n",
      "Epoch: 1, series: 302, nllk loss: -1.06485, kernel loss: 0.19894\n",
      "Epoch: 1, series: 303, nllk loss: -1.11558, kernel loss: 0.45469\n",
      "Epoch: 1, series: 304, nllk loss: -0.78220, kernel loss: 0.32859\n",
      "Epoch: 1, series: 305, nllk loss: -0.71236, kernel loss: 0.43709\n",
      "Epoch: 1, series: 306, nllk loss: -1.10300, kernel loss: 0.44676\n",
      "Epoch: 1, series: 307, nllk loss: -0.83298, kernel loss: 0.19886\n",
      "Epoch: 1, series: 308, nllk loss: -0.97464, kernel loss: 0.43899\n",
      "Epoch: 1, series: 309, nllk loss: -0.89079, kernel loss: 0.37288\n",
      "Epoch: 1, series: 310, nllk loss: -0.90576, kernel loss: 0.55497\n",
      "Epoch: 1, series: 311, nllk loss: -0.72551, kernel loss: 0.16272\n",
      "Epoch: 1, series: 312, nllk loss: -0.94554, kernel loss: 0.27407\n",
      "Epoch: 1, series: 313, nllk loss: -1.09696, kernel loss: 0.18175\n",
      "Epoch: 1, series: 314, nllk loss: -1.19028, kernel loss: 0.14837\n",
      "Epoch: 1, series: 315, nllk loss: -0.63716, kernel loss: 0.33531\n",
      "Epoch: 1, series: 316, nllk loss: -0.75779, kernel loss: 0.29337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, series: 317, nllk loss: 0.28790, kernel loss: 0.39556\n",
      "Epoch: 1, series: 318, nllk loss: 0.69770, kernel loss: 0.80396\n",
      "Epoch: 1, series: 319, nllk loss: -0.54191, kernel loss: 0.30771\n",
      "Epoch: 1, series: 320, nllk loss: -0.60527, kernel loss: 0.30995\n",
      "Epoch: 1, total loss: -262.64288\n",
      "Epoch: 2, series: 0, nllk loss: 1.70096, kernel loss: 0.31284\n",
      "Epoch: 2, series: 1, nllk loss: -0.34425, kernel loss: 0.22107\n",
      "Epoch: 2, series: 2, nllk loss: 0.26324, kernel loss: 0.22529\n",
      "Epoch: 2, series: 3, nllk loss: -0.52933, kernel loss: 0.21822\n",
      "Epoch: 2, series: 4, nllk loss: -0.42558, kernel loss: 0.28144\n",
      "Epoch: 2, series: 5, nllk loss: -0.47674, kernel loss: 0.11464\n",
      "Epoch: 2, series: 6, nllk loss: -0.20461, kernel loss: 0.17497\n",
      "Epoch: 2, series: 7, nllk loss: -0.46911, kernel loss: 0.14931\n",
      "Epoch: 2, series: 8, nllk loss: -0.06273, kernel loss: 0.22975\n",
      "Epoch: 2, series: 9, nllk loss: -0.28472, kernel loss: 0.25910\n",
      "Epoch: 2, series: 10, nllk loss: -0.59055, kernel loss: 0.17599\n",
      "Epoch: 2, series: 11, nllk loss: -0.64170, kernel loss: 0.21062\n",
      "Epoch: 2, series: 12, nllk loss: -0.87283, kernel loss: 0.16190\n",
      "Epoch: 2, series: 13, nllk loss: -0.56332, kernel loss: 0.18879\n",
      "Epoch: 2, series: 14, nllk loss: -0.74396, kernel loss: 0.38325\n",
      "Epoch: 2, series: 15, nllk loss: -0.75832, kernel loss: 0.12904\n",
      "Epoch: 2, series: 16, nllk loss: -0.59994, kernel loss: 0.37407\n",
      "Epoch: 2, series: 17, nllk loss: -0.62324, kernel loss: 0.40123\n",
      "Epoch: 2, series: 18, nllk loss: -0.78886, kernel loss: 0.10419\n",
      "Epoch: 2, series: 19, nllk loss: -0.14734, kernel loss: 0.38884\n",
      "Epoch: 2, series: 20, nllk loss: -0.32345, kernel loss: 0.14399\n",
      "Epoch: 2, series: 21, nllk loss: -0.66942, kernel loss: 0.15175\n",
      "Epoch: 2, series: 22, nllk loss: -0.83897, kernel loss: 0.68131\n",
      "Epoch: 2, series: 23, nllk loss: -0.80750, kernel loss: 0.44008\n",
      "Epoch: 2, series: 24, nllk loss: -0.93186, kernel loss: 0.30751\n",
      "Epoch: 2, series: 25, nllk loss: -0.85407, kernel loss: 0.24804\n",
      "Epoch: 2, series: 26, nllk loss: -0.78485, kernel loss: 0.34935\n",
      "Epoch: 2, series: 27, nllk loss: -0.78708, kernel loss: 0.04086\n",
      "Epoch: 2, series: 28, nllk loss: -0.85323, kernel loss: 0.27007\n",
      "Epoch: 2, series: 29, nllk loss: -0.50681, kernel loss: 0.06177\n",
      "Epoch: 2, series: 30, nllk loss: -0.79316, kernel loss: 0.16737\n",
      "Epoch: 2, series: 31, nllk loss: -0.86149, kernel loss: 0.29353\n",
      "Epoch: 2, series: 32, nllk loss: -0.84338, kernel loss: 0.19217\n",
      "Epoch: 2, series: 33, nllk loss: -0.78187, kernel loss: 0.33786\n",
      "Epoch: 2, series: 34, nllk loss: -0.97749, kernel loss: 0.09354\n",
      "Epoch: 2, series: 35, nllk loss: -0.99499, kernel loss: 0.14101\n",
      "Epoch: 2, series: 36, nllk loss: -1.12113, kernel loss: 0.09631\n",
      "Epoch: 2, series: 37, nllk loss: -0.34494, kernel loss: 0.33133\n",
      "Epoch: 2, series: 38, nllk loss: -0.88394, kernel loss: 0.37777\n",
      "Epoch: 2, series: 39, nllk loss: -0.51339, kernel loss: 0.17592\n",
      "Epoch: 2, series: 40, nllk loss: -1.29242, kernel loss: 0.06159\n",
      "Epoch: 2, series: 41, nllk loss: -0.99480, kernel loss: 0.41019\n",
      "Epoch: 2, series: 42, nllk loss: -0.94855, kernel loss: 0.19320\n",
      "Epoch: 2, series: 43, nllk loss: -0.69045, kernel loss: 0.10318\n",
      "Epoch: 2, series: 44, nllk loss: -0.94556, kernel loss: 0.26487\n",
      "Epoch: 2, series: 45, nllk loss: -1.26864, kernel loss: 0.07967\n",
      "Epoch: 2, series: 46, nllk loss: -1.23248, kernel loss: 0.26602\n",
      "Epoch: 2, series: 47, nllk loss: -1.02895, kernel loss: 0.20983\n",
      "Epoch: 2, series: 48, nllk loss: -1.25330, kernel loss: 0.11037\n",
      "Epoch: 2, series: 49, nllk loss: -0.89408, kernel loss: 0.35143\n",
      "Epoch: 2, series: 50, nllk loss: -0.10742, kernel loss: 0.26121\n",
      "Epoch: 2, series: 51, nllk loss: -1.13801, kernel loss: 0.17193\n",
      "Epoch: 2, series: 52, nllk loss: -0.47098, kernel loss: 0.22044\n",
      "Epoch: 2, series: 53, nllk loss: -1.27891, kernel loss: 0.18108\n",
      "Epoch: 2, series: 54, nllk loss: -1.07535, kernel loss: 0.29036\n",
      "Epoch: 2, series: 55, nllk loss: -0.74618, kernel loss: 0.49647\n",
      "Epoch: 2, series: 56, nllk loss: -1.12380, kernel loss: 0.12344\n",
      "Epoch: 2, series: 57, nllk loss: -0.94248, kernel loss: 0.07897\n",
      "Epoch: 2, series: 58, nllk loss: -0.94437, kernel loss: 0.24484\n",
      "Epoch: 2, series: 59, nllk loss: -0.74187, kernel loss: 0.27934\n",
      "Epoch: 2, series: 60, nllk loss: -0.91953, kernel loss: 0.22935\n",
      "Epoch: 2, series: 61, nllk loss: -1.33033, kernel loss: 0.12504\n",
      "Epoch: 2, series: 62, nllk loss: -1.24829, kernel loss: 0.32129\n",
      "Epoch: 2, series: 63, nllk loss: -1.27516, kernel loss: 0.24556\n",
      "Epoch: 2, series: 64, nllk loss: -1.03209, kernel loss: 0.46870\n",
      "Epoch: 2, series: 65, nllk loss: -1.27476, kernel loss: 0.31293\n",
      "Epoch: 2, series: 66, nllk loss: -1.16389, kernel loss: 0.24478\n",
      "Epoch: 2, series: 67, nllk loss: -1.09259, kernel loss: 0.27440\n",
      "Epoch: 2, series: 68, nllk loss: -0.59352, kernel loss: 0.14010\n",
      "Epoch: 2, series: 69, nllk loss: -1.06829, kernel loss: 0.03055\n",
      "Epoch: 2, series: 70, nllk loss: -1.21465, kernel loss: 0.27515\n",
      "Epoch: 2, series: 71, nllk loss: -1.21211, kernel loss: 0.24511\n",
      "Epoch: 2, series: 72, nllk loss: -1.40370, kernel loss: 0.24157\n",
      "Epoch: 2, series: 73, nllk loss: -1.14314, kernel loss: 0.16183\n",
      "Epoch: 2, series: 74, nllk loss: -1.51622, kernel loss: 0.24849\n",
      "Epoch: 2, series: 75, nllk loss: -1.24973, kernel loss: 0.30260\n",
      "Epoch: 2, series: 76, nllk loss: -1.27127, kernel loss: 0.27907\n",
      "Epoch: 2, series: 77, nllk loss: -0.96960, kernel loss: 0.21166\n",
      "Epoch: 2, series: 78, nllk loss: -1.31500, kernel loss: 0.10484\n",
      "Epoch: 2, series: 79, nllk loss: -0.53625, kernel loss: 0.47352\n",
      "Epoch: 2, series: 80, nllk loss: -1.47559, kernel loss: 0.20669\n",
      "Epoch: 2, series: 81, nllk loss: -1.20738, kernel loss: 0.21108\n",
      "Epoch: 2, series: 82, nllk loss: -0.35132, kernel loss: 0.23909\n",
      "Epoch: 2, series: 83, nllk loss: -0.21787, kernel loss: 0.27197\n",
      "Epoch: 2, series: 84, nllk loss: -0.84614, kernel loss: 0.10742\n",
      "Epoch: 2, series: 85, nllk loss: -1.05321, kernel loss: 0.20065\n",
      "Epoch: 2, series: 86, nllk loss: -0.12649, kernel loss: 0.36266\n",
      "Epoch: 2, series: 87, nllk loss: -1.44458, kernel loss: 0.12146\n",
      "Epoch: 2, series: 88, nllk loss: -1.68572, kernel loss: 0.20600\n",
      "Epoch: 2, series: 89, nllk loss: -1.53222, kernel loss: 0.18853\n",
      "Epoch: 2, series: 90, nllk loss: -1.43188, kernel loss: 0.20985\n",
      "Epoch: 2, series: 91, nllk loss: -1.46768, kernel loss: 0.08990\n",
      "Epoch: 2, series: 92, nllk loss: 0.04977, kernel loss: 0.23093\n",
      "Epoch: 2, series: 93, nllk loss: -1.56448, kernel loss: 0.13629\n",
      "Epoch: 2, series: 94, nllk loss: -1.61489, kernel loss: 0.04893\n",
      "Epoch: 2, series: 95, nllk loss: -1.62379, kernel loss: 0.12700\n",
      "Epoch: 2, series: 96, nllk loss: -1.25895, kernel loss: 0.17550\n",
      "Epoch: 2, series: 97, nllk loss: -0.60043, kernel loss: 0.16471\n",
      "Epoch: 2, series: 98, nllk loss: -0.53266, kernel loss: 0.08346\n",
      "Epoch: 2, series: 99, nllk loss: -1.07585, kernel loss: 0.26385\n",
      "Epoch: 2, series: 100, nllk loss: -0.92156, kernel loss: 0.56842\n",
      "Epoch: 2, series: 101, nllk loss: -1.23131, kernel loss: 0.16649\n",
      "Epoch: 2, series: 102, nllk loss: -1.05992, kernel loss: 0.21745\n",
      "Epoch: 2, series: 103, nllk loss: -0.97210, kernel loss: 0.09668\n",
      "Epoch: 2, series: 104, nllk loss: 0.30190, kernel loss: 0.18992\n",
      "Epoch: 2, series: 105, nllk loss: 0.62545, kernel loss: 0.09476\n",
      "Epoch: 2, series: 106, nllk loss: -0.88073, kernel loss: 0.15655\n",
      "Epoch: 2, series: 107, nllk loss: -0.83187, kernel loss: 0.44193\n",
      "Epoch: 2, series: 108, nllk loss: -0.73926, kernel loss: 0.18937\n",
      "Epoch: 2, series: 109, nllk loss: 0.22933, kernel loss: 0.05731\n",
      "Epoch: 2, series: 110, nllk loss: -1.04407, kernel loss: 0.03771\n",
      "Epoch: 2, series: 111, nllk loss: -1.06556, kernel loss: 0.73192\n",
      "Epoch: 2, series: 112, nllk loss: -0.43913, kernel loss: 0.13804\n",
      "Epoch: 2, series: 113, nllk loss: -0.66615, kernel loss: 0.38547\n",
      "Epoch: 2, series: 114, nllk loss: -0.54349, kernel loss: 0.44732\n",
      "Epoch: 2, series: 115, nllk loss: -0.74143, kernel loss: 0.16240\n",
      "Epoch: 2, series: 116, nllk loss: -1.44359, kernel loss: 0.18430\n",
      "Epoch: 2, series: 117, nllk loss: -0.63588, kernel loss: 0.46664\n",
      "Epoch: 2, series: 118, nllk loss: -1.53840, kernel loss: 0.12261\n",
      "Epoch: 2, series: 119, nllk loss: -0.60214, kernel loss: 0.18720\n",
      "Epoch: 2, series: 120, nllk loss: -1.26182, kernel loss: 0.09217\n",
      "Epoch: 2, series: 121, nllk loss: 0.04103, kernel loss: 0.22000\n",
      "Epoch: 2, series: 122, nllk loss: -0.48525, kernel loss: 0.13330\n",
      "Epoch: 2, series: 123, nllk loss: -1.20547, kernel loss: 0.18993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, series: 124, nllk loss: -1.27020, kernel loss: 0.31732\n",
      "Epoch: 2, series: 125, nllk loss: -1.21273, kernel loss: 0.26851\n",
      "Epoch: 2, series: 126, nllk loss: -1.26651, kernel loss: 0.18226\n",
      "Epoch: 2, series: 127, nllk loss: -1.22798, kernel loss: 0.14645\n",
      "Epoch: 2, series: 128, nllk loss: -0.87459, kernel loss: 0.08261\n",
      "Epoch: 2, series: 129, nllk loss: -0.60253, kernel loss: 0.14901\n",
      "Epoch: 2, series: 130, nllk loss: -1.04095, kernel loss: 0.27713\n",
      "Epoch: 2, series: 131, nllk loss: 0.31901, kernel loss: 0.14754\n",
      "Epoch: 2, series: 132, nllk loss: -0.08416, kernel loss: 0.11134\n",
      "Epoch: 2, series: 133, nllk loss: -0.78771, kernel loss: 0.16246\n",
      "Epoch: 2, series: 134, nllk loss: -0.79159, kernel loss: 0.38068\n",
      "Epoch: 2, series: 135, nllk loss: -1.25510, kernel loss: 0.20808\n",
      "Epoch: 2, series: 136, nllk loss: -1.13664, kernel loss: 0.07195\n",
      "Epoch: 2, series: 137, nllk loss: -1.36946, kernel loss: 0.06246\n",
      "Epoch: 2, series: 138, nllk loss: -1.39700, kernel loss: 0.08142\n",
      "Epoch: 2, series: 139, nllk loss: -1.26208, kernel loss: 0.21898\n",
      "Epoch: 2, series: 140, nllk loss: -1.20938, kernel loss: 0.16853\n",
      "Epoch: 2, series: 141, nllk loss: -1.29844, kernel loss: 0.08163\n",
      "Epoch: 2, series: 142, nllk loss: -1.10040, kernel loss: 0.20501\n",
      "Epoch: 2, series: 143, nllk loss: -1.26094, kernel loss: 0.26367\n",
      "Epoch: 2, series: 144, nllk loss: -1.37096, kernel loss: 0.09184\n",
      "Epoch: 2, series: 145, nllk loss: -1.37198, kernel loss: 0.11047\n",
      "Epoch: 2, series: 146, nllk loss: 3.15379, kernel loss: 0.24050\n",
      "Epoch: 2, series: 147, nllk loss: -1.33970, kernel loss: 0.18367\n",
      "Epoch: 2, series: 148, nllk loss: -1.17777, kernel loss: 0.21654\n",
      "Epoch: 2, series: 149, nllk loss: -1.44093, kernel loss: 0.07024\n",
      "Epoch: 2, series: 150, nllk loss: -1.61527, kernel loss: 0.19520\n",
      "Epoch: 2, series: 151, nllk loss: -1.60697, kernel loss: 0.20335\n",
      "Epoch: 2, series: 152, nllk loss: -1.52111, kernel loss: 0.09520\n",
      "Epoch: 2, series: 153, nllk loss: -1.44170, kernel loss: 0.04923\n",
      "Epoch: 2, series: 154, nllk loss: -1.28711, kernel loss: 0.27761\n",
      "Epoch: 2, series: 155, nllk loss: -1.40348, kernel loss: 0.15278\n",
      "Epoch: 2, series: 156, nllk loss: -1.40000, kernel loss: 0.07697\n",
      "Epoch: 2, series: 157, nllk loss: -1.12475, kernel loss: 0.16378\n",
      "Epoch: 2, series: 158, nllk loss: -1.42919, kernel loss: 0.11471\n",
      "Epoch: 2, series: 159, nllk loss: -1.62840, kernel loss: 0.12214\n",
      "Epoch: 2, series: 160, nllk loss: -1.48488, kernel loss: 0.14578\n",
      "Epoch: 2, series: 161, nllk loss: -1.44172, kernel loss: 0.30796\n",
      "Epoch: 2, series: 162, nllk loss: -1.41736, kernel loss: 0.31897\n",
      "Epoch: 2, series: 163, nllk loss: -1.81433, kernel loss: 0.06644\n",
      "Epoch: 2, series: 164, nllk loss: -1.35469, kernel loss: 0.18066\n",
      "Epoch: 2, series: 165, nllk loss: -1.49646, kernel loss: 0.14996\n",
      "Epoch: 2, series: 166, nllk loss: -1.23150, kernel loss: 0.09897\n",
      "Epoch: 2, series: 167, nllk loss: -1.87314, kernel loss: 0.25195\n",
      "Epoch: 2, series: 168, nllk loss: -1.71523, kernel loss: 0.37902\n",
      "Epoch: 2, series: 169, nllk loss: -1.73660, kernel loss: 0.36885\n",
      "Epoch: 2, series: 170, nllk loss: -1.51856, kernel loss: 0.15934\n",
      "Epoch: 2, series: 171, nllk loss: -1.77572, kernel loss: 0.07972\n",
      "Epoch: 2, series: 172, nllk loss: -1.47383, kernel loss: 0.02705\n",
      "Epoch: 2, series: 173, nllk loss: -1.89777, kernel loss: 0.16462\n",
      "Epoch: 2, series: 174, nllk loss: -1.47762, kernel loss: 0.20775\n",
      "Epoch: 2, series: 175, nllk loss: -1.87351, kernel loss: 0.31210\n",
      "Epoch: 2, series: 176, nllk loss: -1.44360, kernel loss: 0.34779\n",
      "Epoch: 2, series: 177, nllk loss: -1.14549, kernel loss: 0.10949\n",
      "Epoch: 2, series: 178, nllk loss: -1.18633, kernel loss: 0.09745\n",
      "Epoch: 2, series: 179, nllk loss: -1.59953, kernel loss: 0.25447\n",
      "Epoch: 2, series: 180, nllk loss: -1.52800, kernel loss: 0.22834\n",
      "Epoch: 2, series: 181, nllk loss: -1.79685, kernel loss: 0.03138\n",
      "Epoch: 2, series: 182, nllk loss: -1.74325, kernel loss: 0.26017\n",
      "Epoch: 2, series: 183, nllk loss: -1.70740, kernel loss: 0.13558\n",
      "Epoch: 2, series: 184, nllk loss: -1.54369, kernel loss: 0.20028\n",
      "Epoch: 2, series: 185, nllk loss: -1.62471, kernel loss: 0.20070\n",
      "Epoch: 2, series: 186, nllk loss: -1.76736, kernel loss: 0.26643\n",
      "Epoch: 2, series: 187, nllk loss: -1.74452, kernel loss: 0.22318\n",
      "Epoch: 2, series: 188, nllk loss: -1.39356, kernel loss: 0.05117\n",
      "Epoch: 2, series: 189, nllk loss: -1.21098, kernel loss: 0.17108\n",
      "Epoch: 2, series: 190, nllk loss: -1.47151, kernel loss: 0.01993\n",
      "Epoch: 2, series: 191, nllk loss: -1.51451, kernel loss: 0.33514\n",
      "Epoch: 2, series: 192, nllk loss: -1.78659, kernel loss: 0.16766\n",
      "Epoch: 2, series: 193, nllk loss: -1.30265, kernel loss: 0.18064\n",
      "Epoch: 2, series: 194, nllk loss: -1.10673, kernel loss: 0.10586\n",
      "Epoch: 2, series: 195, nllk loss: -1.77185, kernel loss: 0.21473\n",
      "Epoch: 2, series: 196, nllk loss: -1.42659, kernel loss: 0.07719\n",
      "Epoch: 2, series: 197, nllk loss: -1.68110, kernel loss: 0.22090\n",
      "Epoch: 2, series: 198, nllk loss: -1.77954, kernel loss: 0.31351\n",
      "Epoch: 2, series: 199, nllk loss: -1.60387, kernel loss: 0.15907\n",
      "Epoch: 2, series: 200, nllk loss: -1.66731, kernel loss: 0.24100\n",
      "Epoch: 2, series: 201, nllk loss: -1.85507, kernel loss: 0.22187\n",
      "Epoch: 2, series: 202, nllk loss: -1.60375, kernel loss: 0.01960\n",
      "Epoch: 2, series: 203, nllk loss: -1.67495, kernel loss: 0.27818\n",
      "Epoch: 2, series: 204, nllk loss: -0.79902, kernel loss: 0.14792\n",
      "Epoch: 2, series: 205, nllk loss: -1.60703, kernel loss: 0.11023\n",
      "Epoch: 2, series: 206, nllk loss: -1.74661, kernel loss: 0.10485\n",
      "Epoch: 2, series: 207, nllk loss: -1.09029, kernel loss: 0.19846\n",
      "Epoch: 2, series: 208, nllk loss: -1.96571, kernel loss: 0.12547\n",
      "Epoch: 2, series: 209, nllk loss: -1.43379, kernel loss: 0.14357\n",
      "Epoch: 2, series: 210, nllk loss: -2.02479, kernel loss: 0.12356\n",
      "Epoch: 2, series: 211, nllk loss: -1.90471, kernel loss: 0.29327\n",
      "Epoch: 2, series: 212, nllk loss: -1.46484, kernel loss: 0.39227\n",
      "Epoch: 2, series: 213, nllk loss: -1.78359, kernel loss: 0.10125\n",
      "Epoch: 2, series: 214, nllk loss: -1.62544, kernel loss: 0.29212\n",
      "Epoch: 2, series: 215, nllk loss: -2.02333, kernel loss: 0.28993\n",
      "Epoch: 2, series: 216, nllk loss: -1.13605, kernel loss: 0.22992\n",
      "Epoch: 2, series: 217, nllk loss: -1.33852, kernel loss: 0.23806\n",
      "Epoch: 2, series: 218, nllk loss: -1.27313, kernel loss: 0.44836\n",
      "Epoch: 2, series: 219, nllk loss: -1.65814, kernel loss: 0.02614\n",
      "Epoch: 2, series: 220, nllk loss: -1.57577, kernel loss: 0.21134\n",
      "Epoch: 2, series: 221, nllk loss: -1.90745, kernel loss: 0.07795\n",
      "Epoch: 2, series: 222, nllk loss: -1.74041, kernel loss: 0.10301\n",
      "Epoch: 2, series: 223, nllk loss: -1.43368, kernel loss: 0.12458\n",
      "Epoch: 2, series: 224, nllk loss: -1.85524, kernel loss: 0.20183\n",
      "Epoch: 2, series: 225, nllk loss: -1.65034, kernel loss: 0.20315\n",
      "Epoch: 2, series: 226, nllk loss: -1.40858, kernel loss: 0.20480\n",
      "Epoch: 2, series: 227, nllk loss: -1.46764, kernel loss: 0.19832\n",
      "Epoch: 2, series: 228, nllk loss: -1.50187, kernel loss: 0.02644\n",
      "Epoch: 2, series: 229, nllk loss: -1.46625, kernel loss: 0.07879\n",
      "Epoch: 2, series: 230, nllk loss: -1.95634, kernel loss: 0.16566\n",
      "Epoch: 2, series: 231, nllk loss: -1.54853, kernel loss: 0.19808\n",
      "Epoch: 2, series: 232, nllk loss: -1.97087, kernel loss: 0.13003\n",
      "Epoch: 2, series: 233, nllk loss: -1.92239, kernel loss: 0.36844\n",
      "Epoch: 2, series: 234, nllk loss: -1.65382, kernel loss: 0.36905\n",
      "Epoch: 2, series: 235, nllk loss: -2.03702, kernel loss: 0.09006\n",
      "Epoch: 2, series: 236, nllk loss: -0.96819, kernel loss: 0.21763\n",
      "Epoch: 2, series: 237, nllk loss: -1.65570, kernel loss: 0.16180\n",
      "Epoch: 2, series: 238, nllk loss: -1.49060, kernel loss: 0.10845\n",
      "Epoch: 2, series: 239, nllk loss: -1.70014, kernel loss: 0.33730\n",
      "Epoch: 2, series: 240, nllk loss: -1.50700, kernel loss: 0.27858\n",
      "Epoch: 2, series: 241, nllk loss: -1.45351, kernel loss: 0.17352\n",
      "Epoch: 2, series: 242, nllk loss: -1.65707, kernel loss: 0.27969\n",
      "Epoch: 2, series: 243, nllk loss: -2.05533, kernel loss: 0.15051\n",
      "Epoch: 2, series: 244, nllk loss: -1.51745, kernel loss: 0.15354\n",
      "Epoch: 2, series: 245, nllk loss: -1.88033, kernel loss: 0.05133\n",
      "Epoch: 2, series: 246, nllk loss: -0.04184, kernel loss: 0.17410\n",
      "Epoch: 2, series: 247, nllk loss: -1.60643, kernel loss: 0.24172\n",
      "Epoch: 2, series: 248, nllk loss: -1.61689, kernel loss: 0.09342\n",
      "Epoch: 2, series: 249, nllk loss: -1.69595, kernel loss: 0.09428\n",
      "Epoch: 2, series: 250, nllk loss: -1.59745, kernel loss: 0.00911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, series: 251, nllk loss: -0.91372, kernel loss: 0.12592\n",
      "Epoch: 2, series: 252, nllk loss: -0.62679, kernel loss: 0.17056\n",
      "Epoch: 2, series: 253, nllk loss: -1.52033, kernel loss: 0.13720\n",
      "Epoch: 2, series: 254, nllk loss: -1.91248, kernel loss: 0.27705\n",
      "Epoch: 2, series: 255, nllk loss: -1.76988, kernel loss: 0.04529\n",
      "Epoch: 2, series: 256, nllk loss: -1.40861, kernel loss: 0.07824\n",
      "Epoch: 2, series: 257, nllk loss: -1.71696, kernel loss: 0.37706\n",
      "Epoch: 2, series: 258, nllk loss: -1.75454, kernel loss: 0.07326\n",
      "Epoch: 2, series: 259, nllk loss: -1.33312, kernel loss: 0.14020\n",
      "Epoch: 2, series: 260, nllk loss: -1.57041, kernel loss: 0.15860\n",
      "Epoch: 2, series: 261, nllk loss: -1.87928, kernel loss: 0.07013\n",
      "Epoch: 2, series: 262, nllk loss: -1.97539, kernel loss: 0.28346\n",
      "Epoch: 2, series: 263, nllk loss: -0.54498, kernel loss: 0.16046\n",
      "Epoch: 2, series: 264, nllk loss: -1.67314, kernel loss: 0.23632\n",
      "Epoch: 2, series: 265, nllk loss: -1.77240, kernel loss: 0.15681\n",
      "Epoch: 2, series: 266, nllk loss: -1.78362, kernel loss: 0.18337\n",
      "Epoch: 2, series: 267, nllk loss: -1.79023, kernel loss: 0.02505\n",
      "Epoch: 2, series: 268, nllk loss: -1.80893, kernel loss: 0.28878\n",
      "Epoch: 2, series: 269, nllk loss: -1.24234, kernel loss: 0.29085\n",
      "Epoch: 2, series: 270, nllk loss: -1.51360, kernel loss: 0.11159\n",
      "Epoch: 2, series: 271, nllk loss: -1.67542, kernel loss: 0.13816\n",
      "Epoch: 2, series: 272, nllk loss: -1.64474, kernel loss: 0.28767\n",
      "Epoch: 2, series: 273, nllk loss: -1.83197, kernel loss: 0.25574\n",
      "Epoch: 2, series: 274, nllk loss: -1.39663, kernel loss: 0.11441\n",
      "Epoch: 2, series: 275, nllk loss: -1.70796, kernel loss: 0.14112\n",
      "Epoch: 2, series: 276, nllk loss: -0.88648, kernel loss: 0.12468\n",
      "Epoch: 2, series: 277, nllk loss: -1.98458, kernel loss: 0.06285\n",
      "Epoch: 2, series: 278, nllk loss: -1.61423, kernel loss: 0.08047\n",
      "Epoch: 2, series: 279, nllk loss: -2.04636, kernel loss: 0.06475\n",
      "Epoch: 2, series: 280, nllk loss: -1.93293, kernel loss: 0.10124\n",
      "Epoch: 2, series: 281, nllk loss: -1.99972, kernel loss: 0.23385\n",
      "Epoch: 2, series: 282, nllk loss: -1.98025, kernel loss: 0.13128\n",
      "Epoch: 2, series: 283, nllk loss: -1.77011, kernel loss: 0.20257\n",
      "Epoch: 2, series: 284, nllk loss: -1.65599, kernel loss: 0.26609\n",
      "Epoch: 2, series: 285, nllk loss: -1.83716, kernel loss: 0.19175\n",
      "Epoch: 2, series: 286, nllk loss: -1.87052, kernel loss: 0.07298\n",
      "Epoch: 2, series: 287, nllk loss: -2.26773, kernel loss: 0.03813\n",
      "Epoch: 2, series: 288, nllk loss: -0.86794, kernel loss: 0.18409\n",
      "Epoch: 2, series: 289, nllk loss: -0.61971, kernel loss: 0.10769\n",
      "Epoch: 2, series: 290, nllk loss: -1.80518, kernel loss: 0.21696\n",
      "Epoch: 2, series: 291, nllk loss: -1.94728, kernel loss: 0.09753\n",
      "Epoch: 2, series: 292, nllk loss: -2.07388, kernel loss: 0.04941\n",
      "Epoch: 2, series: 293, nllk loss: -2.09439, kernel loss: 0.33010\n",
      "Epoch: 2, series: 294, nllk loss: -1.18123, kernel loss: 0.17869\n",
      "Epoch: 2, series: 295, nllk loss: -0.82849, kernel loss: 0.16389\n",
      "Epoch: 2, series: 296, nllk loss: -2.20632, kernel loss: 0.07400\n",
      "Epoch: 2, series: 297, nllk loss: -1.93558, kernel loss: 0.05754\n",
      "Epoch: 2, series: 298, nllk loss: 4.89470, kernel loss: 0.18684\n",
      "Epoch: 2, series: 299, nllk loss: 1.94588, kernel loss: 0.09428\n",
      "Epoch: 2, series: 300, nllk loss: -1.68819, kernel loss: 0.18636\n",
      "Epoch: 2, series: 301, nllk loss: -1.39114, kernel loss: 0.32961\n",
      "Epoch: 2, series: 302, nllk loss: -1.43504, kernel loss: 0.27382\n",
      "Epoch: 2, series: 303, nllk loss: -1.29625, kernel loss: 0.00574\n",
      "Epoch: 2, series: 304, nllk loss: -0.73977, kernel loss: 0.15435\n",
      "Epoch: 2, series: 305, nllk loss: -1.03328, kernel loss: 0.05587\n",
      "Epoch: 2, series: 306, nllk loss: -1.54218, kernel loss: 0.25154\n",
      "Epoch: 2, series: 307, nllk loss: -1.03230, kernel loss: 0.17150\n",
      "Epoch: 2, series: 308, nllk loss: -1.39418, kernel loss: 0.27162\n",
      "Epoch: 2, series: 309, nllk loss: -1.25351, kernel loss: 0.53924\n",
      "Epoch: 2, series: 310, nllk loss: -1.32910, kernel loss: 0.37240\n",
      "Epoch: 2, series: 311, nllk loss: -1.06167, kernel loss: 0.08960\n",
      "Epoch: 2, series: 312, nllk loss: -1.34636, kernel loss: 0.33101\n",
      "Epoch: 2, series: 313, nllk loss: -1.47677, kernel loss: 0.23064\n",
      "Epoch: 2, series: 314, nllk loss: -1.60784, kernel loss: 0.16509\n",
      "Epoch: 2, series: 315, nllk loss: -0.80824, kernel loss: 0.28429\n",
      "Epoch: 2, series: 316, nllk loss: -1.19959, kernel loss: 0.36130\n",
      "Epoch: 2, series: 317, nllk loss: 0.36862, kernel loss: 0.20293\n",
      "Epoch: 2, series: 318, nllk loss: 1.01802, kernel loss: 0.25671\n",
      "Epoch: 2, series: 319, nllk loss: -0.62759, kernel loss: 0.16180\n",
      "Epoch: 2, series: 320, nllk loss: -0.80284, kernel loss: 0.02248\n",
      "Epoch: 2, total loss: -312.11691\n",
      "Epoch: 3, series: 0, nllk loss: 2.36084, kernel loss: 0.14445\n",
      "Epoch: 3, series: 1, nllk loss: -0.70202, kernel loss: 0.52667\n",
      "Epoch: 3, series: 2, nllk loss: 0.37460, kernel loss: 0.24743\n",
      "Epoch: 3, series: 3, nllk loss: -0.89354, kernel loss: 0.20535\n",
      "Epoch: 3, series: 4, nllk loss: -0.73897, kernel loss: 0.11548\n",
      "Epoch: 3, series: 5, nllk loss: -0.82376, kernel loss: 0.04139\n",
      "Epoch: 3, series: 6, nllk loss: -0.32474, kernel loss: 0.21241\n",
      "Epoch: 3, series: 7, nllk loss: -0.77099, kernel loss: 0.13015\n",
      "Epoch: 3, series: 8, nllk loss: -0.23764, kernel loss: 0.41728\n",
      "Epoch: 3, series: 9, nllk loss: -0.45613, kernel loss: 0.54217\n",
      "Epoch: 3, series: 10, nllk loss: -0.97508, kernel loss: 0.18760\n",
      "Epoch: 3, series: 11, nllk loss: -0.77006, kernel loss: 0.07499\n",
      "Epoch: 3, series: 12, nllk loss: -1.03082, kernel loss: 0.21724\n",
      "Epoch: 3, series: 13, nllk loss: -0.86377, kernel loss: 0.28736\n",
      "Epoch: 3, series: 14, nllk loss: -0.97921, kernel loss: 0.24933\n",
      "Epoch: 3, series: 15, nllk loss: -1.04550, kernel loss: 0.21694\n",
      "Epoch: 3, series: 16, nllk loss: -0.76750, kernel loss: 0.13918\n",
      "Epoch: 3, series: 17, nllk loss: -0.85509, kernel loss: 0.31239\n",
      "Epoch: 3, series: 18, nllk loss: -1.04094, kernel loss: 0.27965\n",
      "Epoch: 3, series: 19, nllk loss: -0.26956, kernel loss: 0.14487\n",
      "Epoch: 3, series: 20, nllk loss: -0.55654, kernel loss: 0.22271\n",
      "Epoch: 3, series: 21, nllk loss: -0.86444, kernel loss: 0.15868\n",
      "Epoch: 3, series: 22, nllk loss: -1.13156, kernel loss: 0.31563\n",
      "Epoch: 3, series: 23, nllk loss: -1.08474, kernel loss: 0.18495\n",
      "Epoch: 3, series: 24, nllk loss: -1.21477, kernel loss: 0.22926\n",
      "Epoch: 3, series: 25, nllk loss: -1.24280, kernel loss: 0.19468\n",
      "Epoch: 3, series: 26, nllk loss: -1.07149, kernel loss: 0.23376\n",
      "Epoch: 3, series: 27, nllk loss: -1.03583, kernel loss: 0.19966\n",
      "Epoch: 3, series: 28, nllk loss: -1.08007, kernel loss: 0.28271\n",
      "Epoch: 3, series: 29, nllk loss: -0.57202, kernel loss: 0.08925\n",
      "Epoch: 3, series: 30, nllk loss: -1.04657, kernel loss: 0.17565\n",
      "Epoch: 3, series: 31, nllk loss: -1.00090, kernel loss: 0.18001\n",
      "Epoch: 3, series: 32, nllk loss: -0.93974, kernel loss: 0.15375\n",
      "Epoch: 3, series: 33, nllk loss: -0.95049, kernel loss: 0.21784\n",
      "Epoch: 3, series: 34, nllk loss: -1.18627, kernel loss: 0.12228\n",
      "Epoch: 3, series: 35, nllk loss: -1.23848, kernel loss: 0.06752\n",
      "Epoch: 3, series: 36, nllk loss: -1.18590, kernel loss: 0.10682\n",
      "Epoch: 3, series: 37, nllk loss: -0.40676, kernel loss: 0.14622\n",
      "Epoch: 3, series: 38, nllk loss: -0.99315, kernel loss: 0.18595\n",
      "Epoch: 3, series: 39, nllk loss: -0.65675, kernel loss: 0.09888\n",
      "Epoch: 3, series: 40, nllk loss: -1.51478, kernel loss: 0.24679\n",
      "Epoch: 3, series: 41, nllk loss: -1.17952, kernel loss: 0.26346\n",
      "Epoch: 3, series: 42, nllk loss: -1.12908, kernel loss: 0.19132\n",
      "Epoch: 3, series: 43, nllk loss: -0.80789, kernel loss: 0.03811\n",
      "Epoch: 3, series: 44, nllk loss: -1.30943, kernel loss: 0.08366\n",
      "Epoch: 3, series: 45, nllk loss: -1.47428, kernel loss: 0.13426\n",
      "Epoch: 3, series: 46, nllk loss: -1.38415, kernel loss: 0.18883\n",
      "Epoch: 3, series: 47, nllk loss: -1.29021, kernel loss: 0.32460\n",
      "Epoch: 3, series: 48, nllk loss: -1.32119, kernel loss: 0.29888\n",
      "Epoch: 3, series: 49, nllk loss: -1.04159, kernel loss: 0.04689\n",
      "Epoch: 3, series: 50, nllk loss: -0.07879, kernel loss: 0.25338\n",
      "Epoch: 3, series: 51, nllk loss: -1.30647, kernel loss: 0.10872\n",
      "Epoch: 3, series: 52, nllk loss: -0.48205, kernel loss: 0.13116\n",
      "Epoch: 3, series: 53, nllk loss: -1.32971, kernel loss: 0.15233\n",
      "Epoch: 3, series: 54, nllk loss: -1.08765, kernel loss: 0.20658\n",
      "Epoch: 3, series: 55, nllk loss: -0.92046, kernel loss: 0.10829\n",
      "Epoch: 3, series: 56, nllk loss: -1.10348, kernel loss: 0.32319\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, series: 57, nllk loss: -1.09257, kernel loss: 0.19145\n",
      "Epoch: 3, series: 58, nllk loss: -1.26995, kernel loss: 0.46250\n",
      "Epoch: 3, series: 59, nllk loss: -0.88859, kernel loss: 0.09682\n",
      "Epoch: 3, series: 60, nllk loss: -1.00940, kernel loss: 0.13061\n",
      "Epoch: 3, series: 61, nllk loss: -1.35533, kernel loss: 0.16645\n",
      "Epoch: 3, series: 62, nllk loss: -1.35351, kernel loss: 0.19639\n",
      "Epoch: 3, series: 63, nllk loss: -1.33704, kernel loss: 0.42490\n",
      "Epoch: 3, series: 64, nllk loss: -0.91498, kernel loss: 0.13177\n",
      "Epoch: 3, series: 65, nllk loss: -1.36286, kernel loss: 0.11155\n",
      "Epoch: 3, series: 66, nllk loss: -1.25461, kernel loss: 0.30261\n",
      "Epoch: 3, series: 67, nllk loss: -1.08378, kernel loss: 0.43154\n",
      "Epoch: 3, series: 68, nllk loss: -0.54849, kernel loss: 0.28795\n",
      "Epoch: 3, series: 69, nllk loss: -1.15894, kernel loss: 0.02933\n",
      "Epoch: 3, series: 70, nllk loss: -1.22015, kernel loss: 0.27581\n",
      "Epoch: 3, series: 71, nllk loss: -1.27844, kernel loss: 0.38309\n",
      "Epoch: 3, series: 72, nllk loss: -1.54570, kernel loss: 0.24370\n",
      "Epoch: 3, series: 73, nllk loss: -1.19111, kernel loss: 0.13506\n",
      "Epoch: 3, series: 74, nllk loss: -1.55447, kernel loss: 0.28794\n",
      "Epoch: 3, series: 75, nllk loss: -1.19174, kernel loss: 0.08471\n",
      "Epoch: 3, series: 76, nllk loss: -1.30221, kernel loss: 0.22431\n",
      "Epoch: 3, series: 77, nllk loss: -1.00614, kernel loss: 0.13570\n",
      "Epoch: 3, series: 78, nllk loss: -1.22293, kernel loss: 0.07588\n",
      "Epoch: 3, series: 79, nllk loss: -0.68768, kernel loss: 0.11779\n",
      "Epoch: 3, series: 80, nllk loss: -1.59028, kernel loss: 0.33412\n",
      "Epoch: 3, series: 81, nllk loss: -1.15103, kernel loss: 0.20793\n",
      "Epoch: 3, series: 82, nllk loss: 0.02337, kernel loss: 0.19192\n",
      "Epoch: 3, series: 83, nllk loss: -0.39209, kernel loss: 0.27428\n",
      "Epoch: 3, series: 84, nllk loss: -0.98895, kernel loss: 0.13205\n",
      "Epoch: 3, series: 85, nllk loss: -0.90763, kernel loss: 0.04147\n",
      "Epoch: 3, series: 86, nllk loss: -0.13075, kernel loss: 0.16323\n",
      "Epoch: 3, series: 87, nllk loss: -1.40009, kernel loss: 0.10135\n",
      "Epoch: 3, series: 88, nllk loss: -1.71594, kernel loss: 0.17389\n",
      "Epoch: 3, series: 89, nllk loss: -1.62131, kernel loss: 0.10737\n",
      "Epoch: 3, series: 90, nllk loss: -1.51517, kernel loss: 0.28719\n",
      "Epoch: 3, series: 91, nllk loss: -1.58759, kernel loss: 0.08314\n",
      "Epoch: 3, series: 92, nllk loss: 0.28660, kernel loss: 0.31662\n",
      "Epoch: 3, series: 93, nllk loss: -1.72895, kernel loss: 0.17139\n",
      "Epoch: 3, series: 94, nllk loss: -1.68056, kernel loss: 0.08431\n",
      "Epoch: 3, series: 95, nllk loss: -1.64091, kernel loss: 0.10768\n",
      "Epoch: 3, series: 96, nllk loss: -1.42013, kernel loss: 0.21089\n",
      "Epoch: 3, series: 97, nllk loss: -0.63582, kernel loss: 0.05965\n",
      "Epoch: 3, series: 98, nllk loss: -0.78292, kernel loss: 0.44670\n",
      "Epoch: 3, series: 99, nllk loss: -1.08643, kernel loss: 0.21360\n",
      "Epoch: 3, series: 100, nllk loss: -1.02868, kernel loss: 0.13015\n",
      "Epoch: 3, series: 101, nllk loss: -1.38504, kernel loss: 0.13516\n",
      "Epoch: 3, series: 102, nllk loss: -1.19408, kernel loss: 0.16854\n",
      "Epoch: 3, series: 103, nllk loss: -1.04215, kernel loss: 0.24880\n",
      "Epoch: 3, series: 104, nllk loss: 0.26628, kernel loss: 0.12847\n",
      "Epoch: 3, series: 105, nllk loss: 0.68633, kernel loss: 0.09516\n",
      "Epoch: 3, series: 106, nllk loss: -0.78296, kernel loss: 0.10490\n",
      "Epoch: 3, series: 107, nllk loss: -0.70507, kernel loss: 0.07496\n",
      "Epoch: 3, series: 108, nllk loss: -0.94726, kernel loss: 0.33824\n",
      "Epoch: 3, series: 109, nllk loss: 0.26775, kernel loss: 0.18826\n",
      "Epoch: 3, series: 110, nllk loss: -1.09814, kernel loss: 0.06244\n",
      "Epoch: 3, series: 111, nllk loss: -1.11226, kernel loss: 0.24896\n",
      "Epoch: 3, series: 112, nllk loss: -0.51812, kernel loss: 0.07706\n",
      "Epoch: 3, series: 113, nllk loss: -0.86618, kernel loss: 0.03109\n",
      "Epoch: 3, series: 114, nllk loss: -0.60662, kernel loss: 0.39128\n",
      "Epoch: 3, series: 115, nllk loss: -0.80954, kernel loss: 0.07601\n",
      "Epoch: 3, series: 116, nllk loss: -1.44653, kernel loss: 0.20731\n",
      "Epoch: 3, series: 117, nllk loss: -0.50446, kernel loss: 0.14493\n",
      "Epoch: 3, series: 118, nllk loss: -1.58172, kernel loss: 0.27932\n",
      "Epoch: 3, series: 119, nllk loss: -0.45642, kernel loss: 0.58404\n",
      "Epoch: 3, series: 120, nllk loss: -1.35405, kernel loss: 0.27607\n",
      "Epoch: 3, series: 121, nllk loss: 0.12143, kernel loss: 0.09836\n",
      "Epoch: 3, series: 122, nllk loss: -0.51068, kernel loss: 0.31987\n",
      "Epoch: 3, series: 123, nllk loss: -1.33477, kernel loss: 0.29642\n",
      "Epoch: 3, series: 124, nllk loss: -1.41275, kernel loss: 0.36896\n",
      "Epoch: 3, series: 125, nllk loss: -1.29071, kernel loss: 0.08109\n",
      "Epoch: 3, series: 126, nllk loss: -1.32236, kernel loss: 0.12387\n",
      "Epoch: 3, series: 127, nllk loss: -1.32903, kernel loss: 0.09790\n",
      "Epoch: 3, series: 128, nllk loss: -0.93665, kernel loss: 0.23328\n",
      "Epoch: 3, series: 129, nllk loss: -0.65662, kernel loss: 0.14877\n",
      "Epoch: 3, series: 130, nllk loss: -1.04887, kernel loss: 0.14222\n",
      "Epoch: 3, series: 131, nllk loss: 0.40244, kernel loss: 0.06406\n",
      "Epoch: 3, series: 132, nllk loss: -0.01803, kernel loss: 0.18447\n",
      "Epoch: 3, series: 133, nllk loss: -0.78403, kernel loss: 0.19375\n",
      "Epoch: 3, series: 134, nllk loss: -0.77234, kernel loss: 0.31106\n",
      "Epoch: 3, series: 135, nllk loss: -1.30778, kernel loss: 0.24802\n",
      "Epoch: 3, series: 136, nllk loss: -1.30068, kernel loss: 0.11255\n",
      "Epoch: 3, series: 137, nllk loss: -1.47875, kernel loss: 0.33633\n",
      "Epoch: 3, series: 138, nllk loss: -1.50672, kernel loss: 0.21225\n",
      "Epoch: 3, series: 139, nllk loss: -1.31999, kernel loss: 0.10518\n",
      "Epoch: 3, series: 140, nllk loss: -1.22037, kernel loss: 0.04882\n",
      "Epoch: 3, series: 141, nllk loss: -1.42873, kernel loss: 0.07072\n",
      "Epoch: 3, series: 142, nllk loss: -1.27060, kernel loss: 0.09630\n",
      "Epoch: 3, series: 143, nllk loss: -1.41297, kernel loss: 0.22732\n",
      "Epoch: 3, series: 144, nllk loss: -1.47116, kernel loss: 0.08483\n",
      "Epoch: 3, series: 145, nllk loss: -1.44592, kernel loss: 0.20235\n",
      "Epoch: 3, series: 146, nllk loss: 3.33600, kernel loss: 0.05830\n",
      "Epoch: 3, series: 147, nllk loss: -1.36849, kernel loss: 0.19573\n",
      "Epoch: 3, series: 148, nllk loss: -1.25091, kernel loss: 0.15623\n",
      "Epoch: 3, series: 149, nllk loss: -1.43724, kernel loss: 0.11989\n",
      "Epoch: 3, series: 150, nllk loss: -1.59946, kernel loss: 0.19533\n",
      "Epoch: 3, series: 151, nllk loss: -1.61466, kernel loss: 0.21233\n",
      "Epoch: 3, series: 152, nllk loss: -1.48846, kernel loss: 0.24044\n",
      "Epoch: 3, series: 153, nllk loss: -1.38381, kernel loss: 0.05610\n",
      "Epoch: 3, series: 154, nllk loss: -1.31908, kernel loss: 0.09553\n",
      "Epoch: 3, series: 155, nllk loss: -1.46934, kernel loss: 0.15403\n",
      "Epoch: 3, series: 156, nllk loss: -1.51970, kernel loss: 0.16646\n",
      "Epoch: 3, series: 157, nllk loss: -1.15247, kernel loss: 0.15792\n",
      "Epoch: 3, series: 158, nllk loss: -1.58074, kernel loss: 0.35098\n",
      "Epoch: 3, series: 159, nllk loss: -1.69183, kernel loss: 0.13365\n",
      "Epoch: 3, series: 160, nllk loss: -1.50516, kernel loss: 0.17472\n",
      "Epoch: 3, series: 161, nllk loss: -1.49270, kernel loss: 0.30867\n",
      "Epoch: 3, series: 162, nllk loss: -1.54036, kernel loss: 0.01284\n",
      "Epoch: 3, series: 163, nllk loss: -1.86219, kernel loss: 0.23536\n",
      "Epoch: 3, series: 164, nllk loss: -1.51772, kernel loss: 0.15060\n",
      "Epoch: 3, series: 165, nllk loss: -1.58061, kernel loss: 0.01517\n",
      "Epoch: 3, series: 166, nllk loss: -1.18453, kernel loss: 0.14478\n",
      "Epoch: 3, series: 167, nllk loss: -1.89236, kernel loss: 0.22172\n",
      "Epoch: 3, series: 168, nllk loss: -1.80947, kernel loss: 0.11767\n",
      "Epoch: 3, series: 169, nllk loss: -1.92734, kernel loss: 0.13120\n",
      "Epoch: 3, series: 170, nllk loss: -1.53385, kernel loss: 0.16571\n",
      "Epoch: 3, series: 171, nllk loss: -1.88938, kernel loss: 0.25235\n",
      "Epoch: 3, series: 172, nllk loss: -1.69787, kernel loss: 0.16049\n",
      "Epoch: 3, series: 173, nllk loss: -1.98842, kernel loss: 0.11386\n",
      "Epoch: 3, series: 174, nllk loss: -1.53596, kernel loss: 0.23544\n",
      "Epoch: 3, series: 175, nllk loss: -1.84511, kernel loss: 0.20313\n",
      "Epoch: 3, series: 176, nllk loss: -2.00112, kernel loss: 0.02999\n",
      "Epoch: 3, series: 177, nllk loss: -1.39675, kernel loss: 0.03193\n",
      "Epoch: 3, series: 178, nllk loss: -1.09786, kernel loss: 0.21081\n",
      "Epoch: 3, series: 179, nllk loss: -1.79030, kernel loss: 0.08286\n",
      "Epoch: 3, series: 180, nllk loss: -1.76638, kernel loss: 0.31826\n",
      "Epoch: 3, series: 181, nllk loss: -1.94037, kernel loss: 0.09480\n",
      "Epoch: 3, series: 182, nllk loss: -1.69552, kernel loss: 0.13892\n",
      "Epoch: 3, series: 183, nllk loss: -1.77187, kernel loss: 0.12028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, series: 184, nllk loss: -1.64908, kernel loss: 0.18260\n",
      "Epoch: 3, series: 185, nllk loss: -1.61540, kernel loss: 0.18793\n",
      "Epoch: 3, series: 186, nllk loss: -1.99407, kernel loss: 0.25535\n",
      "Epoch: 3, series: 187, nllk loss: -2.14688, kernel loss: 0.66967\n",
      "Epoch: 3, series: 188, nllk loss: -1.34059, kernel loss: 0.15494\n",
      "Epoch: 3, series: 189, nllk loss: -1.08736, kernel loss: 0.09049\n",
      "Epoch: 3, series: 190, nllk loss: -1.55291, kernel loss: 0.14188\n",
      "Epoch: 3, series: 191, nllk loss: -1.60751, kernel loss: 0.20928\n",
      "Epoch: 3, series: 192, nllk loss: -1.78570, kernel loss: 0.17763\n",
      "Epoch: 3, series: 193, nllk loss: -1.49933, kernel loss: 0.23783\n",
      "Epoch: 3, series: 194, nllk loss: -1.14005, kernel loss: 0.04466\n",
      "Epoch: 3, series: 195, nllk loss: -1.92187, kernel loss: 0.23097\n",
      "Epoch: 3, series: 196, nllk loss: -1.67460, kernel loss: 0.36025\n",
      "Epoch: 3, series: 197, nllk loss: -1.81736, kernel loss: 0.11800\n",
      "Epoch: 3, series: 198, nllk loss: -1.97446, kernel loss: 0.18854\n",
      "Epoch: 3, series: 199, nllk loss: -1.63373, kernel loss: 0.11521\n",
      "Epoch: 3, series: 200, nllk loss: -1.98588, kernel loss: 0.20240\n",
      "Epoch: 3, series: 201, nllk loss: -1.89140, kernel loss: 0.47145\n",
      "Epoch: 3, series: 202, nllk loss: -1.73585, kernel loss: 0.08474\n",
      "Epoch: 3, series: 203, nllk loss: -1.71953, kernel loss: 0.13293\n",
      "Epoch: 3, series: 204, nllk loss: -0.66945, kernel loss: 0.13938\n",
      "Epoch: 3, series: 205, nllk loss: -1.59647, kernel loss: 0.08048\n",
      "Epoch: 3, series: 206, nllk loss: -1.90561, kernel loss: 0.16412\n",
      "Epoch: 3, series: 207, nllk loss: -1.11964, kernel loss: 0.21509\n",
      "Epoch: 3, series: 208, nllk loss: -2.12169, kernel loss: 0.16265\n",
      "Epoch: 3, series: 209, nllk loss: -1.50322, kernel loss: 0.11236\n",
      "Epoch: 3, series: 210, nllk loss: -2.18752, kernel loss: 0.17969\n",
      "Epoch: 3, series: 211, nllk loss: -1.94769, kernel loss: 0.14045\n",
      "Epoch: 3, series: 212, nllk loss: -1.43204, kernel loss: 0.10267\n",
      "Epoch: 3, series: 213, nllk loss: -1.79093, kernel loss: 0.12432\n",
      "Epoch: 3, series: 214, nllk loss: -1.57292, kernel loss: 0.21379\n",
      "Epoch: 3, series: 215, nllk loss: -2.02067, kernel loss: 0.17396\n",
      "Epoch: 3, series: 216, nllk loss: -0.90534, kernel loss: 0.46601\n",
      "Epoch: 3, series: 217, nllk loss: -1.47310, kernel loss: 0.14852\n",
      "Epoch: 3, series: 218, nllk loss: -1.18548, kernel loss: 0.09752\n",
      "Epoch: 3, series: 219, nllk loss: -1.66066, kernel loss: 0.10538\n",
      "Epoch: 3, series: 220, nllk loss: -1.54332, kernel loss: 0.31346\n",
      "Epoch: 3, series: 221, nllk loss: -1.84777, kernel loss: 0.19182\n",
      "Epoch: 3, series: 222, nllk loss: -1.80682, kernel loss: 0.16270\n",
      "Epoch: 3, series: 223, nllk loss: -1.57074, kernel loss: 0.11717\n",
      "Epoch: 3, series: 224, nllk loss: -1.87884, kernel loss: 0.08266\n",
      "Epoch: 3, series: 225, nllk loss: -1.63979, kernel loss: 0.08471\n",
      "Epoch: 3, series: 226, nllk loss: -1.40362, kernel loss: 0.11397\n",
      "Epoch: 3, series: 227, nllk loss: -1.43974, kernel loss: 0.13576\n",
      "Epoch: 3, series: 228, nllk loss: -1.62222, kernel loss: 0.20814\n",
      "Epoch: 3, series: 229, nllk loss: -1.46895, kernel loss: 0.10560\n",
      "Epoch: 3, series: 230, nllk loss: -1.80801, kernel loss: 0.07119\n",
      "Epoch: 3, series: 231, nllk loss: -1.45160, kernel loss: 0.06221\n",
      "Epoch: 3, series: 232, nllk loss: -2.02412, kernel loss: 0.11931\n",
      "Epoch: 3, series: 233, nllk loss: -1.91695, kernel loss: 0.31383\n",
      "Epoch: 3, series: 234, nllk loss: -1.62972, kernel loss: 0.28028\n",
      "Epoch: 3, series: 235, nllk loss: -1.92931, kernel loss: 0.15645\n",
      "Epoch: 3, series: 236, nllk loss: -1.08567, kernel loss: 0.41489\n",
      "Epoch: 3, series: 237, nllk loss: -1.74876, kernel loss: 0.18079\n",
      "Epoch: 3, series: 238, nllk loss: -1.61833, kernel loss: 0.21136\n",
      "Epoch: 3, series: 239, nllk loss: -1.64153, kernel loss: 0.16897\n",
      "Epoch: 3, series: 240, nllk loss: -1.41963, kernel loss: 0.07891\n",
      "Epoch: 3, series: 241, nllk loss: -1.49904, kernel loss: 0.09383\n",
      "Epoch: 3, series: 242, nllk loss: -1.73646, kernel loss: 0.28163\n",
      "Epoch: 3, series: 243, nllk loss: -2.06598, kernel loss: 0.34065\n",
      "Epoch: 3, series: 244, nllk loss: -1.53471, kernel loss: 0.14125\n",
      "Epoch: 3, series: 245, nllk loss: -1.85115, kernel loss: 0.06177\n",
      "Epoch: 3, series: 246, nllk loss: -0.08056, kernel loss: 0.25864\n",
      "Epoch: 3, series: 247, nllk loss: -1.63285, kernel loss: 0.32106\n",
      "Epoch: 3, series: 248, nllk loss: -1.71716, kernel loss: 0.20437\n",
      "Epoch: 3, series: 249, nllk loss: -1.84074, kernel loss: 0.15442\n",
      "Epoch: 3, series: 250, nllk loss: -1.63853, kernel loss: 0.14027\n",
      "Epoch: 3, series: 251, nllk loss: -0.92775, kernel loss: 0.23265\n",
      "Epoch: 3, series: 252, nllk loss: -0.80875, kernel loss: 0.17908\n",
      "Epoch: 3, series: 253, nllk loss: -1.62287, kernel loss: 0.11823\n",
      "Epoch: 3, series: 254, nllk loss: -2.02723, kernel loss: 0.34329\n",
      "Epoch: 3, series: 255, nllk loss: -1.82703, kernel loss: 0.06938\n",
      "Epoch: 3, series: 256, nllk loss: -1.36556, kernel loss: 0.10853\n",
      "Epoch: 3, series: 257, nllk loss: -1.77486, kernel loss: 0.26394\n",
      "Epoch: 3, series: 258, nllk loss: -1.79758, kernel loss: 0.22264\n",
      "Epoch: 3, series: 259, nllk loss: -1.43851, kernel loss: 0.18631\n",
      "Epoch: 3, series: 260, nllk loss: -1.59042, kernel loss: 0.22837\n",
      "Epoch: 3, series: 261, nllk loss: -1.93858, kernel loss: 0.41924\n",
      "Epoch: 3, series: 262, nllk loss: -2.00867, kernel loss: 0.13013\n",
      "Epoch: 3, series: 263, nllk loss: -0.58751, kernel loss: 0.27180\n",
      "Epoch: 3, series: 264, nllk loss: -1.63909, kernel loss: 0.30728\n",
      "Epoch: 3, series: 265, nllk loss: -1.83800, kernel loss: 0.09088\n",
      "Epoch: 3, series: 266, nllk loss: -1.73508, kernel loss: 0.14559\n",
      "Epoch: 3, series: 267, nllk loss: -1.83649, kernel loss: 0.10846\n",
      "Epoch: 3, series: 268, nllk loss: -1.89665, kernel loss: 0.15470\n",
      "Epoch: 3, series: 269, nllk loss: -1.38950, kernel loss: 0.15924\n",
      "Epoch: 3, series: 270, nllk loss: -1.53416, kernel loss: 0.12383\n",
      "Epoch: 3, series: 271, nllk loss: -1.70580, kernel loss: 0.00000\n",
      "Epoch: 3, series: 272, nllk loss: -1.72310, kernel loss: 0.21441\n",
      "Epoch: 3, series: 273, nllk loss: -1.85047, kernel loss: 0.17715\n",
      "Epoch: 3, series: 274, nllk loss: -1.47336, kernel loss: 0.10134\n",
      "Epoch: 3, series: 275, nllk loss: -1.73067, kernel loss: 0.08388\n",
      "Epoch: 3, series: 276, nllk loss: -0.86399, kernel loss: 0.02858\n",
      "Epoch: 3, series: 277, nllk loss: -1.96977, kernel loss: 0.04142\n",
      "Epoch: 3, series: 278, nllk loss: -1.62922, kernel loss: 0.32431\n",
      "Epoch: 3, series: 279, nllk loss: -2.12802, kernel loss: 0.02217\n",
      "Epoch: 3, series: 280, nllk loss: -1.93260, kernel loss: 0.09271\n",
      "Epoch: 3, series: 281, nllk loss: -2.07336, kernel loss: 0.13392\n",
      "Epoch: 3, series: 282, nllk loss: -2.03825, kernel loss: 0.06740\n",
      "Epoch: 3, series: 283, nllk loss: -1.85870, kernel loss: 0.08426\n",
      "Epoch: 3, series: 284, nllk loss: -1.77360, kernel loss: 0.09488\n",
      "Epoch: 3, series: 285, nllk loss: -1.82961, kernel loss: 0.14656\n",
      "Epoch: 3, series: 286, nllk loss: -1.84061, kernel loss: 0.19592\n",
      "Epoch: 3, series: 287, nllk loss: -2.27385, kernel loss: 0.12641\n",
      "Epoch: 3, series: 288, nllk loss: -0.87413, kernel loss: 0.12885\n",
      "Epoch: 3, series: 289, nllk loss: -0.58013, kernel loss: 0.14274\n",
      "Epoch: 3, series: 290, nllk loss: -1.95090, kernel loss: 0.14369\n",
      "Epoch: 3, series: 291, nllk loss: -2.04213, kernel loss: 0.10489\n",
      "Epoch: 3, series: 292, nllk loss: -2.15769, kernel loss: 0.25755\n",
      "Epoch: 3, series: 293, nllk loss: -2.16353, kernel loss: 0.18940\n",
      "Epoch: 3, series: 294, nllk loss: -1.35563, kernel loss: 0.14017\n",
      "Epoch: 3, series: 295, nllk loss: -0.85122, kernel loss: 0.22237\n",
      "Epoch: 3, series: 296, nllk loss: -2.00311, kernel loss: 0.51067\n",
      "Epoch: 3, series: 297, nllk loss: -1.95051, kernel loss: 0.12931\n",
      "Epoch: 3, series: 298, nllk loss: 4.49552, kernel loss: 0.18285\n",
      "Epoch: 3, series: 299, nllk loss: 1.90234, kernel loss: 0.10966\n",
      "Epoch: 3, series: 300, nllk loss: -1.82145, kernel loss: 0.13743\n",
      "Epoch: 3, series: 301, nllk loss: -1.55056, kernel loss: 0.21680\n",
      "Epoch: 3, series: 302, nllk loss: -1.49167, kernel loss: 0.51967\n",
      "Epoch: 3, series: 303, nllk loss: -1.32498, kernel loss: 0.02849\n",
      "Epoch: 3, series: 304, nllk loss: -0.61979, kernel loss: 0.26904\n",
      "Epoch: 3, series: 305, nllk loss: -1.11339, kernel loss: 0.33816\n",
      "Epoch: 3, series: 306, nllk loss: -1.65104, kernel loss: 0.17983\n",
      "Epoch: 3, series: 307, nllk loss: -1.12572, kernel loss: 0.08848\n",
      "Epoch: 3, series: 308, nllk loss: -1.41381, kernel loss: 0.11677\n",
      "Epoch: 3, series: 309, nllk loss: -1.28435, kernel loss: 0.22482\n",
      "Epoch: 3, series: 310, nllk loss: -1.32343, kernel loss: 0.27394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, series: 311, nllk loss: -1.15050, kernel loss: 0.14550\n",
      "Epoch: 3, series: 312, nllk loss: -1.39190, kernel loss: 0.20422\n",
      "Epoch: 3, series: 313, nllk loss: -1.48976, kernel loss: 0.22281\n",
      "Epoch: 3, series: 314, nllk loss: -1.61059, kernel loss: 0.12271\n",
      "Epoch: 3, series: 315, nllk loss: -0.87313, kernel loss: 0.25981\n",
      "Epoch: 3, series: 316, nllk loss: -1.21792, kernel loss: 0.35062\n",
      "Epoch: 3, series: 317, nllk loss: 0.30630, kernel loss: 0.17237\n",
      "Epoch: 3, series: 318, nllk loss: 1.04981, kernel loss: 0.05954\n",
      "Epoch: 3, series: 319, nllk loss: -0.75066, kernel loss: 0.28418\n",
      "Epoch: 3, series: 320, nllk loss: -0.92555, kernel loss: 0.56059\n",
      "Epoch: 3, total loss: -339.49702\n",
      "Epoch: 4, series: 0, nllk loss: 2.63334, kernel loss: 0.32818\n",
      "Epoch: 4, series: 1, nllk loss: -0.80874, kernel loss: 0.31448\n",
      "Epoch: 4, series: 2, nllk loss: 0.31358, kernel loss: 0.15447\n",
      "Epoch: 4, series: 3, nllk loss: -0.85425, kernel loss: 0.11054\n",
      "Epoch: 4, series: 4, nllk loss: -0.65068, kernel loss: 0.23286\n",
      "Epoch: 4, series: 5, nllk loss: -0.83625, kernel loss: 0.35099\n",
      "Epoch: 4, series: 6, nllk loss: -0.42281, kernel loss: 0.22391\n",
      "Epoch: 4, series: 7, nllk loss: -0.98428, kernel loss: 0.10036\n",
      "Epoch: 4, series: 8, nllk loss: -0.35948, kernel loss: 0.14579\n",
      "Epoch: 4, series: 9, nllk loss: -0.45553, kernel loss: 0.21963\n",
      "Epoch: 4, series: 10, nllk loss: -1.02443, kernel loss: 0.34446\n",
      "Epoch: 4, series: 11, nllk loss: -0.77302, kernel loss: 0.20028\n",
      "Epoch: 4, series: 12, nllk loss: -1.13145, kernel loss: 0.17938\n",
      "Epoch: 4, series: 13, nllk loss: -0.90554, kernel loss: 0.17077\n",
      "Epoch: 4, series: 14, nllk loss: -1.02602, kernel loss: 0.16826\n",
      "Epoch: 4, series: 15, nllk loss: -1.04058, kernel loss: 0.27094\n",
      "Epoch: 4, series: 16, nllk loss: -0.76881, kernel loss: 0.14887\n",
      "Epoch: 4, series: 17, nllk loss: -0.86440, kernel loss: 0.19039\n",
      "Epoch: 4, series: 18, nllk loss: -1.11341, kernel loss: 0.26487\n",
      "Epoch: 4, series: 19, nllk loss: -0.32964, kernel loss: 0.15623\n",
      "Epoch: 4, series: 20, nllk loss: -0.71189, kernel loss: 0.17366\n",
      "Epoch: 4, series: 21, nllk loss: -0.89991, kernel loss: 0.07176\n",
      "Epoch: 4, series: 22, nllk loss: -1.10414, kernel loss: 0.38444\n",
      "Epoch: 4, series: 23, nllk loss: -1.06789, kernel loss: 0.27089\n",
      "Epoch: 4, series: 24, nllk loss: -1.22881, kernel loss: 0.03221\n",
      "Epoch: 4, series: 25, nllk loss: -1.27647, kernel loss: 0.03844\n",
      "Epoch: 4, series: 26, nllk loss: -1.08229, kernel loss: 0.28728\n",
      "Epoch: 4, series: 27, nllk loss: -1.00360, kernel loss: 0.00000\n",
      "Epoch: 4, series: 28, nllk loss: -1.13551, kernel loss: 0.17445\n",
      "Epoch: 4, series: 29, nllk loss: -0.50257, kernel loss: 0.08029\n",
      "Epoch: 4, series: 30, nllk loss: -1.14782, kernel loss: 0.16593\n",
      "Epoch: 4, series: 31, nllk loss: -1.00067, kernel loss: 0.14652\n",
      "Epoch: 4, series: 32, nllk loss: -1.00558, kernel loss: 0.24671\n",
      "Epoch: 4, series: 33, nllk loss: -0.99539, kernel loss: 0.20827\n",
      "Epoch: 4, series: 34, nllk loss: -1.23073, kernel loss: 0.20099\n",
      "Epoch: 4, series: 35, nllk loss: -1.33933, kernel loss: 0.27237\n",
      "Epoch: 4, series: 36, nllk loss: -1.23577, kernel loss: 0.11841\n",
      "Epoch: 4, series: 37, nllk loss: -0.31418, kernel loss: 0.05575\n",
      "Epoch: 4, series: 38, nllk loss: -1.00207, kernel loss: 0.07161\n",
      "Epoch: 4, series: 39, nllk loss: -0.65057, kernel loss: 0.25189\n",
      "Epoch: 4, series: 40, nllk loss: -1.51548, kernel loss: 0.15360\n",
      "Epoch: 4, series: 41, nllk loss: -1.12126, kernel loss: 0.17621\n",
      "Epoch: 4, series: 42, nllk loss: -1.09688, kernel loss: 0.13135\n",
      "Epoch: 4, series: 43, nllk loss: -0.87920, kernel loss: 0.20181\n",
      "Epoch: 4, series: 44, nllk loss: -1.32059, kernel loss: 0.01725\n",
      "Epoch: 4, series: 45, nllk loss: -1.51366, kernel loss: 0.23505\n",
      "Epoch: 4, series: 46, nllk loss: -1.42423, kernel loss: 0.19303\n",
      "Epoch: 4, series: 47, nllk loss: -1.33279, kernel loss: 0.28331\n",
      "Epoch: 4, series: 48, nllk loss: -1.39665, kernel loss: 0.05108\n",
      "Epoch: 4, series: 49, nllk loss: -0.99391, kernel loss: 0.20072\n",
      "Epoch: 4, series: 50, nllk loss: 0.08374, kernel loss: 0.24000\n",
      "Epoch: 4, series: 51, nllk loss: -1.29772, kernel loss: 0.24135\n",
      "Epoch: 4, series: 52, nllk loss: -0.39471, kernel loss: 0.15579\n",
      "Epoch: 4, series: 53, nllk loss: -1.29586, kernel loss: 0.22425\n",
      "Epoch: 4, series: 54, nllk loss: -0.99216, kernel loss: 0.14334\n",
      "Epoch: 4, series: 55, nllk loss: -0.99035, kernel loss: 0.11182\n",
      "Epoch: 4, series: 56, nllk loss: -1.14789, kernel loss: 0.21300\n",
      "Epoch: 4, series: 57, nllk loss: -1.06934, kernel loss: 0.12998\n",
      "Epoch: 4, series: 58, nllk loss: -1.21115, kernel loss: 0.12431\n",
      "Epoch: 4, series: 59, nllk loss: -0.98895, kernel loss: 0.21635\n",
      "Epoch: 4, series: 60, nllk loss: -0.98414, kernel loss: 0.22918\n",
      "Epoch: 4, series: 61, nllk loss: -1.48318, kernel loss: 0.16375\n",
      "Epoch: 4, series: 62, nllk loss: -1.45266, kernel loss: 0.26465\n",
      "Epoch: 4, series: 63, nllk loss: -1.39923, kernel loss: 0.07032\n",
      "Epoch: 4, series: 64, nllk loss: -0.95654, kernel loss: 0.30265\n",
      "Epoch: 4, series: 65, nllk loss: -1.34183, kernel loss: 0.28326\n",
      "Epoch: 4, series: 66, nllk loss: -1.30642, kernel loss: 0.23860\n",
      "Epoch: 4, series: 67, nllk loss: -1.27603, kernel loss: 0.20426\n",
      "Epoch: 4, series: 68, nllk loss: -0.61594, kernel loss: 0.10881\n",
      "Epoch: 4, series: 69, nllk loss: -1.22805, kernel loss: 0.09481\n",
      "Epoch: 4, series: 70, nllk loss: -1.46402, kernel loss: 0.09240\n",
      "Epoch: 4, series: 71, nllk loss: -1.35777, kernel loss: 0.13302\n",
      "Epoch: 4, series: 72, nllk loss: -1.61107, kernel loss: 0.11083\n",
      "Epoch: 4, series: 73, nllk loss: -1.14686, kernel loss: 0.18094\n",
      "Epoch: 4, series: 74, nllk loss: -1.65709, kernel loss: 0.21408\n",
      "Epoch: 4, series: 75, nllk loss: -1.19241, kernel loss: 0.17462\n",
      "Epoch: 4, series: 76, nllk loss: -1.36247, kernel loss: 0.16211\n",
      "Epoch: 4, series: 77, nllk loss: -1.07898, kernel loss: 0.07828\n",
      "Epoch: 4, series: 78, nllk loss: -1.39394, kernel loss: 0.04807\n",
      "Epoch: 4, series: 79, nllk loss: -0.67503, kernel loss: 0.18804\n",
      "Epoch: 4, series: 80, nllk loss: -1.57079, kernel loss: 0.11862\n",
      "Epoch: 4, series: 81, nllk loss: -1.11024, kernel loss: 0.16535\n",
      "Epoch: 4, series: 82, nllk loss: -0.26119, kernel loss: 0.06093\n",
      "Epoch: 4, series: 83, nllk loss: -0.51739, kernel loss: 0.05111\n",
      "Epoch: 4, series: 84, nllk loss: -0.98289, kernel loss: 0.14484\n",
      "Epoch: 4, series: 85, nllk loss: -1.17603, kernel loss: 0.13595\n",
      "Epoch: 4, series: 86, nllk loss: -0.16546, kernel loss: 0.10764\n",
      "Epoch: 4, series: 87, nllk loss: -1.55912, kernel loss: 0.16368\n",
      "Epoch: 4, series: 88, nllk loss: -1.78244, kernel loss: 0.09459\n",
      "Epoch: 4, series: 89, nllk loss: -1.74702, kernel loss: 0.41515\n",
      "Epoch: 4, series: 90, nllk loss: -1.67954, kernel loss: 0.10452\n",
      "Epoch: 4, series: 91, nllk loss: -1.72175, kernel loss: 0.10514\n",
      "Epoch: 4, series: 92, nllk loss: 0.47630, kernel loss: 0.05049\n",
      "Epoch: 4, series: 93, nllk loss: -1.86914, kernel loss: 0.26806\n",
      "Epoch: 4, series: 94, nllk loss: -1.83547, kernel loss: 0.24181\n",
      "Epoch: 4, series: 95, nllk loss: -1.81603, kernel loss: 0.03411\n",
      "Epoch: 4, series: 96, nllk loss: -1.52493, kernel loss: 0.38074\n",
      "Epoch: 4, series: 97, nllk loss: -0.61188, kernel loss: 0.28215\n",
      "Epoch: 4, series: 98, nllk loss: -0.70916, kernel loss: 0.33939\n",
      "Epoch: 4, series: 99, nllk loss: -1.17151, kernel loss: 0.13979\n",
      "Epoch: 4, series: 100, nllk loss: -0.81670, kernel loss: 0.17352\n",
      "Epoch: 4, series: 101, nllk loss: -1.17003, kernel loss: 0.04708\n",
      "Epoch: 4, series: 102, nllk loss: -0.99288, kernel loss: 0.18565\n",
      "Epoch: 4, series: 103, nllk loss: -1.09652, kernel loss: 0.02694\n",
      "Epoch: 4, series: 104, nllk loss: 0.34233, kernel loss: 0.07760\n",
      "Epoch: 4, series: 105, nllk loss: 0.54631, kernel loss: 0.04956\n",
      "Epoch: 4, series: 106, nllk loss: -0.89343, kernel loss: 0.07249\n",
      "Epoch: 4, series: 107, nllk loss: -0.74516, kernel loss: 0.16107\n",
      "Epoch: 4, series: 108, nllk loss: -1.12029, kernel loss: 0.35230\n",
      "Epoch: 4, series: 109, nllk loss: -0.22289, kernel loss: 0.11280\n",
      "Epoch: 4, series: 110, nllk loss: -1.20953, kernel loss: 0.13146\n",
      "Epoch: 4, series: 111, nllk loss: -1.16059, kernel loss: 0.13012\n",
      "Epoch: 4, series: 112, nllk loss: -0.59930, kernel loss: 0.17898\n",
      "Epoch: 4, series: 113, nllk loss: -0.88130, kernel loss: 0.16901\n",
      "Epoch: 4, series: 114, nllk loss: -0.66769, kernel loss: 0.09486\n",
      "Epoch: 4, series: 115, nllk loss: -0.89448, kernel loss: 0.12294\n",
      "Epoch: 4, series: 116, nllk loss: -1.44377, kernel loss: 0.24681\n",
      "Epoch: 4, series: 117, nllk loss: -0.60911, kernel loss: 0.16482\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, series: 118, nllk loss: -1.64506, kernel loss: 0.12654\n",
      "Epoch: 4, series: 119, nllk loss: -0.52493, kernel loss: 0.31445\n",
      "Epoch: 4, series: 120, nllk loss: -1.41659, kernel loss: 0.23516\n",
      "Epoch: 4, series: 121, nllk loss: 0.15325, kernel loss: 0.02010\n",
      "Epoch: 4, series: 122, nllk loss: -0.42836, kernel loss: 0.02300\n",
      "Epoch: 4, series: 123, nllk loss: -1.36145, kernel loss: 0.20257\n",
      "Epoch: 4, series: 124, nllk loss: -1.42922, kernel loss: 0.10421\n",
      "Epoch: 4, series: 125, nllk loss: -1.30370, kernel loss: 0.05716\n",
      "Epoch: 4, series: 126, nllk loss: -1.39186, kernel loss: 0.05007\n",
      "Epoch: 4, series: 127, nllk loss: -1.36082, kernel loss: 0.11522\n",
      "Epoch: 4, series: 128, nllk loss: -0.93758, kernel loss: 0.17191\n",
      "Epoch: 4, series: 129, nllk loss: -0.71091, kernel loss: 0.08278\n",
      "Epoch: 4, series: 130, nllk loss: -1.05766, kernel loss: 0.21850\n",
      "Epoch: 4, series: 131, nllk loss: 0.42071, kernel loss: 0.26689\n",
      "Epoch: 4, series: 132, nllk loss: -0.10211, kernel loss: 0.11838\n",
      "Epoch: 4, series: 133, nllk loss: -0.82436, kernel loss: 0.10984\n",
      "Epoch: 4, series: 134, nllk loss: -0.73151, kernel loss: 0.03491\n",
      "Epoch: 4, series: 135, nllk loss: -1.34481, kernel loss: 0.08954\n",
      "Epoch: 4, series: 136, nllk loss: -1.28503, kernel loss: 0.10784\n",
      "Epoch: 4, series: 137, nllk loss: -1.42444, kernel loss: 0.09854\n",
      "Epoch: 4, series: 138, nllk loss: -1.50514, kernel loss: 0.18700\n",
      "Epoch: 4, series: 139, nllk loss: -1.35576, kernel loss: 0.09782\n",
      "Epoch: 4, series: 140, nllk loss: -1.27009, kernel loss: 0.17912\n",
      "Epoch: 4, series: 141, nllk loss: -1.46259, kernel loss: 0.06955\n",
      "Epoch: 4, series: 142, nllk loss: -1.32740, kernel loss: 0.16767\n",
      "Epoch: 4, series: 143, nllk loss: -1.44321, kernel loss: 0.31475\n",
      "Epoch: 4, series: 144, nllk loss: -1.53116, kernel loss: 0.12344\n",
      "Epoch: 4, series: 145, nllk loss: -1.51919, kernel loss: 0.21624\n",
      "Epoch: 4, series: 146, nllk loss: 3.22599, kernel loss: 0.16322\n",
      "Epoch: 4, series: 147, nllk loss: -1.43295, kernel loss: 0.05736\n",
      "Epoch: 4, series: 148, nllk loss: -1.28987, kernel loss: 0.09162\n",
      "Epoch: 4, series: 149, nllk loss: -1.47164, kernel loss: 0.14504\n",
      "Epoch: 4, series: 150, nllk loss: -1.62073, kernel loss: 0.16628\n",
      "Epoch: 4, series: 151, nllk loss: -1.62165, kernel loss: 0.10475\n",
      "Epoch: 4, series: 152, nllk loss: -1.50483, kernel loss: 0.02704\n",
      "Epoch: 4, series: 153, nllk loss: -1.41504, kernel loss: 0.13595\n",
      "Epoch: 4, series: 154, nllk loss: -1.39391, kernel loss: 0.08900\n",
      "Epoch: 4, series: 155, nllk loss: -1.55204, kernel loss: 0.01381\n",
      "Epoch: 4, series: 156, nllk loss: -1.64998, kernel loss: 0.00398\n",
      "Epoch: 4, series: 157, nllk loss: -1.18324, kernel loss: 0.03623\n",
      "Epoch: 4, series: 158, nllk loss: -1.58689, kernel loss: 0.15127\n",
      "Epoch: 4, series: 159, nllk loss: -1.66714, kernel loss: 0.20716\n",
      "Epoch: 4, series: 160, nllk loss: -1.56411, kernel loss: 0.20378\n",
      "Epoch: 4, series: 161, nllk loss: -1.50656, kernel loss: 0.03784\n",
      "Epoch: 4, series: 162, nllk loss: -1.61026, kernel loss: 0.13886\n",
      "Epoch: 4, series: 163, nllk loss: -1.91997, kernel loss: 0.15842\n",
      "Epoch: 4, series: 164, nllk loss: -1.64028, kernel loss: 0.17816\n",
      "Epoch: 4, series: 165, nllk loss: -1.72844, kernel loss: 0.17010\n",
      "Epoch: 4, series: 166, nllk loss: -1.27769, kernel loss: 0.17174\n",
      "Epoch: 4, series: 167, nllk loss: -1.99979, kernel loss: 0.04579\n",
      "Epoch: 4, series: 168, nllk loss: -1.88896, kernel loss: 0.26088\n",
      "Epoch: 4, series: 169, nllk loss: -1.99191, kernel loss: 0.07411\n",
      "Epoch: 4, series: 170, nllk loss: -1.69994, kernel loss: 0.28163\n",
      "Epoch: 4, series: 171, nllk loss: -1.95251, kernel loss: 0.19960\n",
      "Epoch: 4, series: 172, nllk loss: -1.78818, kernel loss: 0.07130\n",
      "Epoch: 4, series: 173, nllk loss: -2.13750, kernel loss: 0.11410\n",
      "Epoch: 4, series: 174, nllk loss: -1.61477, kernel loss: 0.18007\n",
      "Epoch: 4, series: 175, nllk loss: -1.94962, kernel loss: 0.16222\n",
      "Epoch: 4, series: 176, nllk loss: -1.95402, kernel loss: 0.07614\n",
      "Epoch: 4, series: 177, nllk loss: -1.48778, kernel loss: 0.16003\n",
      "Epoch: 4, series: 178, nllk loss: -1.37923, kernel loss: 0.25649\n",
      "Epoch: 4, series: 179, nllk loss: -1.87308, kernel loss: 0.03285\n",
      "Epoch: 4, series: 180, nllk loss: -1.79684, kernel loss: 0.01308\n",
      "Epoch: 4, series: 181, nllk loss: -2.08300, kernel loss: 0.04656\n",
      "Epoch: 4, series: 182, nllk loss: -1.85136, kernel loss: 0.24534\n",
      "Epoch: 4, series: 183, nllk loss: -1.84382, kernel loss: 0.08047\n",
      "Epoch: 4, series: 184, nllk loss: -1.75665, kernel loss: 0.26441\n",
      "Epoch: 4, series: 185, nllk loss: -1.64168, kernel loss: 0.04257\n",
      "Epoch: 4, series: 186, nllk loss: -2.02134, kernel loss: 0.30664\n",
      "Epoch: 4, series: 187, nllk loss: -2.09134, kernel loss: 0.05629\n",
      "Epoch: 4, series: 188, nllk loss: -1.43342, kernel loss: 0.12201\n",
      "Epoch: 4, series: 189, nllk loss: -1.23304, kernel loss: 0.19510\n",
      "Epoch: 4, series: 190, nllk loss: -1.83125, kernel loss: 0.21438\n",
      "Epoch: 4, series: 191, nllk loss: -1.86479, kernel loss: 0.21637\n",
      "Epoch: 4, series: 192, nllk loss: -1.82945, kernel loss: 0.24337\n",
      "Epoch: 4, series: 193, nllk loss: -1.28002, kernel loss: 0.33576\n",
      "Epoch: 4, series: 194, nllk loss: -1.21751, kernel loss: 0.12026\n",
      "Epoch: 4, series: 195, nllk loss: -2.09078, kernel loss: 0.04036\n",
      "Epoch: 4, series: 196, nllk loss: -1.61102, kernel loss: 0.15467\n",
      "Epoch: 4, series: 197, nllk loss: -1.81008, kernel loss: 0.47271\n",
      "Epoch: 4, series: 198, nllk loss: -1.92314, kernel loss: 0.19196\n",
      "Epoch: 4, series: 199, nllk loss: -1.81055, kernel loss: 0.03628\n",
      "Epoch: 4, series: 200, nllk loss: -2.00286, kernel loss: 0.09256\n",
      "Epoch: 4, series: 201, nllk loss: -1.91959, kernel loss: 0.15089\n",
      "Epoch: 4, series: 202, nllk loss: -1.79399, kernel loss: 0.16587\n",
      "Epoch: 4, series: 203, nllk loss: -1.88525, kernel loss: 0.20445\n",
      "Epoch: 4, series: 204, nllk loss: -0.92194, kernel loss: 0.11844\n",
      "Epoch: 4, series: 205, nllk loss: -1.65771, kernel loss: 0.28416\n",
      "Epoch: 4, series: 206, nllk loss: -1.95965, kernel loss: 0.46068\n",
      "Epoch: 4, series: 207, nllk loss: -1.08659, kernel loss: 0.22296\n",
      "Epoch: 4, series: 208, nllk loss: -2.03170, kernel loss: 0.15550\n",
      "Epoch: 4, series: 209, nllk loss: -1.24680, kernel loss: 0.33128\n",
      "Epoch: 4, series: 210, nllk loss: -2.12273, kernel loss: 0.29725\n",
      "Epoch: 4, series: 211, nllk loss: -1.95129, kernel loss: 0.28525\n",
      "Epoch: 4, series: 212, nllk loss: -1.55518, kernel loss: 0.04404\n",
      "Epoch: 4, series: 213, nllk loss: -1.84146, kernel loss: 0.04502\n",
      "Epoch: 4, series: 214, nllk loss: -1.97785, kernel loss: 0.09342\n",
      "Epoch: 4, series: 215, nllk loss: -2.12246, kernel loss: 0.17881\n",
      "Epoch: 4, series: 216, nllk loss: -1.03033, kernel loss: 0.44566\n",
      "Epoch: 4, series: 217, nllk loss: -1.59584, kernel loss: 0.09860\n",
      "Epoch: 4, series: 218, nllk loss: -1.21321, kernel loss: 0.11482\n",
      "Epoch: 4, series: 219, nllk loss: -1.48595, kernel loss: 0.10495\n",
      "Epoch: 4, series: 220, nllk loss: -1.64023, kernel loss: 0.12234\n",
      "Epoch: 4, series: 221, nllk loss: -1.99662, kernel loss: 0.21942\n",
      "Epoch: 4, series: 222, nllk loss: -1.90282, kernel loss: 0.19281\n",
      "Epoch: 4, series: 223, nllk loss: -1.35619, kernel loss: 0.27803\n",
      "Epoch: 4, series: 224, nllk loss: -1.98083, kernel loss: 0.19990\n",
      "Epoch: 4, series: 225, nllk loss: -1.77873, kernel loss: 0.19174\n",
      "Epoch: 4, series: 226, nllk loss: -1.47961, kernel loss: 0.17706\n",
      "Epoch: 4, series: 227, nllk loss: -1.58452, kernel loss: 0.16495\n",
      "Epoch: 4, series: 228, nllk loss: -1.63881, kernel loss: 0.07844\n",
      "Epoch: 4, series: 229, nllk loss: -1.57192, kernel loss: 0.08913\n",
      "Epoch: 4, series: 230, nllk loss: -1.93107, kernel loss: 0.26464\n",
      "Epoch: 4, series: 231, nllk loss: -1.56056, kernel loss: 0.06272\n",
      "Epoch: 4, series: 232, nllk loss: -2.12154, kernel loss: 0.09147\n",
      "Epoch: 4, series: 233, nllk loss: -1.99940, kernel loss: 0.10339\n",
      "Epoch: 4, series: 234, nllk loss: -1.71375, kernel loss: 0.09522\n",
      "Epoch: 4, series: 235, nllk loss: -2.09458, kernel loss: 0.06347\n",
      "Epoch: 4, series: 236, nllk loss: -1.24705, kernel loss: 0.10330\n",
      "Epoch: 4, series: 237, nllk loss: -1.80934, kernel loss: 0.11952\n",
      "Epoch: 4, series: 238, nllk loss: -1.58043, kernel loss: 0.20590\n",
      "Epoch: 4, series: 239, nllk loss: -1.59019, kernel loss: 0.09686\n",
      "Epoch: 4, series: 240, nllk loss: -1.38060, kernel loss: 0.12631\n",
      "Epoch: 4, series: 241, nllk loss: -1.62393, kernel loss: 0.19612\n",
      "Epoch: 4, series: 242, nllk loss: -1.84586, kernel loss: 0.28373\n",
      "Epoch: 4, series: 243, nllk loss: -2.15444, kernel loss: 0.26703\n",
      "Epoch: 4, series: 244, nllk loss: -1.66864, kernel loss: 0.04660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, series: 245, nllk loss: -1.93168, kernel loss: 0.10252\n",
      "Epoch: 4, series: 246, nllk loss: 0.11214, kernel loss: 0.15261\n",
      "Epoch: 4, series: 247, nllk loss: -1.58311, kernel loss: 0.09295\n",
      "Epoch: 4, series: 248, nllk loss: -1.75096, kernel loss: 0.09988\n",
      "Epoch: 4, series: 249, nllk loss: -1.61186, kernel loss: 0.17469\n",
      "Epoch: 4, series: 250, nllk loss: -1.56375, kernel loss: 0.36632\n",
      "Epoch: 4, series: 251, nllk loss: -0.94854, kernel loss: 0.24744\n",
      "Epoch: 4, series: 252, nllk loss: -0.72390, kernel loss: 0.06673\n",
      "Epoch: 4, series: 253, nllk loss: -1.62431, kernel loss: 0.06172\n",
      "Epoch: 4, series: 254, nllk loss: -2.03569, kernel loss: 0.10091\n",
      "Epoch: 4, series: 255, nllk loss: -1.81456, kernel loss: 0.15412\n",
      "Epoch: 4, series: 256, nllk loss: -1.38390, kernel loss: 0.26545\n",
      "Epoch: 4, series: 257, nllk loss: -1.87688, kernel loss: 0.16707\n",
      "Epoch: 4, series: 258, nllk loss: -1.83285, kernel loss: 0.22294\n",
      "Epoch: 4, series: 259, nllk loss: -1.50670, kernel loss: 0.11434\n",
      "Epoch: 4, series: 260, nllk loss: -1.52959, kernel loss: 0.07709\n",
      "Epoch: 4, series: 261, nllk loss: -1.81193, kernel loss: 0.03482\n",
      "Epoch: 4, series: 262, nllk loss: -1.97801, kernel loss: 0.06096\n",
      "Epoch: 4, series: 263, nllk loss: -0.65921, kernel loss: 0.04818\n",
      "Epoch: 4, series: 264, nllk loss: -1.72194, kernel loss: 0.07658\n",
      "Epoch: 4, series: 265, nllk loss: -1.73948, kernel loss: 0.28021\n",
      "Epoch: 4, series: 266, nllk loss: -1.78499, kernel loss: 0.25885\n",
      "Epoch: 4, series: 267, nllk loss: -1.80550, kernel loss: 0.19257\n",
      "Epoch: 4, series: 268, nllk loss: -1.97419, kernel loss: 0.09517\n",
      "Epoch: 4, series: 269, nllk loss: -1.52261, kernel loss: 0.08507\n",
      "Epoch: 4, series: 270, nllk loss: -1.56583, kernel loss: 0.13225\n",
      "Epoch: 4, series: 271, nllk loss: -1.69972, kernel loss: 0.27945\n",
      "Epoch: 4, series: 272, nllk loss: -1.71697, kernel loss: 0.15813\n",
      "Epoch: 4, series: 273, nllk loss: -1.84060, kernel loss: 0.15643\n",
      "Epoch: 4, series: 274, nllk loss: -1.34670, kernel loss: 0.13855\n",
      "Epoch: 4, series: 275, nllk loss: -1.79095, kernel loss: 0.11403\n",
      "Epoch: 4, series: 276, nllk loss: -0.92006, kernel loss: 0.11432\n",
      "Epoch: 4, series: 277, nllk loss: -1.80220, kernel loss: 0.09406\n",
      "Epoch: 4, series: 278, nllk loss: -1.53524, kernel loss: 0.07443\n",
      "Epoch: 4, series: 279, nllk loss: -2.08848, kernel loss: 0.16792\n",
      "Epoch: 4, series: 280, nllk loss: -1.94302, kernel loss: 0.04679\n",
      "Epoch: 4, series: 281, nllk loss: -2.05546, kernel loss: 0.08510\n",
      "Epoch: 4, series: 282, nllk loss: -1.96001, kernel loss: 0.20611\n",
      "Epoch: 4, series: 283, nllk loss: -1.82276, kernel loss: 0.10167\n",
      "Epoch: 4, series: 284, nllk loss: -1.69596, kernel loss: 0.13578\n",
      "Epoch: 4, series: 285, nllk loss: -1.79399, kernel loss: 0.17904\n",
      "Epoch: 4, series: 286, nllk loss: -1.85920, kernel loss: 0.24012\n",
      "Epoch: 4, series: 287, nllk loss: -2.20804, kernel loss: 0.07144\n",
      "Epoch: 4, series: 288, nllk loss: -0.90855, kernel loss: 0.02092\n",
      "Epoch: 4, series: 289, nllk loss: -0.85392, kernel loss: 0.05960\n",
      "Epoch: 4, series: 290, nllk loss: -2.06947, kernel loss: 0.07178\n",
      "Epoch: 4, series: 291, nllk loss: -1.97585, kernel loss: 0.30961\n",
      "Epoch: 4, series: 292, nllk loss: -2.04063, kernel loss: 0.08998\n",
      "Epoch: 4, series: 293, nllk loss: -2.16561, kernel loss: 0.12454\n",
      "Epoch: 4, series: 294, nllk loss: -1.43673, kernel loss: 0.11662\n",
      "Epoch: 4, series: 295, nllk loss: -1.06523, kernel loss: 0.15131\n",
      "Epoch: 4, series: 296, nllk loss: -2.10888, kernel loss: 0.28562\n",
      "Epoch: 4, series: 297, nllk loss: -2.03517, kernel loss: 0.05484\n",
      "Epoch: 4, series: 298, nllk loss: 4.05261, kernel loss: 0.18875\n",
      "Epoch: 4, series: 299, nllk loss: 2.19062, kernel loss: 0.21102\n",
      "Epoch: 4, series: 300, nllk loss: -1.79458, kernel loss: 0.15526\n",
      "Epoch: 4, series: 301, nllk loss: -1.58502, kernel loss: 0.24601\n",
      "Epoch: 4, series: 302, nllk loss: -1.62893, kernel loss: 0.26486\n",
      "Epoch: 4, series: 303, nllk loss: -1.28697, kernel loss: 0.19974\n",
      "Epoch: 4, series: 304, nllk loss: -0.84820, kernel loss: 0.05768\n",
      "Epoch: 4, series: 305, nllk loss: -1.10685, kernel loss: 0.31684\n",
      "Epoch: 4, series: 306, nllk loss: -1.73819, kernel loss: 0.26080\n",
      "Epoch: 4, series: 307, nllk loss: -1.18783, kernel loss: 0.24038\n",
      "Epoch: 4, series: 308, nllk loss: -1.62591, kernel loss: 0.16811\n",
      "Epoch: 4, series: 309, nllk loss: -1.44379, kernel loss: 0.17577\n",
      "Epoch: 4, series: 310, nllk loss: -1.55806, kernel loss: 0.30028\n",
      "Epoch: 4, series: 311, nllk loss: -1.30511, kernel loss: 0.30467\n",
      "Epoch: 4, series: 312, nllk loss: -1.58919, kernel loss: 0.20544\n",
      "Epoch: 4, series: 313, nllk loss: -1.70948, kernel loss: 0.24148\n",
      "Epoch: 4, series: 314, nllk loss: -1.87699, kernel loss: 0.23055\n",
      "Epoch: 4, series: 315, nllk loss: -0.89673, kernel loss: 0.02766\n",
      "Epoch: 4, series: 316, nllk loss: -1.41289, kernel loss: 0.17636\n",
      "Epoch: 4, series: 317, nllk loss: 0.66952, kernel loss: 0.09783\n",
      "Epoch: 4, series: 318, nllk loss: 1.78200, kernel loss: 0.23602\n",
      "Epoch: 4, series: 319, nllk loss: -0.72323, kernel loss: 0.50592\n",
      "Epoch: 4, series: 320, nllk loss: -0.85581, kernel loss: 0.30249\n",
      "Epoch: 4, total loss: -360.39117\n",
      "Epoch: 5, series: 0, nllk loss: 2.98856, kernel loss: 0.09169\n",
      "Epoch: 5, series: 1, nllk loss: -0.72960, kernel loss: 0.19625\n",
      "Epoch: 5, series: 2, nllk loss: 0.44086, kernel loss: 0.22852\n",
      "Epoch: 5, series: 3, nllk loss: -0.78652, kernel loss: 0.16544\n",
      "Epoch: 5, series: 4, nllk loss: -0.67076, kernel loss: 0.11200\n",
      "Epoch: 5, series: 5, nllk loss: -0.74352, kernel loss: 0.14855\n",
      "Epoch: 5, series: 6, nllk loss: -0.40511, kernel loss: 0.17998\n",
      "Epoch: 5, series: 7, nllk loss: -0.97217, kernel loss: 0.22435\n",
      "Epoch: 5, series: 8, nllk loss: -0.43665, kernel loss: 0.64705\n",
      "Epoch: 5, series: 9, nllk loss: -0.43793, kernel loss: 0.22564\n",
      "Epoch: 5, series: 10, nllk loss: -0.95644, kernel loss: 0.43841\n",
      "Epoch: 5, series: 11, nllk loss: -0.73222, kernel loss: 0.28061\n",
      "Epoch: 5, series: 12, nllk loss: -1.10249, kernel loss: 0.06761\n",
      "Epoch: 5, series: 13, nllk loss: -1.03239, kernel loss: 0.27777\n",
      "Epoch: 5, series: 14, nllk loss: -1.11014, kernel loss: 0.14019\n",
      "Epoch: 5, series: 15, nllk loss: -1.08117, kernel loss: 0.09746\n",
      "Epoch: 5, series: 16, nllk loss: -0.80643, kernel loss: 0.18119\n",
      "Epoch: 5, series: 17, nllk loss: -0.88982, kernel loss: 0.21470\n",
      "Epoch: 5, series: 18, nllk loss: -1.03923, kernel loss: 0.21307\n",
      "Epoch: 5, series: 19, nllk loss: -0.34071, kernel loss: 0.24636\n",
      "Epoch: 5, series: 20, nllk loss: -0.70113, kernel loss: 0.15447\n",
      "Epoch: 5, series: 21, nllk loss: -0.92260, kernel loss: 0.14061\n",
      "Epoch: 5, series: 22, nllk loss: -1.13145, kernel loss: 0.07205\n",
      "Epoch: 5, series: 23, nllk loss: -1.11246, kernel loss: 0.09880\n",
      "Epoch: 5, series: 24, nllk loss: -1.30497, kernel loss: 0.07940\n",
      "Epoch: 5, series: 25, nllk loss: -1.24936, kernel loss: 0.14224\n",
      "Epoch: 5, series: 26, nllk loss: -1.17384, kernel loss: 0.12876\n",
      "Epoch: 5, series: 27, nllk loss: -1.03209, kernel loss: 0.15809\n",
      "Epoch: 5, series: 28, nllk loss: -1.20902, kernel loss: 0.22117\n",
      "Epoch: 5, series: 29, nllk loss: -0.55846, kernel loss: 0.33618\n",
      "Epoch: 5, series: 30, nllk loss: -1.19096, kernel loss: 0.16677\n",
      "Epoch: 5, series: 31, nllk loss: -1.09763, kernel loss: 0.18759\n",
      "Epoch: 5, series: 32, nllk loss: -1.05351, kernel loss: 0.15514\n",
      "Epoch: 5, series: 33, nllk loss: -1.00158, kernel loss: 0.14577\n",
      "Epoch: 5, series: 34, nllk loss: -1.24520, kernel loss: 0.03947\n",
      "Epoch: 5, series: 35, nllk loss: -1.30419, kernel loss: 0.06910\n",
      "Epoch: 5, series: 36, nllk loss: -1.25267, kernel loss: 0.00793\n",
      "Epoch: 5, series: 37, nllk loss: -0.39360, kernel loss: 0.12776\n",
      "Epoch: 5, series: 38, nllk loss: -1.04584, kernel loss: 0.11049\n",
      "Epoch: 5, series: 39, nllk loss: -0.78160, kernel loss: 0.18613\n",
      "Epoch: 5, series: 40, nllk loss: -1.56318, kernel loss: 0.17259\n",
      "Epoch: 5, series: 41, nllk loss: -1.23856, kernel loss: 0.25162\n",
      "Epoch: 5, series: 42, nllk loss: -1.08042, kernel loss: 0.06024\n",
      "Epoch: 5, series: 43, nllk loss: -0.97369, kernel loss: 0.09224\n",
      "Epoch: 5, series: 44, nllk loss: -1.46828, kernel loss: 0.20735\n",
      "Epoch: 5, series: 45, nllk loss: -1.52123, kernel loss: 0.03210\n",
      "Epoch: 5, series: 46, nllk loss: -1.48811, kernel loss: 0.14829\n",
      "Epoch: 5, series: 47, nllk loss: -1.45115, kernel loss: 0.04767\n",
      "Epoch: 5, series: 48, nllk loss: -1.45508, kernel loss: 0.05908\n",
      "Epoch: 5, series: 49, nllk loss: -1.18457, kernel loss: 0.08076\n",
      "Epoch: 5, series: 50, nllk loss: 0.06899, kernel loss: 0.23837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, series: 51, nllk loss: -1.31936, kernel loss: 0.21434\n",
      "Epoch: 5, series: 52, nllk loss: -0.46393, kernel loss: 0.00000\n",
      "Epoch: 5, series: 53, nllk loss: -1.38918, kernel loss: 0.14046\n",
      "Epoch: 5, series: 54, nllk loss: -1.04802, kernel loss: 0.00829\n",
      "Epoch: 5, series: 55, nllk loss: -0.91547, kernel loss: 0.16654\n",
      "Epoch: 5, series: 56, nllk loss: -1.22457, kernel loss: 0.23055\n",
      "Epoch: 5, series: 57, nllk loss: -1.21924, kernel loss: 0.04928\n",
      "Epoch: 5, series: 58, nllk loss: -1.33554, kernel loss: 0.00000\n",
      "Epoch: 5, series: 59, nllk loss: -0.92845, kernel loss: 0.04133\n",
      "Epoch: 5, series: 60, nllk loss: -0.97439, kernel loss: 0.25498\n",
      "Epoch: 5, series: 61, nllk loss: -1.57706, kernel loss: 0.10118\n",
      "Epoch: 5, series: 62, nllk loss: -1.58265, kernel loss: 0.10241\n",
      "Epoch: 5, series: 63, nllk loss: -1.44046, kernel loss: 0.10789\n",
      "Epoch: 5, series: 64, nllk loss: -0.93519, kernel loss: 0.09312\n",
      "Epoch: 5, series: 65, nllk loss: -1.42920, kernel loss: 0.00728\n",
      "Epoch: 5, series: 66, nllk loss: -1.36691, kernel loss: 0.13776\n",
      "Epoch: 5, series: 67, nllk loss: -1.22378, kernel loss: 0.03164\n",
      "Epoch: 5, series: 68, nllk loss: -0.54559, kernel loss: 0.28323\n",
      "Epoch: 5, series: 69, nllk loss: -1.35211, kernel loss: 0.13645\n",
      "Epoch: 5, series: 70, nllk loss: -1.45191, kernel loss: 0.29001\n",
      "Epoch: 5, series: 71, nllk loss: -1.37848, kernel loss: 0.07115\n",
      "Epoch: 5, series: 72, nllk loss: -1.61536, kernel loss: 0.34725\n",
      "Epoch: 5, series: 73, nllk loss: -1.19657, kernel loss: 0.21115\n",
      "Epoch: 5, series: 74, nllk loss: -1.67798, kernel loss: 0.02561\n",
      "Epoch: 5, series: 75, nllk loss: -1.31265, kernel loss: 0.34118\n",
      "Epoch: 5, series: 76, nllk loss: -1.33298, kernel loss: 0.12327\n",
      "Epoch: 5, series: 77, nllk loss: -1.07994, kernel loss: 0.25352\n",
      "Epoch: 5, series: 78, nllk loss: -1.37583, kernel loss: 0.02175\n",
      "Epoch: 5, series: 79, nllk loss: -0.67558, kernel loss: 0.00000\n",
      "Epoch: 5, series: 80, nllk loss: -1.56933, kernel loss: 0.39936\n",
      "Epoch: 5, series: 81, nllk loss: -1.14724, kernel loss: 0.14629\n",
      "Epoch: 5, series: 82, nllk loss: -0.21221, kernel loss: 0.09259\n",
      "Epoch: 5, series: 83, nllk loss: -0.55109, kernel loss: 0.25090\n",
      "Epoch: 5, series: 84, nllk loss: -0.98403, kernel loss: 0.01265\n",
      "Epoch: 5, series: 85, nllk loss: -1.08995, kernel loss: 0.09921\n",
      "Epoch: 5, series: 86, nllk loss: -0.17778, kernel loss: 0.00000\n",
      "Epoch: 5, series: 87, nllk loss: -1.55675, kernel loss: 0.18154\n",
      "Epoch: 5, series: 88, nllk loss: -1.75410, kernel loss: 0.40279\n",
      "Epoch: 5, series: 89, nllk loss: -1.75322, kernel loss: 0.23043\n",
      "Epoch: 5, series: 90, nllk loss: -1.68518, kernel loss: 0.14089\n",
      "Epoch: 5, series: 91, nllk loss: -1.72651, kernel loss: 0.01380\n",
      "Epoch: 5, series: 92, nllk loss: 0.49597, kernel loss: 0.12955\n",
      "Epoch: 5, series: 93, nllk loss: -1.84108, kernel loss: 0.14106\n",
      "Epoch: 5, series: 94, nllk loss: -1.85033, kernel loss: 0.14961\n",
      "Epoch: 5, series: 95, nllk loss: -1.79493, kernel loss: 0.20532\n",
      "Epoch: 5, series: 96, nllk loss: -1.40425, kernel loss: 0.14121\n",
      "Epoch: 5, series: 97, nllk loss: -0.62117, kernel loss: 0.35993\n",
      "Epoch: 5, series: 98, nllk loss: -0.79138, kernel loss: 0.12834\n",
      "Epoch: 5, series: 99, nllk loss: -1.17701, kernel loss: 0.17774\n",
      "Epoch: 5, series: 100, nllk loss: -1.07846, kernel loss: 0.23752\n",
      "Epoch: 5, series: 101, nllk loss: -1.49001, kernel loss: 0.06230\n",
      "Epoch: 5, series: 102, nllk loss: -1.15610, kernel loss: 0.11092\n",
      "Epoch: 5, series: 103, nllk loss: -0.97029, kernel loss: 0.27572\n",
      "Epoch: 5, series: 104, nllk loss: 0.26828, kernel loss: 0.07373\n",
      "Epoch: 5, series: 105, nllk loss: 0.35744, kernel loss: 0.05535\n",
      "Epoch: 5, series: 106, nllk loss: -0.88742, kernel loss: 0.05609\n",
      "Epoch: 5, series: 107, nllk loss: -0.73267, kernel loss: 0.15268\n",
      "Epoch: 5, series: 108, nllk loss: -1.06748, kernel loss: 0.07590\n",
      "Epoch: 5, series: 109, nllk loss: -0.15928, kernel loss: 0.32555\n",
      "Epoch: 5, series: 110, nllk loss: -1.34035, kernel loss: 0.13748\n",
      "Epoch: 5, series: 111, nllk loss: -1.19261, kernel loss: 0.27774\n",
      "Epoch: 5, series: 112, nllk loss: -0.39614, kernel loss: 0.45951\n",
      "Epoch: 5, series: 113, nllk loss: -0.91576, kernel loss: 0.36056\n",
      "Epoch: 5, series: 114, nllk loss: -0.50320, kernel loss: 0.35499\n",
      "Epoch: 5, series: 115, nllk loss: -0.87407, kernel loss: 0.22763\n",
      "Epoch: 5, series: 116, nllk loss: -1.54407, kernel loss: 0.05265\n",
      "Epoch: 5, series: 117, nllk loss: -0.57652, kernel loss: 0.07276\n",
      "Epoch: 5, series: 118, nllk loss: -1.63486, kernel loss: 0.03791\n",
      "Epoch: 5, series: 119, nllk loss: -0.56589, kernel loss: 0.05555\n",
      "Epoch: 5, series: 120, nllk loss: -1.43837, kernel loss: 0.17635\n",
      "Epoch: 5, series: 121, nllk loss: 0.19939, kernel loss: 0.22537\n",
      "Epoch: 5, series: 122, nllk loss: -0.47649, kernel loss: 0.06077\n",
      "Epoch: 5, series: 123, nllk loss: -1.33166, kernel loss: 0.21138\n",
      "Epoch: 5, series: 124, nllk loss: -1.48195, kernel loss: 0.14093\n",
      "Epoch: 5, series: 125, nllk loss: -1.32722, kernel loss: 0.08597\n",
      "Epoch: 5, series: 126, nllk loss: -1.42378, kernel loss: 0.11860\n",
      "Epoch: 5, series: 127, nllk loss: -1.38951, kernel loss: 0.08932\n",
      "Epoch: 5, series: 128, nllk loss: -0.90356, kernel loss: 0.08849\n",
      "Epoch: 5, series: 129, nllk loss: -0.66657, kernel loss: 0.01093\n",
      "Epoch: 5, series: 130, nllk loss: -1.01826, kernel loss: 0.14769\n",
      "Epoch: 5, series: 131, nllk loss: 0.51705, kernel loss: 0.13159\n",
      "Epoch: 5, series: 132, nllk loss: -0.00236, kernel loss: 0.16953\n",
      "Epoch: 5, series: 133, nllk loss: -0.79448, kernel loss: 0.09287\n",
      "Epoch: 5, series: 134, nllk loss: -0.73292, kernel loss: 0.07922\n",
      "Epoch: 5, series: 135, nllk loss: -1.34443, kernel loss: 0.14145\n",
      "Epoch: 5, series: 136, nllk loss: -1.33013, kernel loss: 0.12860\n",
      "Epoch: 5, series: 137, nllk loss: -1.52265, kernel loss: 0.05784\n",
      "Epoch: 5, series: 138, nllk loss: -1.55564, kernel loss: 0.06735\n",
      "Epoch: 5, series: 139, nllk loss: -1.38266, kernel loss: 0.12048\n",
      "Epoch: 5, series: 140, nllk loss: -1.29912, kernel loss: 0.10029\n",
      "Epoch: 5, series: 141, nllk loss: -1.43426, kernel loss: 0.17673\n",
      "Epoch: 5, series: 142, nllk loss: -1.30913, kernel loss: 0.07984\n",
      "Epoch: 5, series: 143, nllk loss: -1.46473, kernel loss: 0.20617\n",
      "Epoch: 5, series: 144, nllk loss: -1.55721, kernel loss: 0.33285\n",
      "Epoch: 5, series: 145, nllk loss: -1.55529, kernel loss: 0.06670\n",
      "Epoch: 5, series: 146, nllk loss: 3.57663, kernel loss: 0.28100\n",
      "Epoch: 5, series: 147, nllk loss: -1.41371, kernel loss: 0.03273\n",
      "Epoch: 5, series: 148, nllk loss: -1.28327, kernel loss: 0.03579\n",
      "Epoch: 5, series: 149, nllk loss: -1.46985, kernel loss: 0.14327\n",
      "Epoch: 5, series: 150, nllk loss: -1.62914, kernel loss: 0.05876\n",
      "Epoch: 5, series: 151, nllk loss: -1.71138, kernel loss: 0.08022\n",
      "Epoch: 5, series: 152, nllk loss: -1.60423, kernel loss: 0.16973\n",
      "Epoch: 5, series: 153, nllk loss: -1.47287, kernel loss: 0.05514\n",
      "Epoch: 5, series: 154, nllk loss: -1.48128, kernel loss: 0.11797\n",
      "Epoch: 5, series: 155, nllk loss: -1.52377, kernel loss: 0.27409\n",
      "Epoch: 5, series: 156, nllk loss: -1.68899, kernel loss: 0.11376\n",
      "Epoch: 5, series: 157, nllk loss: -1.25019, kernel loss: 0.08727\n",
      "Epoch: 5, series: 158, nllk loss: -1.62026, kernel loss: 0.29214\n",
      "Epoch: 5, series: 159, nllk loss: -1.70873, kernel loss: 0.09097\n",
      "Epoch: 5, series: 160, nllk loss: -1.57570, kernel loss: 0.22839\n",
      "Epoch: 5, series: 161, nllk loss: -1.49203, kernel loss: 0.04724\n",
      "Epoch: 5, series: 162, nllk loss: -1.62069, kernel loss: 0.15065\n",
      "Epoch: 5, series: 163, nllk loss: -1.95607, kernel loss: 0.14135\n",
      "Epoch: 5, series: 164, nllk loss: -1.64752, kernel loss: 0.26004\n",
      "Epoch: 5, series: 165, nllk loss: -1.76191, kernel loss: 0.25694\n",
      "Epoch: 5, series: 166, nllk loss: -1.29505, kernel loss: 0.19549\n",
      "Epoch: 5, series: 167, nllk loss: -2.02325, kernel loss: 0.09270\n",
      "Epoch: 5, series: 168, nllk loss: -1.89491, kernel loss: 0.13753\n",
      "Epoch: 5, series: 169, nllk loss: -1.99289, kernel loss: 0.24235\n",
      "Epoch: 5, series: 170, nllk loss: -1.63902, kernel loss: 0.08359\n",
      "Epoch: 5, series: 171, nllk loss: -1.95388, kernel loss: 0.20343\n",
      "Epoch: 5, series: 172, nllk loss: -1.75409, kernel loss: 0.09285\n",
      "Epoch: 5, series: 173, nllk loss: -2.16758, kernel loss: 0.11428\n",
      "Epoch: 5, series: 174, nllk loss: -1.71997, kernel loss: 0.16497\n",
      "Epoch: 5, series: 175, nllk loss: -1.99115, kernel loss: 0.15562\n",
      "Epoch: 5, series: 176, nllk loss: -1.99094, kernel loss: 0.31454\n",
      "Epoch: 5, series: 177, nllk loss: -1.60149, kernel loss: 0.03957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, series: 178, nllk loss: -1.39036, kernel loss: 0.18716\n",
      "Epoch: 5, series: 179, nllk loss: -1.87228, kernel loss: 0.24834\n",
      "Epoch: 5, series: 180, nllk loss: -1.88717, kernel loss: 0.17085\n",
      "Epoch: 5, series: 181, nllk loss: -2.09509, kernel loss: 0.01874\n",
      "Epoch: 5, series: 182, nllk loss: -1.87136, kernel loss: 0.18227\n",
      "Epoch: 5, series: 183, nllk loss: -1.88751, kernel loss: 0.18389\n",
      "Epoch: 5, series: 184, nllk loss: -1.71557, kernel loss: 0.14353\n",
      "Epoch: 5, series: 185, nllk loss: -1.68884, kernel loss: 0.15327\n",
      "Epoch: 5, series: 186, nllk loss: -2.21121, kernel loss: 0.49246\n",
      "Epoch: 5, series: 187, nllk loss: -2.31172, kernel loss: 0.14962\n",
      "Epoch: 5, series: 188, nllk loss: -1.50382, kernel loss: 0.10250\n",
      "Epoch: 5, series: 189, nllk loss: -1.31264, kernel loss: 0.22506\n",
      "Epoch: 5, series: 190, nllk loss: -1.73364, kernel loss: 0.24854\n",
      "Epoch: 5, series: 191, nllk loss: -1.73641, kernel loss: 0.26433\n",
      "Epoch: 5, series: 192, nllk loss: -1.84372, kernel loss: 0.28925\n",
      "Epoch: 5, series: 193, nllk loss: -1.48209, kernel loss: 0.20814\n",
      "Epoch: 5, series: 194, nllk loss: -1.18611, kernel loss: 0.17216\n",
      "Epoch: 5, series: 195, nllk loss: -2.12296, kernel loss: 0.36664\n",
      "Epoch: 5, series: 196, nllk loss: -1.61749, kernel loss: 0.23946\n",
      "Epoch: 5, series: 197, nllk loss: -1.73331, kernel loss: 0.10597\n",
      "Epoch: 5, series: 198, nllk loss: -2.08278, kernel loss: 0.44926\n",
      "Epoch: 5, series: 199, nllk loss: -1.79597, kernel loss: 0.14552\n",
      "Epoch: 5, series: 200, nllk loss: -2.00741, kernel loss: 0.17914\n",
      "Epoch: 5, series: 201, nllk loss: -1.93172, kernel loss: 0.21592\n",
      "Epoch: 5, series: 202, nllk loss: -1.88485, kernel loss: 0.24006\n",
      "Epoch: 5, series: 203, nllk loss: -1.97834, kernel loss: 0.27741\n",
      "Epoch: 5, series: 204, nllk loss: -0.77036, kernel loss: 0.20061\n",
      "Epoch: 5, series: 205, nllk loss: -1.69501, kernel loss: 0.13280\n",
      "Epoch: 5, series: 206, nllk loss: -1.93770, kernel loss: 0.12247\n",
      "Epoch: 5, series: 207, nllk loss: -1.01586, kernel loss: 0.26150\n",
      "Epoch: 5, series: 208, nllk loss: -2.07246, kernel loss: 0.20156\n",
      "Epoch: 5, series: 209, nllk loss: -1.24966, kernel loss: 0.16714\n",
      "Epoch: 5, series: 210, nllk loss: -2.22791, kernel loss: 0.08233\n",
      "Epoch: 5, series: 211, nllk loss: -2.03465, kernel loss: 0.09678\n",
      "Epoch: 5, series: 212, nllk loss: -1.38046, kernel loss: 0.18415\n",
      "Epoch: 5, series: 213, nllk loss: -1.76046, kernel loss: 0.16830\n",
      "Epoch: 5, series: 214, nllk loss: -1.94164, kernel loss: 0.23685\n",
      "Epoch: 5, series: 215, nllk loss: -2.01014, kernel loss: 0.17311\n",
      "Epoch: 5, series: 216, nllk loss: -0.96514, kernel loss: 0.13184\n",
      "Epoch: 5, series: 217, nllk loss: -1.64367, kernel loss: 0.06822\n",
      "Epoch: 5, series: 218, nllk loss: -1.24319, kernel loss: 0.08515\n",
      "Epoch: 5, series: 219, nllk loss: -1.58269, kernel loss: 0.03011\n",
      "Epoch: 5, series: 220, nllk loss: -1.63709, kernel loss: 0.07521\n",
      "Epoch: 5, series: 221, nllk loss: -1.80490, kernel loss: 0.04164\n",
      "Epoch: 5, series: 222, nllk loss: -1.74632, kernel loss: 0.24321\n",
      "Epoch: 5, series: 223, nllk loss: -1.45260, kernel loss: 0.16773\n",
      "Epoch: 5, series: 224, nllk loss: -2.10074, kernel loss: 0.10427\n",
      "Epoch: 5, series: 225, nllk loss: -1.74731, kernel loss: 0.19992\n",
      "Epoch: 5, series: 226, nllk loss: -1.38761, kernel loss: 0.22425\n",
      "Epoch: 5, series: 227, nllk loss: -1.59721, kernel loss: 0.05067\n",
      "Epoch: 5, series: 228, nllk loss: -1.76960, kernel loss: 0.29501\n",
      "Epoch: 5, series: 229, nllk loss: -1.66306, kernel loss: 0.04838\n",
      "Epoch: 5, series: 230, nllk loss: -1.96551, kernel loss: 0.05592\n",
      "Epoch: 5, series: 231, nllk loss: -1.59097, kernel loss: 0.00000\n",
      "Epoch: 5, series: 232, nllk loss: -2.03048, kernel loss: 0.03423\n",
      "Epoch: 5, series: 233, nllk loss: -1.99820, kernel loss: 0.16968\n",
      "Epoch: 5, series: 234, nllk loss: -1.88302, kernel loss: 0.26267\n",
      "Epoch: 5, series: 235, nllk loss: -2.24617, kernel loss: 0.28035\n",
      "Epoch: 5, series: 236, nllk loss: -1.23610, kernel loss: 0.22519\n",
      "Epoch: 5, series: 237, nllk loss: -1.66724, kernel loss: 0.23344\n",
      "Epoch: 5, series: 238, nllk loss: -1.55860, kernel loss: 0.06258\n",
      "Epoch: 5, series: 239, nllk loss: -1.81532, kernel loss: 0.26894\n",
      "Epoch: 5, series: 240, nllk loss: -1.46608, kernel loss: 0.13478\n",
      "Epoch: 5, series: 241, nllk loss: -1.61242, kernel loss: 0.04171\n",
      "Epoch: 5, series: 242, nllk loss: -1.74493, kernel loss: 0.15738\n",
      "Epoch: 5, series: 243, nllk loss: -2.18389, kernel loss: 0.16577\n",
      "Epoch: 5, series: 244, nllk loss: -1.70510, kernel loss: 0.13805\n",
      "Epoch: 5, series: 245, nllk loss: -1.93580, kernel loss: 0.24295\n",
      "Epoch: 5, series: 246, nllk loss: 0.27337, kernel loss: 0.10750\n",
      "Epoch: 5, series: 247, nllk loss: -1.53432, kernel loss: 0.11598\n",
      "Epoch: 5, series: 248, nllk loss: -1.67819, kernel loss: 0.11928\n",
      "Epoch: 5, series: 249, nllk loss: -1.78143, kernel loss: 0.03903\n",
      "Epoch: 5, series: 250, nllk loss: -1.57520, kernel loss: 0.24405\n",
      "Epoch: 5, series: 251, nllk loss: -0.98052, kernel loss: 0.16331\n",
      "Epoch: 5, series: 252, nllk loss: -0.80774, kernel loss: 0.11182\n",
      "Epoch: 5, series: 253, nllk loss: -1.64462, kernel loss: 0.19208\n",
      "Epoch: 5, series: 254, nllk loss: -2.10450, kernel loss: 0.05400\n",
      "Epoch: 5, series: 255, nllk loss: -1.92457, kernel loss: 0.13401\n",
      "Epoch: 5, series: 256, nllk loss: -1.63292, kernel loss: 0.09850\n",
      "Epoch: 5, series: 257, nllk loss: -1.85045, kernel loss: 0.06685\n",
      "Epoch: 5, series: 258, nllk loss: -1.86749, kernel loss: 0.38019\n",
      "Epoch: 5, series: 259, nllk loss: -1.65737, kernel loss: 0.24667\n",
      "Epoch: 5, series: 260, nllk loss: -1.69944, kernel loss: 0.25172\n",
      "Epoch: 5, series: 261, nllk loss: -1.98084, kernel loss: 0.20152\n",
      "Epoch: 5, series: 262, nllk loss: -2.16414, kernel loss: 0.12513\n",
      "Epoch: 5, series: 263, nllk loss: -0.70973, kernel loss: 0.03626\n",
      "Epoch: 5, series: 264, nllk loss: -1.74599, kernel loss: 0.10040\n",
      "Epoch: 5, series: 265, nllk loss: -1.84653, kernel loss: 0.12155\n",
      "Epoch: 5, series: 266, nllk loss: -1.89252, kernel loss: 0.12426\n",
      "Epoch: 5, series: 267, nllk loss: -1.89256, kernel loss: 0.03857\n",
      "Epoch: 5, series: 268, nllk loss: -2.02215, kernel loss: 0.07873\n",
      "Epoch: 5, series: 269, nllk loss: -1.68630, kernel loss: 0.14179\n",
      "Epoch: 5, series: 270, nllk loss: -1.64201, kernel loss: 0.00792\n",
      "Epoch: 5, series: 271, nllk loss: -1.77623, kernel loss: 0.36571\n",
      "Epoch: 5, series: 272, nllk loss: -1.83155, kernel loss: 0.40705\n",
      "Epoch: 5, series: 273, nllk loss: -1.91326, kernel loss: 0.02964\n",
      "Epoch: 5, series: 274, nllk loss: -1.46160, kernel loss: 0.15861\n",
      "Epoch: 5, series: 275, nllk loss: -1.82451, kernel loss: 0.36387\n",
      "Epoch: 5, series: 276, nllk loss: -0.95839, kernel loss: 0.26459\n",
      "Epoch: 5, series: 277, nllk loss: -2.01330, kernel loss: 0.22463\n",
      "Epoch: 5, series: 278, nllk loss: -1.70970, kernel loss: 0.12725\n",
      "Epoch: 5, series: 279, nllk loss: -2.20750, kernel loss: 0.11814\n",
      "Epoch: 5, series: 280, nllk loss: -2.04908, kernel loss: 0.01185\n",
      "Epoch: 5, series: 281, nllk loss: -2.18118, kernel loss: 0.20718\n",
      "Epoch: 5, series: 282, nllk loss: -2.06587, kernel loss: 0.12673\n",
      "Epoch: 5, series: 283, nllk loss: -2.00080, kernel loss: 0.02142\n",
      "Epoch: 5, series: 284, nllk loss: -1.77947, kernel loss: 0.14552\n",
      "Epoch: 5, series: 285, nllk loss: -1.90462, kernel loss: 0.19242\n",
      "Epoch: 5, series: 286, nllk loss: -1.95685, kernel loss: 0.15509\n",
      "Epoch: 5, series: 287, nllk loss: -2.33055, kernel loss: 0.12642\n",
      "Epoch: 5, series: 288, nllk loss: -0.84342, kernel loss: 0.00753\n",
      "Epoch: 5, series: 289, nllk loss: -0.81084, kernel loss: 0.27494\n",
      "Epoch: 5, series: 290, nllk loss: -2.02129, kernel loss: 0.16475\n",
      "Epoch: 5, series: 291, nllk loss: -2.04714, kernel loss: 0.22090\n",
      "Epoch: 5, series: 292, nllk loss: -2.14928, kernel loss: 0.20442\n",
      "Epoch: 5, series: 293, nllk loss: -2.31059, kernel loss: 0.13896\n",
      "Epoch: 5, series: 294, nllk loss: -1.43923, kernel loss: 0.54771\n",
      "Epoch: 5, series: 295, nllk loss: -0.90379, kernel loss: 0.35777\n",
      "Epoch: 5, series: 296, nllk loss: -2.16454, kernel loss: 0.19902\n",
      "Epoch: 5, series: 297, nllk loss: -2.19554, kernel loss: 0.28009\n",
      "Epoch: 5, series: 298, nllk loss: 4.14140, kernel loss: 0.20622\n",
      "Epoch: 5, series: 299, nllk loss: 1.53234, kernel loss: 0.09902\n",
      "Epoch: 5, series: 300, nllk loss: -1.83243, kernel loss: 0.15953\n",
      "Epoch: 5, series: 301, nllk loss: -1.72754, kernel loss: 0.20658\n",
      "Epoch: 5, series: 302, nllk loss: -1.73422, kernel loss: 0.23322\n",
      "Epoch: 5, series: 303, nllk loss: -1.43310, kernel loss: 0.37557\n",
      "Epoch: 5, series: 304, nllk loss: -0.62520, kernel loss: 0.16010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5, series: 305, nllk loss: -1.15175, kernel loss: 0.18378\n",
      "Epoch: 5, series: 306, nllk loss: -1.78921, kernel loss: 0.23400\n",
      "Epoch: 5, series: 307, nllk loss: -1.18766, kernel loss: 0.24445\n",
      "Epoch: 5, series: 308, nllk loss: -1.69719, kernel loss: 0.11172\n",
      "Epoch: 5, series: 309, nllk loss: -1.50891, kernel loss: 0.07797\n",
      "Epoch: 5, series: 310, nllk loss: -1.56224, kernel loss: 0.16699\n",
      "Epoch: 5, series: 311, nllk loss: -1.38245, kernel loss: 0.50429\n",
      "Epoch: 5, series: 312, nllk loss: -1.65419, kernel loss: 0.00000\n",
      "Epoch: 5, series: 313, nllk loss: -1.75980, kernel loss: 0.32324\n",
      "Epoch: 5, series: 314, nllk loss: -1.93082, kernel loss: 0.24216\n",
      "Epoch: 5, series: 315, nllk loss: -0.90109, kernel loss: 0.15597\n",
      "Epoch: 5, series: 316, nllk loss: -1.44704, kernel loss: 0.28396\n",
      "Epoch: 5, series: 317, nllk loss: 0.59899, kernel loss: 0.21443\n",
      "Epoch: 5, series: 318, nllk loss: 1.49343, kernel loss: 0.09995\n",
      "Epoch: 5, series: 319, nllk loss: -0.61806, kernel loss: 0.24269\n",
      "Epoch: 5, series: 320, nllk loss: -0.77787, kernel loss: 0.23068\n",
      "Epoch: 5, total loss: -369.54006\n",
      "Epoch: 6, series: 0, nllk loss: 2.62373, kernel loss: 0.11142\n",
      "Epoch: 6, series: 1, nllk loss: -0.69402, kernel loss: 0.20467\n",
      "Epoch: 6, series: 2, nllk loss: 0.46433, kernel loss: 0.10104\n",
      "Epoch: 6, series: 3, nllk loss: -0.88735, kernel loss: 0.47795\n",
      "Epoch: 6, series: 4, nllk loss: -0.79271, kernel loss: 0.17386\n",
      "Epoch: 6, series: 5, nllk loss: -1.13180, kernel loss: 0.09686\n",
      "Epoch: 6, series: 6, nllk loss: -0.46902, kernel loss: 0.27404\n",
      "Epoch: 6, series: 7, nllk loss: -1.04223, kernel loss: 0.32144\n",
      "Epoch: 6, series: 8, nllk loss: -0.32890, kernel loss: 0.17292\n",
      "Epoch: 6, series: 9, nllk loss: -0.34097, kernel loss: 0.12825\n",
      "Epoch: 6, series: 10, nllk loss: -1.09877, kernel loss: 0.20131\n",
      "Epoch: 6, series: 11, nllk loss: -0.85617, kernel loss: 0.29833\n",
      "Epoch: 6, series: 12, nllk loss: -1.20128, kernel loss: 0.07406\n",
      "Epoch: 6, series: 13, nllk loss: -1.07064, kernel loss: 0.07653\n",
      "Epoch: 6, series: 14, nllk loss: -1.07813, kernel loss: 0.11154\n",
      "Epoch: 6, series: 15, nllk loss: -1.11168, kernel loss: 0.23055\n",
      "Epoch: 6, series: 16, nllk loss: -0.87310, kernel loss: 0.08822\n",
      "Epoch: 6, series: 17, nllk loss: -0.95905, kernel loss: 0.09323\n",
      "Epoch: 6, series: 18, nllk loss: -1.15712, kernel loss: 0.21934\n",
      "Epoch: 6, series: 19, nllk loss: -0.29137, kernel loss: 0.19245\n",
      "Epoch: 6, series: 20, nllk loss: -0.72872, kernel loss: 0.25014\n",
      "Epoch: 6, series: 21, nllk loss: -0.95628, kernel loss: 0.10545\n",
      "Epoch: 6, series: 22, nllk loss: -1.19953, kernel loss: 0.15975\n",
      "Epoch: 6, series: 23, nllk loss: -1.20123, kernel loss: 0.23123\n",
      "Epoch: 6, series: 24, nllk loss: -1.37388, kernel loss: 0.09885\n",
      "Epoch: 6, series: 25, nllk loss: -1.30548, kernel loss: 0.07466\n",
      "Epoch: 6, series: 26, nllk loss: -1.10861, kernel loss: 0.16380\n",
      "Epoch: 6, series: 27, nllk loss: -1.09767, kernel loss: 0.06378\n",
      "Epoch: 6, series: 28, nllk loss: -1.20286, kernel loss: 0.06468\n",
      "Epoch: 6, series: 29, nllk loss: -0.68684, kernel loss: 0.10408\n",
      "Epoch: 6, series: 30, nllk loss: -1.23006, kernel loss: 0.07524\n",
      "Epoch: 6, series: 31, nllk loss: -1.06594, kernel loss: 0.21178\n",
      "Epoch: 6, series: 32, nllk loss: -1.06198, kernel loss: 0.09919\n",
      "Epoch: 6, series: 33, nllk loss: -0.98190, kernel loss: 0.13200\n",
      "Epoch: 6, series: 34, nllk loss: -1.23919, kernel loss: 0.34051\n",
      "Epoch: 6, series: 35, nllk loss: -1.39062, kernel loss: 0.09177\n",
      "Epoch: 6, series: 36, nllk loss: -1.32042, kernel loss: 0.12103\n",
      "Epoch: 6, series: 37, nllk loss: -0.41463, kernel loss: 0.08726\n",
      "Epoch: 6, series: 38, nllk loss: -1.03778, kernel loss: 0.06453\n",
      "Epoch: 6, series: 39, nllk loss: -0.81247, kernel loss: 0.22228\n",
      "Epoch: 6, series: 40, nllk loss: -1.63129, kernel loss: 0.04062\n",
      "Epoch: 6, series: 41, nllk loss: -1.27223, kernel loss: 0.14940\n",
      "Epoch: 6, series: 42, nllk loss: -1.07826, kernel loss: 0.15934\n",
      "Epoch: 6, series: 43, nllk loss: -1.05145, kernel loss: 0.28082\n",
      "Epoch: 6, series: 44, nllk loss: -1.41970, kernel loss: 0.22971\n",
      "Epoch: 6, series: 45, nllk loss: -1.55550, kernel loss: 0.14383\n",
      "Epoch: 6, series: 46, nllk loss: -1.55882, kernel loss: 0.08427\n",
      "Epoch: 6, series: 47, nllk loss: -1.48072, kernel loss: 0.07405\n",
      "Epoch: 6, series: 48, nllk loss: -1.53251, kernel loss: 0.27765\n",
      "Epoch: 6, series: 49, nllk loss: -1.14585, kernel loss: 0.04442\n",
      "Epoch: 6, series: 50, nllk loss: 0.13413, kernel loss: 0.06994\n",
      "Epoch: 6, series: 51, nllk loss: -1.28589, kernel loss: 0.06025\n",
      "Epoch: 6, series: 52, nllk loss: -0.34907, kernel loss: 0.32030\n",
      "Epoch: 6, series: 53, nllk loss: -1.52038, kernel loss: 0.09750\n",
      "Epoch: 6, series: 54, nllk loss: -1.13448, kernel loss: 0.22499\n",
      "Epoch: 6, series: 55, nllk loss: -0.95701, kernel loss: 0.10741\n",
      "Epoch: 6, series: 56, nllk loss: -1.21997, kernel loss: 0.14095\n",
      "Epoch: 6, series: 57, nllk loss: -1.25451, kernel loss: 0.16956\n",
      "Epoch: 6, series: 58, nllk loss: -1.39124, kernel loss: 0.18638\n",
      "Epoch: 6, series: 59, nllk loss: -0.97050, kernel loss: 0.10603\n",
      "Epoch: 6, series: 60, nllk loss: -0.97519, kernel loss: 0.04204\n",
      "Epoch: 6, series: 61, nllk loss: -1.39706, kernel loss: 0.31504\n",
      "Epoch: 6, series: 62, nllk loss: -1.54405, kernel loss: 0.14930\n",
      "Epoch: 6, series: 63, nllk loss: -1.51297, kernel loss: 0.13173\n",
      "Epoch: 6, series: 64, nllk loss: -1.01404, kernel loss: 0.09224\n",
      "Epoch: 6, series: 65, nllk loss: -1.43283, kernel loss: 0.11306\n",
      "Epoch: 6, series: 66, nllk loss: -1.38299, kernel loss: 0.11495\n",
      "Epoch: 6, series: 67, nllk loss: -1.30801, kernel loss: 0.15007\n",
      "Epoch: 6, series: 68, nllk loss: -0.69697, kernel loss: 0.22642\n",
      "Epoch: 6, series: 69, nllk loss: -1.19074, kernel loss: 0.08872\n",
      "Epoch: 6, series: 70, nllk loss: -1.38336, kernel loss: 0.22125\n",
      "Epoch: 6, series: 71, nllk loss: -1.35456, kernel loss: 0.23199\n",
      "Epoch: 6, series: 72, nllk loss: -1.65130, kernel loss: 0.30707\n",
      "Epoch: 6, series: 73, nllk loss: -1.19758, kernel loss: 0.13175\n",
      "Epoch: 6, series: 74, nllk loss: -1.73874, kernel loss: 0.09461\n",
      "Epoch: 6, series: 75, nllk loss: -1.29251, kernel loss: 0.12193\n",
      "Epoch: 6, series: 76, nllk loss: -1.29835, kernel loss: 0.11287\n",
      "Epoch: 6, series: 77, nllk loss: -1.12943, kernel loss: 0.04431\n",
      "Epoch: 6, series: 78, nllk loss: -1.36337, kernel loss: 0.21824\n",
      "Epoch: 6, series: 79, nllk loss: -0.69200, kernel loss: 0.03780\n",
      "Epoch: 6, series: 80, nllk loss: -1.66684, kernel loss: 0.17147\n",
      "Epoch: 6, series: 81, nllk loss: -1.12955, kernel loss: 0.20549\n",
      "Epoch: 6, series: 82, nllk loss: -0.22014, kernel loss: 0.15473\n",
      "Epoch: 6, series: 83, nllk loss: -0.62271, kernel loss: 0.07856\n",
      "Epoch: 6, series: 84, nllk loss: -1.04866, kernel loss: 0.13161\n",
      "Epoch: 6, series: 85, nllk loss: -1.17432, kernel loss: 0.17488\n",
      "Epoch: 6, series: 86, nllk loss: -0.26545, kernel loss: 0.12021\n",
      "Epoch: 6, series: 87, nllk loss: -1.56365, kernel loss: 0.05853\n",
      "Epoch: 6, series: 88, nllk loss: -1.83868, kernel loss: 0.08155\n",
      "Epoch: 6, series: 89, nllk loss: -1.82911, kernel loss: 0.21106\n",
      "Epoch: 6, series: 90, nllk loss: -1.76985, kernel loss: 0.17754\n",
      "Epoch: 6, series: 91, nllk loss: -1.80108, kernel loss: 0.10606\n",
      "Epoch: 6, series: 92, nllk loss: 0.76767, kernel loss: 0.09887\n",
      "Epoch: 6, series: 93, nllk loss: -1.99449, kernel loss: 0.03337\n",
      "Epoch: 6, series: 94, nllk loss: -1.88621, kernel loss: 0.11923\n",
      "Epoch: 6, series: 95, nllk loss: -1.84029, kernel loss: 0.05483\n",
      "Epoch: 6, series: 96, nllk loss: -1.52233, kernel loss: 0.11470\n",
      "Epoch: 6, series: 97, nllk loss: -0.69481, kernel loss: 0.23228\n",
      "Epoch: 6, series: 98, nllk loss: -0.80987, kernel loss: 0.10957\n",
      "Epoch: 6, series: 99, nllk loss: -1.18823, kernel loss: 0.12014\n",
      "Epoch: 6, series: 100, nllk loss: -0.88654, kernel loss: 0.03189\n",
      "Epoch: 6, series: 101, nllk loss: -1.16128, kernel loss: 0.00592\n",
      "Epoch: 6, series: 102, nllk loss: -0.93810, kernel loss: 0.05894\n",
      "Epoch: 6, series: 103, nllk loss: -1.04025, kernel loss: 0.00920\n",
      "Epoch: 6, series: 104, nllk loss: 0.41903, kernel loss: 0.13211\n",
      "Epoch: 6, series: 105, nllk loss: 0.44747, kernel loss: 0.21584\n",
      "Epoch: 6, series: 106, nllk loss: -0.90568, kernel loss: 0.10633\n",
      "Epoch: 6, series: 107, nllk loss: -0.78535, kernel loss: 0.06767\n",
      "Epoch: 6, series: 108, nllk loss: -1.21739, kernel loss: 0.12132\n",
      "Epoch: 6, series: 109, nllk loss: -0.64194, kernel loss: 0.29145\n",
      "Epoch: 6, series: 110, nllk loss: -1.34285, kernel loss: 0.32151\n",
      "Epoch: 6, series: 111, nllk loss: -1.19583, kernel loss: 0.05465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, series: 112, nllk loss: -0.48581, kernel loss: 0.40464\n",
      "Epoch: 6, series: 113, nllk loss: -1.01214, kernel loss: 0.11414\n",
      "Epoch: 6, series: 114, nllk loss: -0.72810, kernel loss: 0.24033\n",
      "Epoch: 6, series: 115, nllk loss: -0.91202, kernel loss: 0.17924\n",
      "Epoch: 6, series: 116, nllk loss: -1.58503, kernel loss: 0.23388\n",
      "Epoch: 6, series: 117, nllk loss: -0.62691, kernel loss: 0.12860\n",
      "Epoch: 6, series: 118, nllk loss: -1.68095, kernel loss: 0.27596\n",
      "Epoch: 6, series: 119, nllk loss: -0.53977, kernel loss: 0.09834\n",
      "Epoch: 6, series: 120, nllk loss: -1.43866, kernel loss: 0.17486\n",
      "Epoch: 6, series: 121, nllk loss: 0.23263, kernel loss: 0.16025\n",
      "Epoch: 6, series: 122, nllk loss: -0.32027, kernel loss: 0.17686\n",
      "Epoch: 6, series: 123, nllk loss: -1.40668, kernel loss: 0.06319\n",
      "Epoch: 6, series: 124, nllk loss: -1.50123, kernel loss: 0.10047\n",
      "Epoch: 6, series: 125, nllk loss: -1.35661, kernel loss: 0.24246\n",
      "Epoch: 6, series: 126, nllk loss: -1.41803, kernel loss: 0.27465\n",
      "Epoch: 6, series: 127, nllk loss: -1.39272, kernel loss: 0.07515\n",
      "Epoch: 6, series: 128, nllk loss: -0.91864, kernel loss: 0.09821\n",
      "Epoch: 6, series: 129, nllk loss: -0.66261, kernel loss: 0.06631\n",
      "Epoch: 6, series: 130, nllk loss: -1.08382, kernel loss: 0.13933\n",
      "Epoch: 6, series: 131, nllk loss: 0.42490, kernel loss: 0.21921\n",
      "Epoch: 6, series: 132, nllk loss: -0.01762, kernel loss: 0.23077\n",
      "Epoch: 6, series: 133, nllk loss: -0.78324, kernel loss: 0.32599\n",
      "Epoch: 6, series: 134, nllk loss: -0.68867, kernel loss: 0.17068\n",
      "Epoch: 6, series: 135, nllk loss: -1.27643, kernel loss: 0.06197\n",
      "Epoch: 6, series: 136, nllk loss: -1.31396, kernel loss: 0.14253\n",
      "Epoch: 6, series: 137, nllk loss: -1.45775, kernel loss: 0.23977\n",
      "Epoch: 6, series: 138, nllk loss: -1.55270, kernel loss: 0.13671\n",
      "Epoch: 6, series: 139, nllk loss: -1.41646, kernel loss: 0.16649\n",
      "Epoch: 6, series: 140, nllk loss: -1.25605, kernel loss: 0.06431\n",
      "Epoch: 6, series: 141, nllk loss: -1.43986, kernel loss: 0.22934\n",
      "Epoch: 6, series: 142, nllk loss: -1.31882, kernel loss: 0.21194\n",
      "Epoch: 6, series: 143, nllk loss: -1.51011, kernel loss: 0.14606\n",
      "Epoch: 6, series: 144, nllk loss: -1.59592, kernel loss: 0.05582\n",
      "Epoch: 6, series: 145, nllk loss: -1.57992, kernel loss: 0.14682\n",
      "Epoch: 6, series: 146, nllk loss: 3.21001, kernel loss: 0.10709\n",
      "Epoch: 6, series: 147, nllk loss: -1.37588, kernel loss: 0.26291\n",
      "Epoch: 6, series: 148, nllk loss: -1.29985, kernel loss: 0.05156\n",
      "Epoch: 6, series: 149, nllk loss: -1.46992, kernel loss: 0.05244\n",
      "Epoch: 6, series: 150, nllk loss: -1.61287, kernel loss: 0.11821\n",
      "Epoch: 6, series: 151, nllk loss: -1.67586, kernel loss: 0.20910\n",
      "Epoch: 6, series: 152, nllk loss: -1.58767, kernel loss: 0.25339\n",
      "Epoch: 6, series: 153, nllk loss: -1.42302, kernel loss: 0.16976\n",
      "Epoch: 6, series: 154, nllk loss: -1.38993, kernel loss: 0.07202\n",
      "Epoch: 6, series: 155, nllk loss: -1.51012, kernel loss: 0.17787\n",
      "Epoch: 6, series: 156, nllk loss: -1.66316, kernel loss: 0.14537\n",
      "Epoch: 6, series: 157, nllk loss: -1.20164, kernel loss: 0.23338\n",
      "Epoch: 6, series: 158, nllk loss: -1.60920, kernel loss: 0.06141\n",
      "Epoch: 6, series: 159, nllk loss: -1.72305, kernel loss: 0.11350\n",
      "Epoch: 6, series: 160, nllk loss: -1.60617, kernel loss: 0.13779\n",
      "Epoch: 6, series: 161, nllk loss: -1.53203, kernel loss: 0.09669\n",
      "Epoch: 6, series: 162, nllk loss: -1.58977, kernel loss: 0.18829\n",
      "Epoch: 6, series: 163, nllk loss: -1.91699, kernel loss: 0.01287\n",
      "Epoch: 6, series: 164, nllk loss: -1.61844, kernel loss: 0.08044\n",
      "Epoch: 6, series: 165, nllk loss: -1.76683, kernel loss: 0.03660\n",
      "Epoch: 6, series: 166, nllk loss: -1.34453, kernel loss: 0.24596\n",
      "Epoch: 6, series: 167, nllk loss: -2.04871, kernel loss: 0.15164\n",
      "Epoch: 6, series: 168, nllk loss: -1.93433, kernel loss: 0.21388\n",
      "Epoch: 6, series: 169, nllk loss: -2.02412, kernel loss: 0.22414\n",
      "Epoch: 6, series: 170, nllk loss: -1.73594, kernel loss: 0.25235\n",
      "Epoch: 6, series: 171, nllk loss: -1.98291, kernel loss: 0.07695\n",
      "Epoch: 6, series: 172, nllk loss: -1.77004, kernel loss: 0.19759\n",
      "Epoch: 6, series: 173, nllk loss: -2.15820, kernel loss: 0.07968\n",
      "Epoch: 6, series: 174, nllk loss: -1.76437, kernel loss: 0.05780\n",
      "Epoch: 6, series: 175, nllk loss: -2.08249, kernel loss: 0.01072\n",
      "Epoch: 6, series: 176, nllk loss: -2.00270, kernel loss: 0.03438\n",
      "Epoch: 6, series: 177, nllk loss: -1.59391, kernel loss: 0.27237\n",
      "Epoch: 6, series: 178, nllk loss: -1.47320, kernel loss: 0.16942\n",
      "Epoch: 6, series: 179, nllk loss: -1.96223, kernel loss: 0.11664\n",
      "Epoch: 6, series: 180, nllk loss: -1.98991, kernel loss: 0.15230\n",
      "Epoch: 6, series: 181, nllk loss: -2.19644, kernel loss: 0.25589\n",
      "Epoch: 6, series: 182, nllk loss: -1.90280, kernel loss: 0.19438\n",
      "Epoch: 6, series: 183, nllk loss: -1.84381, kernel loss: 0.13420\n",
      "Epoch: 6, series: 184, nllk loss: -1.81320, kernel loss: 0.24211\n",
      "Epoch: 6, series: 185, nllk loss: -1.59636, kernel loss: 0.12059\n",
      "Epoch: 6, series: 186, nllk loss: -2.10192, kernel loss: 0.04503\n",
      "Epoch: 6, series: 187, nllk loss: -2.25674, kernel loss: 0.25722\n",
      "Epoch: 6, series: 188, nllk loss: -1.62387, kernel loss: 0.33990\n",
      "Epoch: 6, series: 189, nllk loss: -1.38416, kernel loss: 0.19233\n",
      "Epoch: 6, series: 190, nllk loss: -1.80980, kernel loss: 0.03863\n",
      "Epoch: 6, series: 191, nllk loss: -1.80113, kernel loss: 0.05315\n",
      "Epoch: 6, series: 192, nllk loss: -1.88398, kernel loss: 0.19983\n",
      "Epoch: 6, series: 193, nllk loss: -1.58851, kernel loss: 0.31097\n",
      "Epoch: 6, series: 194, nllk loss: -1.21404, kernel loss: 0.21514\n",
      "Epoch: 6, series: 195, nllk loss: -2.02634, kernel loss: 0.05313\n",
      "Epoch: 6, series: 196, nllk loss: -1.76839, kernel loss: 0.14756\n",
      "Epoch: 6, series: 197, nllk loss: -1.89447, kernel loss: 0.09895\n",
      "Epoch: 6, series: 198, nllk loss: -2.15255, kernel loss: 0.23756\n",
      "Epoch: 6, series: 199, nllk loss: -1.86705, kernel loss: 0.01549\n",
      "Epoch: 6, series: 200, nllk loss: -2.04307, kernel loss: 0.11285\n",
      "Epoch: 6, series: 201, nllk loss: -2.05081, kernel loss: 0.12475\n",
      "Epoch: 6, series: 202, nllk loss: -1.85126, kernel loss: 0.18444\n",
      "Epoch: 6, series: 203, nllk loss: -1.88056, kernel loss: 0.21442\n",
      "Epoch: 6, series: 204, nllk loss: -0.73169, kernel loss: 0.22534\n",
      "Epoch: 6, series: 205, nllk loss: -1.77751, kernel loss: 0.04149\n",
      "Epoch: 6, series: 206, nllk loss: -1.91420, kernel loss: 0.14111\n",
      "Epoch: 6, series: 207, nllk loss: -0.95714, kernel loss: 0.08918\n",
      "Epoch: 6, series: 208, nllk loss: -2.04167, kernel loss: 0.17624\n",
      "Epoch: 6, series: 209, nllk loss: -1.24550, kernel loss: 0.09286\n",
      "Epoch: 6, series: 210, nllk loss: -2.26387, kernel loss: 0.04987\n",
      "Epoch: 6, series: 211, nllk loss: -2.07494, kernel loss: 0.10393\n",
      "Epoch: 6, series: 212, nllk loss: -1.49964, kernel loss: 0.09168\n",
      "Epoch: 6, series: 213, nllk loss: -1.67399, kernel loss: 0.05846\n",
      "Epoch: 6, series: 214, nllk loss: -1.90164, kernel loss: 0.14501\n",
      "Epoch: 6, series: 215, nllk loss: -2.18648, kernel loss: 0.09070\n",
      "Epoch: 6, series: 216, nllk loss: -0.71656, kernel loss: 0.03067\n",
      "Epoch: 6, series: 217, nllk loss: -1.62725, kernel loss: 0.33099\n",
      "Epoch: 6, series: 218, nllk loss: -1.24955, kernel loss: 0.19803\n",
      "Epoch: 6, series: 219, nllk loss: -1.65740, kernel loss: 0.41621\n",
      "Epoch: 6, series: 220, nllk loss: -1.73865, kernel loss: 0.16573\n",
      "Epoch: 6, series: 221, nllk loss: -1.96043, kernel loss: 0.03545\n",
      "Epoch: 6, series: 222, nllk loss: -1.95054, kernel loss: 0.04575\n",
      "Epoch: 6, series: 223, nllk loss: -1.41522, kernel loss: 0.19167\n",
      "Epoch: 6, series: 224, nllk loss: -2.01781, kernel loss: 0.13875\n",
      "Epoch: 6, series: 225, nllk loss: -1.81362, kernel loss: 0.18516\n",
      "Epoch: 6, series: 226, nllk loss: -1.43986, kernel loss: 0.03284\n",
      "Epoch: 6, series: 227, nllk loss: -1.64133, kernel loss: 0.19001\n",
      "Epoch: 6, series: 228, nllk loss: -1.68777, kernel loss: 0.20104\n",
      "Epoch: 6, series: 229, nllk loss: -1.69458, kernel loss: 0.15306\n",
      "Epoch: 6, series: 230, nllk loss: -1.92803, kernel loss: 0.30192\n",
      "Epoch: 6, series: 231, nllk loss: -1.62000, kernel loss: 0.21449\n",
      "Epoch: 6, series: 232, nllk loss: -2.10672, kernel loss: 0.15060\n",
      "Epoch: 6, series: 233, nllk loss: -2.02730, kernel loss: 0.27076\n",
      "Epoch: 6, series: 234, nllk loss: -1.74341, kernel loss: 0.07963\n",
      "Epoch: 6, series: 235, nllk loss: -2.25106, kernel loss: 0.04607\n",
      "Epoch: 6, series: 236, nllk loss: -1.41396, kernel loss: 0.15628\n",
      "Epoch: 6, series: 237, nllk loss: -1.91151, kernel loss: 0.42854\n",
      "Epoch: 6, series: 238, nllk loss: -1.69087, kernel loss: 0.14204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6, series: 239, nllk loss: -1.94302, kernel loss: 0.05546\n",
      "Epoch: 6, series: 240, nllk loss: -1.38629, kernel loss: 0.28281\n",
      "Epoch: 6, series: 241, nllk loss: -1.78003, kernel loss: 0.05975\n",
      "Epoch: 6, series: 242, nllk loss: -1.91964, kernel loss: 0.33338\n",
      "Epoch: 6, series: 243, nllk loss: -2.11152, kernel loss: 0.05796\n",
      "Epoch: 6, series: 244, nllk loss: -1.78291, kernel loss: 0.05851\n",
      "Epoch: 6, series: 245, nllk loss: -2.01243, kernel loss: 0.17979\n",
      "Epoch: 6, series: 246, nllk loss: 0.13381, kernel loss: 0.26521\n",
      "Epoch: 6, series: 247, nllk loss: -1.68981, kernel loss: 0.32750\n",
      "Epoch: 6, series: 248, nllk loss: -1.84120, kernel loss: 0.35137\n",
      "Epoch: 6, series: 249, nllk loss: -1.83572, kernel loss: 0.21055\n",
      "Epoch: 6, series: 250, nllk loss: -1.63646, kernel loss: 0.25893\n",
      "Epoch: 6, series: 251, nllk loss: -1.06393, kernel loss: 0.14263\n",
      "Epoch: 6, series: 252, nllk loss: -0.99464, kernel loss: 0.01860\n",
      "Epoch: 6, series: 253, nllk loss: -1.69871, kernel loss: 0.06237\n",
      "Epoch: 6, series: 254, nllk loss: -2.23752, kernel loss: 0.27975\n",
      "Epoch: 6, series: 255, nllk loss: -2.05797, kernel loss: 0.21175\n",
      "Epoch: 6, series: 256, nllk loss: -1.69953, kernel loss: 0.23218\n",
      "Epoch: 6, series: 257, nllk loss: -1.91092, kernel loss: 0.23183\n",
      "Epoch: 6, series: 258, nllk loss: -1.97008, kernel loss: 0.16399\n",
      "Epoch: 6, series: 259, nllk loss: -1.71566, kernel loss: 0.07989\n",
      "Epoch: 6, series: 260, nllk loss: -1.81900, kernel loss: 0.11211\n",
      "Epoch: 6, series: 261, nllk loss: -1.98579, kernel loss: 0.12416\n",
      "Epoch: 6, series: 262, nllk loss: -2.19044, kernel loss: 0.18322\n",
      "Epoch: 6, series: 263, nllk loss: -0.67420, kernel loss: 0.11866\n",
      "Epoch: 6, series: 264, nllk loss: -1.83667, kernel loss: 0.32529\n",
      "Epoch: 6, series: 265, nllk loss: -1.88361, kernel loss: 0.20207\n",
      "Epoch: 6, series: 266, nllk loss: -1.94781, kernel loss: 0.05640\n",
      "Epoch: 6, series: 267, nllk loss: -1.93072, kernel loss: 0.32337\n",
      "Epoch: 6, series: 268, nllk loss: -2.04033, kernel loss: 0.32680\n",
      "Epoch: 6, series: 269, nllk loss: -1.62898, kernel loss: 0.06169\n",
      "Epoch: 6, series: 270, nllk loss: -1.71598, kernel loss: 0.04172\n",
      "Epoch: 6, series: 271, nllk loss: -1.93115, kernel loss: 0.11209\n",
      "Epoch: 6, series: 272, nllk loss: -1.86490, kernel loss: 0.03251\n",
      "Epoch: 6, series: 273, nllk loss: -1.93710, kernel loss: 0.03864\n",
      "Epoch: 6, series: 274, nllk loss: -1.41556, kernel loss: 0.06306\n",
      "Epoch: 6, series: 275, nllk loss: -1.81110, kernel loss: 0.05105\n",
      "Epoch: 6, series: 276, nllk loss: -1.14860, kernel loss: 0.05491\n",
      "Epoch: 6, series: 277, nllk loss: -2.10027, kernel loss: 0.10912\n",
      "Epoch: 6, series: 278, nllk loss: -1.89510, kernel loss: 0.04394\n",
      "Epoch: 6, series: 279, nllk loss: -2.24509, kernel loss: 0.09313\n",
      "Epoch: 6, series: 280, nllk loss: -2.05260, kernel loss: 0.19228\n",
      "Epoch: 6, series: 281, nllk loss: -2.20592, kernel loss: 0.17308\n",
      "Epoch: 6, series: 282, nllk loss: -2.06760, kernel loss: 0.15830\n",
      "Epoch: 6, series: 283, nllk loss: -2.00722, kernel loss: 0.08316\n",
      "Epoch: 6, series: 284, nllk loss: -1.72569, kernel loss: 0.30221\n",
      "Epoch: 6, series: 285, nllk loss: -1.79802, kernel loss: 0.09363\n",
      "Epoch: 6, series: 286, nllk loss: -1.97426, kernel loss: 0.07057\n",
      "Epoch: 6, series: 287, nllk loss: -2.35087, kernel loss: 0.16352\n",
      "Epoch: 6, series: 288, nllk loss: -1.04754, kernel loss: 0.23848\n",
      "Epoch: 6, series: 289, nllk loss: -0.79783, kernel loss: 0.26149\n",
      "Epoch: 6, series: 290, nllk loss: -2.20609, kernel loss: 0.13832\n",
      "Epoch: 6, series: 291, nllk loss: -2.22322, kernel loss: 0.24117\n",
      "Epoch: 6, series: 292, nllk loss: -2.20495, kernel loss: 0.21503\n",
      "Epoch: 6, series: 293, nllk loss: -2.28514, kernel loss: 0.21736\n",
      "Epoch: 6, series: 294, nllk loss: -1.58888, kernel loss: 0.20957\n",
      "Epoch: 6, series: 295, nllk loss: -1.06819, kernel loss: 0.23828\n",
      "Epoch: 6, series: 296, nllk loss: -2.07586, kernel loss: 0.33095\n",
      "Epoch: 6, series: 297, nllk loss: -2.31506, kernel loss: 0.12988\n",
      "Epoch: 6, series: 298, nllk loss: 3.34867, kernel loss: 0.10714\n",
      "Epoch: 6, series: 299, nllk loss: 1.01779, kernel loss: 0.16804\n",
      "Epoch: 6, series: 300, nllk loss: -1.65687, kernel loss: 0.61173\n",
      "Epoch: 6, series: 301, nllk loss: -1.74194, kernel loss: 0.40316\n",
      "Epoch: 6, series: 302, nllk loss: -1.78870, kernel loss: 0.40656\n",
      "Epoch: 6, series: 303, nllk loss: -1.23754, kernel loss: 0.18179\n",
      "Epoch: 6, series: 304, nllk loss: -0.65453, kernel loss: 0.13958\n",
      "Epoch: 6, series: 305, nllk loss: -1.34453, kernel loss: 0.29982\n",
      "Epoch: 6, series: 306, nllk loss: -1.93999, kernel loss: 0.22839\n",
      "Epoch: 6, series: 307, nllk loss: -1.16681, kernel loss: 0.04850\n",
      "Epoch: 6, series: 308, nllk loss: -1.68510, kernel loss: 0.12280\n",
      "Epoch: 6, series: 309, nllk loss: -1.47604, kernel loss: 0.25991\n",
      "Epoch: 6, series: 310, nllk loss: -1.59195, kernel loss: 0.19105\n",
      "Epoch: 6, series: 311, nllk loss: -1.42504, kernel loss: 0.17016\n",
      "Epoch: 6, series: 312, nllk loss: -1.73686, kernel loss: 0.12480\n",
      "Epoch: 6, series: 313, nllk loss: -1.79962, kernel loss: 0.33869\n",
      "Epoch: 6, series: 314, nllk loss: -1.98857, kernel loss: 0.14073\n",
      "Epoch: 6, series: 315, nllk loss: -0.80860, kernel loss: 0.23742\n",
      "Epoch: 6, series: 316, nllk loss: -1.49305, kernel loss: 0.22280\n",
      "Epoch: 6, series: 317, nllk loss: 0.74802, kernel loss: 0.19852\n",
      "Epoch: 6, series: 318, nllk loss: 1.72659, kernel loss: 0.05001\n",
      "Epoch: 6, series: 319, nllk loss: -0.70827, kernel loss: 0.16496\n",
      "Epoch: 6, series: 320, nllk loss: -0.81770, kernel loss: 0.18754\n",
      "Epoch: 6, total loss: -382.71019\n",
      "Epoch: 7, series: 0, nllk loss: 2.68147, kernel loss: 0.09478\n",
      "Epoch: 7, series: 1, nllk loss: -0.59923, kernel loss: 0.19404\n",
      "Epoch: 7, series: 2, nllk loss: 0.41687, kernel loss: 0.70738\n",
      "Epoch: 7, series: 3, nllk loss: -0.91288, kernel loss: 0.09539\n",
      "Epoch: 7, series: 4, nllk loss: -0.70944, kernel loss: 0.31225\n",
      "Epoch: 7, series: 5, nllk loss: -1.10977, kernel loss: 0.31959\n",
      "Epoch: 7, series: 6, nllk loss: -0.47320, kernel loss: 0.23675\n",
      "Epoch: 7, series: 7, nllk loss: -1.02410, kernel loss: 0.30229\n",
      "Epoch: 7, series: 8, nllk loss: -0.46664, kernel loss: 0.31558\n",
      "Epoch: 7, series: 9, nllk loss: -0.40776, kernel loss: 0.03101\n",
      "Epoch: 7, series: 10, nllk loss: -1.06928, kernel loss: 0.23384\n",
      "Epoch: 7, series: 11, nllk loss: -0.82423, kernel loss: 0.32653\n",
      "Epoch: 7, series: 12, nllk loss: -1.19820, kernel loss: 0.22142\n",
      "Epoch: 7, series: 13, nllk loss: -1.08115, kernel loss: 0.12767\n",
      "Epoch: 7, series: 14, nllk loss: -1.08608, kernel loss: 0.15071\n",
      "Epoch: 7, series: 15, nllk loss: -1.07302, kernel loss: 0.11613\n",
      "Epoch: 7, series: 16, nllk loss: -0.86184, kernel loss: 0.24124\n",
      "Epoch: 7, series: 17, nllk loss: -0.93058, kernel loss: 0.27145\n",
      "Epoch: 7, series: 18, nllk loss: -1.12074, kernel loss: 0.10218\n",
      "Epoch: 7, series: 19, nllk loss: -0.32637, kernel loss: 0.05401\n",
      "Epoch: 7, series: 20, nllk loss: -0.68788, kernel loss: 0.24104\n",
      "Epoch: 7, series: 21, nllk loss: -0.94535, kernel loss: 0.14101\n",
      "Epoch: 7, series: 22, nllk loss: -1.15515, kernel loss: 0.36312\n",
      "Epoch: 7, series: 23, nllk loss: -1.13622, kernel loss: 0.15818\n",
      "Epoch: 7, series: 24, nllk loss: -1.26854, kernel loss: 0.21399\n",
      "Epoch: 7, series: 25, nllk loss: -1.36274, kernel loss: 0.36588\n",
      "Epoch: 7, series: 26, nllk loss: -1.20145, kernel loss: 0.08295\n",
      "Epoch: 7, series: 27, nllk loss: -1.11385, kernel loss: 0.12381\n",
      "Epoch: 7, series: 28, nllk loss: -1.21159, kernel loss: 0.12975\n",
      "Epoch: 7, series: 29, nllk loss: -0.67617, kernel loss: 0.03097\n",
      "Epoch: 7, series: 30, nllk loss: -1.12712, kernel loss: 0.13620\n",
      "Epoch: 7, series: 31, nllk loss: -1.01063, kernel loss: 0.15587\n",
      "Epoch: 7, series: 32, nllk loss: -0.89898, kernel loss: 0.14074\n",
      "Epoch: 7, series: 33, nllk loss: -0.91078, kernel loss: 0.05399\n",
      "Epoch: 7, series: 34, nllk loss: -1.28450, kernel loss: 0.05135\n",
      "Epoch: 7, series: 35, nllk loss: -1.42953, kernel loss: 0.27124\n",
      "Epoch: 7, series: 36, nllk loss: -1.31178, kernel loss: 0.14830\n",
      "Epoch: 7, series: 37, nllk loss: -0.38727, kernel loss: 0.00813\n",
      "Epoch: 7, series: 38, nllk loss: -1.04793, kernel loss: 0.09680\n",
      "Epoch: 7, series: 39, nllk loss: -0.89949, kernel loss: 0.01725\n",
      "Epoch: 7, series: 40, nllk loss: -1.60303, kernel loss: 0.13490\n",
      "Epoch: 7, series: 41, nllk loss: -1.30389, kernel loss: 0.12377\n",
      "Epoch: 7, series: 42, nllk loss: -1.08312, kernel loss: 0.42737\n",
      "Epoch: 7, series: 43, nllk loss: -0.99929, kernel loss: 0.06038\n",
      "Epoch: 7, series: 44, nllk loss: -1.43586, kernel loss: 0.13001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, series: 45, nllk loss: -1.51369, kernel loss: 0.10043\n",
      "Epoch: 7, series: 46, nllk loss: -1.52119, kernel loss: 0.20163\n",
      "Epoch: 7, series: 47, nllk loss: -1.41303, kernel loss: 0.11128\n",
      "Epoch: 7, series: 48, nllk loss: -1.51150, kernel loss: 0.01592\n",
      "Epoch: 7, series: 49, nllk loss: -1.17839, kernel loss: 0.15380\n",
      "Epoch: 7, series: 50, nllk loss: 0.00586, kernel loss: 0.16156\n",
      "Epoch: 7, series: 51, nllk loss: -1.32665, kernel loss: 0.15141\n",
      "Epoch: 7, series: 52, nllk loss: -0.40845, kernel loss: 0.18375\n",
      "Epoch: 7, series: 53, nllk loss: -1.57031, kernel loss: 0.14725\n",
      "Epoch: 7, series: 54, nllk loss: -1.21484, kernel loss: 0.16569\n",
      "Epoch: 7, series: 55, nllk loss: -0.90034, kernel loss: 0.01558\n",
      "Epoch: 7, series: 56, nllk loss: -1.27813, kernel loss: 0.04795\n",
      "Epoch: 7, series: 57, nllk loss: -1.28668, kernel loss: 0.14210\n",
      "Epoch: 7, series: 58, nllk loss: -1.40878, kernel loss: 0.32355\n",
      "Epoch: 7, series: 59, nllk loss: -1.07125, kernel loss: 0.11855\n",
      "Epoch: 7, series: 60, nllk loss: -1.03402, kernel loss: 0.07693\n",
      "Epoch: 7, series: 61, nllk loss: -1.54452, kernel loss: 0.21279\n",
      "Epoch: 7, series: 62, nllk loss: -1.60041, kernel loss: 0.10500\n",
      "Epoch: 7, series: 63, nllk loss: -1.52149, kernel loss: 0.06614\n",
      "Epoch: 7, series: 64, nllk loss: -1.13053, kernel loss: 0.27271\n",
      "Epoch: 7, series: 65, nllk loss: -1.48262, kernel loss: 0.05719\n",
      "Epoch: 7, series: 66, nllk loss: -1.39611, kernel loss: 0.06312\n",
      "Epoch: 7, series: 67, nllk loss: -1.27417, kernel loss: 0.18019\n",
      "Epoch: 7, series: 68, nllk loss: -0.74251, kernel loss: 0.10567\n",
      "Epoch: 7, series: 69, nllk loss: -1.25975, kernel loss: 0.10554\n",
      "Epoch: 7, series: 70, nllk loss: -1.42734, kernel loss: 0.14731\n",
      "Epoch: 7, series: 71, nllk loss: -1.41294, kernel loss: 0.17420\n",
      "Epoch: 7, series: 72, nllk loss: -1.68032, kernel loss: 0.15963\n",
      "Epoch: 7, series: 73, nllk loss: -1.23573, kernel loss: 0.05210\n",
      "Epoch: 7, series: 74, nllk loss: -1.78294, kernel loss: 0.00287\n",
      "Epoch: 7, series: 75, nllk loss: -1.35310, kernel loss: 0.04847\n",
      "Epoch: 7, series: 76, nllk loss: -1.34929, kernel loss: 0.28895\n",
      "Epoch: 7, series: 77, nllk loss: -1.14352, kernel loss: 0.01859\n",
      "Epoch: 7, series: 78, nllk loss: -1.30387, kernel loss: 0.19206\n",
      "Epoch: 7, series: 79, nllk loss: -0.58977, kernel loss: 0.06596\n",
      "Epoch: 7, series: 80, nllk loss: -1.66980, kernel loss: 0.14172\n",
      "Epoch: 7, series: 81, nllk loss: -1.17160, kernel loss: 0.18708\n",
      "Epoch: 7, series: 82, nllk loss: -0.26322, kernel loss: 0.21487\n",
      "Epoch: 7, series: 83, nllk loss: -0.69450, kernel loss: 0.10532\n",
      "Epoch: 7, series: 84, nllk loss: -1.09898, kernel loss: 0.01726\n",
      "Epoch: 7, series: 85, nllk loss: -1.15443, kernel loss: 0.15610\n",
      "Epoch: 7, series: 86, nllk loss: -0.25665, kernel loss: 0.17371\n",
      "Epoch: 7, series: 87, nllk loss: -1.60338, kernel loss: 0.04840\n",
      "Epoch: 7, series: 88, nllk loss: -1.86843, kernel loss: 0.07068\n",
      "Epoch: 7, series: 89, nllk loss: -1.86710, kernel loss: 0.05790\n",
      "Epoch: 7, series: 90, nllk loss: -1.89018, kernel loss: 0.32725\n",
      "Epoch: 7, series: 91, nllk loss: -1.91234, kernel loss: 0.13554\n",
      "Epoch: 7, series: 92, nllk loss: 0.72476, kernel loss: 0.16576\n",
      "Epoch: 7, series: 93, nllk loss: -2.06083, kernel loss: 0.13480\n",
      "Epoch: 7, series: 94, nllk loss: -2.00851, kernel loss: 0.09789\n",
      "Epoch: 7, series: 95, nllk loss: -1.97492, kernel loss: 0.09022\n",
      "Epoch: 7, series: 96, nllk loss: -1.55284, kernel loss: 0.20368\n",
      "Epoch: 7, series: 97, nllk loss: -0.68265, kernel loss: 0.18397\n",
      "Epoch: 7, series: 98, nllk loss: -0.80984, kernel loss: 0.04263\n",
      "Epoch: 7, series: 99, nllk loss: -1.24981, kernel loss: 0.09816\n",
      "Epoch: 7, series: 100, nllk loss: -0.84884, kernel loss: 0.03868\n",
      "Epoch: 7, series: 101, nllk loss: -1.41068, kernel loss: 0.11251\n",
      "Epoch: 7, series: 102, nllk loss: -0.98623, kernel loss: 0.15616\n",
      "Epoch: 7, series: 103, nllk loss: -0.90902, kernel loss: 0.16059\n",
      "Epoch: 7, series: 104, nllk loss: 0.55835, kernel loss: 0.19628\n",
      "Epoch: 7, series: 105, nllk loss: 0.25335, kernel loss: 0.21412\n",
      "Epoch: 7, series: 106, nllk loss: -1.03955, kernel loss: 0.16783\n",
      "Epoch: 7, series: 107, nllk loss: -0.87906, kernel loss: 0.16147\n",
      "Epoch: 7, series: 108, nllk loss: -1.13019, kernel loss: 0.09252\n",
      "Epoch: 7, series: 109, nllk loss: -0.28826, kernel loss: 0.10340\n",
      "Epoch: 7, series: 110, nllk loss: -1.32851, kernel loss: 0.18813\n",
      "Epoch: 7, series: 111, nllk loss: -1.25163, kernel loss: 0.08247\n",
      "Epoch: 7, series: 112, nllk loss: -0.61408, kernel loss: 0.07834\n",
      "Epoch: 7, series: 113, nllk loss: -0.96069, kernel loss: 0.29997\n",
      "Epoch: 7, series: 114, nllk loss: -0.68556, kernel loss: 0.23732\n",
      "Epoch: 7, series: 115, nllk loss: -0.88648, kernel loss: 0.15161\n",
      "Epoch: 7, series: 116, nllk loss: -1.53865, kernel loss: 0.21599\n",
      "Epoch: 7, series: 117, nllk loss: -0.50937, kernel loss: 0.14577\n",
      "Epoch: 7, series: 118, nllk loss: -1.64373, kernel loss: 0.11771\n",
      "Epoch: 7, series: 119, nllk loss: -0.66277, kernel loss: 0.30991\n",
      "Epoch: 7, series: 120, nllk loss: -1.44867, kernel loss: 0.11626\n",
      "Epoch: 7, series: 121, nllk loss: 0.19402, kernel loss: 0.05753\n",
      "Epoch: 7, series: 122, nllk loss: -0.42359, kernel loss: 0.13280\n",
      "Epoch: 7, series: 123, nllk loss: -1.44596, kernel loss: 0.12645\n",
      "Epoch: 7, series: 124, nllk loss: -1.54068, kernel loss: 0.07914\n",
      "Epoch: 7, series: 125, nllk loss: -1.32965, kernel loss: 0.08306\n",
      "Epoch: 7, series: 126, nllk loss: -1.43103, kernel loss: 0.07020\n",
      "Epoch: 7, series: 127, nllk loss: -1.37573, kernel loss: 0.13386\n",
      "Epoch: 7, series: 128, nllk loss: -0.90148, kernel loss: 0.15816\n",
      "Epoch: 7, series: 129, nllk loss: -0.68295, kernel loss: 0.10980\n",
      "Epoch: 7, series: 130, nllk loss: -1.12328, kernel loss: 0.03087\n",
      "Epoch: 7, series: 131, nllk loss: 0.46244, kernel loss: 0.13365\n",
      "Epoch: 7, series: 132, nllk loss: 0.03760, kernel loss: 0.08155\n",
      "Epoch: 7, series: 133, nllk loss: -0.85118, kernel loss: 0.29206\n",
      "Epoch: 7, series: 134, nllk loss: -0.69612, kernel loss: 0.14683\n",
      "Epoch: 7, series: 135, nllk loss: -1.31676, kernel loss: 0.02829\n",
      "Epoch: 7, series: 136, nllk loss: -1.33111, kernel loss: 0.09706\n",
      "Epoch: 7, series: 137, nllk loss: -1.46125, kernel loss: 0.32770\n",
      "Epoch: 7, series: 138, nllk loss: -1.53842, kernel loss: 0.00792\n",
      "Epoch: 7, series: 139, nllk loss: -1.44504, kernel loss: 0.15086\n",
      "Epoch: 7, series: 140, nllk loss: -1.31250, kernel loss: 0.08019\n",
      "Epoch: 7, series: 141, nllk loss: -1.43814, kernel loss: 0.04599\n",
      "Epoch: 7, series: 142, nllk loss: -1.33502, kernel loss: 0.15612\n",
      "Epoch: 7, series: 143, nllk loss: -1.46036, kernel loss: 0.19567\n",
      "Epoch: 7, series: 144, nllk loss: -1.59246, kernel loss: 0.15769\n",
      "Epoch: 7, series: 145, nllk loss: -1.60110, kernel loss: 0.20742\n",
      "Epoch: 7, series: 146, nllk loss: 3.25937, kernel loss: 0.11904\n",
      "Epoch: 7, series: 147, nllk loss: -1.38560, kernel loss: 0.21024\n",
      "Epoch: 7, series: 148, nllk loss: -1.33024, kernel loss: 0.04186\n",
      "Epoch: 7, series: 149, nllk loss: -1.46709, kernel loss: 0.03931\n",
      "Epoch: 7, series: 150, nllk loss: -1.61336, kernel loss: 0.11710\n",
      "Epoch: 7, series: 151, nllk loss: -1.67657, kernel loss: 0.15680\n",
      "Epoch: 7, series: 152, nllk loss: -1.60094, kernel loss: 0.04840\n",
      "Epoch: 7, series: 153, nllk loss: -1.48197, kernel loss: 0.18337\n",
      "Epoch: 7, series: 154, nllk loss: -1.49725, kernel loss: 0.13086\n",
      "Epoch: 7, series: 155, nllk loss: -1.56428, kernel loss: 0.20404\n",
      "Epoch: 7, series: 156, nllk loss: -1.71060, kernel loss: 0.19913\n",
      "Epoch: 7, series: 157, nllk loss: -1.26666, kernel loss: 0.17772\n",
      "Epoch: 7, series: 158, nllk loss: -1.68300, kernel loss: 0.05555\n",
      "Epoch: 7, series: 159, nllk loss: -1.77035, kernel loss: 0.20556\n",
      "Epoch: 7, series: 160, nllk loss: -1.65763, kernel loss: 0.04844\n",
      "Epoch: 7, series: 161, nllk loss: -1.54238, kernel loss: 0.08760\n",
      "Epoch: 7, series: 162, nllk loss: -1.71635, kernel loss: 0.07847\n",
      "Epoch: 7, series: 163, nllk loss: -2.01410, kernel loss: 0.14024\n",
      "Epoch: 7, series: 164, nllk loss: -1.70337, kernel loss: 0.06472\n",
      "Epoch: 7, series: 165, nllk loss: -1.82487, kernel loss: 0.05669\n",
      "Epoch: 7, series: 166, nllk loss: -1.36162, kernel loss: 0.19375\n",
      "Epoch: 7, series: 167, nllk loss: -2.06954, kernel loss: 0.11482\n",
      "Epoch: 7, series: 168, nllk loss: -1.94862, kernel loss: 0.03470\n",
      "Epoch: 7, series: 169, nllk loss: -2.09686, kernel loss: 0.28901\n",
      "Epoch: 7, series: 170, nllk loss: -1.74316, kernel loss: 0.24825\n",
      "Epoch: 7, series: 171, nllk loss: -2.11787, kernel loss: 0.18728\n",
      "Epoch: 7, series: 172, nllk loss: -1.85210, kernel loss: 0.06763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, series: 173, nllk loss: -2.22619, kernel loss: 0.20859\n",
      "Epoch: 7, series: 174, nllk loss: -1.86796, kernel loss: 0.08682\n",
      "Epoch: 7, series: 175, nllk loss: -2.14609, kernel loss: 0.13244\n",
      "Epoch: 7, series: 176, nllk loss: -2.02043, kernel loss: 0.11466\n",
      "Epoch: 7, series: 177, nllk loss: -1.71300, kernel loss: 0.05572\n",
      "Epoch: 7, series: 178, nllk loss: -1.64000, kernel loss: 0.13026\n",
      "Epoch: 7, series: 179, nllk loss: -1.99351, kernel loss: 0.27946\n",
      "Epoch: 7, series: 180, nllk loss: -1.98410, kernel loss: 0.16041\n",
      "Epoch: 7, series: 181, nllk loss: -2.30628, kernel loss: 0.06226\n",
      "Epoch: 7, series: 182, nllk loss: -1.84627, kernel loss: 0.16051\n",
      "Epoch: 7, series: 183, nllk loss: -1.92315, kernel loss: 0.03086\n",
      "Epoch: 7, series: 184, nllk loss: -1.79955, kernel loss: 0.16358\n",
      "Epoch: 7, series: 185, nllk loss: -1.65838, kernel loss: 0.26147\n",
      "Epoch: 7, series: 186, nllk loss: -2.03673, kernel loss: 0.09007\n",
      "Epoch: 7, series: 187, nllk loss: -2.30349, kernel loss: 0.30088\n",
      "Epoch: 7, series: 188, nllk loss: -1.54833, kernel loss: 0.24478\n",
      "Epoch: 7, series: 189, nllk loss: -1.45919, kernel loss: 0.18811\n",
      "Epoch: 7, series: 190, nllk loss: -1.80064, kernel loss: 0.11583\n",
      "Epoch: 7, series: 191, nllk loss: -1.82749, kernel loss: 0.34631\n",
      "Epoch: 7, series: 192, nllk loss: -1.93909, kernel loss: 0.07786\n",
      "Epoch: 7, series: 193, nllk loss: -1.46060, kernel loss: 0.08386\n",
      "Epoch: 7, series: 194, nllk loss: -1.31770, kernel loss: 0.12089\n",
      "Epoch: 7, series: 195, nllk loss: -2.03133, kernel loss: 0.27915\n",
      "Epoch: 7, series: 196, nllk loss: -1.64294, kernel loss: 0.12940\n",
      "Epoch: 7, series: 197, nllk loss: -1.97779, kernel loss: 0.04992\n",
      "Epoch: 7, series: 198, nllk loss: -2.11447, kernel loss: 0.26588\n",
      "Epoch: 7, series: 199, nllk loss: -1.85266, kernel loss: 0.14120\n",
      "Epoch: 7, series: 200, nllk loss: -1.99415, kernel loss: 0.32343\n",
      "Epoch: 7, series: 201, nllk loss: -2.13905, kernel loss: 0.14339\n",
      "Epoch: 7, series: 202, nllk loss: -1.95132, kernel loss: 0.10862\n",
      "Epoch: 7, series: 203, nllk loss: -1.81679, kernel loss: 0.18809\n",
      "Epoch: 7, series: 204, nllk loss: -0.89999, kernel loss: 0.35790\n",
      "Epoch: 7, series: 205, nllk loss: -1.72149, kernel loss: 0.09293\n",
      "Epoch: 7, series: 206, nllk loss: -1.86804, kernel loss: 0.18829\n",
      "Epoch: 7, series: 207, nllk loss: -1.04700, kernel loss: 0.35845\n",
      "Epoch: 7, series: 208, nllk loss: -2.20661, kernel loss: 0.21844\n",
      "Epoch: 7, series: 209, nllk loss: -1.29990, kernel loss: 0.19036\n",
      "Epoch: 7, series: 210, nllk loss: -2.21926, kernel loss: 0.13664\n",
      "Epoch: 7, series: 211, nllk loss: -1.98263, kernel loss: 0.26632\n",
      "Epoch: 7, series: 212, nllk loss: -1.46025, kernel loss: 0.21678\n",
      "Epoch: 7, series: 213, nllk loss: -1.93838, kernel loss: 0.24803\n",
      "Epoch: 7, series: 214, nllk loss: -1.71800, kernel loss: 0.05492\n",
      "Epoch: 7, series: 215, nllk loss: -2.18543, kernel loss: 0.11539\n",
      "Epoch: 7, series: 216, nllk loss: -1.20869, kernel loss: 0.09589\n",
      "Epoch: 7, series: 217, nllk loss: -1.74212, kernel loss: 0.11056\n",
      "Epoch: 7, series: 218, nllk loss: -1.10543, kernel loss: 0.17438\n",
      "Epoch: 7, series: 219, nllk loss: -1.82349, kernel loss: 0.12969\n",
      "Epoch: 7, series: 220, nllk loss: -1.94232, kernel loss: 0.03929\n",
      "Epoch: 7, series: 221, nllk loss: -2.12746, kernel loss: 0.20415\n",
      "Epoch: 7, series: 222, nllk loss: -2.06894, kernel loss: 0.12080\n",
      "Epoch: 7, series: 223, nllk loss: -1.39925, kernel loss: 0.13724\n",
      "Epoch: 7, series: 224, nllk loss: -2.17344, kernel loss: 0.10201\n",
      "Epoch: 7, series: 225, nllk loss: -1.97999, kernel loss: 0.31582\n",
      "Epoch: 7, series: 226, nllk loss: -1.57281, kernel loss: 0.04378\n",
      "Epoch: 7, series: 227, nllk loss: -1.74809, kernel loss: 0.03942\n",
      "Epoch: 7, series: 228, nllk loss: -1.86179, kernel loss: 0.13102\n",
      "Epoch: 7, series: 229, nllk loss: -1.79664, kernel loss: 0.11100\n",
      "Epoch: 7, series: 230, nllk loss: -2.15248, kernel loss: 0.28291\n",
      "Epoch: 7, series: 231, nllk loss: -1.61759, kernel loss: 0.12510\n",
      "Epoch: 7, series: 232, nllk loss: -2.28944, kernel loss: 0.07005\n",
      "Epoch: 7, series: 233, nllk loss: -2.16841, kernel loss: 0.09404\n",
      "Epoch: 7, series: 234, nllk loss: -1.92832, kernel loss: 0.13111\n",
      "Epoch: 7, series: 235, nllk loss: -2.37743, kernel loss: 0.08201\n",
      "Epoch: 7, series: 236, nllk loss: -1.47127, kernel loss: 0.11208\n",
      "Epoch: 7, series: 237, nllk loss: -1.96810, kernel loss: 0.05025\n",
      "Epoch: 7, series: 238, nllk loss: -1.66202, kernel loss: 0.13936\n",
      "Epoch: 7, series: 239, nllk loss: -2.01478, kernel loss: 0.50268\n",
      "Epoch: 7, series: 240, nllk loss: -1.16817, kernel loss: 0.28805\n",
      "Epoch: 7, series: 241, nllk loss: -1.84964, kernel loss: 0.06920\n",
      "Epoch: 7, series: 242, nllk loss: -1.86356, kernel loss: 0.14619\n",
      "Epoch: 7, series: 243, nllk loss: -2.08144, kernel loss: 0.10751\n",
      "Epoch: 7, series: 244, nllk loss: -1.76813, kernel loss: 0.14640\n",
      "Epoch: 7, series: 245, nllk loss: -1.98404, kernel loss: 0.09597\n",
      "Epoch: 7, series: 246, nllk loss: 0.49598, kernel loss: 0.08824\n",
      "Epoch: 7, series: 247, nllk loss: -1.59788, kernel loss: 0.20108\n",
      "Epoch: 7, series: 248, nllk loss: -1.98861, kernel loss: 0.16780\n",
      "Epoch: 7, series: 249, nllk loss: -1.61707, kernel loss: 0.07921\n",
      "Epoch: 7, series: 250, nllk loss: -1.60522, kernel loss: 0.09134\n",
      "Epoch: 7, series: 251, nllk loss: -0.99189, kernel loss: 0.09331\n",
      "Epoch: 7, series: 252, nllk loss: -1.06105, kernel loss: 0.20671\n",
      "Epoch: 7, series: 253, nllk loss: -1.71962, kernel loss: 0.11071\n",
      "Epoch: 7, series: 254, nllk loss: -2.12602, kernel loss: 0.06220\n",
      "Epoch: 7, series: 255, nllk loss: -2.01738, kernel loss: 0.21528\n",
      "Epoch: 7, series: 256, nllk loss: -1.75661, kernel loss: 0.06069\n",
      "Epoch: 7, series: 257, nllk loss: -1.92994, kernel loss: 0.22053\n",
      "Epoch: 7, series: 258, nllk loss: -1.84525, kernel loss: 0.35504\n",
      "Epoch: 7, series: 259, nllk loss: -1.64640, kernel loss: 0.29020\n",
      "Epoch: 7, series: 260, nllk loss: -1.79541, kernel loss: 0.26023\n",
      "Epoch: 7, series: 261, nllk loss: -2.00003, kernel loss: 0.12472\n",
      "Epoch: 7, series: 262, nllk loss: -2.20449, kernel loss: 0.20542\n",
      "Epoch: 7, series: 263, nllk loss: -0.68837, kernel loss: 0.21383\n",
      "Epoch: 7, series: 264, nllk loss: -1.77591, kernel loss: 0.11444\n",
      "Epoch: 7, series: 265, nllk loss: -1.78126, kernel loss: 0.14299\n",
      "Epoch: 7, series: 266, nllk loss: -1.98457, kernel loss: 0.17790\n",
      "Epoch: 7, series: 267, nllk loss: -1.95611, kernel loss: 0.02035\n",
      "Epoch: 7, series: 268, nllk loss: -2.07047, kernel loss: 0.04230\n",
      "Epoch: 7, series: 269, nllk loss: -1.73406, kernel loss: 0.33437\n",
      "Epoch: 7, series: 270, nllk loss: -1.67036, kernel loss: 0.28976\n",
      "Epoch: 7, series: 271, nllk loss: -1.82472, kernel loss: 0.41899\n",
      "Epoch: 7, series: 272, nllk loss: -1.91257, kernel loss: 0.05586\n",
      "Epoch: 7, series: 273, nllk loss: -1.87874, kernel loss: 0.14441\n",
      "Epoch: 7, series: 274, nllk loss: -1.33574, kernel loss: 0.07489\n",
      "Epoch: 7, series: 275, nllk loss: -1.76314, kernel loss: 0.06911\n",
      "Epoch: 7, series: 276, nllk loss: -1.12423, kernel loss: 0.15896\n",
      "Epoch: 7, series: 277, nllk loss: -2.14435, kernel loss: 0.11483\n",
      "Epoch: 7, series: 278, nllk loss: -1.80999, kernel loss: 0.12519\n",
      "Epoch: 7, series: 279, nllk loss: -2.22551, kernel loss: 0.07062\n",
      "Epoch: 7, series: 280, nllk loss: -2.02858, kernel loss: 0.07175\n",
      "Epoch: 7, series: 281, nllk loss: -2.16240, kernel loss: 0.08071\n",
      "Epoch: 7, series: 282, nllk loss: -2.07870, kernel loss: 0.02713\n",
      "Epoch: 7, series: 283, nllk loss: -2.08537, kernel loss: 0.38106\n",
      "Epoch: 7, series: 284, nllk loss: -1.72506, kernel loss: 0.13620\n",
      "Epoch: 7, series: 285, nllk loss: -1.86932, kernel loss: 0.13692\n",
      "Epoch: 7, series: 286, nllk loss: -2.02847, kernel loss: 0.10139\n",
      "Epoch: 7, series: 287, nllk loss: -2.24289, kernel loss: 0.09495\n",
      "Epoch: 7, series: 288, nllk loss: -1.13564, kernel loss: 0.00257\n",
      "Epoch: 7, series: 289, nllk loss: -1.06618, kernel loss: 0.14943\n",
      "Epoch: 7, series: 290, nllk loss: -2.21282, kernel loss: 0.07271\n",
      "Epoch: 7, series: 291, nllk loss: -2.23828, kernel loss: 0.12765\n",
      "Epoch: 7, series: 292, nllk loss: -2.27263, kernel loss: 0.08651\n",
      "Epoch: 7, series: 293, nllk loss: -2.34707, kernel loss: 0.06610\n",
      "Epoch: 7, series: 294, nllk loss: -1.59660, kernel loss: 0.02970\n",
      "Epoch: 7, series: 295, nllk loss: -1.10251, kernel loss: 0.12193\n",
      "Epoch: 7, series: 296, nllk loss: -2.29252, kernel loss: 0.06977\n",
      "Epoch: 7, series: 297, nllk loss: -2.36539, kernel loss: 0.07590\n",
      "Epoch: 7, series: 298, nllk loss: 3.31839, kernel loss: 0.09309\n",
      "Epoch: 7, series: 299, nllk loss: 1.59852, kernel loss: 0.22867\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, series: 300, nllk loss: -1.86440, kernel loss: 0.21454\n",
      "Epoch: 7, series: 301, nllk loss: -1.78984, kernel loss: 0.27980\n",
      "Epoch: 7, series: 302, nllk loss: -1.85867, kernel loss: 0.17340\n",
      "Epoch: 7, series: 303, nllk loss: -1.47155, kernel loss: 0.17558\n",
      "Epoch: 7, series: 304, nllk loss: -0.24635, kernel loss: 0.14462\n",
      "Epoch: 7, series: 305, nllk loss: -1.32097, kernel loss: 0.10806\n",
      "Epoch: 7, series: 306, nllk loss: -2.01795, kernel loss: 0.14135\n",
      "Epoch: 7, series: 307, nllk loss: -1.33793, kernel loss: 0.12067\n",
      "Epoch: 7, series: 308, nllk loss: -1.84366, kernel loss: 0.07416\n",
      "Epoch: 7, series: 309, nllk loss: -1.62895, kernel loss: 0.16202\n",
      "Epoch: 7, series: 310, nllk loss: -1.71712, kernel loss: 0.13166\n",
      "Epoch: 7, series: 311, nllk loss: -1.56072, kernel loss: 0.09164\n",
      "Epoch: 7, series: 312, nllk loss: -1.85932, kernel loss: 0.18607\n",
      "Epoch: 7, series: 313, nllk loss: -1.93272, kernel loss: 0.03160\n",
      "Epoch: 7, series: 314, nllk loss: -2.13072, kernel loss: 0.09255\n",
      "Epoch: 7, series: 315, nllk loss: -0.96743, kernel loss: 0.39766\n",
      "Epoch: 7, series: 316, nllk loss: -1.64915, kernel loss: 0.14380\n",
      "Epoch: 7, series: 317, nllk loss: 0.70774, kernel loss: 0.10370\n",
      "Epoch: 7, series: 318, nllk loss: 1.91820, kernel loss: 0.14620\n",
      "Epoch: 7, series: 319, nllk loss: -0.79482, kernel loss: 0.09602\n",
      "Epoch: 7, series: 320, nllk loss: -0.88747, kernel loss: 0.02819\n",
      "Epoch: 7, total loss: -393.68344\n",
      "Epoch: 8, series: 0, nllk loss: 2.76184, kernel loss: 0.31200\n",
      "Epoch: 8, series: 1, nllk loss: -0.90099, kernel loss: 0.42117\n",
      "Epoch: 8, series: 2, nllk loss: 0.37921, kernel loss: 0.29031\n",
      "Epoch: 8, series: 3, nllk loss: -0.98245, kernel loss: 0.25367\n",
      "Epoch: 8, series: 4, nllk loss: -0.77701, kernel loss: 0.37744\n",
      "Epoch: 8, series: 5, nllk loss: -1.04721, kernel loss: 0.38856\n",
      "Epoch: 8, series: 6, nllk loss: -0.41644, kernel loss: 0.21884\n",
      "Epoch: 8, series: 7, nllk loss: -1.09449, kernel loss: 0.18543\n",
      "Epoch: 8, series: 8, nllk loss: -0.44551, kernel loss: 0.29676\n",
      "Epoch: 8, series: 9, nllk loss: -0.33586, kernel loss: 0.10490\n",
      "Epoch: 8, series: 10, nllk loss: -1.04317, kernel loss: 0.21138\n",
      "Epoch: 8, series: 11, nllk loss: -0.77780, kernel loss: 0.37344\n",
      "Epoch: 8, series: 12, nllk loss: -1.17377, kernel loss: 0.21476\n",
      "Epoch: 8, series: 13, nllk loss: -1.15848, kernel loss: 0.40528\n",
      "Epoch: 8, series: 14, nllk loss: -1.26096, kernel loss: 0.16015\n",
      "Epoch: 8, series: 15, nllk loss: -1.23753, kernel loss: 0.25996\n",
      "Epoch: 8, series: 16, nllk loss: -0.86397, kernel loss: 0.03291\n",
      "Epoch: 8, series: 17, nllk loss: -0.93514, kernel loss: 0.23556\n",
      "Epoch: 8, series: 18, nllk loss: -1.16606, kernel loss: 0.19036\n",
      "Epoch: 8, series: 19, nllk loss: -0.38941, kernel loss: 0.09334\n",
      "Epoch: 8, series: 20, nllk loss: -0.75221, kernel loss: 0.18637\n",
      "Epoch: 8, series: 21, nllk loss: -0.99302, kernel loss: 0.06030\n",
      "Epoch: 8, series: 22, nllk loss: -1.19035, kernel loss: 0.08360\n",
      "Epoch: 8, series: 23, nllk loss: -1.19670, kernel loss: 0.05455\n",
      "Epoch: 8, series: 24, nllk loss: -1.34201, kernel loss: 0.07041\n",
      "Epoch: 8, series: 25, nllk loss: -1.24716, kernel loss: 0.16793\n",
      "Epoch: 8, series: 26, nllk loss: -1.16481, kernel loss: 0.24728\n",
      "Epoch: 8, series: 27, nllk loss: -1.14436, kernel loss: 0.07029\n",
      "Epoch: 8, series: 28, nllk loss: -1.18538, kernel loss: 0.22445\n",
      "Epoch: 8, series: 29, nllk loss: -0.70220, kernel loss: 0.08002\n",
      "Epoch: 8, series: 30, nllk loss: -1.21365, kernel loss: 0.09852\n",
      "Epoch: 8, series: 31, nllk loss: -1.06833, kernel loss: 0.11940\n",
      "Epoch: 8, series: 32, nllk loss: -1.07025, kernel loss: 0.06359\n",
      "Epoch: 8, series: 33, nllk loss: -0.92942, kernel loss: 0.08850\n",
      "Epoch: 8, series: 34, nllk loss: -1.31554, kernel loss: 0.02964\n",
      "Epoch: 8, series: 35, nllk loss: -1.49284, kernel loss: 0.07270\n",
      "Epoch: 8, series: 36, nllk loss: -1.20738, kernel loss: 0.07086\n",
      "Epoch: 8, series: 37, nllk loss: -0.41344, kernel loss: 0.10598\n",
      "Epoch: 8, series: 38, nllk loss: -1.03800, kernel loss: 0.18847\n",
      "Epoch: 8, series: 39, nllk loss: -0.83989, kernel loss: 0.06604\n",
      "Epoch: 8, series: 40, nllk loss: -1.63773, kernel loss: 0.19172\n",
      "Epoch: 8, series: 41, nllk loss: -1.30589, kernel loss: 0.29124\n",
      "Epoch: 8, series: 42, nllk loss: -1.04152, kernel loss: 0.05336\n",
      "Epoch: 8, series: 43, nllk loss: -0.98674, kernel loss: 0.13449\n",
      "Epoch: 8, series: 44, nllk loss: -1.48664, kernel loss: 0.19614\n",
      "Epoch: 8, series: 45, nllk loss: -1.55491, kernel loss: 0.08480\n",
      "Epoch: 8, series: 46, nllk loss: -1.55436, kernel loss: 0.05062\n",
      "Epoch: 8, series: 47, nllk loss: -1.48849, kernel loss: 0.12599\n",
      "Epoch: 8, series: 48, nllk loss: -1.51889, kernel loss: 0.20903\n",
      "Epoch: 8, series: 49, nllk loss: -1.17017, kernel loss: 0.25034\n",
      "Epoch: 8, series: 50, nllk loss: -0.00957, kernel loss: 0.13072\n",
      "Epoch: 8, series: 51, nllk loss: -1.33016, kernel loss: 0.09792\n",
      "Epoch: 8, series: 52, nllk loss: -0.51358, kernel loss: 0.09593\n",
      "Epoch: 8, series: 53, nllk loss: -1.52423, kernel loss: 0.21439\n",
      "Epoch: 8, series: 54, nllk loss: -1.15645, kernel loss: 0.13103\n",
      "Epoch: 8, series: 55, nllk loss: -0.88673, kernel loss: 0.10585\n",
      "Epoch: 8, series: 56, nllk loss: -1.27034, kernel loss: 0.20937\n",
      "Epoch: 8, series: 57, nllk loss: -1.22844, kernel loss: 0.04719\n",
      "Epoch: 8, series: 58, nllk loss: -1.38670, kernel loss: 0.13369\n",
      "Epoch: 8, series: 59, nllk loss: -1.05505, kernel loss: 0.12604\n",
      "Epoch: 8, series: 60, nllk loss: -1.00647, kernel loss: 0.08763\n",
      "Epoch: 8, series: 61, nllk loss: -1.52862, kernel loss: 0.06105\n",
      "Epoch: 8, series: 62, nllk loss: -1.59111, kernel loss: 0.09964\n",
      "Epoch: 8, series: 63, nllk loss: -1.55594, kernel loss: 0.06099\n",
      "Epoch: 8, series: 64, nllk loss: -1.13427, kernel loss: 0.10214\n",
      "Epoch: 8, series: 65, nllk loss: -1.48817, kernel loss: 0.11637\n",
      "Epoch: 8, series: 66, nllk loss: -1.39633, kernel loss: 0.12768\n",
      "Epoch: 8, series: 67, nllk loss: -1.31808, kernel loss: 0.07705\n",
      "Epoch: 8, series: 68, nllk loss: -0.69111, kernel loss: 0.22554\n",
      "Epoch: 8, series: 69, nllk loss: -1.11750, kernel loss: 0.39564\n",
      "Epoch: 8, series: 70, nllk loss: -1.38530, kernel loss: 0.03235\n",
      "Epoch: 8, series: 71, nllk loss: -1.39970, kernel loss: 0.16593\n",
      "Epoch: 8, series: 72, nllk loss: -1.68722, kernel loss: 0.03664\n",
      "Epoch: 8, series: 73, nllk loss: -1.21047, kernel loss: 0.02640\n",
      "Epoch: 8, series: 74, nllk loss: -1.71588, kernel loss: 0.26569\n",
      "Epoch: 8, series: 75, nllk loss: -1.30416, kernel loss: 0.26049\n",
      "Epoch: 8, series: 76, nllk loss: -1.37277, kernel loss: 0.08056\n",
      "Epoch: 8, series: 77, nllk loss: -1.10724, kernel loss: 0.12389\n",
      "Epoch: 8, series: 78, nllk loss: -1.23799, kernel loss: 0.09702\n",
      "Epoch: 8, series: 79, nllk loss: -0.41773, kernel loss: 0.13466\n",
      "Epoch: 8, series: 80, nllk loss: -1.62627, kernel loss: 0.09282\n",
      "Epoch: 8, series: 81, nllk loss: -1.33230, kernel loss: 0.17495\n",
      "Epoch: 8, series: 82, nllk loss: -0.14525, kernel loss: 0.08153\n",
      "Epoch: 8, series: 83, nllk loss: -0.62988, kernel loss: 0.00911\n",
      "Epoch: 8, series: 84, nllk loss: -1.06224, kernel loss: 0.03852\n",
      "Epoch: 8, series: 85, nllk loss: -1.25828, kernel loss: 0.26926\n",
      "Epoch: 8, series: 86, nllk loss: -0.33216, kernel loss: 0.13240\n",
      "Epoch: 8, series: 87, nllk loss: -1.53414, kernel loss: 0.13846\n",
      "Epoch: 8, series: 88, nllk loss: -1.68348, kernel loss: 0.14991\n",
      "Epoch: 8, series: 89, nllk loss: -1.75076, kernel loss: 0.15631\n",
      "Epoch: 8, series: 90, nllk loss: -1.83112, kernel loss: 0.35339\n",
      "Epoch: 8, series: 91, nllk loss: -1.87910, kernel loss: 0.11894\n",
      "Epoch: 8, series: 92, nllk loss: 0.50404, kernel loss: 0.06733\n",
      "Epoch: 8, series: 93, nllk loss: -2.06367, kernel loss: 0.14453\n",
      "Epoch: 8, series: 94, nllk loss: -2.05351, kernel loss: 0.05636\n",
      "Epoch: 8, series: 95, nllk loss: -2.03301, kernel loss: 0.13353\n",
      "Epoch: 8, series: 96, nllk loss: -1.57323, kernel loss: 0.10886\n",
      "Epoch: 8, series: 97, nllk loss: -0.67393, kernel loss: 0.11478\n",
      "Epoch: 8, series: 98, nllk loss: -0.71959, kernel loss: 0.08709\n",
      "Epoch: 8, series: 99, nllk loss: -1.30351, kernel loss: 0.11618\n",
      "Epoch: 8, series: 100, nllk loss: -0.81042, kernel loss: 0.13764\n",
      "Epoch: 8, series: 101, nllk loss: -1.30298, kernel loss: 0.06888\n",
      "Epoch: 8, series: 102, nllk loss: -0.89080, kernel loss: 0.34035\n",
      "Epoch: 8, series: 103, nllk loss: -1.10275, kernel loss: 0.15105\n",
      "Epoch: 8, series: 104, nllk loss: 0.41555, kernel loss: 0.04757\n",
      "Epoch: 8, series: 105, nllk loss: 0.38062, kernel loss: 0.02166\n",
      "Epoch: 8, series: 106, nllk loss: -1.00756, kernel loss: 0.06453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, series: 107, nllk loss: -0.81347, kernel loss: 0.10644\n",
      "Epoch: 8, series: 108, nllk loss: -1.24209, kernel loss: 0.24592\n",
      "Epoch: 8, series: 109, nllk loss: -0.65544, kernel loss: 0.15674\n",
      "Epoch: 8, series: 110, nllk loss: -1.37039, kernel loss: 0.07405\n",
      "Epoch: 8, series: 111, nllk loss: -1.22038, kernel loss: 0.07228\n",
      "Epoch: 8, series: 112, nllk loss: -0.62875, kernel loss: 0.14432\n",
      "Epoch: 8, series: 113, nllk loss: -0.85363, kernel loss: 0.18233\n",
      "Epoch: 8, series: 114, nllk loss: -0.68628, kernel loss: 0.29920\n",
      "Epoch: 8, series: 115, nllk loss: -0.82010, kernel loss: 0.09340\n",
      "Epoch: 8, series: 116, nllk loss: -1.53111, kernel loss: 0.11743\n",
      "Epoch: 8, series: 117, nllk loss: -0.62119, kernel loss: 0.20929\n",
      "Epoch: 8, series: 118, nllk loss: -1.63620, kernel loss: 0.06196\n",
      "Epoch: 8, series: 119, nllk loss: -0.68896, kernel loss: 0.12213\n",
      "Epoch: 8, series: 120, nllk loss: -1.47990, kernel loss: 0.17163\n",
      "Epoch: 8, series: 121, nllk loss: 0.22600, kernel loss: 0.08312\n",
      "Epoch: 8, series: 122, nllk loss: -0.38350, kernel loss: 0.20868\n",
      "Epoch: 8, series: 123, nllk loss: -1.45345, kernel loss: 0.21520\n",
      "Epoch: 8, series: 124, nllk loss: -1.58810, kernel loss: 0.08438\n",
      "Epoch: 8, series: 125, nllk loss: -1.39108, kernel loss: 0.03041\n",
      "Epoch: 8, series: 126, nllk loss: -1.54707, kernel loss: 0.06400\n",
      "Epoch: 8, series: 127, nllk loss: -1.40529, kernel loss: 0.25353\n",
      "Epoch: 8, series: 128, nllk loss: -0.94588, kernel loss: 0.22062\n",
      "Epoch: 8, series: 129, nllk loss: -0.71989, kernel loss: 0.06186\n",
      "Epoch: 8, series: 130, nllk loss: -1.16419, kernel loss: 0.08231\n",
      "Epoch: 8, series: 131, nllk loss: 0.62789, kernel loss: 0.01442\n",
      "Epoch: 8, series: 132, nllk loss: 0.08298, kernel loss: 0.12234\n",
      "Epoch: 8, series: 133, nllk loss: -0.86439, kernel loss: 0.19940\n",
      "Epoch: 8, series: 134, nllk loss: -0.69717, kernel loss: 0.24538\n",
      "Epoch: 8, series: 135, nllk loss: -1.39539, kernel loss: 0.10135\n",
      "Epoch: 8, series: 136, nllk loss: -1.47904, kernel loss: 0.21966\n",
      "Epoch: 8, series: 137, nllk loss: -1.56868, kernel loss: 0.10059\n",
      "Epoch: 8, series: 138, nllk loss: -1.61993, kernel loss: 0.05924\n",
      "Epoch: 8, series: 139, nllk loss: -1.49639, kernel loss: 0.23303\n",
      "Epoch: 8, series: 140, nllk loss: -1.36936, kernel loss: 0.15672\n",
      "Epoch: 8, series: 141, nllk loss: -1.51942, kernel loss: 0.10084\n",
      "Epoch: 8, series: 142, nllk loss: -1.41464, kernel loss: 0.03719\n",
      "Epoch: 8, series: 143, nllk loss: -1.55500, kernel loss: 0.08734\n",
      "Epoch: 8, series: 144, nllk loss: -1.70099, kernel loss: 0.16146\n",
      "Epoch: 8, series: 145, nllk loss: -1.63479, kernel loss: 0.15770\n",
      "Epoch: 8, series: 146, nllk loss: 3.24689, kernel loss: 0.10790\n",
      "Epoch: 8, series: 147, nllk loss: -1.41068, kernel loss: 0.03921\n",
      "Epoch: 8, series: 148, nllk loss: -1.36275, kernel loss: 0.23691\n",
      "Epoch: 8, series: 149, nllk loss: -1.48641, kernel loss: 0.08979\n",
      "Epoch: 8, series: 150, nllk loss: -1.66531, kernel loss: 0.12097\n",
      "Epoch: 8, series: 151, nllk loss: -1.74263, kernel loss: 0.07490\n",
      "Epoch: 8, series: 152, nllk loss: -1.70409, kernel loss: 0.16403\n",
      "Epoch: 8, series: 153, nllk loss: -1.50567, kernel loss: 0.19730\n",
      "Epoch: 8, series: 154, nllk loss: -1.57439, kernel loss: 0.18094\n",
      "Epoch: 8, series: 155, nllk loss: -1.61721, kernel loss: 0.08929\n",
      "Epoch: 8, series: 156, nllk loss: -1.73856, kernel loss: 0.00665\n",
      "Epoch: 8, series: 157, nllk loss: -1.26875, kernel loss: 0.10985\n",
      "Epoch: 8, series: 158, nllk loss: -1.70202, kernel loss: 0.05809\n",
      "Epoch: 8, series: 159, nllk loss: -1.73646, kernel loss: 0.22419\n",
      "Epoch: 8, series: 160, nllk loss: -1.63539, kernel loss: 0.19667\n",
      "Epoch: 8, series: 161, nllk loss: -1.57218, kernel loss: 0.02780\n",
      "Epoch: 8, series: 162, nllk loss: -1.78870, kernel loss: 0.17051\n",
      "Epoch: 8, series: 163, nllk loss: -2.04482, kernel loss: 0.20309\n",
      "Epoch: 8, series: 164, nllk loss: -1.69072, kernel loss: 0.06925\n",
      "Epoch: 8, series: 165, nllk loss: -1.81507, kernel loss: 0.02865\n",
      "Epoch: 8, series: 166, nllk loss: -1.35464, kernel loss: 0.32059\n",
      "Epoch: 8, series: 167, nllk loss: -2.06710, kernel loss: 0.02236\n",
      "Epoch: 8, series: 168, nllk loss: -1.89498, kernel loss: 0.13617\n",
      "Epoch: 8, series: 169, nllk loss: -2.04325, kernel loss: 0.05899\n",
      "Epoch: 8, series: 170, nllk loss: -1.74443, kernel loss: 0.15501\n",
      "Epoch: 8, series: 171, nllk loss: -2.11113, kernel loss: 0.05301\n",
      "Epoch: 8, series: 172, nllk loss: -1.91431, kernel loss: 0.13172\n",
      "Epoch: 8, series: 173, nllk loss: -2.25525, kernel loss: 0.05048\n",
      "Epoch: 8, series: 174, nllk loss: -1.89326, kernel loss: 0.15450\n",
      "Epoch: 8, series: 175, nllk loss: -2.18676, kernel loss: 0.14393\n",
      "Epoch: 8, series: 176, nllk loss: -2.06357, kernel loss: 0.14675\n",
      "Epoch: 8, series: 177, nllk loss: -1.76613, kernel loss: 0.23214\n",
      "Epoch: 8, series: 178, nllk loss: -1.59490, kernel loss: 0.07176\n",
      "Epoch: 8, series: 179, nllk loss: -2.06675, kernel loss: 0.03839\n",
      "Epoch: 8, series: 180, nllk loss: -2.07990, kernel loss: 0.03957\n",
      "Epoch: 8, series: 181, nllk loss: -2.34930, kernel loss: 0.29261\n",
      "Epoch: 8, series: 182, nllk loss: -1.95181, kernel loss: 0.35193\n",
      "Epoch: 8, series: 183, nllk loss: -1.89004, kernel loss: 0.13194\n",
      "Epoch: 8, series: 184, nllk loss: -1.72456, kernel loss: 0.21610\n",
      "Epoch: 8, series: 185, nllk loss: -1.68447, kernel loss: 0.43878\n",
      "Epoch: 8, series: 186, nllk loss: -2.21543, kernel loss: 0.12127\n",
      "Epoch: 8, series: 187, nllk loss: -2.22915, kernel loss: 0.24615\n",
      "Epoch: 8, series: 188, nllk loss: -1.55814, kernel loss: 0.16874\n",
      "Epoch: 8, series: 189, nllk loss: -1.53384, kernel loss: 0.06783\n",
      "Epoch: 8, series: 190, nllk loss: -1.59021, kernel loss: 0.23288\n",
      "Epoch: 8, series: 191, nllk loss: -1.85285, kernel loss: 0.29143\n",
      "Epoch: 8, series: 192, nllk loss: -1.99747, kernel loss: 0.08812\n",
      "Epoch: 8, series: 193, nllk loss: -1.38906, kernel loss: 0.39003\n",
      "Epoch: 8, series: 194, nllk loss: -1.29445, kernel loss: 0.29477\n",
      "Epoch: 8, series: 195, nllk loss: -2.09271, kernel loss: 0.16126\n",
      "Epoch: 8, series: 196, nllk loss: -1.81747, kernel loss: 0.01999\n",
      "Epoch: 8, series: 197, nllk loss: -1.88390, kernel loss: 0.01344\n",
      "Epoch: 8, series: 198, nllk loss: -2.05690, kernel loss: 0.48098\n",
      "Epoch: 8, series: 199, nllk loss: -1.87064, kernel loss: 0.12436\n",
      "Epoch: 8, series: 200, nllk loss: -1.87419, kernel loss: 0.02886\n",
      "Epoch: 8, series: 201, nllk loss: -2.10386, kernel loss: 0.10818\n",
      "Epoch: 8, series: 202, nllk loss: -1.89455, kernel loss: 0.13263\n",
      "Epoch: 8, series: 203, nllk loss: -1.98952, kernel loss: 0.17621\n",
      "Epoch: 8, series: 204, nllk loss: -0.95097, kernel loss: 0.04980\n",
      "Epoch: 8, series: 205, nllk loss: -1.70647, kernel loss: 0.36823\n",
      "Epoch: 8, series: 206, nllk loss: -1.77205, kernel loss: 0.17628\n",
      "Epoch: 8, series: 207, nllk loss: -1.01276, kernel loss: 0.16380\n",
      "Epoch: 8, series: 208, nllk loss: -2.29171, kernel loss: 0.07997\n",
      "Epoch: 8, series: 209, nllk loss: -1.36967, kernel loss: 0.04998\n",
      "Epoch: 8, series: 210, nllk loss: -2.28337, kernel loss: 0.09956\n",
      "Epoch: 8, series: 211, nllk loss: -2.02331, kernel loss: 0.09777\n",
      "Epoch: 8, series: 212, nllk loss: -1.61546, kernel loss: 0.20939\n",
      "Epoch: 8, series: 213, nllk loss: -1.99211, kernel loss: 0.10862\n",
      "Epoch: 8, series: 214, nllk loss: -1.92427, kernel loss: 0.20569\n",
      "Epoch: 8, series: 215, nllk loss: -2.25672, kernel loss: 0.08334\n",
      "Epoch: 8, series: 216, nllk loss: -1.24170, kernel loss: 0.07630\n",
      "Epoch: 8, series: 217, nllk loss: -1.84809, kernel loss: 0.27217\n",
      "Epoch: 8, series: 218, nllk loss: -1.51426, kernel loss: 0.25257\n",
      "Epoch: 8, series: 219, nllk loss: -1.95300, kernel loss: 0.15424\n",
      "Epoch: 8, series: 220, nllk loss: -1.99294, kernel loss: 0.39023\n",
      "Epoch: 8, series: 221, nllk loss: -2.18891, kernel loss: 0.21109\n",
      "Epoch: 8, series: 222, nllk loss: -2.08171, kernel loss: 0.02717\n",
      "Epoch: 8, series: 223, nllk loss: -1.56590, kernel loss: 0.06785\n",
      "Epoch: 8, series: 224, nllk loss: -2.21086, kernel loss: 0.08418\n",
      "Epoch: 8, series: 225, nllk loss: -2.10859, kernel loss: 0.28564\n",
      "Epoch: 8, series: 226, nllk loss: -1.66561, kernel loss: 0.05376\n",
      "Epoch: 8, series: 227, nllk loss: -1.92223, kernel loss: 0.23085\n",
      "Epoch: 8, series: 228, nllk loss: -1.94799, kernel loss: 0.10237\n",
      "Epoch: 8, series: 229, nllk loss: -1.84660, kernel loss: 0.21323\n",
      "Epoch: 8, series: 230, nllk loss: -2.15551, kernel loss: 0.22458\n",
      "Epoch: 8, series: 231, nllk loss: -1.73105, kernel loss: 0.09521\n",
      "Epoch: 8, series: 232, nllk loss: -2.36914, kernel loss: 0.09348\n",
      "Epoch: 8, series: 233, nllk loss: -2.30204, kernel loss: 0.02834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8, series: 234, nllk loss: -1.93877, kernel loss: 0.05934\n",
      "Epoch: 8, series: 235, nllk loss: -2.47041, kernel loss: 0.13681\n",
      "Epoch: 8, series: 236, nllk loss: -1.52951, kernel loss: 0.17212\n",
      "Epoch: 8, series: 237, nllk loss: -2.07717, kernel loss: 0.13570\n",
      "Epoch: 8, series: 238, nllk loss: -1.61578, kernel loss: 0.03107\n",
      "Epoch: 8, series: 239, nllk loss: -2.11974, kernel loss: 0.11626\n",
      "Epoch: 8, series: 240, nllk loss: -1.24678, kernel loss: 0.25505\n",
      "Epoch: 8, series: 241, nllk loss: -1.86608, kernel loss: 0.27904\n",
      "Epoch: 8, series: 242, nllk loss: -1.77946, kernel loss: 0.16742\n",
      "Epoch: 8, series: 243, nllk loss: -2.15712, kernel loss: 0.07524\n",
      "Epoch: 8, series: 244, nllk loss: -1.76483, kernel loss: 0.06273\n",
      "Epoch: 8, series: 245, nllk loss: -2.06496, kernel loss: 0.08946\n",
      "Epoch: 8, series: 246, nllk loss: 0.68621, kernel loss: 0.14780\n",
      "Epoch: 8, series: 247, nllk loss: -1.65318, kernel loss: 0.03934\n",
      "Epoch: 8, series: 248, nllk loss: -1.94335, kernel loss: 0.16703\n",
      "Epoch: 8, series: 249, nllk loss: -1.73930, kernel loss: 0.06489\n",
      "Epoch: 8, series: 250, nllk loss: -1.61136, kernel loss: 0.12277\n",
      "Epoch: 8, series: 251, nllk loss: -1.08773, kernel loss: 0.06322\n",
      "Epoch: 8, series: 252, nllk loss: -1.18199, kernel loss: 0.01277\n",
      "Epoch: 8, series: 253, nllk loss: -1.74769, kernel loss: 0.08042\n",
      "Epoch: 8, series: 254, nllk loss: -2.12030, kernel loss: 0.10538\n",
      "Epoch: 8, series: 255, nllk loss: -1.99628, kernel loss: 0.20542\n",
      "Epoch: 8, series: 256, nllk loss: -1.76129, kernel loss: 0.18180\n",
      "Epoch: 8, series: 257, nllk loss: -1.92697, kernel loss: 0.16354\n",
      "Epoch: 8, series: 258, nllk loss: -1.89015, kernel loss: 0.02653\n",
      "Epoch: 8, series: 259, nllk loss: -1.68737, kernel loss: 0.02861\n",
      "Epoch: 8, series: 260, nllk loss: -1.79426, kernel loss: 0.13121\n",
      "Epoch: 8, series: 261, nllk loss: -2.05921, kernel loss: 0.10835\n",
      "Epoch: 8, series: 262, nllk loss: -2.30937, kernel loss: 0.33011\n",
      "Epoch: 8, series: 263, nllk loss: -0.70639, kernel loss: 0.06387\n",
      "Epoch: 8, series: 264, nllk loss: -1.78510, kernel loss: 0.12472\n",
      "Epoch: 8, series: 265, nllk loss: -1.78336, kernel loss: 0.05495\n",
      "Epoch: 8, series: 266, nllk loss: -2.04798, kernel loss: 0.19605\n",
      "Epoch: 8, series: 267, nllk loss: -1.99571, kernel loss: 0.13502\n",
      "Epoch: 8, series: 268, nllk loss: -2.11777, kernel loss: 0.01734\n",
      "Epoch: 8, series: 269, nllk loss: -1.85076, kernel loss: 0.18911\n",
      "Epoch: 8, series: 270, nllk loss: -1.74831, kernel loss: 0.12212\n",
      "Epoch: 8, series: 271, nllk loss: -1.86768, kernel loss: 0.12295\n",
      "Epoch: 8, series: 272, nllk loss: -1.90981, kernel loss: 0.02698\n",
      "Epoch: 8, series: 273, nllk loss: -1.94360, kernel loss: 0.03102\n",
      "Epoch: 8, series: 274, nllk loss: -1.30383, kernel loss: 0.09363\n",
      "Epoch: 8, series: 275, nllk loss: -1.77104, kernel loss: 0.05936\n",
      "Epoch: 8, series: 276, nllk loss: -1.16950, kernel loss: 0.06215\n",
      "Epoch: 8, series: 277, nllk loss: -2.13021, kernel loss: 0.22001\n",
      "Epoch: 8, series: 278, nllk loss: -1.81303, kernel loss: 0.17681\n",
      "Epoch: 8, series: 279, nllk loss: -2.20999, kernel loss: 0.16074\n",
      "Epoch: 8, series: 280, nllk loss: -2.00125, kernel loss: 0.20668\n",
      "Epoch: 8, series: 281, nllk loss: -2.24457, kernel loss: 0.04632\n",
      "Epoch: 8, series: 282, nllk loss: -2.09995, kernel loss: 0.11677\n",
      "Epoch: 8, series: 283, nllk loss: -2.11585, kernel loss: 0.10845\n",
      "Epoch: 8, series: 284, nllk loss: -1.62263, kernel loss: 0.16058\n",
      "Epoch: 8, series: 285, nllk loss: -1.83127, kernel loss: 0.06082\n",
      "Epoch: 8, series: 286, nllk loss: -2.06122, kernel loss: 0.11086\n",
      "Epoch: 8, series: 287, nllk loss: -2.30178, kernel loss: 0.08587\n",
      "Epoch: 8, series: 288, nllk loss: -1.13832, kernel loss: 0.09842\n",
      "Epoch: 8, series: 289, nllk loss: -0.89740, kernel loss: 0.23520\n",
      "Epoch: 8, series: 290, nllk loss: -2.13070, kernel loss: 0.34507\n",
      "Epoch: 8, series: 291, nllk loss: -2.15973, kernel loss: 0.01818\n",
      "Epoch: 8, series: 292, nllk loss: -2.26111, kernel loss: 0.07616\n",
      "Epoch: 8, series: 293, nllk loss: -2.38143, kernel loss: 0.04740\n",
      "Epoch: 8, series: 294, nllk loss: -1.49812, kernel loss: 0.03316\n",
      "Epoch: 8, series: 295, nllk loss: -1.08197, kernel loss: 0.06396\n",
      "Epoch: 8, series: 296, nllk loss: -2.28241, kernel loss: 0.31876\n",
      "Epoch: 8, series: 297, nllk loss: -2.35526, kernel loss: 0.14974\n",
      "Epoch: 8, series: 298, nllk loss: 2.63357, kernel loss: 0.12252\n",
      "Epoch: 8, series: 299, nllk loss: 0.79980, kernel loss: 0.13216\n",
      "Epoch: 8, series: 300, nllk loss: -1.73225, kernel loss: 0.02071\n",
      "Epoch: 8, series: 301, nllk loss: -1.82960, kernel loss: 0.24286\n",
      "Epoch: 8, series: 302, nllk loss: -1.91850, kernel loss: 0.19014\n",
      "Epoch: 8, series: 303, nllk loss: -1.68396, kernel loss: 0.16830\n",
      "Epoch: 8, series: 304, nllk loss: 0.08272, kernel loss: 0.31513\n",
      "Epoch: 8, series: 305, nllk loss: -1.60295, kernel loss: 0.15615\n",
      "Epoch: 8, series: 306, nllk loss: -2.06699, kernel loss: 0.25729\n",
      "Epoch: 8, series: 307, nllk loss: -1.37248, kernel loss: 0.44365\n",
      "Epoch: 8, series: 308, nllk loss: -2.00000, kernel loss: 0.25293\n",
      "Epoch: 8, series: 309, nllk loss: -1.64974, kernel loss: 0.22252\n",
      "Epoch: 8, series: 310, nllk loss: -1.81109, kernel loss: 0.22151\n",
      "Epoch: 8, series: 311, nllk loss: -1.57473, kernel loss: 0.16402\n",
      "Epoch: 8, series: 312, nllk loss: -1.89307, kernel loss: 0.09484\n",
      "Epoch: 8, series: 313, nllk loss: -1.92866, kernel loss: 0.14724\n",
      "Epoch: 8, series: 314, nllk loss: -2.14590, kernel loss: 0.14064\n",
      "Epoch: 8, series: 315, nllk loss: -0.80458, kernel loss: 0.05103\n",
      "Epoch: 8, series: 316, nllk loss: -1.65780, kernel loss: 0.19461\n",
      "Epoch: 8, series: 317, nllk loss: 0.82910, kernel loss: 0.17949\n",
      "Epoch: 8, series: 318, nllk loss: 1.94972, kernel loss: 0.15146\n",
      "Epoch: 8, series: 319, nllk loss: -0.75376, kernel loss: 0.11135\n",
      "Epoch: 8, series: 320, nllk loss: -0.88935, kernel loss: 0.13743\n",
      "Epoch: 8, total loss: -402.83542\n",
      "Epoch: 9, series: 0, nllk loss: 2.89159, kernel loss: 0.14965\n",
      "Epoch: 9, series: 1, nllk loss: -0.80045, kernel loss: 0.15828\n",
      "Epoch: 9, series: 2, nllk loss: 0.48076, kernel loss: 0.22778\n",
      "Epoch: 9, series: 3, nllk loss: -0.93093, kernel loss: 0.15644\n",
      "Epoch: 9, series: 4, nllk loss: -0.69249, kernel loss: 0.39084\n",
      "Epoch: 9, series: 5, nllk loss: -0.99902, kernel loss: 0.14291\n",
      "Epoch: 9, series: 6, nllk loss: -0.37826, kernel loss: 0.07752\n",
      "Epoch: 9, series: 7, nllk loss: -1.04526, kernel loss: 0.17037\n",
      "Epoch: 9, series: 8, nllk loss: -0.50192, kernel loss: 0.30362\n",
      "Epoch: 9, series: 9, nllk loss: -0.37799, kernel loss: 0.07286\n",
      "Epoch: 9, series: 10, nllk loss: -1.11281, kernel loss: 0.18143\n",
      "Epoch: 9, series: 11, nllk loss: -0.77195, kernel loss: 0.34965\n",
      "Epoch: 9, series: 12, nllk loss: -1.18338, kernel loss: 0.36272\n",
      "Epoch: 9, series: 13, nllk loss: -1.14708, kernel loss: 0.22204\n",
      "Epoch: 9, series: 14, nllk loss: -1.25150, kernel loss: 0.14358\n",
      "Epoch: 9, series: 15, nllk loss: -1.19586, kernel loss: 0.43372\n",
      "Epoch: 9, series: 16, nllk loss: -0.89138, kernel loss: 0.30664\n",
      "Epoch: 9, series: 17, nllk loss: -0.98813, kernel loss: 0.26044\n",
      "Epoch: 9, series: 18, nllk loss: -1.21557, kernel loss: 0.20411\n",
      "Epoch: 9, series: 19, nllk loss: -0.37233, kernel loss: 0.05559\n",
      "Epoch: 9, series: 20, nllk loss: -0.65659, kernel loss: 0.26031\n",
      "Epoch: 9, series: 21, nllk loss: -1.00975, kernel loss: 0.14574\n",
      "Epoch: 9, series: 22, nllk loss: -1.25282, kernel loss: 0.17478\n",
      "Epoch: 9, series: 23, nllk loss: -1.26322, kernel loss: 0.18554\n",
      "Epoch: 9, series: 24, nllk loss: -1.40201, kernel loss: 0.36821\n",
      "Epoch: 9, series: 25, nllk loss: -1.41783, kernel loss: 0.30676\n",
      "Epoch: 9, series: 26, nllk loss: -1.24352, kernel loss: 0.02295\n",
      "Epoch: 9, series: 27, nllk loss: -1.12883, kernel loss: 0.10245\n",
      "Epoch: 9, series: 28, nllk loss: -1.24872, kernel loss: 0.21393\n",
      "Epoch: 9, series: 29, nllk loss: -0.66146, kernel loss: 0.11386\n",
      "Epoch: 9, series: 30, nllk loss: -1.26327, kernel loss: 0.00000\n",
      "Epoch: 9, series: 31, nllk loss: -1.10410, kernel loss: 0.01337\n",
      "Epoch: 9, series: 32, nllk loss: -1.11305, kernel loss: 0.14583\n",
      "Epoch: 9, series: 33, nllk loss: -0.91837, kernel loss: 0.10332\n",
      "Epoch: 9, series: 34, nllk loss: -1.35922, kernel loss: 0.37885\n",
      "Epoch: 9, series: 35, nllk loss: -1.54810, kernel loss: 0.10658\n",
      "Epoch: 9, series: 36, nllk loss: -1.32795, kernel loss: 0.20377\n",
      "Epoch: 9, series: 37, nllk loss: -0.40368, kernel loss: 0.07958\n",
      "Epoch: 9, series: 38, nllk loss: -1.07211, kernel loss: 0.18649\n",
      "Epoch: 9, series: 39, nllk loss: -0.90606, kernel loss: 0.25259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, series: 40, nllk loss: -1.71274, kernel loss: 0.26836\n",
      "Epoch: 9, series: 41, nllk loss: -1.35920, kernel loss: 0.12332\n",
      "Epoch: 9, series: 42, nllk loss: -1.12209, kernel loss: 0.08341\n",
      "Epoch: 9, series: 43, nllk loss: -0.97950, kernel loss: 0.17929\n",
      "Epoch: 9, series: 44, nllk loss: -1.49296, kernel loss: 0.03414\n",
      "Epoch: 9, series: 45, nllk loss: -1.54020, kernel loss: 0.26636\n",
      "Epoch: 9, series: 46, nllk loss: -1.56484, kernel loss: 0.10356\n",
      "Epoch: 9, series: 47, nllk loss: -1.46916, kernel loss: 0.14916\n",
      "Epoch: 9, series: 48, nllk loss: -1.51887, kernel loss: 0.07723\n",
      "Epoch: 9, series: 49, nllk loss: -1.15899, kernel loss: 0.15013\n",
      "Epoch: 9, series: 50, nllk loss: 0.06739, kernel loss: 0.03992\n",
      "Epoch: 9, series: 51, nllk loss: -1.34516, kernel loss: 0.12421\n",
      "Epoch: 9, series: 52, nllk loss: -0.39747, kernel loss: 0.00515\n",
      "Epoch: 9, series: 53, nllk loss: -1.48754, kernel loss: 0.02013\n",
      "Epoch: 9, series: 54, nllk loss: -1.14585, kernel loss: 0.15175\n",
      "Epoch: 9, series: 55, nllk loss: -0.84588, kernel loss: 0.14688\n",
      "Epoch: 9, series: 56, nllk loss: -1.27542, kernel loss: 0.16928\n",
      "Epoch: 9, series: 57, nllk loss: -1.22926, kernel loss: 0.05121\n",
      "Epoch: 9, series: 58, nllk loss: -1.37362, kernel loss: 0.00534\n",
      "Epoch: 9, series: 59, nllk loss: -1.01865, kernel loss: 0.19266\n",
      "Epoch: 9, series: 60, nllk loss: -1.02167, kernel loss: 0.04306\n",
      "Epoch: 9, series: 61, nllk loss: -1.45442, kernel loss: 0.25151\n",
      "Epoch: 9, series: 62, nllk loss: -1.61633, kernel loss: 0.08469\n",
      "Epoch: 9, series: 63, nllk loss: -1.52881, kernel loss: 0.19706\n",
      "Epoch: 9, series: 64, nllk loss: -1.13997, kernel loss: 0.09861\n",
      "Epoch: 9, series: 65, nllk loss: -1.47662, kernel loss: 0.14257\n",
      "Epoch: 9, series: 66, nllk loss: -1.42504, kernel loss: 0.04963\n",
      "Epoch: 9, series: 67, nllk loss: -1.28483, kernel loss: 0.15265\n",
      "Epoch: 9, series: 68, nllk loss: -0.71455, kernel loss: 0.01541\n",
      "Epoch: 9, series: 69, nllk loss: -1.28706, kernel loss: 0.07427\n",
      "Epoch: 9, series: 70, nllk loss: -1.35716, kernel loss: 0.26679\n",
      "Epoch: 9, series: 71, nllk loss: -1.47019, kernel loss: 0.13362\n",
      "Epoch: 9, series: 72, nllk loss: -1.73019, kernel loss: 0.23227\n",
      "Epoch: 9, series: 73, nllk loss: -1.28109, kernel loss: 0.01334\n",
      "Epoch: 9, series: 74, nllk loss: -1.82151, kernel loss: 0.28445\n",
      "Epoch: 9, series: 75, nllk loss: -1.37113, kernel loss: 0.06065\n",
      "Epoch: 9, series: 76, nllk loss: -1.40192, kernel loss: 0.17197\n",
      "Epoch: 9, series: 77, nllk loss: -1.17814, kernel loss: 0.07776\n",
      "Epoch: 9, series: 78, nllk loss: -1.29827, kernel loss: 0.14975\n",
      "Epoch: 9, series: 79, nllk loss: -0.68714, kernel loss: 0.07604\n",
      "Epoch: 9, series: 80, nllk loss: -1.70954, kernel loss: 0.04544\n",
      "Epoch: 9, series: 81, nllk loss: -1.28553, kernel loss: 0.08306\n",
      "Epoch: 9, series: 82, nllk loss: -0.22526, kernel loss: 0.00547\n",
      "Epoch: 9, series: 83, nllk loss: -0.73916, kernel loss: 0.03136\n",
      "Epoch: 9, series: 84, nllk loss: -1.07011, kernel loss: 0.08747\n",
      "Epoch: 9, series: 85, nllk loss: -1.34915, kernel loss: 0.07118\n",
      "Epoch: 9, series: 86, nllk loss: -0.35966, kernel loss: 0.16388\n",
      "Epoch: 9, series: 87, nllk loss: -1.63898, kernel loss: 0.16063\n",
      "Epoch: 9, series: 88, nllk loss: -1.88873, kernel loss: 0.03681\n",
      "Epoch: 9, series: 89, nllk loss: -1.88783, kernel loss: 0.02933\n",
      "Epoch: 9, series: 90, nllk loss: -1.94598, kernel loss: 0.01093\n",
      "Epoch: 9, series: 91, nllk loss: -1.94189, kernel loss: 0.10315\n",
      "Epoch: 9, series: 92, nllk loss: 0.58491, kernel loss: 0.21791\n",
      "Epoch: 9, series: 93, nllk loss: -2.16170, kernel loss: 0.09279\n",
      "Epoch: 9, series: 94, nllk loss: -2.14267, kernel loss: 0.12750\n",
      "Epoch: 9, series: 95, nllk loss: -2.11038, kernel loss: 0.31368\n",
      "Epoch: 9, series: 96, nllk loss: -1.62380, kernel loss: 0.18836\n",
      "Epoch: 9, series: 97, nllk loss: -0.66987, kernel loss: 0.01211\n",
      "Epoch: 9, series: 98, nllk loss: -0.72695, kernel loss: 0.08766\n",
      "Epoch: 9, series: 99, nllk loss: -1.24249, kernel loss: 0.09762\n",
      "Epoch: 9, series: 100, nllk loss: -0.81403, kernel loss: 0.10901\n",
      "Epoch: 9, series: 101, nllk loss: -1.40781, kernel loss: 0.08827\n",
      "Epoch: 9, series: 102, nllk loss: -0.88796, kernel loss: 0.08805\n",
      "Epoch: 9, series: 103, nllk loss: -0.99436, kernel loss: 0.08970\n",
      "Epoch: 9, series: 104, nllk loss: 0.52830, kernel loss: 0.15958\n",
      "Epoch: 9, series: 105, nllk loss: 0.12554, kernel loss: 0.07273\n",
      "Epoch: 9, series: 106, nllk loss: -1.07798, kernel loss: 0.01880\n",
      "Epoch: 9, series: 107, nllk loss: -0.85587, kernel loss: 0.06771\n",
      "Epoch: 9, series: 108, nllk loss: -1.21592, kernel loss: 0.18551\n",
      "Epoch: 9, series: 109, nllk loss: -0.78764, kernel loss: 0.22166\n",
      "Epoch: 9, series: 110, nllk loss: -1.45346, kernel loss: 0.11912\n",
      "Epoch: 9, series: 111, nllk loss: -1.29819, kernel loss: 0.16530\n",
      "Epoch: 9, series: 112, nllk loss: -0.62746, kernel loss: 0.23160\n",
      "Epoch: 9, series: 113, nllk loss: -1.00945, kernel loss: 0.25689\n",
      "Epoch: 9, series: 114, nllk loss: -0.81518, kernel loss: 0.13841\n",
      "Epoch: 9, series: 115, nllk loss: -0.91468, kernel loss: 0.21435\n",
      "Epoch: 9, series: 116, nllk loss: -1.59988, kernel loss: 0.23186\n",
      "Epoch: 9, series: 117, nllk loss: -0.60252, kernel loss: 0.11168\n",
      "Epoch: 9, series: 118, nllk loss: -1.65833, kernel loss: 0.07176\n",
      "Epoch: 9, series: 119, nllk loss: -0.68594, kernel loss: 0.12531\n",
      "Epoch: 9, series: 120, nllk loss: -1.45738, kernel loss: 0.02432\n",
      "Epoch: 9, series: 121, nllk loss: 0.19014, kernel loss: 0.09882\n",
      "Epoch: 9, series: 122, nllk loss: -0.40590, kernel loss: 0.09002\n",
      "Epoch: 9, series: 123, nllk loss: -1.43103, kernel loss: 0.18944\n",
      "Epoch: 9, series: 124, nllk loss: -1.55494, kernel loss: 0.20504\n",
      "Epoch: 9, series: 125, nllk loss: -1.37672, kernel loss: 0.06309\n",
      "Epoch: 9, series: 126, nllk loss: -1.55236, kernel loss: 0.09105\n",
      "Epoch: 9, series: 127, nllk loss: -1.39224, kernel loss: 0.14918\n",
      "Epoch: 9, series: 128, nllk loss: -0.94922, kernel loss: 0.12248\n",
      "Epoch: 9, series: 129, nllk loss: -0.68245, kernel loss: 0.09892\n",
      "Epoch: 9, series: 130, nllk loss: -1.21754, kernel loss: 0.20182\n",
      "Epoch: 9, series: 131, nllk loss: 0.66234, kernel loss: 0.27080\n",
      "Epoch: 9, series: 132, nllk loss: 0.11179, kernel loss: 0.02890\n",
      "Epoch: 9, series: 133, nllk loss: -0.90149, kernel loss: 0.13767\n",
      "Epoch: 9, series: 134, nllk loss: -0.67990, kernel loss: 0.22786\n",
      "Epoch: 9, series: 135, nllk loss: -1.32852, kernel loss: 0.17943\n",
      "Epoch: 9, series: 136, nllk loss: -1.38785, kernel loss: 0.12483\n",
      "Epoch: 9, series: 137, nllk loss: -1.59712, kernel loss: 0.24268\n",
      "Epoch: 9, series: 138, nllk loss: -1.62329, kernel loss: 0.15031\n",
      "Epoch: 9, series: 139, nllk loss: -1.52226, kernel loss: 0.21040\n",
      "Epoch: 9, series: 140, nllk loss: -1.33429, kernel loss: 0.08777\n",
      "Epoch: 9, series: 141, nllk loss: -1.56068, kernel loss: 0.21867\n",
      "Epoch: 9, series: 142, nllk loss: -1.47154, kernel loss: 0.12259\n",
      "Epoch: 9, series: 143, nllk loss: -1.58006, kernel loss: 0.16299\n",
      "Epoch: 9, series: 144, nllk loss: -1.76323, kernel loss: 0.10803\n",
      "Epoch: 9, series: 145, nllk loss: -1.70022, kernel loss: 0.01519\n",
      "Epoch: 9, series: 146, nllk loss: 3.18422, kernel loss: 0.36936\n",
      "Epoch: 9, series: 147, nllk loss: -1.56502, kernel loss: 0.03612\n",
      "Epoch: 9, series: 148, nllk loss: -1.40204, kernel loss: 0.03673\n",
      "Epoch: 9, series: 149, nllk loss: -1.55001, kernel loss: 0.07453\n",
      "Epoch: 9, series: 150, nllk loss: -1.67329, kernel loss: 0.07068\n",
      "Epoch: 9, series: 151, nllk loss: -1.76684, kernel loss: 0.03421\n",
      "Epoch: 9, series: 152, nllk loss: -1.72588, kernel loss: 0.20671\n",
      "Epoch: 9, series: 153, nllk loss: -1.53358, kernel loss: 0.16699\n",
      "Epoch: 9, series: 154, nllk loss: -1.55229, kernel loss: 0.11628\n",
      "Epoch: 9, series: 155, nllk loss: -1.57933, kernel loss: 0.17382\n",
      "Epoch: 9, series: 156, nllk loss: -1.67563, kernel loss: 0.14195\n",
      "Epoch: 9, series: 157, nllk loss: -1.28015, kernel loss: 0.08844\n",
      "Epoch: 9, series: 158, nllk loss: -1.66989, kernel loss: 0.14835\n",
      "Epoch: 9, series: 159, nllk loss: -1.76602, kernel loss: 0.08495\n",
      "Epoch: 9, series: 160, nllk loss: -1.63890, kernel loss: 0.16902\n",
      "Epoch: 9, series: 161, nllk loss: -1.61238, kernel loss: 0.08318\n",
      "Epoch: 9, series: 162, nllk loss: -1.71387, kernel loss: 0.07727\n",
      "Epoch: 9, series: 163, nllk loss: -2.02616, kernel loss: 0.02344\n",
      "Epoch: 9, series: 164, nllk loss: -1.68914, kernel loss: 0.19030\n",
      "Epoch: 9, series: 165, nllk loss: -1.77708, kernel loss: 0.11367\n",
      "Epoch: 9, series: 166, nllk loss: -1.35113, kernel loss: 0.09594\n",
      "Epoch: 9, series: 167, nllk loss: -2.18338, kernel loss: 0.23567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, series: 168, nllk loss: -2.03534, kernel loss: 0.02191\n",
      "Epoch: 9, series: 169, nllk loss: -2.09541, kernel loss: 0.04713\n",
      "Epoch: 9, series: 170, nllk loss: -1.69788, kernel loss: 0.09935\n",
      "Epoch: 9, series: 171, nllk loss: -2.12595, kernel loss: 0.19595\n",
      "Epoch: 9, series: 172, nllk loss: -1.90387, kernel loss: 0.12574\n",
      "Epoch: 9, series: 173, nllk loss: -2.29148, kernel loss: 0.16826\n",
      "Epoch: 9, series: 174, nllk loss: -1.92285, kernel loss: 0.08879\n",
      "Epoch: 9, series: 175, nllk loss: -2.19799, kernel loss: 0.25590\n",
      "Epoch: 9, series: 176, nllk loss: -2.08390, kernel loss: 0.05230\n",
      "Epoch: 9, series: 177, nllk loss: -1.83669, kernel loss: 0.21750\n",
      "Epoch: 9, series: 178, nllk loss: -1.69169, kernel loss: 0.12280\n",
      "Epoch: 9, series: 179, nllk loss: -2.05138, kernel loss: 0.08034\n",
      "Epoch: 9, series: 180, nllk loss: -2.05699, kernel loss: 0.02490\n",
      "Epoch: 9, series: 181, nllk loss: -2.31619, kernel loss: 0.10022\n",
      "Epoch: 9, series: 182, nllk loss: -2.07220, kernel loss: 0.19919\n",
      "Epoch: 9, series: 183, nllk loss: -1.89683, kernel loss: 0.23344\n",
      "Epoch: 9, series: 184, nllk loss: -1.78944, kernel loss: 0.11196\n",
      "Epoch: 9, series: 185, nllk loss: -1.52782, kernel loss: 0.11482\n",
      "Epoch: 9, series: 186, nllk loss: -2.33506, kernel loss: 0.24833\n",
      "Epoch: 9, series: 187, nllk loss: -2.36827, kernel loss: 0.24523\n",
      "Epoch: 9, series: 188, nllk loss: -1.57546, kernel loss: 0.15230\n",
      "Epoch: 9, series: 189, nllk loss: -1.62914, kernel loss: 0.17161\n",
      "Epoch: 9, series: 190, nllk loss: -1.80500, kernel loss: 0.11787\n",
      "Epoch: 9, series: 191, nllk loss: -1.81312, kernel loss: 0.03021\n",
      "Epoch: 9, series: 192, nllk loss: -1.97751, kernel loss: 0.10941\n",
      "Epoch: 9, series: 193, nllk loss: -1.33868, kernel loss: 0.25621\n",
      "Epoch: 9, series: 194, nllk loss: -1.38690, kernel loss: 0.34784\n",
      "Epoch: 9, series: 195, nllk loss: -2.21202, kernel loss: 0.21002\n",
      "Epoch: 9, series: 196, nllk loss: -1.82011, kernel loss: 0.09700\n",
      "Epoch: 9, series: 197, nllk loss: -1.93118, kernel loss: 0.22793\n",
      "Epoch: 9, series: 198, nllk loss: -1.95945, kernel loss: 0.05937\n",
      "Epoch: 9, series: 199, nllk loss: -1.89197, kernel loss: 0.12154\n",
      "Epoch: 9, series: 200, nllk loss: -2.03425, kernel loss: 0.07753\n",
      "Epoch: 9, series: 201, nllk loss: -2.18130, kernel loss: 0.35418\n",
      "Epoch: 9, series: 202, nllk loss: -1.83982, kernel loss: 0.16004\n",
      "Epoch: 9, series: 203, nllk loss: -1.92502, kernel loss: 0.19110\n",
      "Epoch: 9, series: 204, nllk loss: -1.00549, kernel loss: 0.02620\n",
      "Epoch: 9, series: 205, nllk loss: -1.84243, kernel loss: 0.09308\n",
      "Epoch: 9, series: 206, nllk loss: -1.80121, kernel loss: 0.20993\n",
      "Epoch: 9, series: 207, nllk loss: -0.91889, kernel loss: 0.17431\n",
      "Epoch: 9, series: 208, nllk loss: -2.29852, kernel loss: 0.00804\n",
      "Epoch: 9, series: 209, nllk loss: -1.54058, kernel loss: 0.15455\n",
      "Epoch: 9, series: 210, nllk loss: -2.37527, kernel loss: 0.07492\n",
      "Epoch: 9, series: 211, nllk loss: -2.04031, kernel loss: 0.13668\n",
      "Epoch: 9, series: 212, nllk loss: -1.59129, kernel loss: 0.09964\n",
      "Epoch: 9, series: 213, nllk loss: -1.94665, kernel loss: 0.23241\n",
      "Epoch: 9, series: 214, nllk loss: -1.93668, kernel loss: 0.18728\n",
      "Epoch: 9, series: 215, nllk loss: -2.28553, kernel loss: 0.18771\n",
      "Epoch: 9, series: 216, nllk loss: -1.27311, kernel loss: 0.17202\n",
      "Epoch: 9, series: 217, nllk loss: -1.88018, kernel loss: 0.23366\n",
      "Epoch: 9, series: 218, nllk loss: -1.35407, kernel loss: 0.01491\n",
      "Epoch: 9, series: 219, nllk loss: -1.85948, kernel loss: 0.31148\n",
      "Epoch: 9, series: 220, nllk loss: -2.01749, kernel loss: 0.15222\n",
      "Epoch: 9, series: 221, nllk loss: -2.18050, kernel loss: 0.06435\n",
      "Epoch: 9, series: 222, nllk loss: -2.08896, kernel loss: 0.09279\n",
      "Epoch: 9, series: 223, nllk loss: -1.55271, kernel loss: 0.11499\n",
      "Epoch: 9, series: 224, nllk loss: -2.16861, kernel loss: 0.02225\n",
      "Epoch: 9, series: 225, nllk loss: -2.11868, kernel loss: 0.13528\n",
      "Epoch: 9, series: 226, nllk loss: -1.75964, kernel loss: 0.15279\n",
      "Epoch: 9, series: 227, nllk loss: -1.84605, kernel loss: 0.14366\n",
      "Epoch: 9, series: 228, nllk loss: -2.02095, kernel loss: 0.24359\n",
      "Epoch: 9, series: 229, nllk loss: -1.89614, kernel loss: 0.19412\n",
      "Epoch: 9, series: 230, nllk loss: -2.23170, kernel loss: 0.16247\n",
      "Epoch: 9, series: 231, nllk loss: -1.76147, kernel loss: 0.14794\n",
      "Epoch: 9, series: 232, nllk loss: -2.42705, kernel loss: 0.12853\n",
      "Epoch: 9, series: 233, nllk loss: -2.33002, kernel loss: 0.04735\n",
      "Epoch: 9, series: 234, nllk loss: -2.06273, kernel loss: 0.29807\n",
      "Epoch: 9, series: 235, nllk loss: -2.53993, kernel loss: 0.11530\n",
      "Epoch: 9, series: 236, nllk loss: -1.55814, kernel loss: 0.18623\n",
      "Epoch: 9, series: 237, nllk loss: -2.00428, kernel loss: 0.42032\n",
      "Epoch: 9, series: 238, nllk loss: -1.63535, kernel loss: 0.13250\n",
      "Epoch: 9, series: 239, nllk loss: -2.14132, kernel loss: 0.02706\n",
      "Epoch: 9, series: 240, nllk loss: -1.08438, kernel loss: 0.17954\n",
      "Epoch: 9, series: 241, nllk loss: -1.84151, kernel loss: 0.19476\n",
      "Epoch: 9, series: 242, nllk loss: -1.92880, kernel loss: 0.21333\n",
      "Epoch: 9, series: 243, nllk loss: -2.11831, kernel loss: 0.08088\n",
      "Epoch: 9, series: 244, nllk loss: -1.79670, kernel loss: 0.13589\n",
      "Epoch: 9, series: 245, nllk loss: -2.10969, kernel loss: 0.27416\n",
      "Epoch: 9, series: 246, nllk loss: 0.32400, kernel loss: 0.06685\n",
      "Epoch: 9, series: 247, nllk loss: -1.71039, kernel loss: 0.12616\n",
      "Epoch: 9, series: 248, nllk loss: -1.94791, kernel loss: 0.04445\n",
      "Epoch: 9, series: 249, nllk loss: -1.84461, kernel loss: 0.02372\n",
      "Epoch: 9, series: 250, nllk loss: -1.76356, kernel loss: 0.22132\n",
      "Epoch: 9, series: 251, nllk loss: -1.10529, kernel loss: 0.13083\n",
      "Epoch: 9, series: 252, nllk loss: -1.03882, kernel loss: 0.17199\n",
      "Epoch: 9, series: 253, nllk loss: -1.72880, kernel loss: 0.20230\n",
      "Epoch: 9, series: 254, nllk loss: -2.18462, kernel loss: 0.09710\n",
      "Epoch: 9, series: 255, nllk loss: -2.04901, kernel loss: 0.05994\n",
      "Epoch: 9, series: 256, nllk loss: -1.89935, kernel loss: 0.09888\n",
      "Epoch: 9, series: 257, nllk loss: -1.96755, kernel loss: 0.27759\n",
      "Epoch: 9, series: 258, nllk loss: -1.89323, kernel loss: 0.13350\n",
      "Epoch: 9, series: 259, nllk loss: -1.67418, kernel loss: 0.28698\n",
      "Epoch: 9, series: 260, nllk loss: -1.90120, kernel loss: 0.12334\n",
      "Epoch: 9, series: 261, nllk loss: -2.09386, kernel loss: 0.30259\n",
      "Epoch: 9, series: 262, nllk loss: -2.37174, kernel loss: 0.09128\n",
      "Epoch: 9, series: 263, nllk loss: -0.69806, kernel loss: 0.22736\n",
      "Epoch: 9, series: 264, nllk loss: -1.95013, kernel loss: 0.11292\n",
      "Epoch: 9, series: 265, nllk loss: -1.82303, kernel loss: 0.15715\n",
      "Epoch: 9, series: 266, nllk loss: -2.14828, kernel loss: 0.08680\n",
      "Epoch: 9, series: 267, nllk loss: -2.03117, kernel loss: 0.30906\n",
      "Epoch: 9, series: 268, nllk loss: -2.20220, kernel loss: 0.23175\n",
      "Epoch: 9, series: 269, nllk loss: -1.85367, kernel loss: 0.10096\n",
      "Epoch: 9, series: 270, nllk loss: -1.71260, kernel loss: 0.16892\n",
      "Epoch: 9, series: 271, nllk loss: -1.83587, kernel loss: 0.20642\n",
      "Epoch: 9, series: 272, nllk loss: -1.95907, kernel loss: 0.10152\n",
      "Epoch: 9, series: 273, nllk loss: -1.92359, kernel loss: 0.45493\n",
      "Epoch: 9, series: 274, nllk loss: -1.24211, kernel loss: 0.10889\n",
      "Epoch: 9, series: 275, nllk loss: -1.85282, kernel loss: 0.10280\n",
      "Epoch: 9, series: 276, nllk loss: -1.22422, kernel loss: 0.11179\n",
      "Epoch: 9, series: 277, nllk loss: -2.05085, kernel loss: 0.31022\n",
      "Epoch: 9, series: 278, nllk loss: -1.81412, kernel loss: 0.23995\n",
      "Epoch: 9, series: 279, nllk loss: -2.21583, kernel loss: 0.05173\n",
      "Epoch: 9, series: 280, nllk loss: -2.01792, kernel loss: 0.20993\n",
      "Epoch: 9, series: 281, nllk loss: -2.17355, kernel loss: 0.22041\n",
      "Epoch: 9, series: 282, nllk loss: -2.05750, kernel loss: 0.15593\n",
      "Epoch: 9, series: 283, nllk loss: -1.93232, kernel loss: 0.22472\n",
      "Epoch: 9, series: 284, nllk loss: -1.58786, kernel loss: 0.08017\n",
      "Epoch: 9, series: 285, nllk loss: -1.83216, kernel loss: 0.21884\n",
      "Epoch: 9, series: 286, nllk loss: -2.04286, kernel loss: 0.04727\n",
      "Epoch: 9, series: 287, nllk loss: -2.27022, kernel loss: 0.13840\n",
      "Epoch: 9, series: 288, nllk loss: -1.26660, kernel loss: 0.11592\n",
      "Epoch: 9, series: 289, nllk loss: -0.89513, kernel loss: 0.18890\n",
      "Epoch: 9, series: 290, nllk loss: -2.26107, kernel loss: 0.06157\n",
      "Epoch: 9, series: 291, nllk loss: -2.21228, kernel loss: 0.16695\n",
      "Epoch: 9, series: 292, nllk loss: -2.24602, kernel loss: 0.21168\n",
      "Epoch: 9, series: 293, nllk loss: -2.41200, kernel loss: 0.10614\n",
      "Epoch: 9, series: 294, nllk loss: -1.60421, kernel loss: 0.06676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9, series: 295, nllk loss: -1.18004, kernel loss: 0.33109\n",
      "Epoch: 9, series: 296, nllk loss: -2.24149, kernel loss: 0.10875\n",
      "Epoch: 9, series: 297, nllk loss: -2.33132, kernel loss: 0.38390\n",
      "Epoch: 9, series: 298, nllk loss: 2.26231, kernel loss: 0.10116\n",
      "Epoch: 9, series: 299, nllk loss: 0.50356, kernel loss: 0.10845\n",
      "Epoch: 9, series: 300, nllk loss: -1.96278, kernel loss: 0.22847\n",
      "Epoch: 9, series: 301, nllk loss: -1.87371, kernel loss: 0.06443\n",
      "Epoch: 9, series: 302, nllk loss: -2.12970, kernel loss: 0.18384\n",
      "Epoch: 9, series: 303, nllk loss: -1.78337, kernel loss: 0.15193\n",
      "Epoch: 9, series: 304, nllk loss: -0.26671, kernel loss: 0.25720\n",
      "Epoch: 9, series: 305, nllk loss: -1.56432, kernel loss: 0.11948\n",
      "Epoch: 9, series: 306, nllk loss: -2.14851, kernel loss: 0.25236\n",
      "Epoch: 9, series: 307, nllk loss: -1.46595, kernel loss: 0.04270\n",
      "Epoch: 9, series: 308, nllk loss: -2.07763, kernel loss: 0.20853\n",
      "Epoch: 9, series: 309, nllk loss: -1.84413, kernel loss: 0.21151\n",
      "Epoch: 9, series: 310, nllk loss: -1.83440, kernel loss: 0.02935\n",
      "Epoch: 9, series: 311, nllk loss: -1.71027, kernel loss: 0.31319\n",
      "Epoch: 9, series: 312, nllk loss: -2.00369, kernel loss: 0.06689\n",
      "Epoch: 9, series: 313, nllk loss: -2.10561, kernel loss: 0.12213\n",
      "Epoch: 9, series: 314, nllk loss: -2.36319, kernel loss: 0.18182\n",
      "Epoch: 9, series: 315, nllk loss: -0.89325, kernel loss: 0.17696\n",
      "Epoch: 9, series: 316, nllk loss: -1.82175, kernel loss: 0.03498\n",
      "Epoch: 9, series: 317, nllk loss: 0.87263, kernel loss: 0.21954\n",
      "Epoch: 9, series: 318, nllk loss: 2.12379, kernel loss: 0.25125\n",
      "Epoch: 9, series: 319, nllk loss: -0.75339, kernel loss: 0.15328\n",
      "Epoch: 9, series: 320, nllk loss: -0.85014, kernel loss: 0.11865\n",
      "Epoch: 9, total loss: -411.23441\n",
      "Epoch: 10, series: 0, nllk loss: 2.78794, kernel loss: 0.08105\n",
      "Epoch: 10, series: 1, nllk loss: -0.90150, kernel loss: 0.36362\n",
      "Epoch: 10, series: 2, nllk loss: 0.38809, kernel loss: 0.18110\n",
      "Epoch: 10, series: 3, nllk loss: -1.05676, kernel loss: 0.23254\n",
      "Epoch: 10, series: 4, nllk loss: -0.78144, kernel loss: 0.16985\n",
      "Epoch: 10, series: 5, nllk loss: -1.06191, kernel loss: 0.42360\n",
      "Epoch: 10, series: 6, nllk loss: -0.51092, kernel loss: 0.12902\n",
      "Epoch: 10, series: 7, nllk loss: -1.11408, kernel loss: 0.39974\n",
      "Epoch: 10, series: 8, nllk loss: -0.56475, kernel loss: 0.32947\n",
      "Epoch: 10, series: 9, nllk loss: -0.36765, kernel loss: 0.15243\n",
      "Epoch: 10, series: 10, nllk loss: -1.14069, kernel loss: 0.10534\n",
      "Epoch: 10, series: 11, nllk loss: -0.87487, kernel loss: 0.03468\n",
      "Epoch: 10, series: 12, nllk loss: -1.25481, kernel loss: 0.34460\n",
      "Epoch: 10, series: 13, nllk loss: -1.16910, kernel loss: 0.16766\n",
      "Epoch: 10, series: 14, nllk loss: -1.24245, kernel loss: 0.52709\n",
      "Epoch: 10, series: 15, nllk loss: -1.20001, kernel loss: 0.03023\n",
      "Epoch: 10, series: 16, nllk loss: -0.97894, kernel loss: 0.37656\n",
      "Epoch: 10, series: 17, nllk loss: -1.01895, kernel loss: 0.17980\n",
      "Epoch: 10, series: 18, nllk loss: -1.07801, kernel loss: 0.30348\n",
      "Epoch: 10, series: 19, nllk loss: -0.42756, kernel loss: 0.14825\n",
      "Epoch: 10, series: 20, nllk loss: -0.73408, kernel loss: 0.11405\n",
      "Epoch: 10, series: 21, nllk loss: -1.01268, kernel loss: 0.18049\n",
      "Epoch: 10, series: 22, nllk loss: -1.22217, kernel loss: 0.03070\n",
      "Epoch: 10, series: 23, nllk loss: -1.17546, kernel loss: 0.14261\n",
      "Epoch: 10, series: 24, nllk loss: -1.29366, kernel loss: 0.28891\n",
      "Epoch: 10, series: 25, nllk loss: -1.44195, kernel loss: 0.02757\n",
      "Epoch: 10, series: 26, nllk loss: -1.18552, kernel loss: 0.28404\n",
      "Epoch: 10, series: 27, nllk loss: -1.13126, kernel loss: 0.19894\n",
      "Epoch: 10, series: 28, nllk loss: -1.21303, kernel loss: 0.10238\n",
      "Epoch: 10, series: 29, nllk loss: -0.67935, kernel loss: 0.11763\n",
      "Epoch: 10, series: 30, nllk loss: -1.19492, kernel loss: 0.05135\n",
      "Epoch: 10, series: 31, nllk loss: -1.08746, kernel loss: 0.06867\n",
      "Epoch: 10, series: 32, nllk loss: -0.94966, kernel loss: 0.09511\n",
      "Epoch: 10, series: 33, nllk loss: -0.95573, kernel loss: 0.05957\n",
      "Epoch: 10, series: 34, nllk loss: -1.30703, kernel loss: 0.12451\n",
      "Epoch: 10, series: 35, nllk loss: -1.48291, kernel loss: 0.12521\n",
      "Epoch: 10, series: 36, nllk loss: -1.35515, kernel loss: 0.22631\n",
      "Epoch: 10, series: 37, nllk loss: -0.34786, kernel loss: 0.11983\n",
      "Epoch: 10, series: 38, nllk loss: -1.04708, kernel loss: 0.10840\n",
      "Epoch: 10, series: 39, nllk loss: -0.84806, kernel loss: 0.14907\n",
      "Epoch: 10, series: 40, nllk loss: -1.71480, kernel loss: 0.32104\n",
      "Epoch: 10, series: 41, nllk loss: -1.30244, kernel loss: 0.02815\n",
      "Epoch: 10, series: 42, nllk loss: -1.07556, kernel loss: 0.24917\n",
      "Epoch: 10, series: 43, nllk loss: -0.95652, kernel loss: 0.10072\n",
      "Epoch: 10, series: 44, nllk loss: -1.39428, kernel loss: 0.17582\n",
      "Epoch: 10, series: 45, nllk loss: -1.52865, kernel loss: 0.08126\n",
      "Epoch: 10, series: 46, nllk loss: -1.55583, kernel loss: 0.04053\n",
      "Epoch: 10, series: 47, nllk loss: -1.45566, kernel loss: 0.16667\n",
      "Epoch: 10, series: 48, nllk loss: -1.52401, kernel loss: 0.05877\n",
      "Epoch: 10, series: 49, nllk loss: -1.21218, kernel loss: 0.04789\n",
      "Epoch: 10, series: 50, nllk loss: 0.00852, kernel loss: 0.16930\n",
      "Epoch: 10, series: 51, nllk loss: -1.35678, kernel loss: 0.17506\n",
      "Epoch: 10, series: 52, nllk loss: -0.37222, kernel loss: 0.18665\n",
      "Epoch: 10, series: 53, nllk loss: -1.60083, kernel loss: 0.15911\n",
      "Epoch: 10, series: 54, nllk loss: -1.26391, kernel loss: 0.07697\n",
      "Epoch: 10, series: 55, nllk loss: -0.84159, kernel loss: 0.29819\n",
      "Epoch: 10, series: 56, nllk loss: -1.27938, kernel loss: 0.14174\n",
      "Epoch: 10, series: 57, nllk loss: -1.21650, kernel loss: 0.03042\n",
      "Epoch: 10, series: 58, nllk loss: -1.33696, kernel loss: 0.10903\n",
      "Epoch: 10, series: 59, nllk loss: -1.14261, kernel loss: 0.06604\n",
      "Epoch: 10, series: 60, nllk loss: -1.03147, kernel loss: 0.25336\n",
      "Epoch: 10, series: 61, nllk loss: -1.57884, kernel loss: 0.02296\n",
      "Epoch: 10, series: 62, nllk loss: -1.60530, kernel loss: 0.06832\n",
      "Epoch: 10, series: 63, nllk loss: -1.49163, kernel loss: 0.20849\n",
      "Epoch: 10, series: 64, nllk loss: -1.12811, kernel loss: 0.05791\n",
      "Epoch: 10, series: 65, nllk loss: -1.50793, kernel loss: 0.21029\n",
      "Epoch: 10, series: 66, nllk loss: -1.44168, kernel loss: 0.15141\n",
      "Epoch: 10, series: 67, nllk loss: -1.32741, kernel loss: 0.08428\n",
      "Epoch: 10, series: 68, nllk loss: -0.72809, kernel loss: 0.09556\n",
      "Epoch: 10, series: 69, nllk loss: -1.27598, kernel loss: 0.17599\n",
      "Epoch: 10, series: 70, nllk loss: -1.35779, kernel loss: 0.03471\n",
      "Epoch: 10, series: 71, nllk loss: -1.36603, kernel loss: 0.19997\n",
      "Epoch: 10, series: 72, nllk loss: -1.73567, kernel loss: 0.07601\n",
      "Epoch: 10, series: 73, nllk loss: -1.33822, kernel loss: 0.19577\n",
      "Epoch: 10, series: 74, nllk loss: -1.78356, kernel loss: 0.03397\n",
      "Epoch: 10, series: 75, nllk loss: -1.36655, kernel loss: 0.12983\n",
      "Epoch: 10, series: 76, nllk loss: -1.29612, kernel loss: 0.05650\n",
      "Epoch: 10, series: 77, nllk loss: -1.20447, kernel loss: 0.01609\n",
      "Epoch: 10, series: 78, nllk loss: -1.37417, kernel loss: 0.08445\n",
      "Epoch: 10, series: 79, nllk loss: -0.74229, kernel loss: 0.06589\n",
      "Epoch: 10, series: 80, nllk loss: -1.67994, kernel loss: 0.10822\n",
      "Epoch: 10, series: 81, nllk loss: -1.21722, kernel loss: 0.02011\n",
      "Epoch: 10, series: 82, nllk loss: -0.35446, kernel loss: 0.32369\n",
      "Epoch: 10, series: 83, nllk loss: -0.78622, kernel loss: 0.11391\n",
      "Epoch: 10, series: 84, nllk loss: -1.14288, kernel loss: 0.03506\n",
      "Epoch: 10, series: 85, nllk loss: -1.33789, kernel loss: 0.03930\n",
      "Epoch: 10, series: 86, nllk loss: -0.42775, kernel loss: 0.08777\n",
      "Epoch: 10, series: 87, nllk loss: -1.66777, kernel loss: 0.06544\n",
      "Epoch: 10, series: 88, nllk loss: -1.99083, kernel loss: 0.05835\n",
      "Epoch: 10, series: 89, nllk loss: -1.93210, kernel loss: 0.14228\n",
      "Epoch: 10, series: 90, nllk loss: -2.01853, kernel loss: 0.12487\n",
      "Epoch: 10, series: 91, nllk loss: -1.97438, kernel loss: 0.08612\n",
      "Epoch: 10, series: 92, nllk loss: 0.50044, kernel loss: 0.24766\n",
      "Epoch: 10, series: 93, nllk loss: -2.18570, kernel loss: 0.10186\n",
      "Epoch: 10, series: 94, nllk loss: -2.14154, kernel loss: 0.05661\n",
      "Epoch: 10, series: 95, nllk loss: -2.10827, kernel loss: 0.10285\n",
      "Epoch: 10, series: 96, nllk loss: -1.60818, kernel loss: 0.11201\n",
      "Epoch: 10, series: 97, nllk loss: -0.75375, kernel loss: 0.08661\n",
      "Epoch: 10, series: 98, nllk loss: -0.67888, kernel loss: 0.07737\n",
      "Epoch: 10, series: 99, nllk loss: -1.30322, kernel loss: 0.06728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, series: 100, nllk loss: -0.80761, kernel loss: 0.23343\n",
      "Epoch: 10, series: 101, nllk loss: -1.45193, kernel loss: 0.03937\n",
      "Epoch: 10, series: 102, nllk loss: -0.84074, kernel loss: 0.13657\n",
      "Epoch: 10, series: 103, nllk loss: -0.98857, kernel loss: 0.16185\n",
      "Epoch: 10, series: 104, nllk loss: 0.44374, kernel loss: 0.09684\n",
      "Epoch: 10, series: 105, nllk loss: 0.12919, kernel loss: 0.19382\n",
      "Epoch: 10, series: 106, nllk loss: -1.06419, kernel loss: 0.01204\n",
      "Epoch: 10, series: 107, nllk loss: -0.91863, kernel loss: 0.10704\n",
      "Epoch: 10, series: 108, nllk loss: -1.23624, kernel loss: 0.17829\n",
      "Epoch: 10, series: 109, nllk loss: -0.67669, kernel loss: 0.18746\n",
      "Epoch: 10, series: 110, nllk loss: -1.41896, kernel loss: 0.18673\n",
      "Epoch: 10, series: 111, nllk loss: -1.33944, kernel loss: 0.22218\n",
      "Epoch: 10, series: 112, nllk loss: -0.70863, kernel loss: 0.16515\n",
      "Epoch: 10, series: 113, nllk loss: -1.06162, kernel loss: 0.24668\n",
      "Epoch: 10, series: 114, nllk loss: -0.82311, kernel loss: 0.18439\n",
      "Epoch: 10, series: 115, nllk loss: -0.99988, kernel loss: 0.08704\n",
      "Epoch: 10, series: 116, nllk loss: -1.59737, kernel loss: 0.08896\n",
      "Epoch: 10, series: 117, nllk loss: -0.54485, kernel loss: 0.07821\n",
      "Epoch: 10, series: 118, nllk loss: -1.64960, kernel loss: 0.07670\n",
      "Epoch: 10, series: 119, nllk loss: -0.74917, kernel loss: 0.11462\n",
      "Epoch: 10, series: 120, nllk loss: -1.45901, kernel loss: 0.11096\n",
      "Epoch: 10, series: 121, nllk loss: 0.16103, kernel loss: 0.10481\n",
      "Epoch: 10, series: 122, nllk loss: -0.43319, kernel loss: 0.17507\n",
      "Epoch: 10, series: 123, nllk loss: -1.55612, kernel loss: 0.15600\n",
      "Epoch: 10, series: 124, nllk loss: -1.59847, kernel loss: 0.13406\n",
      "Epoch: 10, series: 125, nllk loss: -1.37374, kernel loss: 0.11658\n",
      "Epoch: 10, series: 126, nllk loss: -1.56738, kernel loss: 0.43048\n",
      "Epoch: 10, series: 127, nllk loss: -1.42088, kernel loss: 0.13466\n",
      "Epoch: 10, series: 128, nllk loss: -0.91677, kernel loss: 0.14968\n",
      "Epoch: 10, series: 129, nllk loss: -0.60995, kernel loss: 0.05210\n",
      "Epoch: 10, series: 130, nllk loss: -1.17294, kernel loss: 0.02391\n",
      "Epoch: 10, series: 131, nllk loss: 0.62619, kernel loss: 0.05505\n",
      "Epoch: 10, series: 132, nllk loss: 0.06676, kernel loss: 0.06655\n",
      "Epoch: 10, series: 133, nllk loss: -0.84714, kernel loss: 0.17187\n",
      "Epoch: 10, series: 134, nllk loss: -0.61073, kernel loss: 0.15780\n",
      "Epoch: 10, series: 135, nllk loss: -1.27965, kernel loss: 0.03751\n",
      "Epoch: 10, series: 136, nllk loss: -1.28147, kernel loss: 0.10891\n",
      "Epoch: 10, series: 137, nllk loss: -1.41683, kernel loss: 0.11344\n",
      "Epoch: 10, series: 138, nllk loss: -1.50508, kernel loss: 0.12370\n",
      "Epoch: 10, series: 139, nllk loss: -1.44839, kernel loss: 0.19195\n",
      "Epoch: 10, series: 140, nllk loss: -1.37248, kernel loss: 0.20192\n",
      "Epoch: 10, series: 141, nllk loss: -1.48246, kernel loss: 0.05909\n",
      "Epoch: 10, series: 142, nllk loss: -1.44662, kernel loss: 0.09506\n",
      "Epoch: 10, series: 143, nllk loss: -1.52137, kernel loss: 0.14542\n",
      "Epoch: 10, series: 144, nllk loss: -1.72598, kernel loss: 0.19206\n",
      "Epoch: 10, series: 145, nllk loss: -1.68464, kernel loss: 0.25220\n",
      "Epoch: 10, series: 146, nllk loss: 3.24756, kernel loss: 0.20321\n",
      "Epoch: 10, series: 147, nllk loss: -1.44742, kernel loss: 0.03429\n",
      "Epoch: 10, series: 148, nllk loss: -1.49930, kernel loss: 0.33769\n",
      "Epoch: 10, series: 149, nllk loss: -1.59136, kernel loss: 0.25743\n",
      "Epoch: 10, series: 150, nllk loss: -1.69124, kernel loss: 0.12309\n",
      "Epoch: 10, series: 151, nllk loss: -1.73897, kernel loss: 0.21388\n",
      "Epoch: 10, series: 152, nllk loss: -1.69470, kernel loss: 0.09245\n",
      "Epoch: 10, series: 153, nllk loss: -1.52385, kernel loss: 0.26362\n",
      "Epoch: 10, series: 154, nllk loss: -1.56042, kernel loss: 0.09425\n",
      "Epoch: 10, series: 155, nllk loss: -1.66151, kernel loss: 0.13148\n",
      "Epoch: 10, series: 156, nllk loss: -1.75058, kernel loss: 0.04571\n",
      "Epoch: 10, series: 157, nllk loss: -1.29105, kernel loss: 0.15905\n",
      "Epoch: 10, series: 158, nllk loss: -1.78200, kernel loss: 0.11270\n",
      "Epoch: 10, series: 159, nllk loss: -1.80321, kernel loss: 0.09649\n",
      "Epoch: 10, series: 160, nllk loss: -1.70311, kernel loss: 0.22917\n",
      "Epoch: 10, series: 161, nllk loss: -1.58914, kernel loss: 0.12806\n",
      "Epoch: 10, series: 162, nllk loss: -1.85804, kernel loss: 0.19223\n",
      "Epoch: 10, series: 163, nllk loss: -2.09502, kernel loss: 0.15139\n",
      "Epoch: 10, series: 164, nllk loss: -1.73508, kernel loss: 0.19661\n",
      "Epoch: 10, series: 165, nllk loss: -1.79151, kernel loss: 0.06821\n",
      "Epoch: 10, series: 166, nllk loss: -1.32590, kernel loss: 0.06342\n",
      "Epoch: 10, series: 167, nllk loss: -2.20003, kernel loss: 0.12125\n",
      "Epoch: 10, series: 168, nllk loss: -1.94724, kernel loss: 0.12164\n",
      "Epoch: 10, series: 169, nllk loss: -2.14041, kernel loss: 0.07984\n",
      "Epoch: 10, series: 170, nllk loss: -1.82280, kernel loss: 0.22727\n",
      "Epoch: 10, series: 171, nllk loss: -2.22764, kernel loss: 0.14079\n",
      "Epoch: 10, series: 172, nllk loss: -1.91411, kernel loss: 0.22771\n",
      "Epoch: 10, series: 173, nllk loss: -2.31872, kernel loss: 0.05802\n",
      "Epoch: 10, series: 174, nllk loss: -1.94074, kernel loss: 0.31699\n",
      "Epoch: 10, series: 175, nllk loss: -2.26876, kernel loss: 0.17888\n",
      "Epoch: 10, series: 176, nllk loss: -2.03531, kernel loss: 0.20534\n",
      "Epoch: 10, series: 177, nllk loss: -1.85504, kernel loss: 0.20188\n",
      "Epoch: 10, series: 178, nllk loss: -1.61301, kernel loss: 0.31172\n",
      "Epoch: 10, series: 179, nllk loss: -2.02899, kernel loss: 0.17948\n",
      "Epoch: 10, series: 180, nllk loss: -2.00601, kernel loss: 0.10048\n",
      "Epoch: 10, series: 181, nllk loss: -2.20239, kernel loss: 0.07524\n",
      "Epoch: 10, series: 182, nllk loss: -2.01681, kernel loss: 0.07157\n",
      "Epoch: 10, series: 183, nllk loss: -1.93499, kernel loss: 0.17278\n",
      "Epoch: 10, series: 184, nllk loss: -1.80047, kernel loss: 0.13769\n",
      "Epoch: 10, series: 185, nllk loss: -1.55825, kernel loss: 0.08857\n",
      "Epoch: 10, series: 186, nllk loss: -2.42187, kernel loss: 0.13393\n",
      "Epoch: 10, series: 187, nllk loss: -2.45757, kernel loss: 0.07652\n",
      "Epoch: 10, series: 188, nllk loss: -1.52628, kernel loss: 0.06416\n",
      "Epoch: 10, series: 189, nllk loss: -1.50186, kernel loss: 0.07710\n",
      "Epoch: 10, series: 190, nllk loss: -1.78886, kernel loss: 0.09523\n",
      "Epoch: 10, series: 191, nllk loss: -1.83902, kernel loss: 0.06715\n",
      "Epoch: 10, series: 192, nllk loss: -2.02862, kernel loss: 0.12616\n",
      "Epoch: 10, series: 193, nllk loss: -1.48814, kernel loss: 0.38931\n",
      "Epoch: 10, series: 194, nllk loss: -1.36539, kernel loss: 0.09063\n",
      "Epoch: 10, series: 195, nllk loss: -2.26738, kernel loss: 0.06310\n",
      "Epoch: 10, series: 196, nllk loss: -1.83014, kernel loss: 0.28471\n",
      "Epoch: 10, series: 197, nllk loss: -2.07135, kernel loss: 0.16995\n",
      "Epoch: 10, series: 198, nllk loss: -2.00791, kernel loss: 0.22407\n",
      "Epoch: 10, series: 199, nllk loss: -1.83276, kernel loss: 0.10576\n",
      "Epoch: 10, series: 200, nllk loss: -2.30782, kernel loss: 0.14606\n",
      "Epoch: 10, series: 201, nllk loss: -2.22866, kernel loss: 0.20564\n",
      "Epoch: 10, series: 202, nllk loss: -1.98125, kernel loss: 0.00049\n",
      "Epoch: 10, series: 203, nllk loss: -1.87741, kernel loss: 0.11633\n",
      "Epoch: 10, series: 204, nllk loss: -0.96524, kernel loss: 0.02595\n",
      "Epoch: 10, series: 205, nllk loss: -2.08857, kernel loss: 0.15971\n",
      "Epoch: 10, series: 206, nllk loss: -2.10405, kernel loss: 0.10904\n",
      "Epoch: 10, series: 207, nllk loss: -0.98218, kernel loss: 0.17231\n",
      "Epoch: 10, series: 208, nllk loss: -2.32481, kernel loss: 0.16145\n",
      "Epoch: 10, series: 209, nllk loss: -1.75542, kernel loss: 0.23153\n",
      "Epoch: 10, series: 210, nllk loss: -2.43395, kernel loss: 0.25887\n",
      "Epoch: 10, series: 211, nllk loss: -2.04137, kernel loss: 0.21350\n",
      "Epoch: 10, series: 212, nllk loss: -1.73513, kernel loss: 0.12687\n",
      "Epoch: 10, series: 213, nllk loss: -2.09402, kernel loss: 0.10022\n",
      "Epoch: 10, series: 214, nllk loss: -2.08983, kernel loss: 0.19484\n",
      "Epoch: 10, series: 215, nllk loss: -2.43503, kernel loss: 0.09423\n",
      "Epoch: 10, series: 216, nllk loss: -1.04770, kernel loss: 0.04193\n",
      "Epoch: 10, series: 217, nllk loss: -1.95093, kernel loss: 0.18868\n",
      "Epoch: 10, series: 218, nllk loss: -1.39087, kernel loss: 0.12338\n",
      "Epoch: 10, series: 219, nllk loss: -1.92509, kernel loss: 0.18710\n",
      "Epoch: 10, series: 220, nllk loss: -2.00830, kernel loss: 0.13363\n",
      "Epoch: 10, series: 221, nllk loss: -2.20830, kernel loss: 0.09520\n",
      "Epoch: 10, series: 222, nllk loss: -2.12723, kernel loss: 0.13659\n",
      "Epoch: 10, series: 223, nllk loss: -1.63294, kernel loss: 0.15113\n",
      "Epoch: 10, series: 224, nllk loss: -2.24848, kernel loss: 0.24120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, series: 225, nllk loss: -2.08225, kernel loss: 0.25458\n",
      "Epoch: 10, series: 226, nllk loss: -1.64228, kernel loss: 0.12925\n",
      "Epoch: 10, series: 227, nllk loss: -1.95675, kernel loss: 0.11897\n",
      "Epoch: 10, series: 228, nllk loss: -2.12694, kernel loss: 0.26886\n",
      "Epoch: 10, series: 229, nllk loss: -1.90357, kernel loss: 0.19635\n",
      "Epoch: 10, series: 230, nllk loss: -2.25432, kernel loss: 0.31921\n",
      "Epoch: 10, series: 231, nllk loss: -1.82071, kernel loss: 0.08174\n",
      "Epoch: 10, series: 232, nllk loss: -2.48147, kernel loss: 0.20429\n",
      "Epoch: 10, series: 233, nllk loss: -2.38406, kernel loss: 0.04398\n",
      "Epoch: 10, series: 234, nllk loss: -2.02753, kernel loss: 0.03485\n",
      "Epoch: 10, series: 235, nllk loss: -2.55663, kernel loss: 0.02125\n",
      "Epoch: 10, series: 236, nllk loss: -1.47379, kernel loss: 0.11506\n",
      "Epoch: 10, series: 237, nllk loss: -2.20871, kernel loss: 0.14121\n",
      "Epoch: 10, series: 238, nllk loss: -1.65091, kernel loss: 0.25813\n",
      "Epoch: 10, series: 239, nllk loss: -2.22522, kernel loss: 0.28497\n",
      "Epoch: 10, series: 240, nllk loss: -1.21475, kernel loss: 0.17558\n",
      "Epoch: 10, series: 241, nllk loss: -1.93016, kernel loss: 0.04329\n",
      "Epoch: 10, series: 242, nllk loss: -1.79894, kernel loss: 0.05687\n",
      "Epoch: 10, series: 243, nllk loss: -2.21915, kernel loss: 0.12029\n",
      "Epoch: 10, series: 244, nllk loss: -1.80320, kernel loss: 0.15954\n",
      "Epoch: 10, series: 245, nllk loss: -2.14960, kernel loss: 0.29387\n",
      "Epoch: 10, series: 246, nllk loss: 0.27315, kernel loss: 0.09429\n",
      "Epoch: 10, series: 247, nllk loss: -1.66086, kernel loss: 0.10384\n",
      "Epoch: 10, series: 248, nllk loss: -1.95689, kernel loss: 0.29045\n",
      "Epoch: 10, series: 249, nllk loss: -1.89974, kernel loss: 0.04758\n",
      "Epoch: 10, series: 250, nllk loss: -1.67812, kernel loss: 0.06610\n",
      "Epoch: 10, series: 251, nllk loss: -1.05932, kernel loss: 0.07843\n",
      "Epoch: 10, series: 252, nllk loss: -1.22348, kernel loss: 0.07522\n",
      "Epoch: 10, series: 253, nllk loss: -1.74646, kernel loss: 0.03185\n",
      "Epoch: 10, series: 254, nllk loss: -2.23713, kernel loss: 0.09817\n",
      "Epoch: 10, series: 255, nllk loss: -2.01593, kernel loss: 0.27787\n",
      "Epoch: 10, series: 256, nllk loss: -1.83025, kernel loss: 0.03787\n",
      "Epoch: 10, series: 257, nllk loss: -2.04096, kernel loss: 0.20409\n",
      "Epoch: 10, series: 258, nllk loss: -2.01301, kernel loss: 0.04209\n",
      "Epoch: 10, series: 259, nllk loss: -1.71248, kernel loss: 0.08096\n",
      "Epoch: 10, series: 260, nllk loss: -1.88686, kernel loss: 0.10494\n",
      "Epoch: 10, series: 261, nllk loss: -2.10841, kernel loss: 0.16274\n",
      "Epoch: 10, series: 262, nllk loss: -2.44345, kernel loss: 0.16754\n",
      "Epoch: 10, series: 263, nllk loss: -0.72124, kernel loss: 0.02811\n",
      "Epoch: 10, series: 264, nllk loss: -1.92021, kernel loss: 0.07409\n",
      "Epoch: 10, series: 265, nllk loss: -1.73183, kernel loss: 0.14742\n",
      "Epoch: 10, series: 266, nllk loss: -2.22171, kernel loss: 0.12777\n",
      "Epoch: 10, series: 267, nllk loss: -1.96639, kernel loss: 0.28176\n",
      "Epoch: 10, series: 268, nllk loss: -2.14968, kernel loss: 0.27374\n",
      "Epoch: 10, series: 269, nllk loss: -1.74242, kernel loss: 0.03068\n",
      "Epoch: 10, series: 270, nllk loss: -1.77129, kernel loss: 0.06614\n",
      "Epoch: 10, series: 271, nllk loss: -1.90396, kernel loss: 0.18273\n",
      "Epoch: 10, series: 272, nllk loss: -1.85640, kernel loss: 0.11577\n",
      "Epoch: 10, series: 273, nllk loss: -1.97943, kernel loss: 0.05432\n",
      "Epoch: 10, series: 274, nllk loss: -1.51696, kernel loss: 0.15702\n",
      "Epoch: 10, series: 275, nllk loss: -1.61181, kernel loss: 0.11882\n",
      "Epoch: 10, series: 276, nllk loss: -1.16929, kernel loss: 0.04613\n",
      "Epoch: 10, series: 277, nllk loss: -2.13028, kernel loss: 0.25960\n",
      "Epoch: 10, series: 278, nllk loss: -2.03188, kernel loss: 0.15555\n",
      "Epoch: 10, series: 279, nllk loss: -2.24800, kernel loss: 0.08622\n",
      "Epoch: 10, series: 280, nllk loss: -1.98325, kernel loss: 0.35527\n",
      "Epoch: 10, series: 281, nllk loss: -2.12250, kernel loss: 0.29426\n",
      "Epoch: 10, series: 282, nllk loss: -2.19422, kernel loss: 0.14688\n",
      "Epoch: 10, series: 283, nllk loss: -2.14367, kernel loss: 0.10412\n",
      "Epoch: 10, series: 284, nllk loss: -1.63668, kernel loss: 0.20086\n",
      "Epoch: 10, series: 285, nllk loss: -1.62859, kernel loss: 0.01965\n",
      "Epoch: 10, series: 286, nllk loss: -2.06285, kernel loss: 0.07650\n",
      "Epoch: 10, series: 287, nllk loss: -2.31508, kernel loss: 0.32563\n",
      "Epoch: 10, series: 288, nllk loss: -1.21463, kernel loss: 0.11276\n",
      "Epoch: 10, series: 289, nllk loss: -1.02255, kernel loss: 0.21189\n",
      "Epoch: 10, series: 290, nllk loss: -2.12595, kernel loss: 0.09437\n",
      "Epoch: 10, series: 291, nllk loss: -2.08854, kernel loss: 0.22064\n",
      "Epoch: 10, series: 292, nllk loss: -2.13390, kernel loss: 0.34156\n",
      "Epoch: 10, series: 293, nllk loss: -2.33089, kernel loss: 0.13270\n",
      "Epoch: 10, series: 294, nllk loss: -1.47912, kernel loss: 0.12778\n",
      "Epoch: 10, series: 295, nllk loss: -1.14194, kernel loss: 0.21589\n",
      "Epoch: 10, series: 296, nllk loss: -2.13716, kernel loss: 0.29270\n",
      "Epoch: 10, series: 297, nllk loss: -2.32894, kernel loss: 0.05894\n",
      "Epoch: 10, series: 298, nllk loss: 1.95580, kernel loss: 0.04232\n",
      "Epoch: 10, series: 299, nllk loss: 0.40083, kernel loss: 0.14078\n",
      "Epoch: 10, series: 300, nllk loss: -1.86938, kernel loss: 0.05622\n",
      "Epoch: 10, series: 301, nllk loss: -1.91117, kernel loss: 0.20877\n",
      "Epoch: 10, series: 302, nllk loss: -2.03292, kernel loss: 0.06782\n",
      "Epoch: 10, series: 303, nllk loss: -1.78785, kernel loss: 0.04619\n",
      "Epoch: 10, series: 304, nllk loss: -0.06218, kernel loss: 0.08003\n",
      "Epoch: 10, series: 305, nllk loss: -1.48336, kernel loss: 0.08580\n",
      "Epoch: 10, series: 306, nllk loss: -2.07375, kernel loss: 0.17290\n",
      "Epoch: 10, series: 307, nllk loss: -1.39428, kernel loss: 0.06452\n",
      "Epoch: 10, series: 308, nllk loss: -2.06530, kernel loss: 0.19741\n",
      "Epoch: 10, series: 309, nllk loss: -1.77261, kernel loss: 0.16184\n",
      "Epoch: 10, series: 310, nllk loss: -1.90276, kernel loss: 0.13810\n",
      "Epoch: 10, series: 311, nllk loss: -1.68649, kernel loss: 0.20093\n",
      "Epoch: 10, series: 312, nllk loss: -1.90801, kernel loss: 0.01829\n",
      "Epoch: 10, series: 313, nllk loss: -2.07046, kernel loss: 0.21653\n",
      "Epoch: 10, series: 314, nllk loss: -2.28188, kernel loss: 0.11659\n",
      "Epoch: 10, series: 315, nllk loss: -0.76421, kernel loss: 0.04794\n",
      "Epoch: 10, series: 316, nllk loss: -1.69141, kernel loss: 0.12653\n",
      "Epoch: 10, series: 317, nllk loss: 0.71385, kernel loss: 0.16286\n",
      "Epoch: 10, series: 318, nllk loss: 1.75863, kernel loss: 0.09471\n",
      "Epoch: 10, series: 319, nllk loss: -0.82967, kernel loss: 0.13947\n",
      "Epoch: 10, series: 320, nllk loss: -0.86043, kernel loss: 0.26438\n",
      "Epoch: 10, total loss: -417.60416\n",
      "Epoch: 11, series: 0, nllk loss: 2.25827, kernel loss: 0.11024\n",
      "Epoch: 11, series: 1, nllk loss: -0.82145, kernel loss: 0.10886\n",
      "Epoch: 11, series: 2, nllk loss: 0.21154, kernel loss: 0.13332\n",
      "Epoch: 11, series: 3, nllk loss: -1.06729, kernel loss: 0.18468\n",
      "Epoch: 11, series: 4, nllk loss: -0.80986, kernel loss: 0.19704\n",
      "Epoch: 11, series: 5, nllk loss: -1.07254, kernel loss: 0.13205\n",
      "Epoch: 11, series: 6, nllk loss: -0.32987, kernel loss: 0.19236\n",
      "Epoch: 11, series: 7, nllk loss: -1.12678, kernel loss: 0.38061\n",
      "Epoch: 11, series: 8, nllk loss: -0.56500, kernel loss: 0.15022\n",
      "Epoch: 11, series: 9, nllk loss: -0.50019, kernel loss: 0.16282\n",
      "Epoch: 11, series: 10, nllk loss: -1.15008, kernel loss: 0.11036\n",
      "Epoch: 11, series: 11, nllk loss: -0.90051, kernel loss: 0.26736\n",
      "Epoch: 11, series: 12, nllk loss: -1.28840, kernel loss: 0.18759\n",
      "Epoch: 11, series: 13, nllk loss: -1.26211, kernel loss: 0.29511\n",
      "Epoch: 11, series: 14, nllk loss: -1.35112, kernel loss: 0.21010\n",
      "Epoch: 11, series: 15, nllk loss: -1.33099, kernel loss: 0.04889\n",
      "Epoch: 11, series: 16, nllk loss: -1.01543, kernel loss: 0.00899\n",
      "Epoch: 11, series: 17, nllk loss: -1.11007, kernel loss: 0.29109\n",
      "Epoch: 11, series: 18, nllk loss: -1.25712, kernel loss: 0.18121\n",
      "Epoch: 11, series: 19, nllk loss: -0.31009, kernel loss: 0.18116\n",
      "Epoch: 11, series: 20, nllk loss: -0.62157, kernel loss: 0.15309\n",
      "Epoch: 11, series: 21, nllk loss: -1.01876, kernel loss: 0.12549\n",
      "Epoch: 11, series: 22, nllk loss: -1.28079, kernel loss: 0.12785\n",
      "Epoch: 11, series: 23, nllk loss: -1.23445, kernel loss: 0.13048\n",
      "Epoch: 11, series: 24, nllk loss: -1.43154, kernel loss: 0.06560\n",
      "Epoch: 11, series: 25, nllk loss: -1.48979, kernel loss: 0.02838\n",
      "Epoch: 11, series: 26, nllk loss: -1.29482, kernel loss: 0.05963\n",
      "Epoch: 11, series: 27, nllk loss: -1.15927, kernel loss: 0.52868\n",
      "Epoch: 11, series: 28, nllk loss: -1.30576, kernel loss: 0.19276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, series: 29, nllk loss: -0.76753, kernel loss: 0.13940\n",
      "Epoch: 11, series: 30, nllk loss: -1.31479, kernel loss: 0.06558\n",
      "Epoch: 11, series: 31, nllk loss: -1.12388, kernel loss: 0.17601\n",
      "Epoch: 11, series: 32, nllk loss: -1.08808, kernel loss: 0.16952\n",
      "Epoch: 11, series: 33, nllk loss: -0.89156, kernel loss: 0.13838\n",
      "Epoch: 11, series: 34, nllk loss: -1.33691, kernel loss: 0.23416\n",
      "Epoch: 11, series: 35, nllk loss: -1.52816, kernel loss: 0.05150\n",
      "Epoch: 11, series: 36, nllk loss: -1.50694, kernel loss: 0.08324\n",
      "Epoch: 11, series: 37, nllk loss: -0.38034, kernel loss: 0.26228\n",
      "Epoch: 11, series: 38, nllk loss: -1.04609, kernel loss: 0.10651\n",
      "Epoch: 11, series: 39, nllk loss: -0.78811, kernel loss: 0.29178\n",
      "Epoch: 11, series: 40, nllk loss: -1.74016, kernel loss: 0.29538\n",
      "Epoch: 11, series: 41, nllk loss: -1.29848, kernel loss: 0.02324\n",
      "Epoch: 11, series: 42, nllk loss: -1.09520, kernel loss: 0.09759\n",
      "Epoch: 11, series: 43, nllk loss: -1.07774, kernel loss: 0.03570\n",
      "Epoch: 11, series: 44, nllk loss: -1.48256, kernel loss: 0.07453\n",
      "Epoch: 11, series: 45, nllk loss: -1.56113, kernel loss: 0.06367\n",
      "Epoch: 11, series: 46, nllk loss: -1.59381, kernel loss: 0.28482\n",
      "Epoch: 11, series: 47, nllk loss: -1.50166, kernel loss: 0.19634\n",
      "Epoch: 11, series: 48, nllk loss: -1.58895, kernel loss: 0.03059\n",
      "Epoch: 11, series: 49, nllk loss: -1.26827, kernel loss: 0.04729\n",
      "Epoch: 11, series: 50, nllk loss: 0.08672, kernel loss: 0.08333\n",
      "Epoch: 11, series: 51, nllk loss: -1.29774, kernel loss: 0.19275\n",
      "Epoch: 11, series: 52, nllk loss: -0.27354, kernel loss: 0.09478\n",
      "Epoch: 11, series: 53, nllk loss: -1.63405, kernel loss: 0.02225\n",
      "Epoch: 11, series: 54, nllk loss: -1.30342, kernel loss: 0.09359\n",
      "Epoch: 11, series: 55, nllk loss: -0.95582, kernel loss: 0.04150\n",
      "Epoch: 11, series: 56, nllk loss: -1.34398, kernel loss: 0.11213\n",
      "Epoch: 11, series: 57, nllk loss: -1.34032, kernel loss: 0.10070\n",
      "Epoch: 11, series: 58, nllk loss: -1.44716, kernel loss: 0.15263\n",
      "Epoch: 11, series: 59, nllk loss: -1.14985, kernel loss: 0.08806\n",
      "Epoch: 11, series: 60, nllk loss: -1.06255, kernel loss: 0.25263\n",
      "Epoch: 11, series: 61, nllk loss: -1.56336, kernel loss: 0.23512\n",
      "Epoch: 11, series: 62, nllk loss: -1.63145, kernel loss: 0.05399\n",
      "Epoch: 11, series: 63, nllk loss: -1.50629, kernel loss: 0.15847\n",
      "Epoch: 11, series: 64, nllk loss: -1.04511, kernel loss: 0.07171\n",
      "Epoch: 11, series: 65, nllk loss: -1.51413, kernel loss: 0.02091\n",
      "Epoch: 11, series: 66, nllk loss: -1.44824, kernel loss: 0.14163\n",
      "Epoch: 11, series: 67, nllk loss: -1.34153, kernel loss: 0.02601\n",
      "Epoch: 11, series: 68, nllk loss: -0.79136, kernel loss: 0.18685\n",
      "Epoch: 11, series: 69, nllk loss: -1.41444, kernel loss: 0.03676\n",
      "Epoch: 11, series: 70, nllk loss: -1.42131, kernel loss: 0.27709\n",
      "Epoch: 11, series: 71, nllk loss: -1.45929, kernel loss: 0.14147\n",
      "Epoch: 11, series: 72, nllk loss: -1.76334, kernel loss: 0.21221\n",
      "Epoch: 11, series: 73, nllk loss: -1.24626, kernel loss: 0.09724\n",
      "Epoch: 11, series: 74, nllk loss: -1.85230, kernel loss: 0.01670\n",
      "Epoch: 11, series: 75, nllk loss: -1.41287, kernel loss: 0.09583\n",
      "Epoch: 11, series: 76, nllk loss: -1.42660, kernel loss: 0.08782\n",
      "Epoch: 11, series: 77, nllk loss: -1.24591, kernel loss: 0.03517\n",
      "Epoch: 11, series: 78, nllk loss: -1.30627, kernel loss: 0.10724\n",
      "Epoch: 11, series: 79, nllk loss: -0.57254, kernel loss: 0.05408\n",
      "Epoch: 11, series: 80, nllk loss: -1.71271, kernel loss: 0.21505\n",
      "Epoch: 11, series: 81, nllk loss: -1.13701, kernel loss: 0.02971\n",
      "Epoch: 11, series: 82, nllk loss: -0.26388, kernel loss: 0.02932\n",
      "Epoch: 11, series: 83, nllk loss: -0.81033, kernel loss: 0.04078\n",
      "Epoch: 11, series: 84, nllk loss: -1.12861, kernel loss: 0.08156\n",
      "Epoch: 11, series: 85, nllk loss: -1.29864, kernel loss: 0.14069\n",
      "Epoch: 11, series: 86, nllk loss: -0.40775, kernel loss: 0.10617\n",
      "Epoch: 11, series: 87, nllk loss: -1.59378, kernel loss: 0.08364\n",
      "Epoch: 11, series: 88, nllk loss: -1.93999, kernel loss: 0.26960\n",
      "Epoch: 11, series: 89, nllk loss: -1.91966, kernel loss: 0.02623\n",
      "Epoch: 11, series: 90, nllk loss: -2.06513, kernel loss: 0.08003\n",
      "Epoch: 11, series: 91, nllk loss: -2.02168, kernel loss: 0.19406\n",
      "Epoch: 11, series: 92, nllk loss: 0.54658, kernel loss: 0.19480\n",
      "Epoch: 11, series: 93, nllk loss: -2.21691, kernel loss: 0.30581\n",
      "Epoch: 11, series: 94, nllk loss: -2.21706, kernel loss: 0.16158\n",
      "Epoch: 11, series: 95, nllk loss: -2.19352, kernel loss: 0.11854\n",
      "Epoch: 11, series: 96, nllk loss: -1.60843, kernel loss: 0.07039\n",
      "Epoch: 11, series: 97, nllk loss: -0.71607, kernel loss: 0.18126\n",
      "Epoch: 11, series: 98, nllk loss: -0.84746, kernel loss: 0.11535\n",
      "Epoch: 11, series: 99, nllk loss: -1.32548, kernel loss: 0.04513\n",
      "Epoch: 11, series: 100, nllk loss: -0.73028, kernel loss: 0.16527\n",
      "Epoch: 11, series: 101, nllk loss: -1.34462, kernel loss: 0.03534\n",
      "Epoch: 11, series: 102, nllk loss: -0.59733, kernel loss: 0.07744\n",
      "Epoch: 11, series: 103, nllk loss: -1.00232, kernel loss: 0.23875\n",
      "Epoch: 11, series: 104, nllk loss: 0.38000, kernel loss: 0.12984\n",
      "Epoch: 11, series: 105, nllk loss: 0.18971, kernel loss: 0.27578\n",
      "Epoch: 11, series: 106, nllk loss: -1.07018, kernel loss: 0.16731\n",
      "Epoch: 11, series: 107, nllk loss: -0.93894, kernel loss: 0.16213\n",
      "Epoch: 11, series: 108, nllk loss: -1.31453, kernel loss: 0.20011\n",
      "Epoch: 11, series: 109, nllk loss: -0.93940, kernel loss: 0.10584\n",
      "Epoch: 11, series: 110, nllk loss: -1.53590, kernel loss: 0.22145\n",
      "Epoch: 11, series: 111, nllk loss: -1.40270, kernel loss: 0.22009\n",
      "Epoch: 11, series: 112, nllk loss: -0.72272, kernel loss: 0.12907\n",
      "Epoch: 11, series: 113, nllk loss: -1.04052, kernel loss: 0.15832\n",
      "Epoch: 11, series: 114, nllk loss: -1.02841, kernel loss: 0.05314\n",
      "Epoch: 11, series: 115, nllk loss: -0.89387, kernel loss: 0.30634\n",
      "Epoch: 11, series: 116, nllk loss: -1.55269, kernel loss: 0.18589\n",
      "Epoch: 11, series: 117, nllk loss: -0.57840, kernel loss: 0.10739\n",
      "Epoch: 11, series: 118, nllk loss: -1.62265, kernel loss: 0.03482\n",
      "Epoch: 11, series: 119, nllk loss: -0.73040, kernel loss: 0.07354\n",
      "Epoch: 11, series: 120, nllk loss: -1.48889, kernel loss: 0.26259\n",
      "Epoch: 11, series: 121, nllk loss: 0.16683, kernel loss: 0.14028\n",
      "Epoch: 11, series: 122, nllk loss: -0.49619, kernel loss: 0.11282\n",
      "Epoch: 11, series: 123, nllk loss: -1.43468, kernel loss: 0.21652\n",
      "Epoch: 11, series: 124, nllk loss: -1.62505, kernel loss: 0.09558\n",
      "Epoch: 11, series: 125, nllk loss: -1.33396, kernel loss: 0.24141\n",
      "Epoch: 11, series: 126, nllk loss: -1.56504, kernel loss: 0.14866\n",
      "Epoch: 11, series: 127, nllk loss: -1.39787, kernel loss: 0.04415\n",
      "Epoch: 11, series: 128, nllk loss: -0.94041, kernel loss: 0.12454\n",
      "Epoch: 11, series: 129, nllk loss: -0.65164, kernel loss: 0.07959\n",
      "Epoch: 11, series: 130, nllk loss: -1.17841, kernel loss: 0.27683\n",
      "Epoch: 11, series: 131, nllk loss: 0.61571, kernel loss: 0.18082\n",
      "Epoch: 11, series: 132, nllk loss: 0.06926, kernel loss: 0.12756\n",
      "Epoch: 11, series: 133, nllk loss: -0.91526, kernel loss: 0.24252\n",
      "Epoch: 11, series: 134, nllk loss: -0.74476, kernel loss: 0.03471\n",
      "Epoch: 11, series: 135, nllk loss: -1.35267, kernel loss: 0.06497\n",
      "Epoch: 11, series: 136, nllk loss: -1.40724, kernel loss: 0.05237\n",
      "Epoch: 11, series: 137, nllk loss: -1.59788, kernel loss: 0.08556\n",
      "Epoch: 11, series: 138, nllk loss: -1.62225, kernel loss: 0.03874\n",
      "Epoch: 11, series: 139, nllk loss: -1.59948, kernel loss: 0.07847\n",
      "Epoch: 11, series: 140, nllk loss: -1.37447, kernel loss: 0.19818\n",
      "Epoch: 11, series: 141, nllk loss: -1.58361, kernel loss: 0.24308\n",
      "Epoch: 11, series: 142, nllk loss: -1.59602, kernel loss: 0.26893\n",
      "Epoch: 11, series: 143, nllk loss: -1.58162, kernel loss: 0.15440\n",
      "Epoch: 11, series: 144, nllk loss: -1.78670, kernel loss: 0.17892\n",
      "Epoch: 11, series: 145, nllk loss: -1.75078, kernel loss: 0.20048\n",
      "Epoch: 11, series: 146, nllk loss: 3.00950, kernel loss: 0.13279\n",
      "Epoch: 11, series: 147, nllk loss: -1.58749, kernel loss: 0.08532\n",
      "Epoch: 11, series: 148, nllk loss: -1.43768, kernel loss: 0.02320\n",
      "Epoch: 11, series: 149, nllk loss: -1.67779, kernel loss: 0.26691\n",
      "Epoch: 11, series: 150, nllk loss: -1.72152, kernel loss: 0.27200\n",
      "Epoch: 11, series: 151, nllk loss: -1.80054, kernel loss: 0.10781\n",
      "Epoch: 11, series: 152, nllk loss: -1.76318, kernel loss: 0.09224\n",
      "Epoch: 11, series: 153, nllk loss: -1.57188, kernel loss: 0.09752\n",
      "Epoch: 11, series: 154, nllk loss: -1.64119, kernel loss: 0.05406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, series: 155, nllk loss: -1.72351, kernel loss: 0.10572\n",
      "Epoch: 11, series: 156, nllk loss: -1.79746, kernel loss: 0.50615\n",
      "Epoch: 11, series: 157, nllk loss: -1.26217, kernel loss: 0.20761\n",
      "Epoch: 11, series: 158, nllk loss: -1.82159, kernel loss: 0.19955\n",
      "Epoch: 11, series: 159, nllk loss: -1.86366, kernel loss: 0.13908\n",
      "Epoch: 11, series: 160, nllk loss: -1.74878, kernel loss: 0.15813\n",
      "Epoch: 11, series: 161, nllk loss: -1.68984, kernel loss: 0.10437\n",
      "Epoch: 11, series: 162, nllk loss: -1.84631, kernel loss: 0.26891\n",
      "Epoch: 11, series: 163, nllk loss: -2.13758, kernel loss: 0.10449\n",
      "Epoch: 11, series: 164, nllk loss: -1.71672, kernel loss: 0.22142\n",
      "Epoch: 11, series: 165, nllk loss: -1.76617, kernel loss: 0.11910\n",
      "Epoch: 11, series: 166, nllk loss: -1.36762, kernel loss: 0.03817\n",
      "Epoch: 11, series: 167, nllk loss: -2.25646, kernel loss: 0.01657\n",
      "Epoch: 11, series: 168, nllk loss: -2.08655, kernel loss: 0.07800\n",
      "Epoch: 11, series: 169, nllk loss: -2.16727, kernel loss: 0.24034\n",
      "Epoch: 11, series: 170, nllk loss: -1.83908, kernel loss: 0.12843\n",
      "Epoch: 11, series: 171, nllk loss: -2.31056, kernel loss: 0.05283\n",
      "Epoch: 11, series: 172, nllk loss: -1.97057, kernel loss: 0.31299\n",
      "Epoch: 11, series: 173, nllk loss: -2.41482, kernel loss: 0.29056\n",
      "Epoch: 11, series: 174, nllk loss: -2.04320, kernel loss: 0.07680\n",
      "Epoch: 11, series: 175, nllk loss: -2.34633, kernel loss: 0.19603\n",
      "Epoch: 11, series: 176, nllk loss: -2.04360, kernel loss: 0.15968\n",
      "Epoch: 11, series: 177, nllk loss: -1.92232, kernel loss: 0.09023\n",
      "Epoch: 11, series: 178, nllk loss: -1.66718, kernel loss: 0.22635\n",
      "Epoch: 11, series: 179, nllk loss: -2.08797, kernel loss: 0.20836\n",
      "Epoch: 11, series: 180, nllk loss: -2.16577, kernel loss: 0.18506\n",
      "Epoch: 11, series: 181, nllk loss: -2.38003, kernel loss: 0.23883\n",
      "Epoch: 11, series: 182, nllk loss: -2.08296, kernel loss: 0.27406\n",
      "Epoch: 11, series: 183, nllk loss: -1.95128, kernel loss: 0.65028\n",
      "Epoch: 11, series: 184, nllk loss: -1.72986, kernel loss: 0.00000\n",
      "Epoch: 11, series: 185, nllk loss: -1.51729, kernel loss: 0.14335\n",
      "Epoch: 11, series: 186, nllk loss: -2.46056, kernel loss: 0.02942\n",
      "Epoch: 11, series: 187, nllk loss: -2.42602, kernel loss: 0.05817\n",
      "Epoch: 11, series: 188, nllk loss: -1.55434, kernel loss: 0.10315\n",
      "Epoch: 11, series: 189, nllk loss: -1.51469, kernel loss: 0.15293\n",
      "Epoch: 11, series: 190, nllk loss: -1.77184, kernel loss: 0.07236\n",
      "Epoch: 11, series: 191, nllk loss: -1.74618, kernel loss: 0.24441\n",
      "Epoch: 11, series: 192, nllk loss: -2.08436, kernel loss: 0.07094\n",
      "Epoch: 11, series: 193, nllk loss: -1.58937, kernel loss: 0.14161\n",
      "Epoch: 11, series: 194, nllk loss: -1.40740, kernel loss: 0.28941\n",
      "Epoch: 11, series: 195, nllk loss: -2.30256, kernel loss: 0.23812\n",
      "Epoch: 11, series: 196, nllk loss: -1.90593, kernel loss: 0.05967\n",
      "Epoch: 11, series: 197, nllk loss: -2.07626, kernel loss: 0.12325\n",
      "Epoch: 11, series: 198, nllk loss: -2.04849, kernel loss: 0.14710\n",
      "Epoch: 11, series: 199, nllk loss: -1.85197, kernel loss: 0.13996\n",
      "Epoch: 11, series: 200, nllk loss: -2.21326, kernel loss: 0.06690\n",
      "Epoch: 11, series: 201, nllk loss: -2.27281, kernel loss: 0.18792\n",
      "Epoch: 11, series: 202, nllk loss: -1.94861, kernel loss: 0.21812\n",
      "Epoch: 11, series: 203, nllk loss: -1.77833, kernel loss: 0.20075\n",
      "Epoch: 11, series: 204, nllk loss: -0.76713, kernel loss: 0.08393\n",
      "Epoch: 11, series: 205, nllk loss: -1.92549, kernel loss: 0.17302\n",
      "Epoch: 11, series: 206, nllk loss: -1.88130, kernel loss: 0.18727\n",
      "Epoch: 11, series: 207, nllk loss: -0.95384, kernel loss: 0.10406\n",
      "Epoch: 11, series: 208, nllk loss: -2.27928, kernel loss: 0.13613\n",
      "Epoch: 11, series: 209, nllk loss: -1.75024, kernel loss: 0.14134\n",
      "Epoch: 11, series: 210, nllk loss: -2.31381, kernel loss: 0.02545\n",
      "Epoch: 11, series: 211, nllk loss: -1.90015, kernel loss: 0.18634\n",
      "Epoch: 11, series: 212, nllk loss: -1.57389, kernel loss: 0.23192\n",
      "Epoch: 11, series: 213, nllk loss: -2.00193, kernel loss: 0.24323\n",
      "Epoch: 11, series: 214, nllk loss: -1.90189, kernel loss: 0.23061\n",
      "Epoch: 11, series: 215, nllk loss: -2.13425, kernel loss: 0.01231\n",
      "Epoch: 11, series: 216, nllk loss: -1.35161, kernel loss: 0.11683\n",
      "Epoch: 11, series: 217, nllk loss: -1.91698, kernel loss: 0.16731\n",
      "Epoch: 11, series: 218, nllk loss: -1.50570, kernel loss: 0.07667\n",
      "Epoch: 11, series: 219, nllk loss: -1.81089, kernel loss: 0.19092\n",
      "Epoch: 11, series: 220, nllk loss: -1.96765, kernel loss: 0.29147\n",
      "Epoch: 11, series: 221, nllk loss: -2.24662, kernel loss: 0.17120\n",
      "Epoch: 11, series: 222, nllk loss: -2.12415, kernel loss: 0.19068\n",
      "Epoch: 11, series: 223, nllk loss: -1.75836, kernel loss: 0.12749\n",
      "Epoch: 11, series: 224, nllk loss: -2.33121, kernel loss: 0.21518\n",
      "Epoch: 11, series: 225, nllk loss: -2.12412, kernel loss: 0.08517\n",
      "Epoch: 11, series: 226, nllk loss: -1.74418, kernel loss: 0.15052\n",
      "Epoch: 11, series: 227, nllk loss: -2.00343, kernel loss: 0.10991\n",
      "Epoch: 11, series: 228, nllk loss: -2.14655, kernel loss: 0.11294\n",
      "Epoch: 11, series: 229, nllk loss: -1.94903, kernel loss: 0.21076\n",
      "Epoch: 11, series: 230, nllk loss: -2.25441, kernel loss: 0.10873\n",
      "Epoch: 11, series: 231, nllk loss: -1.85005, kernel loss: 0.06484\n",
      "Epoch: 11, series: 232, nllk loss: -2.53134, kernel loss: 0.17671\n",
      "Epoch: 11, series: 233, nllk loss: -2.38015, kernel loss: 0.06688\n",
      "Epoch: 11, series: 234, nllk loss: -2.03920, kernel loss: 0.07200\n",
      "Epoch: 11, series: 235, nllk loss: -2.56810, kernel loss: 0.02944\n",
      "Epoch: 11, series: 236, nllk loss: -1.46901, kernel loss: 0.08894\n",
      "Epoch: 11, series: 237, nllk loss: -2.04008, kernel loss: 0.06808\n",
      "Epoch: 11, series: 238, nllk loss: -1.78753, kernel loss: 0.09101\n",
      "Epoch: 11, series: 239, nllk loss: -2.16680, kernel loss: 0.09652\n",
      "Epoch: 11, series: 240, nllk loss: -1.06705, kernel loss: 0.01254\n",
      "Epoch: 11, series: 241, nllk loss: -1.87610, kernel loss: 0.24882\n",
      "Epoch: 11, series: 242, nllk loss: -2.01830, kernel loss: 0.05972\n",
      "Epoch: 11, series: 243, nllk loss: -2.22493, kernel loss: 0.23443\n",
      "Epoch: 11, series: 244, nllk loss: -1.78936, kernel loss: 0.15570\n",
      "Epoch: 11, series: 245, nllk loss: -2.11409, kernel loss: 0.15428\n",
      "Epoch: 11, series: 246, nllk loss: 0.23289, kernel loss: 0.30281\n",
      "Epoch: 11, series: 247, nllk loss: -1.56225, kernel loss: 0.25711\n",
      "Epoch: 11, series: 248, nllk loss: -1.95552, kernel loss: 0.08789\n",
      "Epoch: 11, series: 249, nllk loss: -1.72775, kernel loss: 0.18782\n",
      "Epoch: 11, series: 250, nllk loss: -1.63510, kernel loss: 0.08813\n",
      "Epoch: 11, series: 251, nllk loss: -1.02643, kernel loss: 0.15984\n",
      "Epoch: 11, series: 252, nllk loss: -1.26557, kernel loss: 0.15827\n",
      "Epoch: 11, series: 253, nllk loss: -1.86537, kernel loss: 0.09050\n",
      "Epoch: 11, series: 254, nllk loss: -2.24093, kernel loss: 0.16737\n",
      "Epoch: 11, series: 255, nllk loss: -2.03786, kernel loss: 0.19460\n",
      "Epoch: 11, series: 256, nllk loss: -1.83064, kernel loss: 0.21973\n",
      "Epoch: 11, series: 257, nllk loss: -2.04857, kernel loss: 0.18479\n",
      "Epoch: 11, series: 258, nllk loss: -1.95633, kernel loss: 0.16300\n",
      "Epoch: 11, series: 259, nllk loss: -1.69106, kernel loss: 0.01814\n",
      "Epoch: 11, series: 260, nllk loss: -1.93157, kernel loss: 0.09062\n",
      "Epoch: 11, series: 261, nllk loss: -2.11312, kernel loss: 0.08650\n",
      "Epoch: 11, series: 262, nllk loss: -2.47933, kernel loss: 0.06572\n",
      "Epoch: 11, series: 263, nllk loss: -0.66258, kernel loss: 0.04669\n",
      "Epoch: 11, series: 264, nllk loss: -1.92110, kernel loss: 0.07014\n",
      "Epoch: 11, series: 265, nllk loss: -1.64792, kernel loss: 0.11987\n",
      "Epoch: 11, series: 266, nllk loss: -2.21303, kernel loss: 0.12855\n",
      "Epoch: 11, series: 267, nllk loss: -2.05060, kernel loss: 0.19942\n",
      "Epoch: 11, series: 268, nllk loss: -2.26235, kernel loss: 0.01342\n",
      "Epoch: 11, series: 269, nllk loss: -1.84843, kernel loss: 0.02268\n",
      "Epoch: 11, series: 270, nllk loss: -1.60937, kernel loss: 0.22635\n",
      "Epoch: 11, series: 271, nllk loss: -1.80181, kernel loss: 0.27878\n",
      "Epoch: 11, series: 272, nllk loss: -1.91290, kernel loss: 0.18960\n",
      "Epoch: 11, series: 273, nllk loss: -1.97365, kernel loss: 0.02454\n",
      "Epoch: 11, series: 274, nllk loss: -1.30451, kernel loss: 0.01803\n",
      "Epoch: 11, series: 275, nllk loss: -1.67976, kernel loss: 0.03327\n",
      "Epoch: 11, series: 276, nllk loss: -1.18804, kernel loss: 0.10356\n",
      "Epoch: 11, series: 277, nllk loss: -2.08309, kernel loss: 0.09129\n",
      "Epoch: 11, series: 278, nllk loss: -1.80529, kernel loss: 0.18051\n",
      "Epoch: 11, series: 279, nllk loss: -2.26260, kernel loss: 0.12723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11, series: 280, nllk loss: -1.98270, kernel loss: 0.14783\n",
      "Epoch: 11, series: 281, nllk loss: -1.98684, kernel loss: 0.17127\n",
      "Epoch: 11, series: 282, nllk loss: -2.00119, kernel loss: 0.04654\n",
      "Epoch: 11, series: 283, nllk loss: -2.12026, kernel loss: 0.08359\n",
      "Epoch: 11, series: 284, nllk loss: -1.72287, kernel loss: 0.08774\n",
      "Epoch: 11, series: 285, nllk loss: -1.72633, kernel loss: 0.04227\n",
      "Epoch: 11, series: 286, nllk loss: -2.01725, kernel loss: 0.14810\n",
      "Epoch: 11, series: 287, nllk loss: -2.22240, kernel loss: 0.11528\n",
      "Epoch: 11, series: 288, nllk loss: -1.24328, kernel loss: 0.07126\n",
      "Epoch: 11, series: 289, nllk loss: -1.00755, kernel loss: 0.08990\n",
      "Epoch: 11, series: 290, nllk loss: -2.13750, kernel loss: 0.14875\n",
      "Epoch: 11, series: 291, nllk loss: -2.06802, kernel loss: 0.16590\n",
      "Epoch: 11, series: 292, nllk loss: -2.14293, kernel loss: 0.16709\n",
      "Epoch: 11, series: 293, nllk loss: -2.34915, kernel loss: 0.19975\n",
      "Epoch: 11, series: 294, nllk loss: -1.48996, kernel loss: 0.03619\n",
      "Epoch: 11, series: 295, nllk loss: -1.04856, kernel loss: 0.17450\n",
      "Epoch: 11, series: 296, nllk loss: -2.15031, kernel loss: 0.08687\n",
      "Epoch: 11, series: 297, nllk loss: -2.25844, kernel loss: 0.28908\n",
      "Epoch: 11, series: 298, nllk loss: 1.40618, kernel loss: 0.10334\n",
      "Epoch: 11, series: 299, nllk loss: 0.19236, kernel loss: 0.18232\n",
      "Epoch: 11, series: 300, nllk loss: -1.82760, kernel loss: 0.07375\n",
      "Epoch: 11, series: 301, nllk loss: -1.75569, kernel loss: 0.05588\n",
      "Epoch: 11, series: 302, nllk loss: -1.95750, kernel loss: 0.17276\n",
      "Epoch: 11, series: 303, nllk loss: -1.84508, kernel loss: 0.11754\n",
      "Epoch: 11, series: 304, nllk loss: 0.00493, kernel loss: 0.12442\n",
      "Epoch: 11, series: 305, nllk loss: -1.62548, kernel loss: 0.19334\n",
      "Epoch: 11, series: 306, nllk loss: -2.15558, kernel loss: 0.10355\n",
      "Epoch: 11, series: 307, nllk loss: -1.40325, kernel loss: 0.10946\n",
      "Epoch: 11, series: 308, nllk loss: -2.08493, kernel loss: 0.15983\n",
      "Epoch: 11, series: 309, nllk loss: -1.76147, kernel loss: 0.18527\n",
      "Epoch: 11, series: 310, nllk loss: -1.97407, kernel loss: 0.22059\n",
      "Epoch: 11, series: 311, nllk loss: -1.72148, kernel loss: 0.18578\n",
      "Epoch: 11, series: 312, nllk loss: -1.95164, kernel loss: 0.16458\n",
      "Epoch: 11, series: 313, nllk loss: -2.16109, kernel loss: 0.15372\n",
      "Epoch: 11, series: 314, nllk loss: -2.45559, kernel loss: 0.25179\n",
      "Epoch: 11, series: 315, nllk loss: -0.79191, kernel loss: 0.03053\n",
      "Epoch: 11, series: 316, nllk loss: -1.79874, kernel loss: 0.11770\n",
      "Epoch: 11, series: 317, nllk loss: 0.75675, kernel loss: 0.10156\n",
      "Epoch: 11, series: 318, nllk loss: 2.11281, kernel loss: 0.10008\n",
      "Epoch: 11, series: 319, nllk loss: -0.80727, kernel loss: 0.19885\n",
      "Epoch: 11, series: 320, nllk loss: -0.88191, kernel loss: 0.05159\n",
      "Epoch: 11, total loss: -424.28087\n",
      "Epoch: 12, series: 0, nllk loss: 2.03352, kernel loss: 0.06610\n",
      "Epoch: 12, series: 1, nllk loss: -0.92173, kernel loss: 0.10395\n",
      "Epoch: 12, series: 2, nllk loss: 0.22670, kernel loss: 0.10185\n",
      "Epoch: 12, series: 3, nllk loss: -1.03474, kernel loss: 0.05339\n",
      "Epoch: 12, series: 4, nllk loss: -0.79664, kernel loss: 0.15691\n",
      "Epoch: 12, series: 5, nllk loss: -0.95231, kernel loss: 0.36496\n",
      "Epoch: 12, series: 6, nllk loss: -0.45622, kernel loss: 0.39692\n",
      "Epoch: 12, series: 7, nllk loss: -1.05210, kernel loss: 0.17654\n",
      "Epoch: 12, series: 8, nllk loss: -0.57495, kernel loss: 0.20974\n",
      "Epoch: 12, series: 9, nllk loss: -0.49942, kernel loss: 0.25884\n",
      "Epoch: 12, series: 10, nllk loss: -1.21295, kernel loss: 0.17428\n",
      "Epoch: 12, series: 11, nllk loss: -0.97575, kernel loss: 0.20099\n",
      "Epoch: 12, series: 12, nllk loss: -1.36825, kernel loss: 0.20028\n",
      "Epoch: 12, series: 13, nllk loss: -1.17582, kernel loss: 0.07907\n",
      "Epoch: 12, series: 14, nllk loss: -1.34534, kernel loss: 0.20342\n",
      "Epoch: 12, series: 15, nllk loss: -1.32215, kernel loss: 0.15619\n",
      "Epoch: 12, series: 16, nllk loss: -1.03874, kernel loss: 0.23275\n",
      "Epoch: 12, series: 17, nllk loss: -1.08960, kernel loss: 0.34665\n",
      "Epoch: 12, series: 18, nllk loss: -1.21089, kernel loss: 0.04015\n",
      "Epoch: 12, series: 19, nllk loss: -0.31296, kernel loss: 0.22977\n",
      "Epoch: 12, series: 20, nllk loss: -0.77625, kernel loss: 0.09229\n",
      "Epoch: 12, series: 21, nllk loss: -1.04315, kernel loss: 0.16625\n",
      "Epoch: 12, series: 22, nllk loss: -1.36541, kernel loss: 0.18941\n",
      "Epoch: 12, series: 23, nllk loss: -1.31852, kernel loss: 0.04752\n",
      "Epoch: 12, series: 24, nllk loss: -1.49486, kernel loss: 0.06688\n",
      "Epoch: 12, series: 25, nllk loss: -1.48569, kernel loss: 0.01991\n",
      "Epoch: 12, series: 26, nllk loss: -1.30139, kernel loss: 0.28786\n",
      "Epoch: 12, series: 27, nllk loss: -1.17646, kernel loss: 0.28602\n",
      "Epoch: 12, series: 28, nllk loss: -1.27573, kernel loss: 0.15816\n",
      "Epoch: 12, series: 29, nllk loss: -0.75789, kernel loss: 0.04614\n",
      "Epoch: 12, series: 30, nllk loss: -1.36216, kernel loss: 0.03567\n",
      "Epoch: 12, series: 31, nllk loss: -1.11774, kernel loss: 0.13532\n",
      "Epoch: 12, series: 32, nllk loss: -1.09180, kernel loss: 0.04465\n",
      "Epoch: 12, series: 33, nllk loss: -0.97021, kernel loss: 0.16829\n",
      "Epoch: 12, series: 34, nllk loss: -1.30214, kernel loss: 0.14236\n",
      "Epoch: 12, series: 35, nllk loss: -1.56248, kernel loss: 0.02022\n",
      "Epoch: 12, series: 36, nllk loss: -1.47084, kernel loss: 0.10329\n",
      "Epoch: 12, series: 37, nllk loss: -0.44961, kernel loss: 0.13283\n",
      "Epoch: 12, series: 38, nllk loss: -1.02351, kernel loss: 0.05855\n",
      "Epoch: 12, series: 39, nllk loss: -0.78085, kernel loss: 0.06134\n",
      "Epoch: 12, series: 40, nllk loss: -1.74092, kernel loss: 0.03775\n",
      "Epoch: 12, series: 41, nllk loss: -1.35520, kernel loss: 0.17344\n",
      "Epoch: 12, series: 42, nllk loss: -1.06959, kernel loss: 0.07349\n",
      "Epoch: 12, series: 43, nllk loss: -1.05469, kernel loss: 0.14808\n",
      "Epoch: 12, series: 44, nllk loss: -1.47971, kernel loss: 0.03214\n",
      "Epoch: 12, series: 45, nllk loss: -1.58044, kernel loss: 0.12490\n",
      "Epoch: 12, series: 46, nllk loss: -1.59267, kernel loss: 0.22867\n",
      "Epoch: 12, series: 47, nllk loss: -1.53706, kernel loss: 0.06072\n",
      "Epoch: 12, series: 48, nllk loss: -1.60950, kernel loss: 0.05371\n",
      "Epoch: 12, series: 49, nllk loss: -1.24822, kernel loss: 0.23992\n",
      "Epoch: 12, series: 50, nllk loss: -0.00984, kernel loss: 0.12314\n",
      "Epoch: 12, series: 51, nllk loss: -1.36088, kernel loss: 0.16429\n",
      "Epoch: 12, series: 52, nllk loss: -0.35727, kernel loss: 0.10996\n",
      "Epoch: 12, series: 53, nllk loss: -1.60756, kernel loss: 0.08142\n",
      "Epoch: 12, series: 54, nllk loss: -1.30793, kernel loss: 0.11921\n",
      "Epoch: 12, series: 55, nllk loss: -0.94361, kernel loss: 0.18385\n",
      "Epoch: 12, series: 56, nllk loss: -1.38951, kernel loss: 0.10537\n",
      "Epoch: 12, series: 57, nllk loss: -1.31917, kernel loss: 0.26491\n",
      "Epoch: 12, series: 58, nllk loss: -1.40315, kernel loss: 0.07608\n",
      "Epoch: 12, series: 59, nllk loss: -1.16713, kernel loss: 0.05835\n",
      "Epoch: 12, series: 60, nllk loss: -1.07281, kernel loss: 0.10582\n",
      "Epoch: 12, series: 61, nllk loss: -1.60850, kernel loss: 0.24514\n",
      "Epoch: 12, series: 62, nllk loss: -1.69487, kernel loss: 0.10626\n",
      "Epoch: 12, series: 63, nllk loss: -1.55082, kernel loss: 0.19310\n",
      "Epoch: 12, series: 64, nllk loss: -1.04695, kernel loss: 0.00816\n",
      "Epoch: 12, series: 65, nllk loss: -1.52257, kernel loss: 0.18940\n",
      "Epoch: 12, series: 66, nllk loss: -1.51177, kernel loss: 0.22943\n",
      "Epoch: 12, series: 67, nllk loss: -1.36483, kernel loss: 0.03344\n",
      "Epoch: 12, series: 68, nllk loss: -0.77909, kernel loss: 0.13494\n",
      "Epoch: 12, series: 69, nllk loss: -1.45486, kernel loss: 0.05552\n",
      "Epoch: 12, series: 70, nllk loss: -1.40464, kernel loss: 0.09474\n",
      "Epoch: 12, series: 71, nllk loss: -1.41954, kernel loss: 0.05084\n",
      "Epoch: 12, series: 72, nllk loss: -1.74955, kernel loss: 0.09083\n",
      "Epoch: 12, series: 73, nllk loss: -1.28631, kernel loss: 0.13976\n",
      "Epoch: 12, series: 74, nllk loss: -1.89213, kernel loss: 0.06016\n",
      "Epoch: 12, series: 75, nllk loss: -1.46170, kernel loss: 0.18850\n",
      "Epoch: 12, series: 76, nllk loss: -1.42045, kernel loss: 0.08631\n",
      "Epoch: 12, series: 77, nllk loss: -1.22431, kernel loss: 0.16763\n",
      "Epoch: 12, series: 78, nllk loss: -1.32662, kernel loss: 0.26215\n",
      "Epoch: 12, series: 79, nllk loss: -0.53004, kernel loss: 0.14284\n",
      "Epoch: 12, series: 80, nllk loss: -1.73583, kernel loss: 0.15618\n",
      "Epoch: 12, series: 81, nllk loss: -1.22298, kernel loss: 0.16675\n",
      "Epoch: 12, series: 82, nllk loss: -0.20981, kernel loss: 0.13771\n",
      "Epoch: 12, series: 83, nllk loss: -0.82959, kernel loss: 0.04121\n",
      "Epoch: 12, series: 84, nllk loss: -1.18261, kernel loss: 0.12202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, series: 85, nllk loss: -1.32963, kernel loss: 0.05660\n",
      "Epoch: 12, series: 86, nllk loss: -0.48698, kernel loss: 0.00689\n",
      "Epoch: 12, series: 87, nllk loss: -1.63349, kernel loss: 0.07076\n",
      "Epoch: 12, series: 88, nllk loss: -1.85127, kernel loss: 0.07724\n",
      "Epoch: 12, series: 89, nllk loss: -1.84036, kernel loss: 0.05740\n",
      "Epoch: 12, series: 90, nllk loss: -1.99477, kernel loss: 0.09723\n",
      "Epoch: 12, series: 91, nllk loss: -2.01440, kernel loss: 0.07126\n",
      "Epoch: 12, series: 92, nllk loss: 0.41407, kernel loss: 0.10372\n",
      "Epoch: 12, series: 93, nllk loss: -2.22037, kernel loss: 0.19050\n",
      "Epoch: 12, series: 94, nllk loss: -2.20250, kernel loss: 0.31328\n",
      "Epoch: 12, series: 95, nllk loss: -2.19802, kernel loss: 0.06271\n",
      "Epoch: 12, series: 96, nllk loss: -1.50715, kernel loss: 0.23785\n",
      "Epoch: 12, series: 97, nllk loss: -0.62097, kernel loss: 0.12801\n",
      "Epoch: 12, series: 98, nllk loss: -0.82814, kernel loss: 0.11655\n",
      "Epoch: 12, series: 99, nllk loss: -1.38817, kernel loss: 0.05111\n",
      "Epoch: 12, series: 100, nllk loss: -0.83634, kernel loss: 0.26754\n",
      "Epoch: 12, series: 101, nllk loss: -1.35140, kernel loss: 0.13710\n",
      "Epoch: 12, series: 102, nllk loss: -0.86511, kernel loss: 0.20906\n",
      "Epoch: 12, series: 103, nllk loss: -1.18819, kernel loss: 0.13299\n",
      "Epoch: 12, series: 104, nllk loss: 0.29041, kernel loss: 0.06909\n",
      "Epoch: 12, series: 105, nllk loss: 0.13220, kernel loss: 0.09162\n",
      "Epoch: 12, series: 106, nllk loss: -1.07813, kernel loss: 0.22927\n",
      "Epoch: 12, series: 107, nllk loss: -0.96096, kernel loss: 0.08944\n",
      "Epoch: 12, series: 108, nllk loss: -1.34886, kernel loss: 0.03965\n",
      "Epoch: 12, series: 109, nllk loss: -1.10092, kernel loss: 0.15664\n",
      "Epoch: 12, series: 110, nllk loss: -1.61286, kernel loss: 0.04196\n",
      "Epoch: 12, series: 111, nllk loss: -1.45513, kernel loss: 0.38333\n",
      "Epoch: 12, series: 112, nllk loss: -0.85399, kernel loss: 0.15382\n",
      "Epoch: 12, series: 113, nllk loss: -1.05902, kernel loss: 0.41939\n",
      "Epoch: 12, series: 114, nllk loss: -1.11390, kernel loss: 0.26179\n",
      "Epoch: 12, series: 115, nllk loss: -0.94176, kernel loss: 0.39543\n",
      "Epoch: 12, series: 116, nllk loss: -1.63021, kernel loss: 0.11764\n",
      "Epoch: 12, series: 117, nllk loss: -0.52674, kernel loss: 0.15471\n",
      "Epoch: 12, series: 118, nllk loss: -1.69654, kernel loss: 0.12122\n",
      "Epoch: 12, series: 119, nllk loss: -0.73730, kernel loss: 0.03744\n",
      "Epoch: 12, series: 120, nllk loss: -1.53022, kernel loss: 0.11638\n",
      "Epoch: 12, series: 121, nllk loss: 0.15777, kernel loss: 0.17381\n",
      "Epoch: 12, series: 122, nllk loss: -0.56503, kernel loss: 0.17128\n",
      "Epoch: 12, series: 123, nllk loss: -1.56600, kernel loss: 0.12404\n",
      "Epoch: 12, series: 124, nllk loss: -1.65475, kernel loss: 0.18589\n",
      "Epoch: 12, series: 125, nllk loss: -1.35965, kernel loss: 0.18941\n",
      "Epoch: 12, series: 126, nllk loss: -1.60937, kernel loss: 0.09000\n",
      "Epoch: 12, series: 127, nllk loss: -1.37460, kernel loss: 0.23952\n",
      "Epoch: 12, series: 128, nllk loss: -1.00341, kernel loss: 0.07087\n",
      "Epoch: 12, series: 129, nllk loss: -0.71510, kernel loss: 0.13607\n",
      "Epoch: 12, series: 130, nllk loss: -1.29730, kernel loss: 0.02195\n",
      "Epoch: 12, series: 131, nllk loss: 0.65067, kernel loss: 0.14423\n",
      "Epoch: 12, series: 132, nllk loss: 0.14357, kernel loss: 0.22316\n",
      "Epoch: 12, series: 133, nllk loss: -0.92399, kernel loss: 0.02156\n",
      "Epoch: 12, series: 134, nllk loss: -0.71060, kernel loss: 0.14316\n",
      "Epoch: 12, series: 135, nllk loss: -1.43537, kernel loss: 0.07947\n",
      "Epoch: 12, series: 136, nllk loss: -1.45873, kernel loss: 0.10364\n",
      "Epoch: 12, series: 137, nllk loss: -1.56602, kernel loss: 0.06152\n",
      "Epoch: 12, series: 138, nllk loss: -1.66374, kernel loss: 0.05447\n",
      "Epoch: 12, series: 139, nllk loss: -1.63220, kernel loss: 0.06250\n",
      "Epoch: 12, series: 140, nllk loss: -1.45460, kernel loss: 0.09348\n",
      "Epoch: 12, series: 141, nllk loss: -1.64364, kernel loss: 0.04382\n",
      "Epoch: 12, series: 142, nllk loss: -1.61088, kernel loss: 0.07096\n",
      "Epoch: 12, series: 143, nllk loss: -1.63477, kernel loss: 0.10989\n",
      "Epoch: 12, series: 144, nllk loss: -1.90260, kernel loss: 0.21553\n",
      "Epoch: 12, series: 145, nllk loss: -1.84240, kernel loss: 0.06066\n",
      "Epoch: 12, series: 146, nllk loss: 3.18939, kernel loss: 0.20068\n",
      "Epoch: 12, series: 147, nllk loss: -1.58538, kernel loss: 0.17154\n",
      "Epoch: 12, series: 148, nllk loss: -1.43850, kernel loss: 0.26416\n",
      "Epoch: 12, series: 149, nllk loss: -1.70569, kernel loss: 0.14878\n",
      "Epoch: 12, series: 150, nllk loss: -1.80044, kernel loss: 0.08616\n",
      "Epoch: 12, series: 151, nllk loss: -1.84750, kernel loss: 0.06047\n",
      "Epoch: 12, series: 152, nllk loss: -1.71844, kernel loss: 0.09165\n",
      "Epoch: 12, series: 153, nllk loss: -1.46840, kernel loss: 0.01991\n",
      "Epoch: 12, series: 154, nllk loss: -1.54948, kernel loss: 0.02520\n",
      "Epoch: 12, series: 155, nllk loss: -1.69091, kernel loss: 0.06158\n",
      "Epoch: 12, series: 156, nllk loss: -1.81813, kernel loss: 0.11894\n",
      "Epoch: 12, series: 157, nllk loss: -1.34019, kernel loss: 0.06242\n",
      "Epoch: 12, series: 158, nllk loss: -1.80617, kernel loss: 0.08475\n",
      "Epoch: 12, series: 159, nllk loss: -1.85605, kernel loss: 0.03522\n",
      "Epoch: 12, series: 160, nllk loss: -1.74647, kernel loss: 0.13760\n",
      "Epoch: 12, series: 161, nllk loss: -1.63886, kernel loss: 0.08609\n",
      "Epoch: 12, series: 162, nllk loss: -1.91119, kernel loss: 0.10294\n",
      "Epoch: 12, series: 163, nllk loss: -2.16625, kernel loss: 0.07881\n",
      "Epoch: 12, series: 164, nllk loss: -1.75949, kernel loss: 0.17143\n",
      "Epoch: 12, series: 165, nllk loss: -1.87308, kernel loss: 0.18501\n",
      "Epoch: 12, series: 166, nllk loss: -1.32556, kernel loss: 0.14216\n",
      "Epoch: 12, series: 167, nllk loss: -2.32657, kernel loss: 0.30599\n",
      "Epoch: 12, series: 168, nllk loss: -1.99203, kernel loss: 0.11881\n",
      "Epoch: 12, series: 169, nllk loss: -2.15847, kernel loss: 0.04289\n",
      "Epoch: 12, series: 170, nllk loss: -1.83665, kernel loss: 0.08893\n",
      "Epoch: 12, series: 171, nllk loss: -2.23528, kernel loss: 0.13856\n",
      "Epoch: 12, series: 172, nllk loss: -1.96013, kernel loss: 0.10045\n",
      "Epoch: 12, series: 173, nllk loss: -2.43034, kernel loss: 0.10960\n",
      "Epoch: 12, series: 174, nllk loss: -2.05861, kernel loss: 0.16836\n",
      "Epoch: 12, series: 175, nllk loss: -2.34532, kernel loss: 0.14451\n",
      "Epoch: 12, series: 176, nllk loss: -2.04223, kernel loss: 0.04459\n",
      "Epoch: 12, series: 177, nllk loss: -1.95400, kernel loss: 0.20205\n",
      "Epoch: 12, series: 178, nllk loss: -1.70216, kernel loss: 0.19622\n",
      "Epoch: 12, series: 179, nllk loss: -2.15540, kernel loss: 0.08903\n",
      "Epoch: 12, series: 180, nllk loss: -2.11620, kernel loss: 0.04980\n",
      "Epoch: 12, series: 181, nllk loss: -2.39557, kernel loss: 0.13856\n",
      "Epoch: 12, series: 182, nllk loss: -2.05523, kernel loss: 0.02296\n",
      "Epoch: 12, series: 183, nllk loss: -2.00156, kernel loss: 0.07159\n",
      "Epoch: 12, series: 184, nllk loss: -1.85961, kernel loss: 0.31454\n",
      "Epoch: 12, series: 185, nllk loss: -1.55744, kernel loss: 0.20487\n",
      "Epoch: 12, series: 186, nllk loss: -2.42393, kernel loss: 0.17692\n",
      "Epoch: 12, series: 187, nllk loss: -2.57190, kernel loss: 0.26185\n",
      "Epoch: 12, series: 188, nllk loss: -1.57679, kernel loss: 0.26348\n",
      "Epoch: 12, series: 189, nllk loss: -1.45522, kernel loss: 0.12443\n",
      "Epoch: 12, series: 190, nllk loss: -1.80163, kernel loss: 0.07121\n",
      "Epoch: 12, series: 191, nllk loss: -1.81908, kernel loss: 0.20691\n",
      "Epoch: 12, series: 192, nllk loss: -2.05362, kernel loss: 0.15577\n",
      "Epoch: 12, series: 193, nllk loss: -1.57274, kernel loss: 0.18888\n",
      "Epoch: 12, series: 194, nllk loss: -1.40164, kernel loss: 0.19586\n",
      "Epoch: 12, series: 195, nllk loss: -2.32473, kernel loss: 0.00019\n",
      "Epoch: 12, series: 196, nllk loss: -1.85155, kernel loss: 0.16732\n",
      "Epoch: 12, series: 197, nllk loss: -2.03671, kernel loss: 0.15560\n",
      "Epoch: 12, series: 198, nllk loss: -2.16376, kernel loss: 0.15315\n",
      "Epoch: 12, series: 199, nllk loss: -1.93038, kernel loss: 0.13731\n",
      "Epoch: 12, series: 200, nllk loss: -2.29780, kernel loss: 0.03009\n",
      "Epoch: 12, series: 201, nllk loss: -2.25788, kernel loss: 0.20186\n",
      "Epoch: 12, series: 202, nllk loss: -2.01963, kernel loss: 0.20332\n",
      "Epoch: 12, series: 203, nllk loss: -1.91789, kernel loss: 0.10370\n",
      "Epoch: 12, series: 204, nllk loss: -1.00653, kernel loss: 0.09332\n",
      "Epoch: 12, series: 205, nllk loss: -2.12507, kernel loss: 0.17750\n",
      "Epoch: 12, series: 206, nllk loss: -2.12337, kernel loss: 0.16220\n",
      "Epoch: 12, series: 207, nllk loss: -0.89583, kernel loss: 0.25619\n",
      "Epoch: 12, series: 208, nllk loss: -2.32198, kernel loss: 0.22917\n",
      "Epoch: 12, series: 209, nllk loss: -1.75447, kernel loss: 0.33908\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12, series: 210, nllk loss: -2.51041, kernel loss: 0.17963\n",
      "Epoch: 12, series: 211, nllk loss: -2.16195, kernel loss: 0.09035\n",
      "Epoch: 12, series: 212, nllk loss: -1.53736, kernel loss: 0.18805\n",
      "Epoch: 12, series: 213, nllk loss: -2.07917, kernel loss: 0.12190\n",
      "Epoch: 12, series: 214, nllk loss: -2.01264, kernel loss: 0.11138\n",
      "Epoch: 12, series: 215, nllk loss: -2.34780, kernel loss: 0.17643\n",
      "Epoch: 12, series: 216, nllk loss: -1.17988, kernel loss: 0.11321\n",
      "Epoch: 12, series: 217, nllk loss: -2.04226, kernel loss: 0.03301\n",
      "Epoch: 12, series: 218, nllk loss: -1.51708, kernel loss: 0.02001\n",
      "Epoch: 12, series: 219, nllk loss: -2.03089, kernel loss: 0.12859\n",
      "Epoch: 12, series: 220, nllk loss: -2.05473, kernel loss: 0.26285\n",
      "Epoch: 12, series: 221, nllk loss: -2.27994, kernel loss: 0.14110\n",
      "Epoch: 12, series: 222, nllk loss: -2.14116, kernel loss: 0.15034\n",
      "Epoch: 12, series: 223, nllk loss: -1.69888, kernel loss: 0.19727\n",
      "Epoch: 12, series: 224, nllk loss: -2.42231, kernel loss: 0.04244\n",
      "Epoch: 12, series: 225, nllk loss: -2.21589, kernel loss: 0.14988\n",
      "Epoch: 12, series: 226, nllk loss: -1.77007, kernel loss: 0.12660\n",
      "Epoch: 12, series: 227, nllk loss: -2.07340, kernel loss: 0.07308\n",
      "Epoch: 12, series: 228, nllk loss: -2.21574, kernel loss: 0.05794\n",
      "Epoch: 12, series: 229, nllk loss: -1.97883, kernel loss: 0.02801\n",
      "Epoch: 12, series: 230, nllk loss: -2.21080, kernel loss: 0.26857\n",
      "Epoch: 12, series: 231, nllk loss: -1.80855, kernel loss: 0.30675\n",
      "Epoch: 12, series: 232, nllk loss: -2.58920, kernel loss: 0.16147\n",
      "Epoch: 12, series: 233, nllk loss: -2.23333, kernel loss: 0.11376\n",
      "Epoch: 12, series: 234, nllk loss: -1.79858, kernel loss: 0.20609\n",
      "Epoch: 12, series: 235, nllk loss: -2.53894, kernel loss: 0.14578\n",
      "Epoch: 12, series: 236, nllk loss: -1.44397, kernel loss: 0.20625\n",
      "Epoch: 12, series: 237, nllk loss: -2.04403, kernel loss: 0.08508\n",
      "Epoch: 12, series: 238, nllk loss: -1.99548, kernel loss: 0.30848\n",
      "Epoch: 12, series: 239, nllk loss: -2.39489, kernel loss: 0.17006\n",
      "Epoch: 12, series: 240, nllk loss: -1.04410, kernel loss: 0.09949\n",
      "Epoch: 12, series: 241, nllk loss: -1.98068, kernel loss: 0.23347\n",
      "Epoch: 12, series: 242, nllk loss: -2.02258, kernel loss: 0.14538\n",
      "Epoch: 12, series: 243, nllk loss: -2.20586, kernel loss: 0.09606\n",
      "Epoch: 12, series: 244, nllk loss: -1.82967, kernel loss: 0.11013\n",
      "Epoch: 12, series: 245, nllk loss: -2.18508, kernel loss: 0.12840\n",
      "Epoch: 12, series: 246, nllk loss: 0.02736, kernel loss: 0.20889\n",
      "Epoch: 12, series: 247, nllk loss: -1.68540, kernel loss: 0.17732\n",
      "Epoch: 12, series: 248, nllk loss: -1.93414, kernel loss: 0.20706\n",
      "Epoch: 12, series: 249, nllk loss: -1.87173, kernel loss: 0.17601\n",
      "Epoch: 12, series: 250, nllk loss: -1.71878, kernel loss: 0.18954\n",
      "Epoch: 12, series: 251, nllk loss: -1.16394, kernel loss: 0.15393\n",
      "Epoch: 12, series: 252, nllk loss: -1.35397, kernel loss: 0.01423\n",
      "Epoch: 12, series: 253, nllk loss: -1.74130, kernel loss: 0.09261\n",
      "Epoch: 12, series: 254, nllk loss: -2.27928, kernel loss: 0.08100\n",
      "Epoch: 12, series: 255, nllk loss: -2.13692, kernel loss: 0.06750\n",
      "Epoch: 12, series: 256, nllk loss: -1.84192, kernel loss: 0.30955\n",
      "Epoch: 12, series: 257, nllk loss: -2.05803, kernel loss: 0.13137\n",
      "Epoch: 12, series: 258, nllk loss: -1.98170, kernel loss: 0.11976\n",
      "Epoch: 12, series: 259, nllk loss: -1.82150, kernel loss: 0.06215\n",
      "Epoch: 12, series: 260, nllk loss: -1.92778, kernel loss: 0.17241\n",
      "Epoch: 12, series: 261, nllk loss: -1.93081, kernel loss: 0.18167\n",
      "Epoch: 12, series: 262, nllk loss: -2.52715, kernel loss: 0.30969\n",
      "Epoch: 12, series: 263, nllk loss: -0.64209, kernel loss: 0.28916\n",
      "Epoch: 12, series: 264, nllk loss: -1.92942, kernel loss: 0.07814\n",
      "Epoch: 12, series: 265, nllk loss: -1.60866, kernel loss: 0.17780\n",
      "Epoch: 12, series: 266, nllk loss: -2.14951, kernel loss: 0.07740\n",
      "Epoch: 12, series: 267, nllk loss: -1.98974, kernel loss: 0.13283\n",
      "Epoch: 12, series: 268, nllk loss: -2.10802, kernel loss: 0.13839\n",
      "Epoch: 12, series: 269, nllk loss: -1.87263, kernel loss: 0.01883\n",
      "Epoch: 12, series: 270, nllk loss: -1.77084, kernel loss: 0.21714\n",
      "Epoch: 12, series: 271, nllk loss: -1.84957, kernel loss: 0.28161\n",
      "Epoch: 12, series: 272, nllk loss: -1.65384, kernel loss: 0.14633\n",
      "Epoch: 12, series: 273, nllk loss: -1.94751, kernel loss: 0.07221\n",
      "Epoch: 12, series: 274, nllk loss: -1.63684, kernel loss: 0.12814\n",
      "Epoch: 12, series: 275, nllk loss: -1.83131, kernel loss: 0.21566\n",
      "Epoch: 12, series: 276, nllk loss: -1.15674, kernel loss: 0.13986\n",
      "Epoch: 12, series: 277, nllk loss: -2.02755, kernel loss: 0.19715\n",
      "Epoch: 12, series: 278, nllk loss: -1.86873, kernel loss: 0.18417\n",
      "Epoch: 12, series: 279, nllk loss: -2.21467, kernel loss: 0.04296\n",
      "Epoch: 12, series: 280, nllk loss: -2.07645, kernel loss: 0.10975\n",
      "Epoch: 12, series: 281, nllk loss: -2.20825, kernel loss: 0.00196\n",
      "Epoch: 12, series: 282, nllk loss: -2.12266, kernel loss: 0.04076\n",
      "Epoch: 12, series: 283, nllk loss: -2.05425, kernel loss: 0.08105\n",
      "Epoch: 12, series: 284, nllk loss: -1.71200, kernel loss: 0.16560\n",
      "Epoch: 12, series: 285, nllk loss: -1.83486, kernel loss: 0.26613\n",
      "Epoch: 12, series: 286, nllk loss: -2.17000, kernel loss: 0.16780\n",
      "Epoch: 12, series: 287, nllk loss: -2.44165, kernel loss: 0.06831\n",
      "Epoch: 12, series: 288, nllk loss: -1.21198, kernel loss: 0.05366\n",
      "Epoch: 12, series: 289, nllk loss: -0.80510, kernel loss: 0.07782\n",
      "Epoch: 12, series: 290, nllk loss: -2.03872, kernel loss: 0.21718\n",
      "Epoch: 12, series: 291, nllk loss: -2.12057, kernel loss: 0.14160\n",
      "Epoch: 12, series: 292, nllk loss: -2.03238, kernel loss: 0.07188\n",
      "Epoch: 12, series: 293, nllk loss: -2.31205, kernel loss: 0.05730\n",
      "Epoch: 12, series: 294, nllk loss: -1.52066, kernel loss: 0.18173\n",
      "Epoch: 12, series: 295, nllk loss: -1.14939, kernel loss: 0.11826\n",
      "Epoch: 12, series: 296, nllk loss: -2.17554, kernel loss: 0.57911\n",
      "Epoch: 12, series: 297, nllk loss: -2.27407, kernel loss: 0.17435\n",
      "Epoch: 12, series: 298, nllk loss: 1.50629, kernel loss: 0.11907\n",
      "Epoch: 12, series: 299, nllk loss: -0.16630, kernel loss: 0.08135\n",
      "Epoch: 12, series: 300, nllk loss: -1.89808, kernel loss: 0.07392\n",
      "Epoch: 12, series: 301, nllk loss: -2.04707, kernel loss: 0.09186\n",
      "Epoch: 12, series: 302, nllk loss: -2.11327, kernel loss: 0.12491\n",
      "Epoch: 12, series: 303, nllk loss: -1.79680, kernel loss: 0.04960\n",
      "Epoch: 12, series: 304, nllk loss: 0.03801, kernel loss: 0.27168\n",
      "Epoch: 12, series: 305, nllk loss: -1.59537, kernel loss: 0.24095\n",
      "Epoch: 12, series: 306, nllk loss: -2.16228, kernel loss: 0.14782\n",
      "Epoch: 12, series: 307, nllk loss: -1.58806, kernel loss: 0.02713\n",
      "Epoch: 12, series: 308, nllk loss: -2.13005, kernel loss: 0.07742\n",
      "Epoch: 12, series: 309, nllk loss: -1.87493, kernel loss: 0.01354\n",
      "Epoch: 12, series: 310, nllk loss: -1.99652, kernel loss: 0.03257\n",
      "Epoch: 12, series: 311, nllk loss: -1.74329, kernel loss: 0.14093\n",
      "Epoch: 12, series: 312, nllk loss: -1.93840, kernel loss: 0.29051\n",
      "Epoch: 12, series: 313, nllk loss: -2.22306, kernel loss: 0.13162\n",
      "Epoch: 12, series: 314, nllk loss: -2.48626, kernel loss: 0.07644\n",
      "Epoch: 12, series: 315, nllk loss: -0.72765, kernel loss: 0.19520\n",
      "Epoch: 12, series: 316, nllk loss: -1.87101, kernel loss: 0.14207\n",
      "Epoch: 12, series: 317, nllk loss: 0.63926, kernel loss: 0.05418\n",
      "Epoch: 12, series: 318, nllk loss: 1.95304, kernel loss: 0.34111\n",
      "Epoch: 12, series: 319, nllk loss: -0.86810, kernel loss: 0.10978\n",
      "Epoch: 12, series: 320, nllk loss: -0.87017, kernel loss: 0.05199\n",
      "Epoch: 12, total loss: -434.83511\n",
      "Epoch: 13, series: 0, nllk loss: 1.93833, kernel loss: 0.14925\n",
      "Epoch: 13, series: 1, nllk loss: -0.91181, kernel loss: 0.23407\n",
      "Epoch: 13, series: 2, nllk loss: 0.09761, kernel loss: 0.06146\n",
      "Epoch: 13, series: 3, nllk loss: -1.06949, kernel loss: 0.23038\n",
      "Epoch: 13, series: 4, nllk loss: -0.75060, kernel loss: 0.31539\n",
      "Epoch: 13, series: 5, nllk loss: -1.05499, kernel loss: 0.20515\n",
      "Epoch: 13, series: 6, nllk loss: -0.41484, kernel loss: 0.40194\n",
      "Epoch: 13, series: 7, nllk loss: -1.03494, kernel loss: 0.27098\n",
      "Epoch: 13, series: 8, nllk loss: -0.54507, kernel loss: 0.12262\n",
      "Epoch: 13, series: 9, nllk loss: -0.54200, kernel loss: 0.12047\n",
      "Epoch: 13, series: 10, nllk loss: -1.16801, kernel loss: 0.09718\n",
      "Epoch: 13, series: 11, nllk loss: -1.02106, kernel loss: 0.10930\n",
      "Epoch: 13, series: 12, nllk loss: -1.37591, kernel loss: 0.19867\n",
      "Epoch: 13, series: 13, nllk loss: -1.25117, kernel loss: 0.27647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, series: 14, nllk loss: -1.40085, kernel loss: 0.21507\n",
      "Epoch: 13, series: 15, nllk loss: -1.42499, kernel loss: 0.14306\n",
      "Epoch: 13, series: 16, nllk loss: -0.99244, kernel loss: 0.22361\n",
      "Epoch: 13, series: 17, nllk loss: -1.10846, kernel loss: 0.13217\n",
      "Epoch: 13, series: 18, nllk loss: -1.36703, kernel loss: 0.39646\n",
      "Epoch: 13, series: 19, nllk loss: -0.29797, kernel loss: 0.21138\n",
      "Epoch: 13, series: 20, nllk loss: -0.84428, kernel loss: 0.16225\n",
      "Epoch: 13, series: 21, nllk loss: -1.10233, kernel loss: 0.15314\n",
      "Epoch: 13, series: 22, nllk loss: -1.40496, kernel loss: 0.08160\n",
      "Epoch: 13, series: 23, nllk loss: -1.38667, kernel loss: 0.05048\n",
      "Epoch: 13, series: 24, nllk loss: -1.53159, kernel loss: 0.25215\n",
      "Epoch: 13, series: 25, nllk loss: -1.43186, kernel loss: 0.06505\n",
      "Epoch: 13, series: 26, nllk loss: -1.34493, kernel loss: 0.39213\n",
      "Epoch: 13, series: 27, nllk loss: -1.16333, kernel loss: 0.24155\n",
      "Epoch: 13, series: 28, nllk loss: -1.33998, kernel loss: 0.17763\n",
      "Epoch: 13, series: 29, nllk loss: -0.64309, kernel loss: 0.14852\n",
      "Epoch: 13, series: 30, nllk loss: -1.38071, kernel loss: 0.08939\n",
      "Epoch: 13, series: 31, nllk loss: -1.07059, kernel loss: 0.19666\n",
      "Epoch: 13, series: 32, nllk loss: -1.12648, kernel loss: 0.14650\n",
      "Epoch: 13, series: 33, nllk loss: -0.99029, kernel loss: 0.25587\n",
      "Epoch: 13, series: 34, nllk loss: -1.38253, kernel loss: 0.04640\n",
      "Epoch: 13, series: 35, nllk loss: -1.55544, kernel loss: 0.24365\n",
      "Epoch: 13, series: 36, nllk loss: -1.40980, kernel loss: 0.17187\n",
      "Epoch: 13, series: 37, nllk loss: -0.44986, kernel loss: 0.13674\n",
      "Epoch: 13, series: 38, nllk loss: -1.08795, kernel loss: 0.05286\n",
      "Epoch: 13, series: 39, nllk loss: -0.80800, kernel loss: 0.07217\n",
      "Epoch: 13, series: 40, nllk loss: -1.77909, kernel loss: 0.10090\n",
      "Epoch: 13, series: 41, nllk loss: -1.36398, kernel loss: 0.02138\n",
      "Epoch: 13, series: 42, nllk loss: -1.07991, kernel loss: 0.31733\n",
      "Epoch: 13, series: 43, nllk loss: -1.01240, kernel loss: 0.12510\n",
      "Epoch: 13, series: 44, nllk loss: -1.51275, kernel loss: 0.06102\n",
      "Epoch: 13, series: 45, nllk loss: -1.65197, kernel loss: 0.10640\n",
      "Epoch: 13, series: 46, nllk loss: -1.62456, kernel loss: 0.01781\n",
      "Epoch: 13, series: 47, nllk loss: -1.52051, kernel loss: 0.02361\n",
      "Epoch: 13, series: 48, nllk loss: -1.57154, kernel loss: 0.11596\n",
      "Epoch: 13, series: 49, nllk loss: -1.17713, kernel loss: 0.11474\n",
      "Epoch: 13, series: 50, nllk loss: 0.11301, kernel loss: 0.09678\n",
      "Epoch: 13, series: 51, nllk loss: -1.38574, kernel loss: 0.04705\n",
      "Epoch: 13, series: 52, nllk loss: -0.38866, kernel loss: 0.13478\n",
      "Epoch: 13, series: 53, nllk loss: -1.60715, kernel loss: 0.04936\n",
      "Epoch: 13, series: 54, nllk loss: -1.27297, kernel loss: 0.11170\n",
      "Epoch: 13, series: 55, nllk loss: -0.91320, kernel loss: 0.10333\n",
      "Epoch: 13, series: 56, nllk loss: -1.36397, kernel loss: 0.08995\n",
      "Epoch: 13, series: 57, nllk loss: -1.36064, kernel loss: 0.08225\n",
      "Epoch: 13, series: 58, nllk loss: -1.45504, kernel loss: 0.16713\n",
      "Epoch: 13, series: 59, nllk loss: -1.23177, kernel loss: 0.20108\n",
      "Epoch: 13, series: 60, nllk loss: -1.07813, kernel loss: 0.22971\n",
      "Epoch: 13, series: 61, nllk loss: -1.58230, kernel loss: 0.22800\n",
      "Epoch: 13, series: 62, nllk loss: -1.71998, kernel loss: 0.18163\n",
      "Epoch: 13, series: 63, nllk loss: -1.57295, kernel loss: 0.15130\n",
      "Epoch: 13, series: 64, nllk loss: -1.06064, kernel loss: 0.05462\n",
      "Epoch: 13, series: 65, nllk loss: -1.56379, kernel loss: 0.07522\n",
      "Epoch: 13, series: 66, nllk loss: -1.52583, kernel loss: 0.09097\n",
      "Epoch: 13, series: 67, nllk loss: -1.37390, kernel loss: 0.11158\n",
      "Epoch: 13, series: 68, nllk loss: -0.68683, kernel loss: 0.09453\n",
      "Epoch: 13, series: 69, nllk loss: -1.46791, kernel loss: 0.25967\n",
      "Epoch: 13, series: 70, nllk loss: -1.40021, kernel loss: 0.03102\n",
      "Epoch: 13, series: 71, nllk loss: -1.46839, kernel loss: 0.11132\n",
      "Epoch: 13, series: 72, nllk loss: -1.76763, kernel loss: 0.05656\n",
      "Epoch: 13, series: 73, nllk loss: -1.27658, kernel loss: 0.07204\n",
      "Epoch: 13, series: 74, nllk loss: -1.91920, kernel loss: 0.08148\n",
      "Epoch: 13, series: 75, nllk loss: -1.44771, kernel loss: 0.06063\n",
      "Epoch: 13, series: 76, nllk loss: -1.40442, kernel loss: 0.35185\n",
      "Epoch: 13, series: 77, nllk loss: -1.27343, kernel loss: 0.11838\n",
      "Epoch: 13, series: 78, nllk loss: -1.45957, kernel loss: 0.05771\n",
      "Epoch: 13, series: 79, nllk loss: -0.41018, kernel loss: 0.11877\n",
      "Epoch: 13, series: 80, nllk loss: -1.77066, kernel loss: 0.09218\n",
      "Epoch: 13, series: 81, nllk loss: -1.26888, kernel loss: 0.06553\n",
      "Epoch: 13, series: 82, nllk loss: -0.30171, kernel loss: 0.15716\n",
      "Epoch: 13, series: 83, nllk loss: -0.91789, kernel loss: 0.17018\n",
      "Epoch: 13, series: 84, nllk loss: -1.10235, kernel loss: 0.15538\n",
      "Epoch: 13, series: 85, nllk loss: -1.44403, kernel loss: 0.09918\n",
      "Epoch: 13, series: 86, nllk loss: -0.55125, kernel loss: 0.07511\n",
      "Epoch: 13, series: 87, nllk loss: -1.66731, kernel loss: 0.08144\n",
      "Epoch: 13, series: 88, nllk loss: -1.98399, kernel loss: 0.16089\n",
      "Epoch: 13, series: 89, nllk loss: -1.90855, kernel loss: 0.16213\n",
      "Epoch: 13, series: 90, nllk loss: -2.09043, kernel loss: 0.10279\n",
      "Epoch: 13, series: 91, nllk loss: -2.04300, kernel loss: 0.15291\n",
      "Epoch: 13, series: 92, nllk loss: 0.55102, kernel loss: 0.44080\n",
      "Epoch: 13, series: 93, nllk loss: -2.28026, kernel loss: 0.06814\n",
      "Epoch: 13, series: 94, nllk loss: -2.26571, kernel loss: 0.18078\n",
      "Epoch: 13, series: 95, nllk loss: -2.23330, kernel loss: 0.03795\n",
      "Epoch: 13, series: 96, nllk loss: -1.60632, kernel loss: 0.10118\n",
      "Epoch: 13, series: 97, nllk loss: -0.67069, kernel loss: 0.10993\n",
      "Epoch: 13, series: 98, nllk loss: -0.83307, kernel loss: 0.11261\n",
      "Epoch: 13, series: 99, nllk loss: -1.36127, kernel loss: 0.05793\n",
      "Epoch: 13, series: 100, nllk loss: -0.88213, kernel loss: 0.14756\n",
      "Epoch: 13, series: 101, nllk loss: -1.41497, kernel loss: 0.31021\n",
      "Epoch: 13, series: 102, nllk loss: -0.81046, kernel loss: 0.13415\n",
      "Epoch: 13, series: 103, nllk loss: -1.09948, kernel loss: 0.06615\n",
      "Epoch: 13, series: 104, nllk loss: 0.31697, kernel loss: 0.14875\n",
      "Epoch: 13, series: 105, nllk loss: -0.09733, kernel loss: 0.08089\n",
      "Epoch: 13, series: 106, nllk loss: -1.17796, kernel loss: 0.11974\n",
      "Epoch: 13, series: 107, nllk loss: -0.86196, kernel loss: 0.17740\n",
      "Epoch: 13, series: 108, nllk loss: -1.28014, kernel loss: 0.13213\n",
      "Epoch: 13, series: 109, nllk loss: -1.12268, kernel loss: 0.11612\n",
      "Epoch: 13, series: 110, nllk loss: -1.61268, kernel loss: 0.05207\n",
      "Epoch: 13, series: 111, nllk loss: -1.42606, kernel loss: 0.18986\n",
      "Epoch: 13, series: 112, nllk loss: -0.79827, kernel loss: 0.07145\n",
      "Epoch: 13, series: 113, nllk loss: -1.04682, kernel loss: 0.30455\n",
      "Epoch: 13, series: 114, nllk loss: -1.13348, kernel loss: 0.02482\n",
      "Epoch: 13, series: 115, nllk loss: -0.90508, kernel loss: 0.05818\n",
      "Epoch: 13, series: 116, nllk loss: -1.59004, kernel loss: 0.23397\n",
      "Epoch: 13, series: 117, nllk loss: -0.60523, kernel loss: 0.15084\n",
      "Epoch: 13, series: 118, nllk loss: -1.72440, kernel loss: 0.12000\n",
      "Epoch: 13, series: 119, nllk loss: -0.60404, kernel loss: 0.13687\n",
      "Epoch: 13, series: 120, nllk loss: -1.45178, kernel loss: 0.06885\n",
      "Epoch: 13, series: 121, nllk loss: 0.27030, kernel loss: 0.03014\n",
      "Epoch: 13, series: 122, nllk loss: -0.50891, kernel loss: 0.07292\n",
      "Epoch: 13, series: 123, nllk loss: -1.55838, kernel loss: 0.15569\n",
      "Epoch: 13, series: 124, nllk loss: -1.68397, kernel loss: 0.02827\n",
      "Epoch: 13, series: 125, nllk loss: -1.36130, kernel loss: 0.11412\n",
      "Epoch: 13, series: 126, nllk loss: -1.60930, kernel loss: 0.08685\n",
      "Epoch: 13, series: 127, nllk loss: -1.38214, kernel loss: 0.07380\n",
      "Epoch: 13, series: 128, nllk loss: -0.98788, kernel loss: 0.01414\n",
      "Epoch: 13, series: 129, nllk loss: -0.73131, kernel loss: 0.20285\n",
      "Epoch: 13, series: 130, nllk loss: -1.34954, kernel loss: 0.13642\n",
      "Epoch: 13, series: 131, nllk loss: 0.46779, kernel loss: 0.03426\n",
      "Epoch: 13, series: 132, nllk loss: 0.04891, kernel loss: 0.16126\n",
      "Epoch: 13, series: 133, nllk loss: -0.91096, kernel loss: 0.05095\n",
      "Epoch: 13, series: 134, nllk loss: -0.73306, kernel loss: 0.05413\n",
      "Epoch: 13, series: 135, nllk loss: -1.43006, kernel loss: 0.09820\n",
      "Epoch: 13, series: 136, nllk loss: -1.49578, kernel loss: 0.17306\n",
      "Epoch: 13, series: 137, nllk loss: -1.62833, kernel loss: 0.21410\n",
      "Epoch: 13, series: 138, nllk loss: -1.72544, kernel loss: 0.08548\n",
      "Epoch: 13, series: 139, nllk loss: -1.70433, kernel loss: 0.11257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, series: 140, nllk loss: -1.49487, kernel loss: 0.12319\n",
      "Epoch: 13, series: 141, nllk loss: -1.66833, kernel loss: 0.19443\n",
      "Epoch: 13, series: 142, nllk loss: -1.74372, kernel loss: 0.14806\n",
      "Epoch: 13, series: 143, nllk loss: -1.69539, kernel loss: 0.24165\n",
      "Epoch: 13, series: 144, nllk loss: -1.99188, kernel loss: 0.40389\n",
      "Epoch: 13, series: 145, nllk loss: -1.90451, kernel loss: 0.25048\n",
      "Epoch: 13, series: 146, nllk loss: 3.20463, kernel loss: 0.13559\n",
      "Epoch: 13, series: 147, nllk loss: -1.61234, kernel loss: 0.21732\n",
      "Epoch: 13, series: 148, nllk loss: -1.50508, kernel loss: 0.28244\n",
      "Epoch: 13, series: 149, nllk loss: -1.71034, kernel loss: 0.08308\n",
      "Epoch: 13, series: 150, nllk loss: -1.82715, kernel loss: 0.09180\n",
      "Epoch: 13, series: 151, nllk loss: -1.90522, kernel loss: 0.15179\n",
      "Epoch: 13, series: 152, nllk loss: -1.82756, kernel loss: 0.14371\n",
      "Epoch: 13, series: 153, nllk loss: -1.60303, kernel loss: 0.07030\n",
      "Epoch: 13, series: 154, nllk loss: -1.57183, kernel loss: 0.11751\n",
      "Epoch: 13, series: 155, nllk loss: -1.70375, kernel loss: 0.17310\n",
      "Epoch: 13, series: 156, nllk loss: -1.82348, kernel loss: 0.07917\n",
      "Epoch: 13, series: 157, nllk loss: -1.31689, kernel loss: 0.46327\n",
      "Epoch: 13, series: 158, nllk loss: -1.85115, kernel loss: 0.08768\n",
      "Epoch: 13, series: 159, nllk loss: -1.91029, kernel loss: 0.03021\n",
      "Epoch: 13, series: 160, nllk loss: -1.80773, kernel loss: 0.11181\n",
      "Epoch: 13, series: 161, nllk loss: -1.65052, kernel loss: 0.34221\n",
      "Epoch: 13, series: 162, nllk loss: -1.93062, kernel loss: 0.05308\n",
      "Epoch: 13, series: 163, nllk loss: -2.21998, kernel loss: 0.11903\n",
      "Epoch: 13, series: 164, nllk loss: -1.80576, kernel loss: 0.09174\n",
      "Epoch: 13, series: 165, nllk loss: -1.84880, kernel loss: 0.08086\n",
      "Epoch: 13, series: 166, nllk loss: -1.28810, kernel loss: 0.04254\n",
      "Epoch: 13, series: 167, nllk loss: -2.42249, kernel loss: 0.04704\n",
      "Epoch: 13, series: 168, nllk loss: -2.12890, kernel loss: 0.10143\n",
      "Epoch: 13, series: 169, nllk loss: -2.25240, kernel loss: 0.11625\n",
      "Epoch: 13, series: 170, nllk loss: -1.85773, kernel loss: 0.01732\n",
      "Epoch: 13, series: 171, nllk loss: -2.37862, kernel loss: 0.08433\n",
      "Epoch: 13, series: 172, nllk loss: -1.94697, kernel loss: 0.12697\n",
      "Epoch: 13, series: 173, nllk loss: -2.50156, kernel loss: 0.16050\n",
      "Epoch: 13, series: 174, nllk loss: -2.04454, kernel loss: 0.37823\n",
      "Epoch: 13, series: 175, nllk loss: -2.43271, kernel loss: 0.12285\n",
      "Epoch: 13, series: 176, nllk loss: -2.10759, kernel loss: 0.14005\n",
      "Epoch: 13, series: 177, nllk loss: -1.94330, kernel loss: 0.11797\n",
      "Epoch: 13, series: 178, nllk loss: -1.67712, kernel loss: 0.24139\n",
      "Epoch: 13, series: 179, nllk loss: -2.08290, kernel loss: 0.07496\n",
      "Epoch: 13, series: 180, nllk loss: -2.13736, kernel loss: 0.18466\n",
      "Epoch: 13, series: 181, nllk loss: -2.34132, kernel loss: 0.09885\n",
      "Epoch: 13, series: 182, nllk loss: -2.17194, kernel loss: 0.10427\n",
      "Epoch: 13, series: 183, nllk loss: -1.97024, kernel loss: 0.26433\n",
      "Epoch: 13, series: 184, nllk loss: -1.82096, kernel loss: 0.13642\n",
      "Epoch: 13, series: 185, nllk loss: -1.54559, kernel loss: 0.13974\n",
      "Epoch: 13, series: 186, nllk loss: -2.50242, kernel loss: 0.12648\n",
      "Epoch: 13, series: 187, nllk loss: -2.63182, kernel loss: 0.25768\n",
      "Epoch: 13, series: 188, nllk loss: -1.75541, kernel loss: 0.09613\n",
      "Epoch: 13, series: 189, nllk loss: -1.47870, kernel loss: 0.28179\n",
      "Epoch: 13, series: 190, nllk loss: -1.93511, kernel loss: 0.14078\n",
      "Epoch: 13, series: 191, nllk loss: -1.88674, kernel loss: 0.06733\n",
      "Epoch: 13, series: 192, nllk loss: -2.11231, kernel loss: 0.34312\n",
      "Epoch: 13, series: 193, nllk loss: -1.53766, kernel loss: 0.12259\n",
      "Epoch: 13, series: 194, nllk loss: -1.35715, kernel loss: 0.06122\n",
      "Epoch: 13, series: 195, nllk loss: -2.21465, kernel loss: 0.05014\n",
      "Epoch: 13, series: 196, nllk loss: -1.90955, kernel loss: 0.30772\n",
      "Epoch: 13, series: 197, nllk loss: -2.12391, kernel loss: 0.14098\n",
      "Epoch: 13, series: 198, nllk loss: -2.14032, kernel loss: 0.12900\n",
      "Epoch: 13, series: 199, nllk loss: -1.86484, kernel loss: 0.13617\n",
      "Epoch: 13, series: 200, nllk loss: -2.13332, kernel loss: 0.17402\n",
      "Epoch: 13, series: 201, nllk loss: -2.21370, kernel loss: 0.08801\n",
      "Epoch: 13, series: 202, nllk loss: -1.94312, kernel loss: 0.04862\n",
      "Epoch: 13, series: 203, nllk loss: -1.78708, kernel loss: 0.14541\n",
      "Epoch: 13, series: 204, nllk loss: -0.87350, kernel loss: 0.12047\n",
      "Epoch: 13, series: 205, nllk loss: -1.99611, kernel loss: 0.09072\n",
      "Epoch: 13, series: 206, nllk loss: -2.03835, kernel loss: 0.14465\n",
      "Epoch: 13, series: 207, nllk loss: -0.97583, kernel loss: 0.19071\n",
      "Epoch: 13, series: 208, nllk loss: -2.33198, kernel loss: 0.02973\n",
      "Epoch: 13, series: 209, nllk loss: -1.76657, kernel loss: 0.03903\n",
      "Epoch: 13, series: 210, nllk loss: -2.48392, kernel loss: 0.01385\n",
      "Epoch: 13, series: 211, nllk loss: -1.92225, kernel loss: 0.14568\n",
      "Epoch: 13, series: 212, nllk loss: -1.51266, kernel loss: 0.19774\n",
      "Epoch: 13, series: 213, nllk loss: -2.07045, kernel loss: 0.13006\n",
      "Epoch: 13, series: 214, nllk loss: -1.94861, kernel loss: 0.28943\n",
      "Epoch: 13, series: 215, nllk loss: -2.29868, kernel loss: 0.06253\n",
      "Epoch: 13, series: 216, nllk loss: -1.31803, kernel loss: 0.13028\n",
      "Epoch: 13, series: 217, nllk loss: -1.98720, kernel loss: 0.05063\n",
      "Epoch: 13, series: 218, nllk loss: -1.43764, kernel loss: 0.05560\n",
      "Epoch: 13, series: 219, nllk loss: -1.76429, kernel loss: 0.42815\n",
      "Epoch: 13, series: 220, nllk loss: -2.06321, kernel loss: 0.06187\n",
      "Epoch: 13, series: 221, nllk loss: -2.27900, kernel loss: 0.12879\n",
      "Epoch: 13, series: 222, nllk loss: -2.14866, kernel loss: 0.07161\n",
      "Epoch: 13, series: 223, nllk loss: -1.65347, kernel loss: 0.09972\n",
      "Epoch: 13, series: 224, nllk loss: -2.28540, kernel loss: 0.11482\n",
      "Epoch: 13, series: 225, nllk loss: -2.11349, kernel loss: 0.07342\n",
      "Epoch: 13, series: 226, nllk loss: -1.77855, kernel loss: 0.03107\n",
      "Epoch: 13, series: 227, nllk loss: -1.85811, kernel loss: 0.05330\n",
      "Epoch: 13, series: 228, nllk loss: -2.09052, kernel loss: 0.21349\n",
      "Epoch: 13, series: 229, nllk loss: -1.93677, kernel loss: 0.13512\n",
      "Epoch: 13, series: 230, nllk loss: -2.33295, kernel loss: 0.19797\n",
      "Epoch: 13, series: 231, nllk loss: -1.84490, kernel loss: 0.09061\n",
      "Epoch: 13, series: 232, nllk loss: -2.55467, kernel loss: 0.02704\n",
      "Epoch: 13, series: 233, nllk loss: -2.40017, kernel loss: 0.16829\n",
      "Epoch: 13, series: 234, nllk loss: -2.03009, kernel loss: 0.10339\n",
      "Epoch: 13, series: 235, nllk loss: -2.63573, kernel loss: 0.18350\n",
      "Epoch: 13, series: 236, nllk loss: -1.43603, kernel loss: 0.11805\n",
      "Epoch: 13, series: 237, nllk loss: -1.88563, kernel loss: 0.17700\n",
      "Epoch: 13, series: 238, nllk loss: -1.71094, kernel loss: 0.07616\n",
      "Epoch: 13, series: 239, nllk loss: -2.19874, kernel loss: 0.21105\n",
      "Epoch: 13, series: 240, nllk loss: -0.92817, kernel loss: 0.27746\n",
      "Epoch: 13, series: 241, nllk loss: -1.87219, kernel loss: 0.17943\n",
      "Epoch: 13, series: 242, nllk loss: -1.99045, kernel loss: 0.14957\n",
      "Epoch: 13, series: 243, nllk loss: -2.21626, kernel loss: 0.26639\n",
      "Epoch: 13, series: 244, nllk loss: -1.81386, kernel loss: 0.07841\n",
      "Epoch: 13, series: 245, nllk loss: -2.04625, kernel loss: 0.03986\n",
      "Epoch: 13, series: 246, nllk loss: -0.08450, kernel loss: 0.05862\n",
      "Epoch: 13, series: 247, nllk loss: -1.71038, kernel loss: 0.07607\n",
      "Epoch: 13, series: 248, nllk loss: -1.98812, kernel loss: 0.13990\n",
      "Epoch: 13, series: 249, nllk loss: -1.73442, kernel loss: 0.18062\n",
      "Epoch: 13, series: 250, nllk loss: -1.55114, kernel loss: 0.14858\n",
      "Epoch: 13, series: 251, nllk loss: -1.05049, kernel loss: 0.04941\n",
      "Epoch: 13, series: 252, nllk loss: -1.29009, kernel loss: 0.12870\n",
      "Epoch: 13, series: 253, nllk loss: -1.73470, kernel loss: 0.09215\n",
      "Epoch: 13, series: 254, nllk loss: -2.22044, kernel loss: 0.15745\n",
      "Epoch: 13, series: 255, nllk loss: -2.03954, kernel loss: 0.08053\n",
      "Epoch: 13, series: 256, nllk loss: -1.71708, kernel loss: 0.26039\n",
      "Epoch: 13, series: 257, nllk loss: -2.05088, kernel loss: 0.01638\n",
      "Epoch: 13, series: 258, nllk loss: -2.01174, kernel loss: 0.06476\n",
      "Epoch: 13, series: 259, nllk loss: -1.74968, kernel loss: 0.19907\n",
      "Epoch: 13, series: 260, nllk loss: -1.87604, kernel loss: 0.09467\n",
      "Epoch: 13, series: 261, nllk loss: -2.11506, kernel loss: 0.13822\n",
      "Epoch: 13, series: 262, nllk loss: -2.45456, kernel loss: 0.26438\n",
      "Epoch: 13, series: 263, nllk loss: -0.70500, kernel loss: 0.12696\n",
      "Epoch: 13, series: 264, nllk loss: -1.99148, kernel loss: 0.25818\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13, series: 265, nllk loss: -1.69713, kernel loss: 0.15552\n",
      "Epoch: 13, series: 266, nllk loss: -2.20607, kernel loss: 0.13506\n",
      "Epoch: 13, series: 267, nllk loss: -1.82787, kernel loss: 0.28104\n",
      "Epoch: 13, series: 268, nllk loss: -1.90400, kernel loss: 0.24940\n",
      "Epoch: 13, series: 269, nllk loss: -1.53297, kernel loss: 0.15614\n",
      "Epoch: 13, series: 270, nllk loss: -1.83497, kernel loss: 0.08499\n",
      "Epoch: 13, series: 271, nllk loss: -1.88977, kernel loss: 0.22384\n",
      "Epoch: 13, series: 272, nllk loss: -1.74080, kernel loss: 0.14033\n",
      "Epoch: 13, series: 273, nllk loss: -1.90493, kernel loss: 0.01299\n",
      "Epoch: 13, series: 274, nllk loss: -1.63536, kernel loss: 0.08214\n",
      "Epoch: 13, series: 275, nllk loss: -1.82216, kernel loss: 0.10237\n",
      "Epoch: 13, series: 276, nllk loss: -1.15560, kernel loss: 0.35494\n",
      "Epoch: 13, series: 277, nllk loss: -2.09505, kernel loss: 0.04983\n",
      "Epoch: 13, series: 278, nllk loss: -1.92538, kernel loss: 0.12993\n",
      "Epoch: 13, series: 279, nllk loss: -2.23486, kernel loss: 0.26659\n",
      "Epoch: 13, series: 280, nllk loss: -2.08536, kernel loss: 0.05424\n",
      "Epoch: 13, series: 281, nllk loss: -2.25116, kernel loss: 0.08079\n",
      "Epoch: 13, series: 282, nllk loss: -2.09371, kernel loss: 0.05846\n",
      "Epoch: 13, series: 283, nllk loss: -2.01062, kernel loss: 0.13170\n",
      "Epoch: 13, series: 284, nllk loss: -1.77457, kernel loss: 0.08005\n",
      "Epoch: 13, series: 285, nllk loss: -1.71317, kernel loss: 0.27815\n",
      "Epoch: 13, series: 286, nllk loss: -2.01373, kernel loss: 0.05472\n",
      "Epoch: 13, series: 287, nllk loss: -2.41416, kernel loss: 0.14994\n",
      "Epoch: 13, series: 288, nllk loss: -1.04311, kernel loss: 0.04885\n",
      "Epoch: 13, series: 289, nllk loss: -0.93462, kernel loss: 0.07071\n",
      "Epoch: 13, series: 290, nllk loss: -2.17844, kernel loss: 0.11453\n",
      "Epoch: 13, series: 291, nllk loss: -2.16076, kernel loss: 0.06643\n",
      "Epoch: 13, series: 292, nllk loss: -2.08275, kernel loss: 0.30533\n",
      "Epoch: 13, series: 293, nllk loss: -2.24956, kernel loss: 0.06874\n",
      "Epoch: 13, series: 294, nllk loss: -1.35629, kernel loss: 0.11007\n",
      "Epoch: 13, series: 295, nllk loss: -1.26472, kernel loss: 0.11380\n",
      "Epoch: 13, series: 296, nllk loss: -2.35425, kernel loss: 0.22533\n",
      "Epoch: 13, series: 297, nllk loss: -2.40856, kernel loss: 0.13264\n",
      "Epoch: 13, series: 298, nllk loss: 1.33751, kernel loss: 0.21336\n",
      "Epoch: 13, series: 299, nllk loss: -0.36117, kernel loss: 0.20365\n",
      "Epoch: 13, series: 300, nllk loss: -2.04724, kernel loss: 0.25395\n",
      "Epoch: 13, series: 301, nllk loss: -2.13709, kernel loss: 0.14588\n",
      "Epoch: 13, series: 302, nllk loss: -2.13877, kernel loss: 0.26187\n",
      "Epoch: 13, series: 303, nllk loss: -1.90112, kernel loss: 0.09657\n",
      "Epoch: 13, series: 304, nllk loss: 0.33416, kernel loss: 0.27580\n",
      "Epoch: 13, series: 305, nllk loss: -1.55743, kernel loss: 0.19673\n",
      "Epoch: 13, series: 306, nllk loss: -2.24742, kernel loss: 0.20507\n",
      "Epoch: 13, series: 307, nllk loss: -1.57127, kernel loss: 0.13780\n",
      "Epoch: 13, series: 308, nllk loss: -2.14903, kernel loss: 0.39704\n",
      "Epoch: 13, series: 309, nllk loss: -1.94582, kernel loss: 0.21703\n",
      "Epoch: 13, series: 310, nllk loss: -2.05780, kernel loss: 0.08987\n",
      "Epoch: 13, series: 311, nllk loss: -1.80108, kernel loss: 0.19410\n",
      "Epoch: 13, series: 312, nllk loss: -2.11582, kernel loss: 0.10886\n",
      "Epoch: 13, series: 313, nllk loss: -2.26439, kernel loss: 0.35741\n",
      "Epoch: 13, series: 314, nllk loss: -2.53133, kernel loss: 0.13997\n",
      "Epoch: 13, series: 315, nllk loss: -0.81044, kernel loss: 0.53070\n",
      "Epoch: 13, series: 316, nllk loss: -1.95231, kernel loss: 0.22497\n",
      "Epoch: 13, series: 317, nllk loss: 0.78490, kernel loss: 0.05344\n",
      "Epoch: 13, series: 318, nllk loss: 2.01417, kernel loss: 0.36387\n",
      "Epoch: 13, series: 319, nllk loss: -0.86475, kernel loss: 0.13666\n",
      "Epoch: 13, series: 320, nllk loss: -0.86753, kernel loss: 0.09382\n",
      "Epoch: 13, total loss: -435.36158\n",
      "Epoch: 14, series: 0, nllk loss: 1.90720, kernel loss: 0.17716\n",
      "Epoch: 14, series: 1, nllk loss: -1.08582, kernel loss: 0.35897\n",
      "Epoch: 14, series: 2, nllk loss: 0.02595, kernel loss: 0.04742\n",
      "Epoch: 14, series: 3, nllk loss: -1.23714, kernel loss: 0.23755\n",
      "Epoch: 14, series: 4, nllk loss: -0.92467, kernel loss: 0.20006\n",
      "Epoch: 14, series: 5, nllk loss: -1.12705, kernel loss: 0.05580\n",
      "Epoch: 14, series: 6, nllk loss: -0.54877, kernel loss: 0.08045\n",
      "Epoch: 14, series: 7, nllk loss: -1.09511, kernel loss: 0.25741\n",
      "Epoch: 14, series: 8, nllk loss: -0.57168, kernel loss: 0.16880\n",
      "Epoch: 14, series: 9, nllk loss: -0.47775, kernel loss: 0.32844\n",
      "Epoch: 14, series: 10, nllk loss: -1.16385, kernel loss: 0.22610\n",
      "Epoch: 14, series: 11, nllk loss: -1.00377, kernel loss: 0.12352\n",
      "Epoch: 14, series: 12, nllk loss: -1.35899, kernel loss: 0.11517\n",
      "Epoch: 14, series: 13, nllk loss: -1.23614, kernel loss: 0.00906\n",
      "Epoch: 14, series: 14, nllk loss: -1.41299, kernel loss: 0.14300\n",
      "Epoch: 14, series: 15, nllk loss: -1.41471, kernel loss: 0.10018\n",
      "Epoch: 14, series: 16, nllk loss: -1.02674, kernel loss: 0.08749\n",
      "Epoch: 14, series: 17, nllk loss: -1.11594, kernel loss: 0.10544\n",
      "Epoch: 14, series: 18, nllk loss: -1.33617, kernel loss: 0.20114\n",
      "Epoch: 14, series: 19, nllk loss: -0.35733, kernel loss: 0.24138\n",
      "Epoch: 14, series: 20, nllk loss: -0.88349, kernel loss: 0.17955\n",
      "Epoch: 14, series: 21, nllk loss: -1.11726, kernel loss: 0.13951\n",
      "Epoch: 14, series: 22, nllk loss: -1.41830, kernel loss: 0.19766\n",
      "Epoch: 14, series: 23, nllk loss: -1.40135, kernel loss: 0.07981\n",
      "Epoch: 14, series: 24, nllk loss: -1.60073, kernel loss: 0.08955\n",
      "Epoch: 14, series: 25, nllk loss: -1.54393, kernel loss: 0.19082\n",
      "Epoch: 14, series: 26, nllk loss: -1.38375, kernel loss: 0.23596\n",
      "Epoch: 14, series: 27, nllk loss: -1.22548, kernel loss: 0.07789\n",
      "Epoch: 14, series: 28, nllk loss: -1.34459, kernel loss: 0.37837\n",
      "Epoch: 14, series: 29, nllk loss: -0.81238, kernel loss: 0.12848\n",
      "Epoch: 14, series: 30, nllk loss: -1.38498, kernel loss: 0.13880\n",
      "Epoch: 14, series: 31, nllk loss: -1.13722, kernel loss: 0.12588\n",
      "Epoch: 14, series: 32, nllk loss: -1.12182, kernel loss: 0.19698\n",
      "Epoch: 14, series: 33, nllk loss: -0.95541, kernel loss: 0.14303\n",
      "Epoch: 14, series: 34, nllk loss: -1.35907, kernel loss: 0.05459\n",
      "Epoch: 14, series: 35, nllk loss: -1.59365, kernel loss: 0.06458\n",
      "Epoch: 14, series: 36, nllk loss: -1.54102, kernel loss: 0.05374\n",
      "Epoch: 14, series: 37, nllk loss: -0.46661, kernel loss: 0.08239\n",
      "Epoch: 14, series: 38, nllk loss: -1.07782, kernel loss: 0.07643\n",
      "Epoch: 14, series: 39, nllk loss: -0.79794, kernel loss: 0.01370\n",
      "Epoch: 14, series: 40, nllk loss: -1.79070, kernel loss: 0.02485\n",
      "Epoch: 14, series: 41, nllk loss: -1.33019, kernel loss: 0.07135\n",
      "Epoch: 14, series: 42, nllk loss: -1.12768, kernel loss: 0.07641\n",
      "Epoch: 14, series: 43, nllk loss: -1.11040, kernel loss: 0.12567\n",
      "Epoch: 14, series: 44, nllk loss: -1.53976, kernel loss: 0.07253\n",
      "Epoch: 14, series: 45, nllk loss: -1.62829, kernel loss: 0.02556\n",
      "Epoch: 14, series: 46, nllk loss: -1.66106, kernel loss: 0.06370\n",
      "Epoch: 14, series: 47, nllk loss: -1.56385, kernel loss: 0.10233\n",
      "Epoch: 14, series: 48, nllk loss: -1.59546, kernel loss: 0.00357\n",
      "Epoch: 14, series: 49, nllk loss: -1.23594, kernel loss: 0.07441\n",
      "Epoch: 14, series: 50, nllk loss: 0.01768, kernel loss: 0.18513\n",
      "Epoch: 14, series: 51, nllk loss: -1.37824, kernel loss: 0.14602\n",
      "Epoch: 14, series: 52, nllk loss: -0.37590, kernel loss: 0.00520\n",
      "Epoch: 14, series: 53, nllk loss: -1.64955, kernel loss: 0.19629\n",
      "Epoch: 14, series: 54, nllk loss: -1.29900, kernel loss: 0.09691\n",
      "Epoch: 14, series: 55, nllk loss: -0.88511, kernel loss: 0.17258\n",
      "Epoch: 14, series: 56, nllk loss: -1.36382, kernel loss: 0.24185\n",
      "Epoch: 14, series: 57, nllk loss: -1.39215, kernel loss: 0.12526\n",
      "Epoch: 14, series: 58, nllk loss: -1.54092, kernel loss: 0.07637\n",
      "Epoch: 14, series: 59, nllk loss: -1.16398, kernel loss: 0.11082\n",
      "Epoch: 14, series: 60, nllk loss: -1.06935, kernel loss: 0.05981\n",
      "Epoch: 14, series: 61, nllk loss: -1.65969, kernel loss: 0.05718\n",
      "Epoch: 14, series: 62, nllk loss: -1.72111, kernel loss: 0.01567\n",
      "Epoch: 14, series: 63, nllk loss: -1.64159, kernel loss: 0.16390\n",
      "Epoch: 14, series: 64, nllk loss: -1.16547, kernel loss: 0.04643\n",
      "Epoch: 14, series: 65, nllk loss: -1.58062, kernel loss: 0.12562\n",
      "Epoch: 14, series: 66, nllk loss: -1.49659, kernel loss: 0.09149\n",
      "Epoch: 14, series: 67, nllk loss: -1.40433, kernel loss: 0.05502\n",
      "Epoch: 14, series: 68, nllk loss: -0.78784, kernel loss: 0.13427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, series: 69, nllk loss: -1.40805, kernel loss: 0.03117\n",
      "Epoch: 14, series: 70, nllk loss: -1.44005, kernel loss: 0.03860\n",
      "Epoch: 14, series: 71, nllk loss: -1.53413, kernel loss: 0.18947\n",
      "Epoch: 14, series: 72, nllk loss: -1.82399, kernel loss: 0.02844\n",
      "Epoch: 14, series: 73, nllk loss: -1.32754, kernel loss: 0.01356\n",
      "Epoch: 14, series: 74, nllk loss: -1.92935, kernel loss: 0.18782\n",
      "Epoch: 14, series: 75, nllk loss: -1.44083, kernel loss: 0.11738\n",
      "Epoch: 14, series: 76, nllk loss: -1.42936, kernel loss: 0.08544\n",
      "Epoch: 14, series: 77, nllk loss: -1.28366, kernel loss: 0.20553\n",
      "Epoch: 14, series: 78, nllk loss: -1.33914, kernel loss: 0.10680\n",
      "Epoch: 14, series: 79, nllk loss: -0.47828, kernel loss: 0.12159\n",
      "Epoch: 14, series: 80, nllk loss: -1.77564, kernel loss: 0.10004\n",
      "Epoch: 14, series: 81, nllk loss: -1.29590, kernel loss: 0.19721\n",
      "Epoch: 14, series: 82, nllk loss: -0.16936, kernel loss: 0.01879\n",
      "Epoch: 14, series: 83, nllk loss: -0.98946, kernel loss: 0.10037\n",
      "Epoch: 14, series: 84, nllk loss: -1.19351, kernel loss: 0.10148\n",
      "Epoch: 14, series: 85, nllk loss: -1.39643, kernel loss: 0.31319\n",
      "Epoch: 14, series: 86, nllk loss: -0.56136, kernel loss: 0.08360\n",
      "Epoch: 14, series: 87, nllk loss: -1.64104, kernel loss: 0.21612\n",
      "Epoch: 14, series: 88, nllk loss: -1.84354, kernel loss: 0.10284\n",
      "Epoch: 14, series: 89, nllk loss: -1.86017, kernel loss: 0.13421\n",
      "Epoch: 14, series: 90, nllk loss: -2.00859, kernel loss: 0.10887\n",
      "Epoch: 14, series: 91, nllk loss: -1.98329, kernel loss: 0.08658\n",
      "Epoch: 14, series: 92, nllk loss: 0.37632, kernel loss: 0.14617\n",
      "Epoch: 14, series: 93, nllk loss: -2.27192, kernel loss: 0.17766\n",
      "Epoch: 14, series: 94, nllk loss: -2.24894, kernel loss: 0.16213\n",
      "Epoch: 14, series: 95, nllk loss: -2.20879, kernel loss: 0.12757\n",
      "Epoch: 14, series: 96, nllk loss: -1.50295, kernel loss: 0.08839\n",
      "Epoch: 14, series: 97, nllk loss: -0.68744, kernel loss: 0.02008\n",
      "Epoch: 14, series: 98, nllk loss: -0.79403, kernel loss: 0.06310\n",
      "Epoch: 14, series: 99, nllk loss: -1.39686, kernel loss: 0.12374\n",
      "Epoch: 14, series: 100, nllk loss: -0.76009, kernel loss: 0.07915\n",
      "Epoch: 14, series: 101, nllk loss: -1.27615, kernel loss: 0.37475\n",
      "Epoch: 14, series: 102, nllk loss: -0.61885, kernel loss: 0.17437\n",
      "Epoch: 14, series: 103, nllk loss: -1.06881, kernel loss: 0.07869\n",
      "Epoch: 14, series: 104, nllk loss: 0.25057, kernel loss: 0.18290\n",
      "Epoch: 14, series: 105, nllk loss: -0.10075, kernel loss: 0.24696\n",
      "Epoch: 14, series: 106, nllk loss: -1.17256, kernel loss: 0.13136\n",
      "Epoch: 14, series: 107, nllk loss: -0.89951, kernel loss: 0.20385\n",
      "Epoch: 14, series: 108, nllk loss: -1.34773, kernel loss: 0.18882\n",
      "Epoch: 14, series: 109, nllk loss: -1.17440, kernel loss: 0.16403\n",
      "Epoch: 14, series: 110, nllk loss: -1.62272, kernel loss: 0.04688\n",
      "Epoch: 14, series: 111, nllk loss: -1.44926, kernel loss: 0.13339\n",
      "Epoch: 14, series: 112, nllk loss: -0.84942, kernel loss: 0.25976\n",
      "Epoch: 14, series: 113, nllk loss: -1.12042, kernel loss: 0.19086\n",
      "Epoch: 14, series: 114, nllk loss: -1.14624, kernel loss: 0.08541\n",
      "Epoch: 14, series: 115, nllk loss: -0.85732, kernel loss: 0.26464\n",
      "Epoch: 14, series: 116, nllk loss: -1.59338, kernel loss: 0.15726\n",
      "Epoch: 14, series: 117, nllk loss: -0.61341, kernel loss: 0.09336\n",
      "Epoch: 14, series: 118, nllk loss: -1.69222, kernel loss: 0.12553\n",
      "Epoch: 14, series: 119, nllk loss: -0.78196, kernel loss: 0.04787\n",
      "Epoch: 14, series: 120, nllk loss: -1.50552, kernel loss: 0.23177\n",
      "Epoch: 14, series: 121, nllk loss: 0.14394, kernel loss: 0.16434\n",
      "Epoch: 14, series: 122, nllk loss: -0.56561, kernel loss: 0.05412\n",
      "Epoch: 14, series: 123, nllk loss: -1.57991, kernel loss: 0.04427\n",
      "Epoch: 14, series: 124, nllk loss: -1.72302, kernel loss: 0.05697\n",
      "Epoch: 14, series: 125, nllk loss: -1.35536, kernel loss: 0.02528\n",
      "Epoch: 14, series: 126, nllk loss: -1.68599, kernel loss: 0.12338\n",
      "Epoch: 14, series: 127, nllk loss: -1.37616, kernel loss: 0.12435\n",
      "Epoch: 14, series: 128, nllk loss: -0.98588, kernel loss: 0.06342\n",
      "Epoch: 14, series: 129, nllk loss: -0.71732, kernel loss: 0.02156\n",
      "Epoch: 14, series: 130, nllk loss: -1.34874, kernel loss: 0.17954\n",
      "Epoch: 14, series: 131, nllk loss: 0.57091, kernel loss: 0.09891\n",
      "Epoch: 14, series: 132, nllk loss: 0.05257, kernel loss: 0.11578\n",
      "Epoch: 14, series: 133, nllk loss: -0.98876, kernel loss: 0.15624\n",
      "Epoch: 14, series: 134, nllk loss: -0.69511, kernel loss: 0.15120\n",
      "Epoch: 14, series: 135, nllk loss: -1.44177, kernel loss: 0.04000\n",
      "Epoch: 14, series: 136, nllk loss: -1.44800, kernel loss: 0.12628\n",
      "Epoch: 14, series: 137, nllk loss: -1.60957, kernel loss: 0.04446\n",
      "Epoch: 14, series: 138, nllk loss: -1.68376, kernel loss: 0.02661\n",
      "Epoch: 14, series: 139, nllk loss: -1.69931, kernel loss: 0.04856\n",
      "Epoch: 14, series: 140, nllk loss: -1.46052, kernel loss: 0.03697\n",
      "Epoch: 14, series: 141, nllk loss: -1.62794, kernel loss: 0.09544\n",
      "Epoch: 14, series: 142, nllk loss: -1.70971, kernel loss: 0.16351\n",
      "Epoch: 14, series: 143, nllk loss: -1.71691, kernel loss: 0.04786\n",
      "Epoch: 14, series: 144, nllk loss: -2.00371, kernel loss: 0.07160\n",
      "Epoch: 14, series: 145, nllk loss: -1.85850, kernel loss: 0.48107\n",
      "Epoch: 14, series: 146, nllk loss: 3.05247, kernel loss: 0.17965\n",
      "Epoch: 14, series: 147, nllk loss: -1.57008, kernel loss: 0.06851\n",
      "Epoch: 14, series: 148, nllk loss: -1.38454, kernel loss: 0.07396\n",
      "Epoch: 14, series: 149, nllk loss: -1.71599, kernel loss: 0.17878\n",
      "Epoch: 14, series: 150, nllk loss: -1.76443, kernel loss: 0.09247\n",
      "Epoch: 14, series: 151, nllk loss: -1.86322, kernel loss: 0.11952\n",
      "Epoch: 14, series: 152, nllk loss: -1.84258, kernel loss: 0.14345\n",
      "Epoch: 14, series: 153, nllk loss: -1.59800, kernel loss: 0.09132\n",
      "Epoch: 14, series: 154, nllk loss: -1.69463, kernel loss: 0.13289\n",
      "Epoch: 14, series: 155, nllk loss: -1.74867, kernel loss: 0.20970\n",
      "Epoch: 14, series: 156, nllk loss: -1.86183, kernel loss: 0.30689\n",
      "Epoch: 14, series: 157, nllk loss: -1.38679, kernel loss: 0.06823\n",
      "Epoch: 14, series: 158, nllk loss: -1.91495, kernel loss: 0.08634\n",
      "Epoch: 14, series: 159, nllk loss: -1.89079, kernel loss: 0.07075\n",
      "Epoch: 14, series: 160, nllk loss: -1.80513, kernel loss: 0.09161\n",
      "Epoch: 14, series: 161, nllk loss: -1.68464, kernel loss: 0.10936\n",
      "Epoch: 14, series: 162, nllk loss: -1.91242, kernel loss: 0.17524\n",
      "Epoch: 14, series: 163, nllk loss: -2.27419, kernel loss: 0.15885\n",
      "Epoch: 14, series: 164, nllk loss: -1.84142, kernel loss: 0.07472\n",
      "Epoch: 14, series: 165, nllk loss: -1.87183, kernel loss: 0.18900\n",
      "Epoch: 14, series: 166, nllk loss: -1.26661, kernel loss: 0.08725\n",
      "Epoch: 14, series: 167, nllk loss: -2.43191, kernel loss: 0.12632\n",
      "Epoch: 14, series: 168, nllk loss: -2.13409, kernel loss: 0.07035\n",
      "Epoch: 14, series: 169, nllk loss: -2.21066, kernel loss: 0.06399\n",
      "Epoch: 14, series: 170, nllk loss: -1.92480, kernel loss: 0.19558\n",
      "Epoch: 14, series: 171, nllk loss: -2.30590, kernel loss: 0.17703\n",
      "Epoch: 14, series: 172, nllk loss: -2.03273, kernel loss: 0.13545\n",
      "Epoch: 14, series: 173, nllk loss: -2.49092, kernel loss: 0.10264\n",
      "Epoch: 14, series: 174, nllk loss: -2.09514, kernel loss: 0.02795\n",
      "Epoch: 14, series: 175, nllk loss: -2.41587, kernel loss: 0.19431\n",
      "Epoch: 14, series: 176, nllk loss: -2.09250, kernel loss: 0.10866\n",
      "Epoch: 14, series: 177, nllk loss: -1.95542, kernel loss: 0.08140\n",
      "Epoch: 14, series: 178, nllk loss: -1.74046, kernel loss: 0.05219\n",
      "Epoch: 14, series: 179, nllk loss: -2.16633, kernel loss: 0.20615\n",
      "Epoch: 14, series: 180, nllk loss: -2.26255, kernel loss: 0.31045\n",
      "Epoch: 14, series: 181, nllk loss: -2.47518, kernel loss: 0.00084\n",
      "Epoch: 14, series: 182, nllk loss: -2.02595, kernel loss: 0.03319\n",
      "Epoch: 14, series: 183, nllk loss: -2.02315, kernel loss: 0.07384\n",
      "Epoch: 14, series: 184, nllk loss: -1.86159, kernel loss: 0.04870\n",
      "Epoch: 14, series: 185, nllk loss: -1.52986, kernel loss: 0.09712\n",
      "Epoch: 14, series: 186, nllk loss: -2.49823, kernel loss: 0.08440\n",
      "Epoch: 14, series: 187, nllk loss: -2.64192, kernel loss: 0.10929\n",
      "Epoch: 14, series: 188, nllk loss: -1.64231, kernel loss: 0.13434\n",
      "Epoch: 14, series: 189, nllk loss: -1.46709, kernel loss: 0.07790\n",
      "Epoch: 14, series: 190, nllk loss: -1.78098, kernel loss: 0.20980\n",
      "Epoch: 14, series: 191, nllk loss: -1.79272, kernel loss: 0.29765\n",
      "Epoch: 14, series: 192, nllk loss: -2.10022, kernel loss: 0.11116\n",
      "Epoch: 14, series: 193, nllk loss: -1.44521, kernel loss: 0.25802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, series: 194, nllk loss: -1.35485, kernel loss: 0.00000\n",
      "Epoch: 14, series: 195, nllk loss: -2.28397, kernel loss: 0.12465\n",
      "Epoch: 14, series: 196, nllk loss: -1.80363, kernel loss: 0.07869\n",
      "Epoch: 14, series: 197, nllk loss: -2.12398, kernel loss: 0.14825\n",
      "Epoch: 14, series: 198, nllk loss: -2.13581, kernel loss: 0.17115\n",
      "Epoch: 14, series: 199, nllk loss: -1.87068, kernel loss: 0.05112\n",
      "Epoch: 14, series: 200, nllk loss: -2.30774, kernel loss: 0.37491\n",
      "Epoch: 14, series: 201, nllk loss: -2.24827, kernel loss: 0.12525\n",
      "Epoch: 14, series: 202, nllk loss: -2.03047, kernel loss: 0.06231\n",
      "Epoch: 14, series: 203, nllk loss: -1.92378, kernel loss: 0.19641\n",
      "Epoch: 14, series: 204, nllk loss: -0.94970, kernel loss: 0.16668\n",
      "Epoch: 14, series: 205, nllk loss: -2.11294, kernel loss: 0.06099\n",
      "Epoch: 14, series: 206, nllk loss: -2.21022, kernel loss: 0.28053\n",
      "Epoch: 14, series: 207, nllk loss: -1.11055, kernel loss: 0.10851\n",
      "Epoch: 14, series: 208, nllk loss: -2.35016, kernel loss: 0.12657\n",
      "Epoch: 14, series: 209, nllk loss: -1.79546, kernel loss: 0.15663\n",
      "Epoch: 14, series: 210, nllk loss: -2.53319, kernel loss: 0.09538\n",
      "Epoch: 14, series: 211, nllk loss: -2.13188, kernel loss: 0.13022\n",
      "Epoch: 14, series: 212, nllk loss: -1.45339, kernel loss: 0.19455\n",
      "Epoch: 14, series: 213, nllk loss: -2.17463, kernel loss: 0.15185\n",
      "Epoch: 14, series: 214, nllk loss: -2.07108, kernel loss: 0.15666\n",
      "Epoch: 14, series: 215, nllk loss: -2.34339, kernel loss: 0.11835\n",
      "Epoch: 14, series: 216, nllk loss: -1.33638, kernel loss: 0.10452\n",
      "Epoch: 14, series: 217, nllk loss: -1.93285, kernel loss: 0.15567\n",
      "Epoch: 14, series: 218, nllk loss: -1.52701, kernel loss: 0.03511\n",
      "Epoch: 14, series: 219, nllk loss: -2.00159, kernel loss: 0.12081\n",
      "Epoch: 14, series: 220, nllk loss: -1.99832, kernel loss: 0.05478\n",
      "Epoch: 14, series: 221, nllk loss: -2.26576, kernel loss: 0.12030\n",
      "Epoch: 14, series: 222, nllk loss: -2.22673, kernel loss: 0.18926\n",
      "Epoch: 14, series: 223, nllk loss: -1.60917, kernel loss: 0.04841\n",
      "Epoch: 14, series: 224, nllk loss: -2.42242, kernel loss: 0.15986\n",
      "Epoch: 14, series: 225, nllk loss: -2.23149, kernel loss: 0.03937\n",
      "Epoch: 14, series: 226, nllk loss: -1.70746, kernel loss: 0.08338\n",
      "Epoch: 14, series: 227, nllk loss: -1.98851, kernel loss: 0.20833\n",
      "Epoch: 14, series: 228, nllk loss: -2.00774, kernel loss: 0.17029\n",
      "Epoch: 14, series: 229, nllk loss: -1.94652, kernel loss: 0.06668\n",
      "Epoch: 14, series: 230, nllk loss: -2.38719, kernel loss: 0.09029\n",
      "Epoch: 14, series: 231, nllk loss: -1.96328, kernel loss: 0.34857\n",
      "Epoch: 14, series: 232, nllk loss: -2.50089, kernel loss: 0.19213\n",
      "Epoch: 14, series: 233, nllk loss: -2.34688, kernel loss: 0.09836\n",
      "Epoch: 14, series: 234, nllk loss: -2.03928, kernel loss: 0.06822\n",
      "Epoch: 14, series: 235, nllk loss: -2.61758, kernel loss: 0.14263\n",
      "Epoch: 14, series: 236, nllk loss: -1.53163, kernel loss: 0.13018\n",
      "Epoch: 14, series: 237, nllk loss: -2.06118, kernel loss: 0.05285\n",
      "Epoch: 14, series: 238, nllk loss: -1.82845, kernel loss: 0.08396\n",
      "Epoch: 14, series: 239, nllk loss: -2.11699, kernel loss: 0.11028\n",
      "Epoch: 14, series: 240, nllk loss: -1.15225, kernel loss: 0.22688\n",
      "Epoch: 14, series: 241, nllk loss: -1.89892, kernel loss: 0.12187\n",
      "Epoch: 14, series: 242, nllk loss: -2.03931, kernel loss: 0.09106\n",
      "Epoch: 14, series: 243, nllk loss: -2.36290, kernel loss: 0.05736\n",
      "Epoch: 14, series: 244, nllk loss: -2.01187, kernel loss: 0.13181\n",
      "Epoch: 14, series: 245, nllk loss: -2.22754, kernel loss: 0.06598\n",
      "Epoch: 14, series: 246, nllk loss: 0.12413, kernel loss: 0.09676\n",
      "Epoch: 14, series: 247, nllk loss: -1.67525, kernel loss: 0.02395\n",
      "Epoch: 14, series: 248, nllk loss: -1.96919, kernel loss: 0.25592\n",
      "Epoch: 14, series: 249, nllk loss: -1.87426, kernel loss: 0.18612\n",
      "Epoch: 14, series: 250, nllk loss: -1.62593, kernel loss: 0.06420\n",
      "Epoch: 14, series: 251, nllk loss: -1.07529, kernel loss: 0.17077\n",
      "Epoch: 14, series: 252, nllk loss: -1.24185, kernel loss: 0.11190\n",
      "Epoch: 14, series: 253, nllk loss: -1.70511, kernel loss: 0.17470\n",
      "Epoch: 14, series: 254, nllk loss: -2.27190, kernel loss: 0.17478\n",
      "Epoch: 14, series: 255, nllk loss: -2.08673, kernel loss: 0.07601\n",
      "Epoch: 14, series: 256, nllk loss: -1.93309, kernel loss: 0.05175\n",
      "Epoch: 14, series: 257, nllk loss: -2.03721, kernel loss: 0.08630\n",
      "Epoch: 14, series: 258, nllk loss: -2.02620, kernel loss: 0.19954\n",
      "Epoch: 14, series: 259, nllk loss: -1.75893, kernel loss: 0.04277\n",
      "Epoch: 14, series: 260, nllk loss: -2.03103, kernel loss: 0.08279\n",
      "Epoch: 14, series: 261, nllk loss: -2.02249, kernel loss: 0.16694\n",
      "Epoch: 14, series: 262, nllk loss: -2.53603, kernel loss: 0.16860\n",
      "Epoch: 14, series: 263, nllk loss: -0.64739, kernel loss: 0.04785\n",
      "Epoch: 14, series: 264, nllk loss: -2.02863, kernel loss: 0.24528\n",
      "Epoch: 14, series: 265, nllk loss: -1.77156, kernel loss: 0.16784\n",
      "Epoch: 14, series: 266, nllk loss: -2.25451, kernel loss: 0.08881\n",
      "Epoch: 14, series: 267, nllk loss: -2.13118, kernel loss: 0.28107\n",
      "Epoch: 14, series: 268, nllk loss: -2.15568, kernel loss: 0.07364\n",
      "Epoch: 14, series: 269, nllk loss: -1.74482, kernel loss: 0.01558\n",
      "Epoch: 14, series: 270, nllk loss: -1.77072, kernel loss: 0.11899\n",
      "Epoch: 14, series: 271, nllk loss: -1.91080, kernel loss: 0.17203\n",
      "Epoch: 14, series: 272, nllk loss: -1.85472, kernel loss: 0.14659\n",
      "Epoch: 14, series: 273, nllk loss: -2.05448, kernel loss: 0.06436\n",
      "Epoch: 14, series: 274, nllk loss: -1.65179, kernel loss: 0.10322\n",
      "Epoch: 14, series: 275, nllk loss: -1.78086, kernel loss: 0.01792\n",
      "Epoch: 14, series: 276, nllk loss: -1.27703, kernel loss: 0.11135\n",
      "Epoch: 14, series: 277, nllk loss: -2.12003, kernel loss: 0.22138\n",
      "Epoch: 14, series: 278, nllk loss: -1.88773, kernel loss: 0.02152\n",
      "Epoch: 14, series: 279, nllk loss: -2.31739, kernel loss: 0.08991\n",
      "Epoch: 14, series: 280, nllk loss: -2.09959, kernel loss: 0.17410\n",
      "Epoch: 14, series: 281, nllk loss: -2.22010, kernel loss: 0.04515\n",
      "Epoch: 14, series: 282, nllk loss: -2.15537, kernel loss: 0.12573\n",
      "Epoch: 14, series: 283, nllk loss: -2.09153, kernel loss: 0.01515\n",
      "Epoch: 14, series: 284, nllk loss: -1.58757, kernel loss: 0.12681\n",
      "Epoch: 14, series: 285, nllk loss: -1.83812, kernel loss: 0.21162\n",
      "Epoch: 14, series: 286, nllk loss: -2.19863, kernel loss: 0.09889\n",
      "Epoch: 14, series: 287, nllk loss: -2.44105, kernel loss: 0.21553\n",
      "Epoch: 14, series: 288, nllk loss: -1.15357, kernel loss: 0.02143\n",
      "Epoch: 14, series: 289, nllk loss: -0.97262, kernel loss: 0.23270\n",
      "Epoch: 14, series: 290, nllk loss: -2.18592, kernel loss: 0.08893\n",
      "Epoch: 14, series: 291, nllk loss: -2.15789, kernel loss: 0.11516\n",
      "Epoch: 14, series: 292, nllk loss: -2.08123, kernel loss: 0.22781\n",
      "Epoch: 14, series: 293, nllk loss: -2.36389, kernel loss: 0.10271\n",
      "Epoch: 14, series: 294, nllk loss: -1.49885, kernel loss: 0.08998\n",
      "Epoch: 14, series: 295, nllk loss: -1.16179, kernel loss: 0.08225\n",
      "Epoch: 14, series: 296, nllk loss: -2.34717, kernel loss: 0.18574\n",
      "Epoch: 14, series: 297, nllk loss: -2.41121, kernel loss: 0.12798\n",
      "Epoch: 14, series: 298, nllk loss: 0.84403, kernel loss: 0.13263\n",
      "Epoch: 14, series: 299, nllk loss: -0.28513, kernel loss: 0.25712\n",
      "Epoch: 14, series: 300, nllk loss: -2.01556, kernel loss: 0.16350\n",
      "Epoch: 14, series: 301, nllk loss: -2.24742, kernel loss: 0.18872\n",
      "Epoch: 14, series: 302, nllk loss: -2.23593, kernel loss: 0.09208\n",
      "Epoch: 14, series: 303, nllk loss: -1.82152, kernel loss: 0.04422\n",
      "Epoch: 14, series: 304, nllk loss: 0.41460, kernel loss: 0.04291\n",
      "Epoch: 14, series: 305, nllk loss: -1.59578, kernel loss: 0.15690\n",
      "Epoch: 14, series: 306, nllk loss: -2.14337, kernel loss: 0.09404\n",
      "Epoch: 14, series: 307, nllk loss: -1.44296, kernel loss: 0.27914\n",
      "Epoch: 14, series: 308, nllk loss: -2.09541, kernel loss: 0.20878\n",
      "Epoch: 14, series: 309, nllk loss: -1.86887, kernel loss: 0.08259\n",
      "Epoch: 14, series: 310, nllk loss: -2.01538, kernel loss: 0.08055\n",
      "Epoch: 14, series: 311, nllk loss: -1.79952, kernel loss: 0.18236\n",
      "Epoch: 14, series: 312, nllk loss: -1.96620, kernel loss: 0.05051\n",
      "Epoch: 14, series: 313, nllk loss: -2.23045, kernel loss: 0.23303\n",
      "Epoch: 14, series: 314, nllk loss: -2.53397, kernel loss: 0.17079\n",
      "Epoch: 14, series: 315, nllk loss: -0.87787, kernel loss: 0.08983\n",
      "Epoch: 14, series: 316, nllk loss: -1.92178, kernel loss: 0.09847\n",
      "Epoch: 14, series: 317, nllk loss: 0.53566, kernel loss: 0.22515\n",
      "Epoch: 14, series: 318, nllk loss: 1.49855, kernel loss: 0.04720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14, series: 319, nllk loss: -0.82507, kernel loss: 0.19409\n",
      "Epoch: 14, series: 320, nllk loss: -0.83956, kernel loss: 0.05967\n",
      "Epoch: 14, total loss: -449.59436\n",
      "Epoch: 15, series: 0, nllk loss: 1.68011, kernel loss: 0.24551\n",
      "Epoch: 15, series: 1, nllk loss: -1.07594, kernel loss: 0.21930\n",
      "Epoch: 15, series: 2, nllk loss: 0.03974, kernel loss: 0.13522\n",
      "Epoch: 15, series: 3, nllk loss: -1.21833, kernel loss: 0.18905\n",
      "Epoch: 15, series: 4, nllk loss: -0.87926, kernel loss: 0.12962\n",
      "Epoch: 15, series: 5, nllk loss: -1.22106, kernel loss: 0.14070\n",
      "Epoch: 15, series: 6, nllk loss: -0.49415, kernel loss: 0.37405\n",
      "Epoch: 15, series: 7, nllk loss: -1.11459, kernel loss: 0.40157\n",
      "Epoch: 15, series: 8, nllk loss: -0.61821, kernel loss: 0.18835\n",
      "Epoch: 15, series: 9, nllk loss: -0.61192, kernel loss: 0.31734\n",
      "Epoch: 15, series: 10, nllk loss: -1.26193, kernel loss: 0.24288\n",
      "Epoch: 15, series: 11, nllk loss: -1.07426, kernel loss: 0.19807\n",
      "Epoch: 15, series: 12, nllk loss: -1.40422, kernel loss: 0.47592\n",
      "Epoch: 15, series: 13, nllk loss: -1.25071, kernel loss: 0.28381\n",
      "Epoch: 15, series: 14, nllk loss: -1.35000, kernel loss: 0.10173\n",
      "Epoch: 15, series: 15, nllk loss: -1.35225, kernel loss: 0.15105\n",
      "Epoch: 15, series: 16, nllk loss: -1.05689, kernel loss: 0.22849\n",
      "Epoch: 15, series: 17, nllk loss: -1.16079, kernel loss: 0.14923\n",
      "Epoch: 15, series: 18, nllk loss: -1.23548, kernel loss: 0.07642\n",
      "Epoch: 15, series: 19, nllk loss: -0.42045, kernel loss: 0.20526\n",
      "Epoch: 15, series: 20, nllk loss: -0.85671, kernel loss: 0.13606\n",
      "Epoch: 15, series: 21, nllk loss: -1.07068, kernel loss: 0.30000\n",
      "Epoch: 15, series: 22, nllk loss: -1.38534, kernel loss: 0.21241\n",
      "Epoch: 15, series: 23, nllk loss: -1.32272, kernel loss: 0.18604\n",
      "Epoch: 15, series: 24, nllk loss: -1.48686, kernel loss: 0.22701\n",
      "Epoch: 15, series: 25, nllk loss: -1.44963, kernel loss: 0.16787\n",
      "Epoch: 15, series: 26, nllk loss: -1.43468, kernel loss: 0.18912\n",
      "Epoch: 15, series: 27, nllk loss: -1.08822, kernel loss: 0.20083\n",
      "Epoch: 15, series: 28, nllk loss: -1.27263, kernel loss: 0.17570\n",
      "Epoch: 15, series: 29, nllk loss: -0.73901, kernel loss: 0.20207\n",
      "Epoch: 15, series: 30, nllk loss: -1.28883, kernel loss: 0.22231\n",
      "Epoch: 15, series: 31, nllk loss: -1.08646, kernel loss: 0.12814\n",
      "Epoch: 15, series: 32, nllk loss: -1.01032, kernel loss: 0.14050\n",
      "Epoch: 15, series: 33, nllk loss: -0.85643, kernel loss: 0.10076\n",
      "Epoch: 15, series: 34, nllk loss: -1.32441, kernel loss: 0.17391\n",
      "Epoch: 15, series: 35, nllk loss: -1.53245, kernel loss: 0.20996\n",
      "Epoch: 15, series: 36, nllk loss: -1.42431, kernel loss: 0.07138\n",
      "Epoch: 15, series: 37, nllk loss: -0.54925, kernel loss: 0.03949\n",
      "Epoch: 15, series: 38, nllk loss: -1.04151, kernel loss: 0.15809\n",
      "Epoch: 15, series: 39, nllk loss: -0.75188, kernel loss: 0.14681\n",
      "Epoch: 15, series: 40, nllk loss: -1.69703, kernel loss: 0.15478\n",
      "Epoch: 15, series: 41, nllk loss: -1.21094, kernel loss: 0.15013\n",
      "Epoch: 15, series: 42, nllk loss: -1.13325, kernel loss: 0.08491\n",
      "Epoch: 15, series: 43, nllk loss: -1.07387, kernel loss: 0.08503\n",
      "Epoch: 15, series: 44, nllk loss: -1.46729, kernel loss: 0.16734\n",
      "Epoch: 15, series: 45, nllk loss: -1.63781, kernel loss: 0.26225\n",
      "Epoch: 15, series: 46, nllk loss: -1.61675, kernel loss: 0.09605\n",
      "Epoch: 15, series: 47, nllk loss: -1.49177, kernel loss: 0.06293\n",
      "Epoch: 15, series: 48, nllk loss: -1.59997, kernel loss: 0.08537\n",
      "Epoch: 15, series: 49, nllk loss: -1.31308, kernel loss: 0.14832\n",
      "Epoch: 15, series: 50, nllk loss: -0.04801, kernel loss: 0.07438\n",
      "Epoch: 15, series: 51, nllk loss: -1.36827, kernel loss: 0.05401\n",
      "Epoch: 15, series: 52, nllk loss: -0.36799, kernel loss: 0.21746\n",
      "Epoch: 15, series: 53, nllk loss: -1.60983, kernel loss: 0.10721\n",
      "Epoch: 15, series: 54, nllk loss: -1.21405, kernel loss: 0.26060\n",
      "Epoch: 15, series: 55, nllk loss: -0.86863, kernel loss: 0.31098\n",
      "Epoch: 15, series: 56, nllk loss: -1.32946, kernel loss: 0.12031\n",
      "Epoch: 15, series: 57, nllk loss: -1.29234, kernel loss: 0.10047\n",
      "Epoch: 15, series: 58, nllk loss: -1.42405, kernel loss: 0.14994\n",
      "Epoch: 15, series: 59, nllk loss: -1.13930, kernel loss: 0.03907\n",
      "Epoch: 15, series: 60, nllk loss: -1.03803, kernel loss: 0.10129\n",
      "Epoch: 15, series: 61, nllk loss: -1.58550, kernel loss: 0.06631\n",
      "Epoch: 15, series: 62, nllk loss: -1.74141, kernel loss: 0.04603\n",
      "Epoch: 15, series: 63, nllk loss: -1.60210, kernel loss: 0.03505\n",
      "Epoch: 15, series: 64, nllk loss: -1.13631, kernel loss: 0.24961\n",
      "Epoch: 15, series: 65, nllk loss: -1.57917, kernel loss: 0.01347\n",
      "Epoch: 15, series: 66, nllk loss: -1.49256, kernel loss: 0.14736\n",
      "Epoch: 15, series: 67, nllk loss: -1.41334, kernel loss: 0.08045\n",
      "Epoch: 15, series: 68, nllk loss: -0.73538, kernel loss: 0.20415\n",
      "Epoch: 15, series: 69, nllk loss: -1.43896, kernel loss: 0.00000\n",
      "Epoch: 15, series: 70, nllk loss: -1.41272, kernel loss: 0.12031\n",
      "Epoch: 15, series: 71, nllk loss: -1.48412, kernel loss: 0.09572\n",
      "Epoch: 15, series: 72, nllk loss: -1.77681, kernel loss: 0.14416\n",
      "Epoch: 15, series: 73, nllk loss: -1.34260, kernel loss: 0.08760\n",
      "Epoch: 15, series: 74, nllk loss: -1.91661, kernel loss: 0.05777\n",
      "Epoch: 15, series: 75, nllk loss: -1.50925, kernel loss: 0.06469\n",
      "Epoch: 15, series: 76, nllk loss: -1.40011, kernel loss: 0.16907\n",
      "Epoch: 15, series: 77, nllk loss: -1.26789, kernel loss: 0.13916\n",
      "Epoch: 15, series: 78, nllk loss: -1.41028, kernel loss: 0.06999\n",
      "Epoch: 15, series: 79, nllk loss: -0.54492, kernel loss: 0.10028\n",
      "Epoch: 15, series: 80, nllk loss: -1.73296, kernel loss: 0.09674\n",
      "Epoch: 15, series: 81, nllk loss: -1.31057, kernel loss: 0.04919\n",
      "Epoch: 15, series: 82, nllk loss: -0.32365, kernel loss: 0.19585\n",
      "Epoch: 15, series: 83, nllk loss: -0.97454, kernel loss: 0.10674\n",
      "Epoch: 15, series: 84, nllk loss: -1.14291, kernel loss: 0.04729\n",
      "Epoch: 15, series: 85, nllk loss: -1.40606, kernel loss: 0.16297\n",
      "Epoch: 15, series: 86, nllk loss: -0.51673, kernel loss: 0.15205\n",
      "Epoch: 15, series: 87, nllk loss: -1.71049, kernel loss: 0.13957\n",
      "Epoch: 15, series: 88, nllk loss: -1.89761, kernel loss: 0.02784\n",
      "Epoch: 15, series: 89, nllk loss: -1.90217, kernel loss: 0.15786\n",
      "Epoch: 15, series: 90, nllk loss: -2.03495, kernel loss: 0.33538\n",
      "Epoch: 15, series: 91, nllk loss: -2.03296, kernel loss: 0.11416\n",
      "Epoch: 15, series: 92, nllk loss: 0.17622, kernel loss: 0.02937\n",
      "Epoch: 15, series: 93, nllk loss: -2.27025, kernel loss: 0.09781\n",
      "Epoch: 15, series: 94, nllk loss: -2.26669, kernel loss: 0.11628\n",
      "Epoch: 15, series: 95, nllk loss: -2.24870, kernel loss: 0.08403\n",
      "Epoch: 15, series: 96, nllk loss: -1.67270, kernel loss: 0.11224\n",
      "Epoch: 15, series: 97, nllk loss: -0.62481, kernel loss: 0.05085\n",
      "Epoch: 15, series: 98, nllk loss: -0.62069, kernel loss: 0.12278\n",
      "Epoch: 15, series: 99, nllk loss: -1.40582, kernel loss: 0.09557\n",
      "Epoch: 15, series: 100, nllk loss: -0.78892, kernel loss: 0.08454\n",
      "Epoch: 15, series: 101, nllk loss: -1.40964, kernel loss: 0.17242\n",
      "Epoch: 15, series: 102, nllk loss: -0.59698, kernel loss: 0.08825\n",
      "Epoch: 15, series: 103, nllk loss: -1.12864, kernel loss: 0.12421\n",
      "Epoch: 15, series: 104, nllk loss: 0.24155, kernel loss: 0.07834\n",
      "Epoch: 15, series: 105, nllk loss: -0.17018, kernel loss: 0.09169\n",
      "Epoch: 15, series: 106, nllk loss: -1.17856, kernel loss: 0.12987\n",
      "Epoch: 15, series: 107, nllk loss: -0.91098, kernel loss: 0.13819\n",
      "Epoch: 15, series: 108, nllk loss: -1.33172, kernel loss: 0.02050\n",
      "Epoch: 15, series: 109, nllk loss: -1.02059, kernel loss: 0.11977\n",
      "Epoch: 15, series: 110, nllk loss: -1.60419, kernel loss: 0.25741\n",
      "Epoch: 15, series: 111, nllk loss: -1.44708, kernel loss: 0.15921\n",
      "Epoch: 15, series: 112, nllk loss: -0.80306, kernel loss: 0.23811\n",
      "Epoch: 15, series: 113, nllk loss: -1.10326, kernel loss: 0.08122\n",
      "Epoch: 15, series: 114, nllk loss: -1.17963, kernel loss: 0.24149\n",
      "Epoch: 15, series: 115, nllk loss: -0.93941, kernel loss: 0.05417\n",
      "Epoch: 15, series: 116, nllk loss: -1.60368, kernel loss: 0.12293\n",
      "Epoch: 15, series: 117, nllk loss: -0.56950, kernel loss: 0.15288\n",
      "Epoch: 15, series: 118, nllk loss: -1.66947, kernel loss: 0.18051\n",
      "Epoch: 15, series: 119, nllk loss: -0.83283, kernel loss: 0.11547\n",
      "Epoch: 15, series: 120, nllk loss: -1.52462, kernel loss: 0.23536\n",
      "Epoch: 15, series: 121, nllk loss: 0.19563, kernel loss: 0.19345\n",
      "Epoch: 15, series: 122, nllk loss: -0.53952, kernel loss: 0.09447\n",
      "Epoch: 15, series: 123, nllk loss: -1.61353, kernel loss: 0.10597\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, series: 124, nllk loss: -1.77241, kernel loss: 0.22338\n",
      "Epoch: 15, series: 125, nllk loss: -1.33112, kernel loss: 0.07098\n",
      "Epoch: 15, series: 126, nllk loss: -1.72601, kernel loss: 0.03135\n",
      "Epoch: 15, series: 127, nllk loss: -1.34080, kernel loss: 0.02208\n",
      "Epoch: 15, series: 128, nllk loss: -0.98549, kernel loss: 0.09482\n",
      "Epoch: 15, series: 129, nllk loss: -0.69551, kernel loss: 0.04103\n",
      "Epoch: 15, series: 130, nllk loss: -1.35052, kernel loss: 0.05098\n",
      "Epoch: 15, series: 131, nllk loss: 0.48338, kernel loss: 0.01907\n",
      "Epoch: 15, series: 132, nllk loss: 0.11613, kernel loss: 0.12049\n",
      "Epoch: 15, series: 133, nllk loss: -0.92828, kernel loss: 0.31667\n",
      "Epoch: 15, series: 134, nllk loss: -0.74360, kernel loss: 0.05278\n",
      "Epoch: 15, series: 135, nllk loss: -1.40795, kernel loss: 0.11463\n",
      "Epoch: 15, series: 136, nllk loss: -1.39539, kernel loss: 0.27723\n",
      "Epoch: 15, series: 137, nllk loss: -1.55810, kernel loss: 0.06829\n",
      "Epoch: 15, series: 138, nllk loss: -1.68285, kernel loss: 0.11646\n",
      "Epoch: 15, series: 139, nllk loss: -1.63055, kernel loss: 0.11099\n",
      "Epoch: 15, series: 140, nllk loss: -1.49366, kernel loss: 0.18592\n",
      "Epoch: 15, series: 141, nllk loss: -1.62836, kernel loss: 0.16569\n",
      "Epoch: 15, series: 142, nllk loss: -1.71470, kernel loss: 0.21206\n",
      "Epoch: 15, series: 143, nllk loss: -1.65149, kernel loss: 0.17796\n",
      "Epoch: 15, series: 144, nllk loss: -1.90879, kernel loss: 0.02823\n",
      "Epoch: 15, series: 145, nllk loss: -1.87751, kernel loss: 0.15958\n",
      "Epoch: 15, series: 146, nllk loss: 2.58173, kernel loss: 0.15185\n",
      "Epoch: 15, series: 147, nllk loss: -1.64414, kernel loss: 0.12170\n",
      "Epoch: 15, series: 148, nllk loss: -1.45373, kernel loss: 0.02864\n",
      "Epoch: 15, series: 149, nllk loss: -1.76298, kernel loss: 0.08257\n",
      "Epoch: 15, series: 150, nllk loss: -1.75973, kernel loss: 0.17083\n",
      "Epoch: 15, series: 151, nllk loss: -1.92294, kernel loss: 0.09628\n",
      "Epoch: 15, series: 152, nllk loss: -1.89200, kernel loss: 0.04254\n",
      "Epoch: 15, series: 153, nllk loss: -1.69336, kernel loss: 0.28561\n",
      "Epoch: 15, series: 154, nllk loss: -1.75886, kernel loss: 0.10028\n",
      "Epoch: 15, series: 155, nllk loss: -1.78731, kernel loss: 0.05425\n",
      "Epoch: 15, series: 156, nllk loss: -1.87482, kernel loss: 0.03657\n",
      "Epoch: 15, series: 157, nllk loss: -1.38302, kernel loss: 0.23409\n",
      "Epoch: 15, series: 158, nllk loss: -1.91875, kernel loss: 0.06423\n",
      "Epoch: 15, series: 159, nllk loss: -1.89891, kernel loss: 0.10490\n",
      "Epoch: 15, series: 160, nllk loss: -1.85474, kernel loss: 0.14363\n",
      "Epoch: 15, series: 161, nllk loss: -1.76544, kernel loss: 0.22065\n",
      "Epoch: 15, series: 162, nllk loss: -1.89685, kernel loss: 0.13108\n",
      "Epoch: 15, series: 163, nllk loss: -2.19866, kernel loss: 0.05956\n",
      "Epoch: 15, series: 164, nllk loss: -1.80962, kernel loss: 0.21018\n",
      "Epoch: 15, series: 165, nllk loss: -1.88128, kernel loss: 0.29575\n",
      "Epoch: 15, series: 166, nllk loss: -1.36006, kernel loss: 0.26313\n",
      "Epoch: 15, series: 167, nllk loss: -2.44607, kernel loss: 0.13209\n",
      "Epoch: 15, series: 168, nllk loss: -2.22001, kernel loss: 0.18099\n",
      "Epoch: 15, series: 169, nllk loss: -2.27193, kernel loss: 0.11673\n",
      "Epoch: 15, series: 170, nllk loss: -1.81669, kernel loss: 0.16079\n",
      "Epoch: 15, series: 171, nllk loss: -2.34833, kernel loss: 0.24687\n",
      "Epoch: 15, series: 172, nllk loss: -1.96121, kernel loss: 0.18570\n",
      "Epoch: 15, series: 173, nllk loss: -2.45676, kernel loss: 0.14497\n",
      "Epoch: 15, series: 174, nllk loss: -2.09094, kernel loss: 0.06188\n",
      "Epoch: 15, series: 175, nllk loss: -2.50196, kernel loss: 0.19648\n",
      "Epoch: 15, series: 176, nllk loss: -2.08919, kernel loss: 0.13341\n",
      "Epoch: 15, series: 177, nllk loss: -1.92225, kernel loss: 0.03348\n",
      "Epoch: 15, series: 178, nllk loss: -1.76671, kernel loss: 0.22242\n",
      "Epoch: 15, series: 179, nllk loss: -2.20553, kernel loss: 0.19765\n",
      "Epoch: 15, series: 180, nllk loss: -2.16203, kernel loss: 0.12481\n",
      "Epoch: 15, series: 181, nllk loss: -2.49745, kernel loss: 0.05968\n",
      "Epoch: 15, series: 182, nllk loss: -2.20835, kernel loss: 0.26676\n",
      "Epoch: 15, series: 183, nllk loss: -1.89771, kernel loss: 0.12988\n",
      "Epoch: 15, series: 184, nllk loss: -1.96376, kernel loss: 0.04011\n",
      "Epoch: 15, series: 185, nllk loss: -1.61810, kernel loss: 0.07807\n",
      "Epoch: 15, series: 186, nllk loss: -2.55885, kernel loss: 0.09947\n",
      "Epoch: 15, series: 187, nllk loss: -2.67459, kernel loss: 0.10889\n",
      "Epoch: 15, series: 188, nllk loss: -1.66577, kernel loss: 0.13789\n",
      "Epoch: 15, series: 189, nllk loss: -1.45635, kernel loss: 0.02861\n",
      "Epoch: 15, series: 190, nllk loss: -1.82859, kernel loss: 0.12864\n",
      "Epoch: 15, series: 191, nllk loss: -1.84862, kernel loss: 0.24666\n",
      "Epoch: 15, series: 192, nllk loss: -2.20788, kernel loss: 0.08639\n",
      "Epoch: 15, series: 193, nllk loss: -1.52110, kernel loss: 0.04954\n",
      "Epoch: 15, series: 194, nllk loss: -1.41485, kernel loss: 0.13393\n",
      "Epoch: 15, series: 195, nllk loss: -2.19318, kernel loss: 0.15206\n",
      "Epoch: 15, series: 196, nllk loss: -1.80047, kernel loss: 0.10584\n",
      "Epoch: 15, series: 197, nllk loss: -2.15996, kernel loss: 0.06509\n",
      "Epoch: 15, series: 198, nllk loss: -2.15379, kernel loss: 0.16566\n",
      "Epoch: 15, series: 199, nllk loss: -1.84132, kernel loss: 0.13778\n",
      "Epoch: 15, series: 200, nllk loss: -2.22891, kernel loss: 0.06404\n",
      "Epoch: 15, series: 201, nllk loss: -2.33262, kernel loss: 0.25468\n",
      "Epoch: 15, series: 202, nllk loss: -2.05848, kernel loss: 0.14214\n",
      "Epoch: 15, series: 203, nllk loss: -1.84442, kernel loss: 0.12085\n",
      "Epoch: 15, series: 204, nllk loss: -0.91111, kernel loss: 0.08439\n",
      "Epoch: 15, series: 205, nllk loss: -2.00841, kernel loss: 0.07595\n",
      "Epoch: 15, series: 206, nllk loss: -2.05035, kernel loss: 0.31783\n",
      "Epoch: 15, series: 207, nllk loss: -1.00981, kernel loss: 0.27527\n",
      "Epoch: 15, series: 208, nllk loss: -2.38290, kernel loss: 0.24388\n",
      "Epoch: 15, series: 209, nllk loss: -1.75850, kernel loss: 0.10094\n",
      "Epoch: 15, series: 210, nllk loss: -2.47302, kernel loss: 0.09579\n",
      "Epoch: 15, series: 211, nllk loss: -1.86890, kernel loss: 0.07227\n",
      "Epoch: 15, series: 212, nllk loss: -1.39763, kernel loss: 0.07601\n",
      "Epoch: 15, series: 213, nllk loss: -2.13846, kernel loss: 0.11730\n",
      "Epoch: 15, series: 214, nllk loss: -2.05691, kernel loss: 0.01992\n",
      "Epoch: 15, series: 215, nllk loss: -2.31366, kernel loss: 0.06323\n",
      "Epoch: 15, series: 216, nllk loss: -1.31448, kernel loss: 0.06339\n",
      "Epoch: 15, series: 217, nllk loss: -1.85800, kernel loss: 0.03029\n",
      "Epoch: 15, series: 218, nllk loss: -1.42436, kernel loss: 0.06618\n",
      "Epoch: 15, series: 219, nllk loss: -2.02272, kernel loss: 0.15813\n",
      "Epoch: 15, series: 220, nllk loss: -2.11970, kernel loss: 0.05219\n",
      "Epoch: 15, series: 221, nllk loss: -2.29393, kernel loss: 0.04171\n",
      "Epoch: 15, series: 222, nllk loss: -2.17753, kernel loss: 0.18728\n",
      "Epoch: 15, series: 223, nllk loss: -1.41350, kernel loss: 0.09314\n",
      "Epoch: 15, series: 224, nllk loss: -2.39100, kernel loss: 0.17123\n",
      "Epoch: 15, series: 225, nllk loss: -2.31886, kernel loss: 0.03958\n",
      "Epoch: 15, series: 226, nllk loss: -1.81360, kernel loss: 0.09424\n",
      "Epoch: 15, series: 227, nllk loss: -2.01323, kernel loss: 0.11382\n",
      "Epoch: 15, series: 228, nllk loss: -1.99891, kernel loss: 0.14593\n",
      "Epoch: 15, series: 229, nllk loss: -1.86684, kernel loss: 0.14860\n",
      "Epoch: 15, series: 230, nllk loss: -2.24091, kernel loss: 0.18722\n",
      "Epoch: 15, series: 231, nllk loss: -1.88605, kernel loss: 0.00673\n",
      "Epoch: 15, series: 232, nllk loss: -2.48318, kernel loss: 0.26797\n",
      "Epoch: 15, series: 233, nllk loss: -2.39734, kernel loss: 0.07969\n",
      "Epoch: 15, series: 234, nllk loss: -1.98102, kernel loss: 0.01083\n",
      "Epoch: 15, series: 235, nllk loss: -2.45823, kernel loss: 0.08930\n",
      "Epoch: 15, series: 236, nllk loss: -1.56683, kernel loss: 0.01928\n",
      "Epoch: 15, series: 237, nllk loss: -2.10862, kernel loss: 0.15281\n",
      "Epoch: 15, series: 238, nllk loss: -2.00599, kernel loss: 0.03174\n",
      "Epoch: 15, series: 239, nllk loss: -2.18906, kernel loss: 0.19588\n",
      "Epoch: 15, series: 240, nllk loss: -1.14782, kernel loss: 0.16813\n",
      "Epoch: 15, series: 241, nllk loss: -1.89461, kernel loss: 0.01974\n",
      "Epoch: 15, series: 242, nllk loss: -2.00353, kernel loss: 0.02730\n",
      "Epoch: 15, series: 243, nllk loss: -2.49926, kernel loss: 0.14803\n",
      "Epoch: 15, series: 244, nllk loss: -1.98655, kernel loss: 0.24601\n",
      "Epoch: 15, series: 245, nllk loss: -2.15884, kernel loss: 0.08312\n",
      "Epoch: 15, series: 246, nllk loss: 0.13969, kernel loss: 0.03644\n",
      "Epoch: 15, series: 247, nllk loss: -1.80406, kernel loss: 0.06345\n",
      "Epoch: 15, series: 248, nllk loss: -2.07800, kernel loss: 0.03521\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15, series: 249, nllk loss: -2.05637, kernel loss: 0.04060\n",
      "Epoch: 15, series: 250, nllk loss: -1.72283, kernel loss: 0.17453\n",
      "Epoch: 15, series: 251, nllk loss: -1.15735, kernel loss: 0.04148\n",
      "Epoch: 15, series: 252, nllk loss: -1.47559, kernel loss: 0.09816\n",
      "Epoch: 15, series: 253, nllk loss: -1.80798, kernel loss: 0.20080\n",
      "Epoch: 15, series: 254, nllk loss: -2.29636, kernel loss: 0.11160\n",
      "Epoch: 15, series: 255, nllk loss: -2.13465, kernel loss: 0.07906\n",
      "Epoch: 15, series: 256, nllk loss: -1.86583, kernel loss: 0.04231\n",
      "Epoch: 15, series: 257, nllk loss: -2.05177, kernel loss: 0.12105\n",
      "Epoch: 15, series: 258, nllk loss: -2.14477, kernel loss: 0.25884\n",
      "Epoch: 15, series: 259, nllk loss: -1.85847, kernel loss: 0.13061\n",
      "Epoch: 15, series: 260, nllk loss: -2.03578, kernel loss: 0.07434\n",
      "Epoch: 15, series: 261, nllk loss: -2.18365, kernel loss: 0.16430\n",
      "Epoch: 15, series: 262, nllk loss: -2.53797, kernel loss: 0.10712\n",
      "Epoch: 15, series: 263, nllk loss: -0.53883, kernel loss: 0.07377\n",
      "Epoch: 15, series: 264, nllk loss: -1.94850, kernel loss: 0.16278\n",
      "Epoch: 15, series: 265, nllk loss: -1.87587, kernel loss: 0.09954\n",
      "Epoch: 15, series: 266, nllk loss: -2.29308, kernel loss: 0.15630\n",
      "Epoch: 15, series: 267, nllk loss: -2.13901, kernel loss: 0.02387\n",
      "Epoch: 15, series: 268, nllk loss: -2.19664, kernel loss: 0.19723\n",
      "Epoch: 15, series: 269, nllk loss: -1.87415, kernel loss: 0.05148\n",
      "Epoch: 15, series: 270, nllk loss: -1.83013, kernel loss: 0.18817\n",
      "Epoch: 15, series: 271, nllk loss: -1.98758, kernel loss: 0.08273\n",
      "Epoch: 15, series: 272, nllk loss: -1.86363, kernel loss: 0.01401\n",
      "Epoch: 15, series: 273, nllk loss: -2.04254, kernel loss: 0.13287\n",
      "Epoch: 15, series: 274, nllk loss: -1.64774, kernel loss: 0.19862\n",
      "Epoch: 15, series: 275, nllk loss: -1.86022, kernel loss: 0.08478\n",
      "Epoch: 15, series: 276, nllk loss: -1.27457, kernel loss: 0.11844\n",
      "Epoch: 15, series: 277, nllk loss: -2.18299, kernel loss: 0.16959\n",
      "Epoch: 15, series: 278, nllk loss: -1.95094, kernel loss: 0.17647\n",
      "Epoch: 15, series: 279, nllk loss: -2.32102, kernel loss: 0.01853\n",
      "Epoch: 15, series: 280, nllk loss: -2.09844, kernel loss: 0.16168\n",
      "Epoch: 15, series: 281, nllk loss: -2.24030, kernel loss: 0.13986\n",
      "Epoch: 15, series: 282, nllk loss: -2.18869, kernel loss: 0.08410\n",
      "Epoch: 15, series: 283, nllk loss: -2.03535, kernel loss: 0.05240\n",
      "Epoch: 15, series: 284, nllk loss: -1.70450, kernel loss: 0.28254\n",
      "Epoch: 15, series: 285, nllk loss: -1.89536, kernel loss: 0.14771\n",
      "Epoch: 15, series: 286, nllk loss: -2.14583, kernel loss: 0.06284\n",
      "Epoch: 15, series: 287, nllk loss: -2.43752, kernel loss: 0.02893\n",
      "Epoch: 15, series: 288, nllk loss: -1.29325, kernel loss: 0.07276\n",
      "Epoch: 15, series: 289, nllk loss: -1.06439, kernel loss: 0.06578\n",
      "Epoch: 15, series: 290, nllk loss: -2.13686, kernel loss: 0.23544\n",
      "Epoch: 15, series: 291, nllk loss: -2.14886, kernel loss: 0.22019\n",
      "Epoch: 15, series: 292, nllk loss: -2.16716, kernel loss: 0.07426\n",
      "Epoch: 15, series: 293, nllk loss: -2.41640, kernel loss: 0.15327\n",
      "Epoch: 15, series: 294, nllk loss: -1.57356, kernel loss: 0.07187\n",
      "Epoch: 15, series: 295, nllk loss: -1.13206, kernel loss: 0.32489\n",
      "Epoch: 15, series: 296, nllk loss: -2.31479, kernel loss: 0.21427\n",
      "Epoch: 15, series: 297, nllk loss: -2.42493, kernel loss: 0.02410\n",
      "Epoch: 15, series: 298, nllk loss: 0.95889, kernel loss: 0.11387\n",
      "Epoch: 15, series: 299, nllk loss: -0.38870, kernel loss: 0.10850\n",
      "Epoch: 15, series: 300, nllk loss: -1.64365, kernel loss: 0.22753\n",
      "Epoch: 15, series: 301, nllk loss: -1.99614, kernel loss: 0.18755\n",
      "Epoch: 15, series: 302, nllk loss: -2.16480, kernel loss: 0.10850\n",
      "Epoch: 15, series: 303, nllk loss: -1.94023, kernel loss: 0.05248\n",
      "Epoch: 15, series: 304, nllk loss: 0.56641, kernel loss: 0.19001\n",
      "Epoch: 15, series: 305, nllk loss: -1.54301, kernel loss: 0.15199\n",
      "Epoch: 15, series: 306, nllk loss: -2.28608, kernel loss: 0.00130\n",
      "Epoch: 15, series: 307, nllk loss: -1.62738, kernel loss: 0.09128\n",
      "Epoch: 15, series: 308, nllk loss: -2.21369, kernel loss: 0.15899\n",
      "Epoch: 15, series: 309, nllk loss: -1.86173, kernel loss: 0.07189\n",
      "Epoch: 15, series: 310, nllk loss: -1.96539, kernel loss: 0.09824\n",
      "Epoch: 15, series: 311, nllk loss: -1.73199, kernel loss: 0.00000\n",
      "Epoch: 15, series: 312, nllk loss: -2.07405, kernel loss: 0.13572\n",
      "Epoch: 15, series: 313, nllk loss: -2.21661, kernel loss: 0.13314\n",
      "Epoch: 15, series: 314, nllk loss: -2.55409, kernel loss: 0.09351\n",
      "Epoch: 15, series: 315, nllk loss: -0.98711, kernel loss: 0.10554\n",
      "Epoch: 15, series: 316, nllk loss: -2.03387, kernel loss: 0.11831\n",
      "Epoch: 15, series: 317, nllk loss: 0.48027, kernel loss: 0.12222\n",
      "Epoch: 15, series: 318, nllk loss: 1.60649, kernel loss: 0.16182\n",
      "Epoch: 15, series: 319, nllk loss: -0.91718, kernel loss: 0.30526\n",
      "Epoch: 15, series: 320, nllk loss: -0.80810, kernel loss: 0.13783\n",
      "Epoch: 15, total loss: -449.34481\n",
      "Epoch: 16, series: 0, nllk loss: 1.62894, kernel loss: 0.10083\n",
      "Epoch: 16, series: 1, nllk loss: -1.11443, kernel loss: 0.02370\n",
      "Epoch: 16, series: 2, nllk loss: -0.09860, kernel loss: 0.09427\n",
      "Epoch: 16, series: 3, nllk loss: -1.37165, kernel loss: 0.05239\n",
      "Epoch: 16, series: 4, nllk loss: -1.00155, kernel loss: 0.28590\n",
      "Epoch: 16, series: 5, nllk loss: -1.27029, kernel loss: 0.24687\n",
      "Epoch: 16, series: 6, nllk loss: -0.46690, kernel loss: 0.15037\n",
      "Epoch: 16, series: 7, nllk loss: -1.13451, kernel loss: 0.22715\n",
      "Epoch: 16, series: 8, nllk loss: -0.60640, kernel loss: 0.12257\n",
      "Epoch: 16, series: 9, nllk loss: -0.60436, kernel loss: 0.08767\n",
      "Epoch: 16, series: 10, nllk loss: -1.19791, kernel loss: 0.06535\n",
      "Epoch: 16, series: 11, nllk loss: -1.07290, kernel loss: 0.19508\n",
      "Epoch: 16, series: 12, nllk loss: -1.39552, kernel loss: 0.06177\n",
      "Epoch: 16, series: 13, nllk loss: -1.29399, kernel loss: 0.15615\n",
      "Epoch: 16, series: 14, nllk loss: -1.40336, kernel loss: 0.17997\n",
      "Epoch: 16, series: 15, nllk loss: -1.41606, kernel loss: 0.04927\n",
      "Epoch: 16, series: 16, nllk loss: -1.04368, kernel loss: 0.10113\n",
      "Epoch: 16, series: 17, nllk loss: -1.08022, kernel loss: 0.18604\n",
      "Epoch: 16, series: 18, nllk loss: -1.36805, kernel loss: 0.12219\n",
      "Epoch: 16, series: 19, nllk loss: -0.39214, kernel loss: 0.10244\n",
      "Epoch: 16, series: 20, nllk loss: -0.60296, kernel loss: 0.35017\n",
      "Epoch: 16, series: 21, nllk loss: -1.11619, kernel loss: 0.44904\n",
      "Epoch: 16, series: 22, nllk loss: -1.47520, kernel loss: 0.29700\n",
      "Epoch: 16, series: 23, nllk loss: -1.39424, kernel loss: 0.02398\n",
      "Epoch: 16, series: 24, nllk loss: -1.61778, kernel loss: 0.07266\n",
      "Epoch: 16, series: 25, nllk loss: -1.52677, kernel loss: 0.20603\n",
      "Epoch: 16, series: 26, nllk loss: -1.41691, kernel loss: 0.02232\n",
      "Epoch: 16, series: 27, nllk loss: -1.17824, kernel loss: 0.01347\n",
      "Epoch: 16, series: 28, nllk loss: -1.39674, kernel loss: 0.14066\n",
      "Epoch: 16, series: 29, nllk loss: -0.87352, kernel loss: 0.13456\n",
      "Epoch: 16, series: 30, nllk loss: -1.40503, kernel loss: 0.03464\n",
      "Epoch: 16, series: 31, nllk loss: -1.06302, kernel loss: 0.11776\n",
      "Epoch: 16, series: 32, nllk loss: -1.10863, kernel loss: 0.17347\n",
      "Epoch: 16, series: 33, nllk loss: -0.92515, kernel loss: 0.11941\n",
      "Epoch: 16, series: 34, nllk loss: -1.34946, kernel loss: 0.09358\n",
      "Epoch: 16, series: 35, nllk loss: -1.59930, kernel loss: 0.19420\n",
      "Epoch: 16, series: 36, nllk loss: -1.49325, kernel loss: 0.20804\n",
      "Epoch: 16, series: 37, nllk loss: -0.56792, kernel loss: 0.10530\n",
      "Epoch: 16, series: 38, nllk loss: -1.09202, kernel loss: 0.10208\n",
      "Epoch: 16, series: 39, nllk loss: -0.79235, kernel loss: 0.14073\n",
      "Epoch: 16, series: 40, nllk loss: -1.79745, kernel loss: 0.06194\n",
      "Epoch: 16, series: 41, nllk loss: -1.37793, kernel loss: 0.14181\n",
      "Epoch: 16, series: 42, nllk loss: -1.09497, kernel loss: 0.24866\n",
      "Epoch: 16, series: 43, nllk loss: -1.09821, kernel loss: 0.01877\n",
      "Epoch: 16, series: 44, nllk loss: -1.58113, kernel loss: 0.32986\n",
      "Epoch: 16, series: 45, nllk loss: -1.60835, kernel loss: 0.17979\n",
      "Epoch: 16, series: 46, nllk loss: -1.66578, kernel loss: 0.14337\n",
      "Epoch: 16, series: 47, nllk loss: -1.54480, kernel loss: 0.16786\n",
      "Epoch: 16, series: 48, nllk loss: -1.66284, kernel loss: 0.17265\n",
      "Epoch: 16, series: 49, nllk loss: -1.27370, kernel loss: 0.11870\n",
      "Epoch: 16, series: 50, nllk loss: -0.11101, kernel loss: 0.10735\n",
      "Epoch: 16, series: 51, nllk loss: -1.36687, kernel loss: 0.05405\n",
      "Epoch: 16, series: 52, nllk loss: -0.46131, kernel loss: 0.04716\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, series: 53, nllk loss: -1.68082, kernel loss: 0.09012\n",
      "Epoch: 16, series: 54, nllk loss: -1.37735, kernel loss: 0.12764\n",
      "Epoch: 16, series: 55, nllk loss: -0.90944, kernel loss: 0.12186\n",
      "Epoch: 16, series: 56, nllk loss: -1.45720, kernel loss: 0.08096\n",
      "Epoch: 16, series: 57, nllk loss: -1.42608, kernel loss: 0.06194\n",
      "Epoch: 16, series: 58, nllk loss: -1.56382, kernel loss: 0.14827\n",
      "Epoch: 16, series: 59, nllk loss: -1.18974, kernel loss: 0.08334\n",
      "Epoch: 16, series: 60, nllk loss: -1.05084, kernel loss: 0.07520\n",
      "Epoch: 16, series: 61, nllk loss: -1.68406, kernel loss: 0.19486\n",
      "Epoch: 16, series: 62, nllk loss: -1.77414, kernel loss: 0.01639\n",
      "Epoch: 16, series: 63, nllk loss: -1.63399, kernel loss: 0.02815\n",
      "Epoch: 16, series: 64, nllk loss: -1.10154, kernel loss: 0.07510\n",
      "Epoch: 16, series: 65, nllk loss: -1.61949, kernel loss: 0.08861\n",
      "Epoch: 16, series: 66, nllk loss: -1.57033, kernel loss: 0.04465\n",
      "Epoch: 16, series: 67, nllk loss: -1.45136, kernel loss: 0.07812\n",
      "Epoch: 16, series: 68, nllk loss: -0.74601, kernel loss: 0.09608\n",
      "Epoch: 16, series: 69, nllk loss: -1.58932, kernel loss: 0.06910\n",
      "Epoch: 16, series: 70, nllk loss: -1.40683, kernel loss: 0.14812\n",
      "Epoch: 16, series: 71, nllk loss: -1.56063, kernel loss: 0.20979\n",
      "Epoch: 16, series: 72, nllk loss: -1.79083, kernel loss: 0.15779\n",
      "Epoch: 16, series: 73, nllk loss: -1.26759, kernel loss: 0.10030\n",
      "Epoch: 16, series: 74, nllk loss: -1.93744, kernel loss: 0.03859\n",
      "Epoch: 16, series: 75, nllk loss: -1.54479, kernel loss: 0.05379\n",
      "Epoch: 16, series: 76, nllk loss: -1.35979, kernel loss: 0.07468\n",
      "Epoch: 16, series: 77, nllk loss: -1.25158, kernel loss: 0.16017\n",
      "Epoch: 16, series: 78, nllk loss: -1.32197, kernel loss: 0.09148\n",
      "Epoch: 16, series: 79, nllk loss: -0.37077, kernel loss: 0.11954\n",
      "Epoch: 16, series: 80, nllk loss: -1.79756, kernel loss: 0.25507\n",
      "Epoch: 16, series: 81, nllk loss: -1.35179, kernel loss: 0.11973\n",
      "Epoch: 16, series: 82, nllk loss: -0.36529, kernel loss: 0.07195\n",
      "Epoch: 16, series: 83, nllk loss: -1.02994, kernel loss: 0.13978\n",
      "Epoch: 16, series: 84, nllk loss: -1.18150, kernel loss: 0.07046\n",
      "Epoch: 16, series: 85, nllk loss: -1.50891, kernel loss: 0.19523\n",
      "Epoch: 16, series: 86, nllk loss: -0.61483, kernel loss: 0.15018\n",
      "Epoch: 16, series: 87, nllk loss: -1.68602, kernel loss: 0.19156\n",
      "Epoch: 16, series: 88, nllk loss: -1.94551, kernel loss: 0.07601\n",
      "Epoch: 16, series: 89, nllk loss: -1.95322, kernel loss: 0.15392\n",
      "Epoch: 16, series: 90, nllk loss: -2.14628, kernel loss: 0.12659\n",
      "Epoch: 16, series: 91, nllk loss: -2.12746, kernel loss: 0.45254\n",
      "Epoch: 16, series: 92, nllk loss: 0.10480, kernel loss: 0.23930\n",
      "Epoch: 16, series: 93, nllk loss: -2.45696, kernel loss: 0.13227\n",
      "Epoch: 16, series: 94, nllk loss: -2.43510, kernel loss: 0.24411\n",
      "Epoch: 16, series: 95, nllk loss: -2.38640, kernel loss: 0.05339\n",
      "Epoch: 16, series: 96, nllk loss: -1.45201, kernel loss: 0.34112\n",
      "Epoch: 16, series: 97, nllk loss: -0.64564, kernel loss: 0.08836\n",
      "Epoch: 16, series: 98, nllk loss: -0.73117, kernel loss: 0.00000\n",
      "Epoch: 16, series: 99, nllk loss: -1.35801, kernel loss: 0.06500\n",
      "Epoch: 16, series: 100, nllk loss: -0.69346, kernel loss: 0.06074\n",
      "Epoch: 16, series: 101, nllk loss: -1.25743, kernel loss: 0.02891\n",
      "Epoch: 16, series: 102, nllk loss: -0.57219, kernel loss: 0.09090\n",
      "Epoch: 16, series: 103, nllk loss: -1.05790, kernel loss: 0.14077\n",
      "Epoch: 16, series: 104, nllk loss: 0.12435, kernel loss: 0.13674\n",
      "Epoch: 16, series: 105, nllk loss: -0.18239, kernel loss: 0.10825\n",
      "Epoch: 16, series: 106, nllk loss: -1.15827, kernel loss: 0.18273\n",
      "Epoch: 16, series: 107, nllk loss: -0.94957, kernel loss: 0.15049\n",
      "Epoch: 16, series: 108, nllk loss: -1.28927, kernel loss: 0.18150\n",
      "Epoch: 16, series: 109, nllk loss: -1.05728, kernel loss: 0.13435\n",
      "Epoch: 16, series: 110, nllk loss: -1.56731, kernel loss: 0.10300\n",
      "Epoch: 16, series: 111, nllk loss: -1.44046, kernel loss: 0.06769\n",
      "Epoch: 16, series: 112, nllk loss: -0.84106, kernel loss: 0.00437\n",
      "Epoch: 16, series: 113, nllk loss: -1.16666, kernel loss: 0.17350\n",
      "Epoch: 16, series: 114, nllk loss: -1.18858, kernel loss: 0.14266\n",
      "Epoch: 16, series: 115, nllk loss: -0.99346, kernel loss: 0.16761\n",
      "Epoch: 16, series: 116, nllk loss: -1.56139, kernel loss: 0.05990\n",
      "Epoch: 16, series: 117, nllk loss: -0.63623, kernel loss: 0.13615\n",
      "Epoch: 16, series: 118, nllk loss: -1.71902, kernel loss: 0.06032\n",
      "Epoch: 16, series: 119, nllk loss: -0.74400, kernel loss: 0.12865\n",
      "Epoch: 16, series: 120, nllk loss: -1.52483, kernel loss: 0.18728\n",
      "Epoch: 16, series: 121, nllk loss: 0.14822, kernel loss: 0.06135\n",
      "Epoch: 16, series: 122, nllk loss: -0.52605, kernel loss: 0.22072\n",
      "Epoch: 16, series: 123, nllk loss: -1.72050, kernel loss: 0.08216\n",
      "Epoch: 16, series: 124, nllk loss: -1.80663, kernel loss: 0.08265\n",
      "Epoch: 16, series: 125, nllk loss: -1.34610, kernel loss: 0.14756\n",
      "Epoch: 16, series: 126, nllk loss: -1.75083, kernel loss: 0.16687\n",
      "Epoch: 16, series: 127, nllk loss: -1.37381, kernel loss: 0.03069\n",
      "Epoch: 16, series: 128, nllk loss: -0.99558, kernel loss: 0.19496\n",
      "Epoch: 16, series: 129, nllk loss: -0.71539, kernel loss: 0.15234\n",
      "Epoch: 16, series: 130, nllk loss: -1.37177, kernel loss: 0.09491\n",
      "Epoch: 16, series: 131, nllk loss: 0.47609, kernel loss: 0.08962\n",
      "Epoch: 16, series: 132, nllk loss: 0.11166, kernel loss: 0.24050\n",
      "Epoch: 16, series: 133, nllk loss: -0.95866, kernel loss: 0.04016\n",
      "Epoch: 16, series: 134, nllk loss: -0.76422, kernel loss: 0.07808\n",
      "Epoch: 16, series: 135, nllk loss: -1.46686, kernel loss: 0.18346\n",
      "Epoch: 16, series: 136, nllk loss: -1.49906, kernel loss: 0.13733\n",
      "Epoch: 16, series: 137, nllk loss: -1.53518, kernel loss: 0.08356\n",
      "Epoch: 16, series: 138, nllk loss: -1.71034, kernel loss: 0.35021\n",
      "Epoch: 16, series: 139, nllk loss: -1.65301, kernel loss: 0.12305\n",
      "Epoch: 16, series: 140, nllk loss: -1.54961, kernel loss: 0.14245\n",
      "Epoch: 16, series: 141, nllk loss: -1.66998, kernel loss: 0.05639\n",
      "Epoch: 16, series: 142, nllk loss: -1.72724, kernel loss: 0.09911\n",
      "Epoch: 16, series: 143, nllk loss: -1.71143, kernel loss: 0.12389\n",
      "Epoch: 16, series: 144, nllk loss: -2.01115, kernel loss: 0.12731\n",
      "Epoch: 16, series: 145, nllk loss: -1.91286, kernel loss: 0.10297\n",
      "Epoch: 16, series: 146, nllk loss: 2.52604, kernel loss: 0.40122\n",
      "Epoch: 16, series: 147, nllk loss: -1.60658, kernel loss: 0.15152\n",
      "Epoch: 16, series: 148, nllk loss: -1.52457, kernel loss: 0.11126\n",
      "Epoch: 16, series: 149, nllk loss: -1.73809, kernel loss: 0.23782\n",
      "Epoch: 16, series: 150, nllk loss: -1.84802, kernel loss: 0.14542\n",
      "Epoch: 16, series: 151, nllk loss: -1.96308, kernel loss: 0.08569\n",
      "Epoch: 16, series: 152, nllk loss: -1.93321, kernel loss: 0.01659\n",
      "Epoch: 16, series: 153, nllk loss: -1.65996, kernel loss: 0.10910\n",
      "Epoch: 16, series: 154, nllk loss: -1.79660, kernel loss: 0.12983\n",
      "Epoch: 16, series: 155, nllk loss: -1.82300, kernel loss: 0.19393\n",
      "Epoch: 16, series: 156, nllk loss: -1.96325, kernel loss: 0.09833\n",
      "Epoch: 16, series: 157, nllk loss: -1.45656, kernel loss: 0.06124\n",
      "Epoch: 16, series: 158, nllk loss: -1.98189, kernel loss: 0.02126\n",
      "Epoch: 16, series: 159, nllk loss: -1.99151, kernel loss: 0.01820\n",
      "Epoch: 16, series: 160, nllk loss: -1.90131, kernel loss: 0.04499\n",
      "Epoch: 16, series: 161, nllk loss: -1.82121, kernel loss: 0.10089\n",
      "Epoch: 16, series: 162, nllk loss: -2.07133, kernel loss: 0.25932\n",
      "Epoch: 16, series: 163, nllk loss: -2.36127, kernel loss: 0.13685\n",
      "Epoch: 16, series: 164, nllk loss: -1.88974, kernel loss: 0.07052\n",
      "Epoch: 16, series: 165, nllk loss: -1.95704, kernel loss: 0.14820\n",
      "Epoch: 16, series: 166, nllk loss: -1.35727, kernel loss: 0.00447\n",
      "Epoch: 16, series: 167, nllk loss: -2.52217, kernel loss: 0.01670\n",
      "Epoch: 16, series: 168, nllk loss: -2.12894, kernel loss: 0.18209\n",
      "Epoch: 16, series: 169, nllk loss: -2.34300, kernel loss: 0.12330\n",
      "Epoch: 16, series: 170, nllk loss: -1.93485, kernel loss: 0.04249\n",
      "Epoch: 16, series: 171, nllk loss: -2.42826, kernel loss: 0.10745\n",
      "Epoch: 16, series: 172, nllk loss: -2.06379, kernel loss: 0.06248\n",
      "Epoch: 16, series: 173, nllk loss: -2.53333, kernel loss: 0.07558\n",
      "Epoch: 16, series: 174, nllk loss: -2.18515, kernel loss: 0.13492\n",
      "Epoch: 16, series: 175, nllk loss: -2.50553, kernel loss: 0.17492\n",
      "Epoch: 16, series: 176, nllk loss: -2.04308, kernel loss: 0.08133\n",
      "Epoch: 16, series: 177, nllk loss: -1.97054, kernel loss: 0.10655\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, series: 178, nllk loss: -1.73208, kernel loss: 0.20123\n",
      "Epoch: 16, series: 179, nllk loss: -2.23396, kernel loss: 0.13419\n",
      "Epoch: 16, series: 180, nllk loss: -2.34931, kernel loss: 0.12499\n",
      "Epoch: 16, series: 181, nllk loss: -2.60176, kernel loss: 0.36588\n",
      "Epoch: 16, series: 182, nllk loss: -2.10117, kernel loss: 0.14173\n",
      "Epoch: 16, series: 183, nllk loss: -1.98632, kernel loss: 0.19890\n",
      "Epoch: 16, series: 184, nllk loss: -1.95051, kernel loss: 0.15371\n",
      "Epoch: 16, series: 185, nllk loss: -1.49705, kernel loss: 0.12983\n",
      "Epoch: 16, series: 186, nllk loss: -2.52334, kernel loss: 0.16804\n",
      "Epoch: 16, series: 187, nllk loss: -2.64363, kernel loss: 0.25045\n",
      "Epoch: 16, series: 188, nllk loss: -1.63074, kernel loss: 0.18304\n",
      "Epoch: 16, series: 189, nllk loss: -1.46176, kernel loss: 0.00000\n",
      "Epoch: 16, series: 190, nllk loss: -1.86482, kernel loss: 0.19562\n",
      "Epoch: 16, series: 191, nllk loss: -1.89979, kernel loss: 0.05616\n",
      "Epoch: 16, series: 192, nllk loss: -2.07549, kernel loss: 0.26468\n",
      "Epoch: 16, series: 193, nllk loss: -1.55029, kernel loss: 0.07686\n",
      "Epoch: 16, series: 194, nllk loss: -1.43855, kernel loss: 0.16614\n",
      "Epoch: 16, series: 195, nllk loss: -2.25376, kernel loss: 0.06955\n",
      "Epoch: 16, series: 196, nllk loss: -1.88432, kernel loss: 0.02883\n",
      "Epoch: 16, series: 197, nllk loss: -2.09540, kernel loss: 0.22076\n",
      "Epoch: 16, series: 198, nllk loss: -2.10405, kernel loss: 0.14632\n",
      "Epoch: 16, series: 199, nllk loss: -1.92439, kernel loss: 0.11042\n",
      "Epoch: 16, series: 200, nllk loss: -2.22657, kernel loss: 0.06247\n",
      "Epoch: 16, series: 201, nllk loss: -2.31944, kernel loss: 0.02731\n",
      "Epoch: 16, series: 202, nllk loss: -2.07504, kernel loss: 0.12985\n",
      "Epoch: 16, series: 203, nllk loss: -1.97334, kernel loss: 0.04374\n",
      "Epoch: 16, series: 204, nllk loss: -1.07998, kernel loss: 0.13113\n",
      "Epoch: 16, series: 205, nllk loss: -2.17547, kernel loss: 0.07922\n",
      "Epoch: 16, series: 206, nllk loss: -2.21104, kernel loss: 0.20699\n",
      "Epoch: 16, series: 207, nllk loss: -0.91879, kernel loss: 0.03648\n",
      "Epoch: 16, series: 208, nllk loss: -2.31759, kernel loss: 0.09906\n",
      "Epoch: 16, series: 209, nllk loss: -1.82325, kernel loss: 0.09831\n",
      "Epoch: 16, series: 210, nllk loss: -2.58380, kernel loss: 0.07734\n",
      "Epoch: 16, series: 211, nllk loss: -2.10053, kernel loss: 0.13240\n",
      "Epoch: 16, series: 212, nllk loss: -1.55449, kernel loss: 0.04208\n",
      "Epoch: 16, series: 213, nllk loss: -2.20194, kernel loss: 0.17098\n",
      "Epoch: 16, series: 214, nllk loss: -2.14262, kernel loss: 0.13403\n",
      "Epoch: 16, series: 215, nllk loss: -2.46972, kernel loss: 0.11736\n",
      "Epoch: 16, series: 216, nllk loss: -1.24586, kernel loss: 0.24563\n",
      "Epoch: 16, series: 217, nllk loss: -2.07435, kernel loss: 0.26469\n",
      "Epoch: 16, series: 218, nllk loss: -1.47295, kernel loss: 0.10870\n",
      "Epoch: 16, series: 219, nllk loss: -2.07293, kernel loss: 0.13624\n",
      "Epoch: 16, series: 220, nllk loss: -2.10353, kernel loss: 0.11836\n",
      "Epoch: 16, series: 221, nllk loss: -2.33250, kernel loss: 0.00262\n",
      "Epoch: 16, series: 222, nllk loss: -2.23337, kernel loss: 0.30278\n",
      "Epoch: 16, series: 223, nllk loss: -1.71949, kernel loss: 0.10966\n",
      "Epoch: 16, series: 224, nllk loss: -2.48718, kernel loss: 0.12462\n",
      "Epoch: 16, series: 225, nllk loss: -2.32211, kernel loss: 0.12392\n",
      "Epoch: 16, series: 226, nllk loss: -1.81302, kernel loss: 0.07595\n",
      "Epoch: 16, series: 227, nllk loss: -1.99774, kernel loss: 0.17864\n",
      "Epoch: 16, series: 228, nllk loss: -2.12857, kernel loss: 0.04102\n",
      "Epoch: 16, series: 229, nllk loss: -2.04632, kernel loss: 0.04208\n",
      "Epoch: 16, series: 230, nllk loss: -2.44197, kernel loss: 0.06609\n",
      "Epoch: 16, series: 231, nllk loss: -1.93719, kernel loss: 0.06178\n",
      "Epoch: 16, series: 232, nllk loss: -2.58539, kernel loss: 0.00987\n",
      "Epoch: 16, series: 233, nllk loss: -2.48304, kernel loss: 0.33559\n",
      "Epoch: 16, series: 234, nllk loss: -1.98832, kernel loss: 0.07326\n",
      "Epoch: 16, series: 235, nllk loss: -2.69000, kernel loss: 0.13105\n",
      "Epoch: 16, series: 236, nllk loss: -1.51925, kernel loss: 0.13935\n",
      "Epoch: 16, series: 237, nllk loss: -2.02754, kernel loss: 0.08412\n",
      "Epoch: 16, series: 238, nllk loss: -1.99682, kernel loss: 0.02988\n",
      "Epoch: 16, series: 239, nllk loss: -2.33375, kernel loss: 0.17113\n",
      "Epoch: 16, series: 240, nllk loss: -0.84706, kernel loss: 0.00432\n",
      "Epoch: 16, series: 241, nllk loss: -1.90335, kernel loss: 0.21296\n",
      "Epoch: 16, series: 242, nllk loss: -2.06276, kernel loss: 0.14033\n",
      "Epoch: 16, series: 243, nllk loss: -2.29751, kernel loss: 0.13717\n",
      "Epoch: 16, series: 244, nllk loss: -1.90695, kernel loss: 0.08234\n",
      "Epoch: 16, series: 245, nllk loss: -2.10548, kernel loss: 0.16660\n",
      "Epoch: 16, series: 246, nllk loss: -0.20665, kernel loss: 0.15701\n",
      "Epoch: 16, series: 247, nllk loss: -1.69636, kernel loss: 0.07079\n",
      "Epoch: 16, series: 248, nllk loss: -2.00739, kernel loss: 0.05854\n",
      "Epoch: 16, series: 249, nllk loss: -1.92703, kernel loss: 0.07488\n",
      "Epoch: 16, series: 250, nllk loss: -1.71709, kernel loss: 0.01748\n",
      "Epoch: 16, series: 251, nllk loss: -1.12932, kernel loss: 0.09925\n",
      "Epoch: 16, series: 252, nllk loss: -1.37198, kernel loss: 0.17224\n",
      "Epoch: 16, series: 253, nllk loss: -1.75887, kernel loss: 0.09617\n",
      "Epoch: 16, series: 254, nllk loss: -2.29185, kernel loss: 0.08027\n",
      "Epoch: 16, series: 255, nllk loss: -2.09765, kernel loss: 0.09296\n",
      "Epoch: 16, series: 256, nllk loss: -1.84048, kernel loss: 0.13040\n",
      "Epoch: 16, series: 257, nllk loss: -2.09038, kernel loss: 0.03206\n",
      "Epoch: 16, series: 258, nllk loss: -2.13376, kernel loss: 0.14559\n",
      "Epoch: 16, series: 259, nllk loss: -1.87410, kernel loss: 0.11694\n",
      "Epoch: 16, series: 260, nllk loss: -2.01522, kernel loss: 0.36187\n",
      "Epoch: 16, series: 261, nllk loss: -2.13706, kernel loss: 0.05327\n",
      "Epoch: 16, series: 262, nllk loss: -2.60489, kernel loss: 0.08045\n",
      "Epoch: 16, series: 263, nllk loss: -0.67614, kernel loss: 0.18414\n",
      "Epoch: 16, series: 264, nllk loss: -2.04807, kernel loss: 0.07253\n",
      "Epoch: 16, series: 265, nllk loss: -1.67740, kernel loss: 0.04920\n",
      "Epoch: 16, series: 266, nllk loss: -2.33676, kernel loss: 0.03951\n",
      "Epoch: 16, series: 267, nllk loss: -2.09442, kernel loss: 0.06618\n",
      "Epoch: 16, series: 268, nllk loss: -2.17268, kernel loss: 0.09925\n",
      "Epoch: 16, series: 269, nllk loss: -1.89851, kernel loss: 0.16134\n",
      "Epoch: 16, series: 270, nllk loss: -1.86552, kernel loss: 0.27107\n",
      "Epoch: 16, series: 271, nllk loss: -1.98562, kernel loss: 0.07136\n",
      "Epoch: 16, series: 272, nllk loss: -1.83551, kernel loss: 0.02787\n",
      "Epoch: 16, series: 273, nllk loss: -2.08790, kernel loss: 0.20475\n",
      "Epoch: 16, series: 274, nllk loss: -1.58175, kernel loss: 0.01783\n",
      "Epoch: 16, series: 275, nllk loss: -1.84867, kernel loss: 0.39867\n",
      "Epoch: 16, series: 276, nllk loss: -1.25466, kernel loss: 0.07093\n",
      "Epoch: 16, series: 277, nllk loss: -2.13257, kernel loss: 0.08307\n",
      "Epoch: 16, series: 278, nllk loss: -1.88368, kernel loss: 0.13213\n",
      "Epoch: 16, series: 279, nllk loss: -2.33939, kernel loss: 0.11943\n",
      "Epoch: 16, series: 280, nllk loss: -2.11260, kernel loss: 0.27511\n",
      "Epoch: 16, series: 281, nllk loss: -2.32956, kernel loss: 0.05237\n",
      "Epoch: 16, series: 282, nllk loss: -2.17786, kernel loss: 0.09129\n",
      "Epoch: 16, series: 283, nllk loss: -2.11053, kernel loss: 0.12820\n",
      "Epoch: 16, series: 284, nllk loss: -1.71182, kernel loss: 0.07211\n",
      "Epoch: 16, series: 285, nllk loss: -1.89392, kernel loss: 0.07848\n",
      "Epoch: 16, series: 286, nllk loss: -2.17944, kernel loss: 0.14056\n",
      "Epoch: 16, series: 287, nllk loss: -2.41910, kernel loss: 0.07108\n",
      "Epoch: 16, series: 288, nllk loss: -1.29435, kernel loss: 0.07164\n",
      "Epoch: 16, series: 289, nllk loss: -0.99893, kernel loss: 0.10870\n",
      "Epoch: 16, series: 290, nllk loss: -2.19693, kernel loss: 0.24508\n",
      "Epoch: 16, series: 291, nllk loss: -2.25674, kernel loss: 0.05297\n",
      "Epoch: 16, series: 292, nllk loss: -2.19571, kernel loss: 0.18645\n",
      "Epoch: 16, series: 293, nllk loss: -2.37844, kernel loss: 0.12917\n",
      "Epoch: 16, series: 294, nllk loss: -1.37046, kernel loss: 0.13970\n",
      "Epoch: 16, series: 295, nllk loss: -1.20050, kernel loss: 0.43025\n",
      "Epoch: 16, series: 296, nllk loss: -2.46888, kernel loss: 0.16613\n",
      "Epoch: 16, series: 297, nllk loss: -2.52952, kernel loss: 0.42494\n",
      "Epoch: 16, series: 298, nllk loss: 0.83124, kernel loss: 0.30235\n",
      "Epoch: 16, series: 299, nllk loss: -0.48992, kernel loss: 0.13824\n",
      "Epoch: 16, series: 300, nllk loss: -2.09324, kernel loss: 0.11296\n",
      "Epoch: 16, series: 301, nllk loss: -2.23014, kernel loss: 0.23268\n",
      "Epoch: 16, series: 302, nllk loss: -2.23523, kernel loss: 0.07738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16, series: 303, nllk loss: -1.94198, kernel loss: 0.11619\n",
      "Epoch: 16, series: 304, nllk loss: 0.21978, kernel loss: 0.23792\n",
      "Epoch: 16, series: 305, nllk loss: -1.64967, kernel loss: 0.28791\n",
      "Epoch: 16, series: 306, nllk loss: -2.24872, kernel loss: 0.14570\n",
      "Epoch: 16, series: 307, nllk loss: -1.56888, kernel loss: 0.09885\n",
      "Epoch: 16, series: 308, nllk loss: -2.24624, kernel loss: 0.20358\n",
      "Epoch: 16, series: 309, nllk loss: -1.98084, kernel loss: 0.17311\n",
      "Epoch: 16, series: 310, nllk loss: -2.15516, kernel loss: 0.20377\n",
      "Epoch: 16, series: 311, nllk loss: -1.85776, kernel loss: 0.13410\n",
      "Epoch: 16, series: 312, nllk loss: -1.91501, kernel loss: 0.01214\n",
      "Epoch: 16, series: 313, nllk loss: -2.29076, kernel loss: 0.06888\n",
      "Epoch: 16, series: 314, nllk loss: -2.57723, kernel loss: 0.09616\n",
      "Epoch: 16, series: 315, nllk loss: -0.88673, kernel loss: 0.26550\n",
      "Epoch: 16, series: 316, nllk loss: -1.95667, kernel loss: 0.08595\n",
      "Epoch: 16, series: 317, nllk loss: 0.37173, kernel loss: 0.03347\n",
      "Epoch: 16, series: 318, nllk loss: 1.31366, kernel loss: 0.16646\n",
      "Epoch: 16, series: 319, nllk loss: -0.93289, kernel loss: 0.06190\n",
      "Epoch: 16, series: 320, nllk loss: -0.85158, kernel loss: 0.08874\n",
      "Epoch: 16, total loss: -461.98200\n",
      "Epoch: 17, series: 0, nllk loss: 1.53225, kernel loss: 0.03856\n",
      "Epoch: 17, series: 1, nllk loss: -1.16799, kernel loss: 0.22356\n",
      "Epoch: 17, series: 2, nllk loss: -0.05323, kernel loss: 0.11963\n",
      "Epoch: 17, series: 3, nllk loss: -1.37864, kernel loss: 0.12590\n",
      "Epoch: 17, series: 4, nllk loss: -1.05666, kernel loss: 0.29194\n",
      "Epoch: 17, series: 5, nllk loss: -1.42832, kernel loss: 0.44965\n",
      "Epoch: 17, series: 6, nllk loss: -0.55452, kernel loss: 0.23208\n",
      "Epoch: 17, series: 7, nllk loss: -1.19110, kernel loss: 0.18710\n",
      "Epoch: 17, series: 8, nllk loss: -0.58858, kernel loss: 0.16617\n",
      "Epoch: 17, series: 9, nllk loss: -0.56322, kernel loss: 0.27744\n",
      "Epoch: 17, series: 10, nllk loss: -1.30314, kernel loss: 0.31583\n",
      "Epoch: 17, series: 11, nllk loss: -1.13950, kernel loss: 0.02356\n",
      "Epoch: 17, series: 12, nllk loss: -1.50595, kernel loss: 0.05694\n",
      "Epoch: 17, series: 13, nllk loss: -1.43441, kernel loss: 0.25984\n",
      "Epoch: 17, series: 14, nllk loss: -1.50261, kernel loss: 0.13312\n",
      "Epoch: 17, series: 15, nllk loss: -1.51070, kernel loss: 0.08429\n",
      "Epoch: 17, series: 16, nllk loss: -1.08111, kernel loss: 0.24878\n",
      "Epoch: 17, series: 17, nllk loss: -1.19066, kernel loss: 0.16682\n",
      "Epoch: 17, series: 18, nllk loss: -1.37740, kernel loss: 0.09939\n",
      "Epoch: 17, series: 19, nllk loss: -0.35763, kernel loss: 0.03976\n",
      "Epoch: 17, series: 20, nllk loss: -0.74109, kernel loss: 0.10744\n",
      "Epoch: 17, series: 21, nllk loss: -1.16453, kernel loss: 0.17566\n",
      "Epoch: 17, series: 22, nllk loss: -1.52963, kernel loss: 0.16880\n",
      "Epoch: 17, series: 23, nllk loss: -1.51965, kernel loss: 0.09220\n",
      "Epoch: 17, series: 24, nllk loss: -1.74604, kernel loss: 0.11424\n",
      "Epoch: 17, series: 25, nllk loss: -1.49267, kernel loss: 0.08623\n",
      "Epoch: 17, series: 26, nllk loss: -1.45679, kernel loss: 0.03074\n",
      "Epoch: 17, series: 27, nllk loss: -1.22334, kernel loss: 0.16956\n",
      "Epoch: 17, series: 28, nllk loss: -1.46510, kernel loss: 0.10410\n",
      "Epoch: 17, series: 29, nllk loss: -0.75550, kernel loss: 0.04374\n",
      "Epoch: 17, series: 30, nllk loss: -1.46241, kernel loss: 0.00000\n",
      "Epoch: 17, series: 31, nllk loss: -1.16554, kernel loss: 0.10117\n",
      "Epoch: 17, series: 32, nllk loss: -1.17174, kernel loss: 0.13989\n",
      "Epoch: 17, series: 33, nllk loss: -0.96231, kernel loss: 0.04995\n",
      "Epoch: 17, series: 34, nllk loss: -1.38378, kernel loss: 0.13906\n",
      "Epoch: 17, series: 35, nllk loss: -1.69705, kernel loss: 0.06215\n",
      "Epoch: 17, series: 36, nllk loss: -1.54007, kernel loss: 0.00863\n",
      "Epoch: 17, series: 37, nllk loss: -0.57939, kernel loss: 0.08231\n",
      "Epoch: 17, series: 38, nllk loss: -1.02065, kernel loss: 0.11930\n",
      "Epoch: 17, series: 39, nllk loss: -0.84530, kernel loss: 0.04244\n",
      "Epoch: 17, series: 40, nllk loss: -1.88060, kernel loss: 0.15270\n",
      "Epoch: 17, series: 41, nllk loss: -1.41264, kernel loss: 0.06865\n",
      "Epoch: 17, series: 42, nllk loss: -1.10207, kernel loss: 0.00639\n",
      "Epoch: 17, series: 43, nllk loss: -1.08330, kernel loss: 0.06747\n",
      "Epoch: 17, series: 44, nllk loss: -1.61630, kernel loss: 0.06624\n",
      "Epoch: 17, series: 45, nllk loss: -1.67137, kernel loss: 0.06783\n",
      "Epoch: 17, series: 46, nllk loss: -1.72407, kernel loss: 0.20740\n",
      "Epoch: 17, series: 47, nllk loss: -1.62259, kernel loss: 0.12646\n",
      "Epoch: 17, series: 48, nllk loss: -1.65851, kernel loss: 0.19992\n",
      "Epoch: 17, series: 49, nllk loss: -1.26048, kernel loss: 0.18757\n",
      "Epoch: 17, series: 50, nllk loss: -0.02691, kernel loss: 0.24324\n",
      "Epoch: 17, series: 51, nllk loss: -1.36503, kernel loss: 0.16748\n",
      "Epoch: 17, series: 52, nllk loss: -0.42235, kernel loss: 0.04785\n",
      "Epoch: 17, series: 53, nllk loss: -1.65175, kernel loss: 0.05916\n",
      "Epoch: 17, series: 54, nllk loss: -1.35932, kernel loss: 0.22415\n",
      "Epoch: 17, series: 55, nllk loss: -0.90086, kernel loss: 0.08547\n",
      "Epoch: 17, series: 56, nllk loss: -1.43847, kernel loss: 0.17481\n",
      "Epoch: 17, series: 57, nllk loss: -1.40577, kernel loss: 0.09984\n",
      "Epoch: 17, series: 58, nllk loss: -1.53229, kernel loss: 0.11861\n",
      "Epoch: 17, series: 59, nllk loss: -1.16473, kernel loss: 0.17546\n",
      "Epoch: 17, series: 60, nllk loss: -1.03799, kernel loss: 0.01810\n",
      "Epoch: 17, series: 61, nllk loss: -1.71306, kernel loss: 0.16920\n",
      "Epoch: 17, series: 62, nllk loss: -1.78218, kernel loss: 0.14301\n",
      "Epoch: 17, series: 63, nllk loss: -1.69365, kernel loss: 0.12364\n",
      "Epoch: 17, series: 64, nllk loss: -1.19325, kernel loss: 0.01743\n",
      "Epoch: 17, series: 65, nllk loss: -1.67332, kernel loss: 0.06900\n",
      "Epoch: 17, series: 66, nllk loss: -1.59466, kernel loss: 0.23082\n",
      "Epoch: 17, series: 67, nllk loss: -1.41506, kernel loss: 0.02292\n",
      "Epoch: 17, series: 68, nllk loss: -0.80094, kernel loss: 0.06102\n",
      "Epoch: 17, series: 69, nllk loss: -1.54628, kernel loss: 0.01354\n",
      "Epoch: 17, series: 70, nllk loss: -1.39036, kernel loss: 0.23871\n",
      "Epoch: 17, series: 71, nllk loss: -1.51065, kernel loss: 0.03019\n",
      "Epoch: 17, series: 72, nllk loss: -1.87017, kernel loss: 0.14547\n",
      "Epoch: 17, series: 73, nllk loss: -1.33171, kernel loss: 0.13198\n",
      "Epoch: 17, series: 74, nllk loss: -1.98502, kernel loss: 0.18070\n",
      "Epoch: 17, series: 75, nllk loss: -1.54772, kernel loss: 0.01195\n",
      "Epoch: 17, series: 76, nllk loss: -1.41874, kernel loss: 0.13805\n",
      "Epoch: 17, series: 77, nllk loss: -1.26845, kernel loss: 0.05431\n",
      "Epoch: 17, series: 78, nllk loss: -1.39446, kernel loss: 0.03278\n",
      "Epoch: 17, series: 79, nllk loss: -0.44225, kernel loss: 0.16866\n",
      "Epoch: 17, series: 80, nllk loss: -1.79694, kernel loss: 0.01150\n",
      "Epoch: 17, series: 81, nllk loss: -1.47593, kernel loss: 0.20817\n",
      "Epoch: 17, series: 82, nllk loss: -0.41775, kernel loss: 0.06589\n",
      "Epoch: 17, series: 83, nllk loss: -1.05070, kernel loss: 0.03021\n",
      "Epoch: 17, series: 84, nllk loss: -1.23512, kernel loss: 0.27781\n",
      "Epoch: 17, series: 85, nllk loss: -1.56258, kernel loss: 0.02388\n",
      "Epoch: 17, series: 86, nllk loss: -0.74090, kernel loss: 0.05909\n",
      "Epoch: 17, series: 87, nllk loss: -1.78814, kernel loss: 0.22288\n",
      "Epoch: 17, series: 88, nllk loss: -2.03419, kernel loss: 0.02051\n",
      "Epoch: 17, series: 89, nllk loss: -1.91841, kernel loss: 0.00554\n",
      "Epoch: 17, series: 90, nllk loss: -2.12017, kernel loss: 0.16793\n",
      "Epoch: 17, series: 91, nllk loss: -2.11836, kernel loss: 0.00140\n",
      "Epoch: 17, series: 92, nllk loss: 0.18063, kernel loss: 0.28042\n",
      "Epoch: 17, series: 93, nllk loss: -2.47166, kernel loss: 0.22744\n",
      "Epoch: 17, series: 94, nllk loss: -2.47131, kernel loss: 0.12329\n",
      "Epoch: 17, series: 95, nllk loss: -2.38458, kernel loss: 0.12829\n",
      "Epoch: 17, series: 96, nllk loss: -1.76527, kernel loss: 0.08731\n",
      "Epoch: 17, series: 97, nllk loss: -0.59297, kernel loss: 0.21213\n",
      "Epoch: 17, series: 98, nllk loss: -0.56244, kernel loss: 0.10733\n",
      "Epoch: 17, series: 99, nllk loss: -1.45543, kernel loss: 0.10333\n",
      "Epoch: 17, series: 100, nllk loss: -0.70006, kernel loss: 0.06864\n",
      "Epoch: 17, series: 101, nllk loss: -1.34066, kernel loss: 0.05243\n",
      "Epoch: 17, series: 102, nllk loss: -0.63440, kernel loss: 0.12868\n",
      "Epoch: 17, series: 103, nllk loss: -1.11546, kernel loss: 0.07555\n",
      "Epoch: 17, series: 104, nllk loss: 0.06838, kernel loss: 0.03161\n",
      "Epoch: 17, series: 105, nllk loss: -0.10479, kernel loss: 0.18703\n",
      "Epoch: 17, series: 106, nllk loss: -1.14856, kernel loss: 0.28862\n",
      "Epoch: 17, series: 107, nllk loss: -0.96797, kernel loss: 0.14767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, series: 108, nllk loss: -1.32257, kernel loss: 0.13788\n",
      "Epoch: 17, series: 109, nllk loss: -1.10905, kernel loss: 0.00033\n",
      "Epoch: 17, series: 110, nllk loss: -1.56174, kernel loss: 0.05677\n",
      "Epoch: 17, series: 111, nllk loss: -1.37106, kernel loss: 0.14859\n",
      "Epoch: 17, series: 112, nllk loss: -0.86840, kernel loss: 0.23125\n",
      "Epoch: 17, series: 113, nllk loss: -1.12878, kernel loss: 0.01479\n",
      "Epoch: 17, series: 114, nllk loss: -1.15783, kernel loss: 0.11926\n",
      "Epoch: 17, series: 115, nllk loss: -1.00576, kernel loss: 0.23647\n",
      "Epoch: 17, series: 116, nllk loss: -1.56919, kernel loss: 0.10884\n",
      "Epoch: 17, series: 117, nllk loss: -0.65934, kernel loss: 0.17539\n",
      "Epoch: 17, series: 118, nllk loss: -1.73081, kernel loss: 0.03826\n",
      "Epoch: 17, series: 119, nllk loss: -0.72991, kernel loss: 0.12090\n",
      "Epoch: 17, series: 120, nllk loss: -1.48795, kernel loss: 0.00718\n",
      "Epoch: 17, series: 121, nllk loss: 0.04108, kernel loss: 0.06865\n",
      "Epoch: 17, series: 122, nllk loss: -0.64130, kernel loss: 0.18864\n",
      "Epoch: 17, series: 123, nllk loss: -1.66032, kernel loss: 0.19911\n",
      "Epoch: 17, series: 124, nllk loss: -1.75848, kernel loss: 0.05406\n",
      "Epoch: 17, series: 125, nllk loss: -1.34515, kernel loss: 0.02568\n",
      "Epoch: 17, series: 126, nllk loss: -1.75320, kernel loss: 0.08809\n",
      "Epoch: 17, series: 127, nllk loss: -1.35805, kernel loss: 0.10129\n",
      "Epoch: 17, series: 128, nllk loss: -1.01177, kernel loss: 0.11368\n",
      "Epoch: 17, series: 129, nllk loss: -0.71553, kernel loss: 0.06818\n",
      "Epoch: 17, series: 130, nllk loss: -1.39277, kernel loss: 0.04605\n",
      "Epoch: 17, series: 131, nllk loss: 0.40086, kernel loss: 0.05191\n",
      "Epoch: 17, series: 132, nllk loss: 0.09236, kernel loss: 0.05783\n",
      "Epoch: 17, series: 133, nllk loss: -0.96136, kernel loss: 0.08516\n",
      "Epoch: 17, series: 134, nllk loss: -0.81365, kernel loss: 0.13473\n",
      "Epoch: 17, series: 135, nllk loss: -1.47011, kernel loss: 0.02259\n",
      "Epoch: 17, series: 136, nllk loss: -1.51420, kernel loss: 0.15084\n",
      "Epoch: 17, series: 137, nllk loss: -1.66991, kernel loss: 0.04462\n",
      "Epoch: 17, series: 138, nllk loss: -1.80389, kernel loss: 0.01028\n",
      "Epoch: 17, series: 139, nllk loss: -1.72051, kernel loss: 0.02808\n",
      "Epoch: 17, series: 140, nllk loss: -1.51224, kernel loss: 0.21711\n",
      "Epoch: 17, series: 141, nllk loss: -1.66371, kernel loss: 0.20056\n",
      "Epoch: 17, series: 142, nllk loss: -1.74839, kernel loss: 0.14050\n",
      "Epoch: 17, series: 143, nllk loss: -1.78139, kernel loss: 0.17834\n",
      "Epoch: 17, series: 144, nllk loss: -2.10464, kernel loss: 0.10557\n",
      "Epoch: 17, series: 145, nllk loss: -1.92325, kernel loss: 0.22652\n",
      "Epoch: 17, series: 146, nllk loss: 2.35924, kernel loss: 0.05984\n",
      "Epoch: 17, series: 147, nllk loss: -1.60446, kernel loss: 0.18641\n",
      "Epoch: 17, series: 148, nllk loss: -1.51737, kernel loss: 0.14388\n",
      "Epoch: 17, series: 149, nllk loss: -1.83714, kernel loss: 0.11059\n",
      "Epoch: 17, series: 150, nllk loss: -1.90304, kernel loss: 0.09514\n",
      "Epoch: 17, series: 151, nllk loss: -2.00511, kernel loss: 0.08628\n",
      "Epoch: 17, series: 152, nllk loss: -1.97568, kernel loss: 0.01048\n",
      "Epoch: 17, series: 153, nllk loss: -1.72466, kernel loss: 0.16431\n",
      "Epoch: 17, series: 154, nllk loss: -1.79297, kernel loss: 0.04350\n",
      "Epoch: 17, series: 155, nllk loss: -1.88513, kernel loss: 0.16640\n",
      "Epoch: 17, series: 156, nllk loss: -2.00208, kernel loss: 0.07052\n",
      "Epoch: 17, series: 157, nllk loss: -1.49003, kernel loss: 0.04743\n",
      "Epoch: 17, series: 158, nllk loss: -1.95411, kernel loss: 0.18934\n",
      "Epoch: 17, series: 159, nllk loss: -2.01607, kernel loss: 0.09775\n",
      "Epoch: 17, series: 160, nllk loss: -1.84802, kernel loss: 0.10849\n",
      "Epoch: 17, series: 161, nllk loss: -1.79778, kernel loss: 0.05533\n",
      "Epoch: 17, series: 162, nllk loss: -2.05739, kernel loss: 0.08358\n",
      "Epoch: 17, series: 163, nllk loss: -2.35966, kernel loss: 0.14098\n",
      "Epoch: 17, series: 164, nllk loss: -1.83665, kernel loss: 0.17173\n",
      "Epoch: 17, series: 165, nllk loss: -1.89557, kernel loss: 0.04684\n",
      "Epoch: 17, series: 166, nllk loss: -1.32567, kernel loss: 0.20779\n",
      "Epoch: 17, series: 167, nllk loss: -2.51350, kernel loss: 0.11225\n",
      "Epoch: 17, series: 168, nllk loss: -2.12390, kernel loss: 0.04697\n",
      "Epoch: 17, series: 169, nllk loss: -2.30235, kernel loss: 0.10377\n",
      "Epoch: 17, series: 170, nllk loss: -1.93047, kernel loss: 0.26441\n",
      "Epoch: 17, series: 171, nllk loss: -2.48837, kernel loss: 0.17807\n",
      "Epoch: 17, series: 172, nllk loss: -2.02907, kernel loss: 0.16269\n",
      "Epoch: 17, series: 173, nllk loss: -2.54264, kernel loss: 0.04506\n",
      "Epoch: 17, series: 174, nllk loss: -2.16052, kernel loss: 0.16764\n",
      "Epoch: 17, series: 175, nllk loss: -2.50926, kernel loss: 0.13051\n",
      "Epoch: 17, series: 176, nllk loss: -2.14992, kernel loss: 0.09555\n",
      "Epoch: 17, series: 177, nllk loss: -1.94693, kernel loss: 0.19355\n",
      "Epoch: 17, series: 178, nllk loss: -1.71929, kernel loss: 0.22286\n",
      "Epoch: 17, series: 179, nllk loss: -2.22592, kernel loss: 0.05012\n",
      "Epoch: 17, series: 180, nllk loss: -2.33677, kernel loss: 0.21910\n",
      "Epoch: 17, series: 181, nllk loss: -2.56857, kernel loss: 0.04490\n",
      "Epoch: 17, series: 182, nllk loss: -2.16572, kernel loss: 0.13581\n",
      "Epoch: 17, series: 183, nllk loss: -1.94462, kernel loss: 0.28265\n",
      "Epoch: 17, series: 184, nllk loss: -1.92652, kernel loss: 0.19883\n",
      "Epoch: 17, series: 185, nllk loss: -1.50363, kernel loss: 0.06860\n",
      "Epoch: 17, series: 186, nllk loss: -2.48839, kernel loss: 0.05801\n",
      "Epoch: 17, series: 187, nllk loss: -2.70733, kernel loss: 0.10580\n",
      "Epoch: 17, series: 188, nllk loss: -1.58641, kernel loss: 0.11084\n",
      "Epoch: 17, series: 189, nllk loss: -1.31272, kernel loss: 0.04318\n",
      "Epoch: 17, series: 190, nllk loss: -1.76695, kernel loss: 0.04462\n",
      "Epoch: 17, series: 191, nllk loss: -1.85269, kernel loss: 0.12613\n",
      "Epoch: 17, series: 192, nllk loss: -2.25608, kernel loss: 0.23436\n",
      "Epoch: 17, series: 193, nllk loss: -1.61023, kernel loss: 0.18819\n",
      "Epoch: 17, series: 194, nllk loss: -1.52408, kernel loss: 0.10408\n",
      "Epoch: 17, series: 195, nllk loss: -2.12888, kernel loss: 0.18855\n",
      "Epoch: 17, series: 196, nllk loss: -1.94765, kernel loss: 0.15955\n",
      "Epoch: 17, series: 197, nllk loss: -2.14797, kernel loss: 0.00416\n",
      "Epoch: 17, series: 198, nllk loss: -2.14099, kernel loss: 0.08551\n",
      "Epoch: 17, series: 199, nllk loss: -1.86454, kernel loss: 0.07966\n",
      "Epoch: 17, series: 200, nllk loss: -2.24757, kernel loss: 0.06926\n",
      "Epoch: 17, series: 201, nllk loss: -2.29644, kernel loss: 0.24255\n",
      "Epoch: 17, series: 202, nllk loss: -2.07837, kernel loss: 0.12697\n",
      "Epoch: 17, series: 203, nllk loss: -1.87198, kernel loss: 0.06826\n",
      "Epoch: 17, series: 204, nllk loss: -0.96094, kernel loss: 0.04768\n",
      "Epoch: 17, series: 205, nllk loss: -2.09343, kernel loss: 0.00000\n",
      "Epoch: 17, series: 206, nllk loss: -2.26687, kernel loss: 0.16068\n",
      "Epoch: 17, series: 207, nllk loss: -1.01472, kernel loss: 0.16863\n",
      "Epoch: 17, series: 208, nllk loss: -2.45068, kernel loss: 0.13843\n",
      "Epoch: 17, series: 209, nllk loss: -1.80324, kernel loss: 0.09968\n",
      "Epoch: 17, series: 210, nllk loss: -2.59710, kernel loss: 0.01906\n",
      "Epoch: 17, series: 211, nllk loss: -2.11445, kernel loss: 0.12578\n",
      "Epoch: 17, series: 212, nllk loss: -1.56350, kernel loss: 0.14109\n",
      "Epoch: 17, series: 213, nllk loss: -2.08630, kernel loss: 0.04771\n",
      "Epoch: 17, series: 214, nllk loss: -2.04593, kernel loss: 0.09359\n",
      "Epoch: 17, series: 215, nllk loss: -2.41276, kernel loss: 0.03119\n",
      "Epoch: 17, series: 216, nllk loss: -1.39408, kernel loss: 0.03563\n",
      "Epoch: 17, series: 217, nllk loss: -2.02863, kernel loss: 0.07992\n",
      "Epoch: 17, series: 218, nllk loss: -1.46617, kernel loss: 0.16909\n",
      "Epoch: 17, series: 219, nllk loss: -1.92573, kernel loss: 0.10741\n",
      "Epoch: 17, series: 220, nllk loss: -2.14765, kernel loss: 0.14323\n",
      "Epoch: 17, series: 221, nllk loss: -2.38448, kernel loss: 0.25107\n",
      "Epoch: 17, series: 222, nllk loss: -2.23396, kernel loss: 0.10293\n",
      "Epoch: 17, series: 223, nllk loss: -1.64992, kernel loss: 0.05535\n",
      "Epoch: 17, series: 224, nllk loss: -2.45533, kernel loss: 0.09332\n",
      "Epoch: 17, series: 225, nllk loss: -2.31597, kernel loss: 0.07539\n",
      "Epoch: 17, series: 226, nllk loss: -1.84019, kernel loss: 0.07072\n",
      "Epoch: 17, series: 227, nllk loss: -2.03148, kernel loss: 0.19842\n",
      "Epoch: 17, series: 228, nllk loss: -2.18054, kernel loss: 0.16638\n",
      "Epoch: 17, series: 229, nllk loss: -2.04296, kernel loss: 0.05814\n",
      "Epoch: 17, series: 230, nllk loss: -2.44686, kernel loss: 0.08445\n",
      "Epoch: 17, series: 231, nllk loss: -1.93119, kernel loss: 0.25336\n",
      "Epoch: 17, series: 232, nllk loss: -2.57042, kernel loss: 0.13077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17, series: 233, nllk loss: -2.45289, kernel loss: 0.22109\n",
      "Epoch: 17, series: 234, nllk loss: -2.07714, kernel loss: 0.09102\n",
      "Epoch: 17, series: 235, nllk loss: -2.64317, kernel loss: 0.19101\n",
      "Epoch: 17, series: 236, nllk loss: -1.62238, kernel loss: 0.08332\n",
      "Epoch: 17, series: 237, nllk loss: -2.13051, kernel loss: 0.04521\n",
      "Epoch: 17, series: 238, nllk loss: -1.98733, kernel loss: 0.23915\n",
      "Epoch: 17, series: 239, nllk loss: -2.33219, kernel loss: 0.07412\n",
      "Epoch: 17, series: 240, nllk loss: -0.83431, kernel loss: 0.10768\n",
      "Epoch: 17, series: 241, nllk loss: -1.91309, kernel loss: 0.06604\n",
      "Epoch: 17, series: 242, nllk loss: -1.97744, kernel loss: 0.06278\n",
      "Epoch: 17, series: 243, nllk loss: -2.41107, kernel loss: 0.01179\n",
      "Epoch: 17, series: 244, nllk loss: -2.00246, kernel loss: 0.07221\n",
      "Epoch: 17, series: 245, nllk loss: -2.14141, kernel loss: 0.09502\n",
      "Epoch: 17, series: 246, nllk loss: -0.20854, kernel loss: 0.10954\n",
      "Epoch: 17, series: 247, nllk loss: -1.70639, kernel loss: 0.11935\n",
      "Epoch: 17, series: 248, nllk loss: -2.06639, kernel loss: 0.01570\n",
      "Epoch: 17, series: 249, nllk loss: -1.84947, kernel loss: 0.18031\n",
      "Epoch: 17, series: 250, nllk loss: -1.66385, kernel loss: 0.03910\n",
      "Epoch: 17, series: 251, nllk loss: -1.19431, kernel loss: 0.11067\n",
      "Epoch: 17, series: 252, nllk loss: -1.37533, kernel loss: 0.02257\n",
      "Epoch: 17, series: 253, nllk loss: -1.82849, kernel loss: 0.11098\n",
      "Epoch: 17, series: 254, nllk loss: -2.35322, kernel loss: 0.05496\n",
      "Epoch: 17, series: 255, nllk loss: -2.12103, kernel loss: 0.13506\n",
      "Epoch: 17, series: 256, nllk loss: -1.97842, kernel loss: 0.09263\n",
      "Epoch: 17, series: 257, nllk loss: -2.04579, kernel loss: 0.12346\n",
      "Epoch: 17, series: 258, nllk loss: -2.10331, kernel loss: 0.05817\n",
      "Epoch: 17, series: 259, nllk loss: -1.81819, kernel loss: 0.43340\n",
      "Epoch: 17, series: 260, nllk loss: -2.02035, kernel loss: 0.10527\n",
      "Epoch: 17, series: 261, nllk loss: -2.06655, kernel loss: 0.33867\n",
      "Epoch: 17, series: 262, nllk loss: -2.62123, kernel loss: 0.22036\n",
      "Epoch: 17, series: 263, nllk loss: -0.58045, kernel loss: 0.08749\n",
      "Epoch: 17, series: 264, nllk loss: -2.04848, kernel loss: 0.07069\n",
      "Epoch: 17, series: 265, nllk loss: -1.69621, kernel loss: 0.05207\n",
      "Epoch: 17, series: 266, nllk loss: -2.33211, kernel loss: 0.05073\n",
      "Epoch: 17, series: 267, nllk loss: -2.02408, kernel loss: 0.10341\n",
      "Epoch: 17, series: 268, nllk loss: -2.10712, kernel loss: 0.12372\n",
      "Epoch: 17, series: 269, nllk loss: -1.82900, kernel loss: 0.19452\n",
      "Epoch: 17, series: 270, nllk loss: -1.83884, kernel loss: 0.14421\n",
      "Epoch: 17, series: 271, nllk loss: -1.98715, kernel loss: 0.14500\n",
      "Epoch: 17, series: 272, nllk loss: -1.90107, kernel loss: 0.01584\n",
      "Epoch: 17, series: 273, nllk loss: -2.02342, kernel loss: 0.12074\n",
      "Epoch: 17, series: 274, nllk loss: -1.43783, kernel loss: 0.07427\n",
      "Epoch: 17, series: 275, nllk loss: -1.85890, kernel loss: 0.01802\n",
      "Epoch: 17, series: 276, nllk loss: -1.20948, kernel loss: 0.17479\n",
      "Epoch: 17, series: 277, nllk loss: -2.11561, kernel loss: 0.27047\n",
      "Epoch: 17, series: 278, nllk loss: -1.92198, kernel loss: 0.05259\n",
      "Epoch: 17, series: 279, nllk loss: -2.33859, kernel loss: 0.17535\n",
      "Epoch: 17, series: 280, nllk loss: -2.06436, kernel loss: 0.16134\n",
      "Epoch: 17, series: 281, nllk loss: -2.23335, kernel loss: 0.13146\n",
      "Epoch: 17, series: 282, nllk loss: -2.20079, kernel loss: 0.28941\n",
      "Epoch: 17, series: 283, nllk loss: -2.11671, kernel loss: 0.00719\n",
      "Epoch: 17, series: 284, nllk loss: -1.81872, kernel loss: 0.21167\n",
      "Epoch: 17, series: 285, nllk loss: -2.01681, kernel loss: 0.18712\n",
      "Epoch: 17, series: 286, nllk loss: -2.16392, kernel loss: 0.04640\n",
      "Epoch: 17, series: 287, nllk loss: -2.47352, kernel loss: 0.14245\n",
      "Epoch: 17, series: 288, nllk loss: -1.27341, kernel loss: 0.14944\n",
      "Epoch: 17, series: 289, nllk loss: -1.00809, kernel loss: 0.13812\n",
      "Epoch: 17, series: 290, nllk loss: -2.18299, kernel loss: 0.17844\n",
      "Epoch: 17, series: 291, nllk loss: -2.21839, kernel loss: 0.15952\n",
      "Epoch: 17, series: 292, nllk loss: -2.14528, kernel loss: 0.09969\n",
      "Epoch: 17, series: 293, nllk loss: -2.33455, kernel loss: 0.00229\n",
      "Epoch: 17, series: 294, nllk loss: -1.27027, kernel loss: 0.06965\n",
      "Epoch: 17, series: 295, nllk loss: -1.33732, kernel loss: 0.04578\n",
      "Epoch: 17, series: 296, nllk loss: -2.39809, kernel loss: 0.10609\n",
      "Epoch: 17, series: 297, nllk loss: -2.41321, kernel loss: 0.06974\n",
      "Epoch: 17, series: 298, nllk loss: 1.03426, kernel loss: 0.13914\n",
      "Epoch: 17, series: 299, nllk loss: -0.46262, kernel loss: 0.19115\n",
      "Epoch: 17, series: 300, nllk loss: -1.91030, kernel loss: 0.07390\n",
      "Epoch: 17, series: 301, nllk loss: -2.15507, kernel loss: 0.12276\n",
      "Epoch: 17, series: 302, nllk loss: -2.26705, kernel loss: 0.10360\n",
      "Epoch: 17, series: 303, nllk loss: -1.96798, kernel loss: 0.09830\n",
      "Epoch: 17, series: 304, nllk loss: 0.27426, kernel loss: 0.08836\n",
      "Epoch: 17, series: 305, nllk loss: -1.65536, kernel loss: 0.03471\n",
      "Epoch: 17, series: 306, nllk loss: -2.42805, kernel loss: 0.12543\n",
      "Epoch: 17, series: 307, nllk loss: -1.68739, kernel loss: 0.14276\n",
      "Epoch: 17, series: 308, nllk loss: -2.29033, kernel loss: 0.31901\n",
      "Epoch: 17, series: 309, nllk loss: -1.95266, kernel loss: 0.01294\n",
      "Epoch: 17, series: 310, nllk loss: -2.19480, kernel loss: 0.20034\n",
      "Epoch: 17, series: 311, nllk loss: -1.89807, kernel loss: 0.26445\n",
      "Epoch: 17, series: 312, nllk loss: -2.10755, kernel loss: 0.09510\n",
      "Epoch: 17, series: 313, nllk loss: -2.28501, kernel loss: 0.08246\n",
      "Epoch: 17, series: 314, nllk loss: -2.64910, kernel loss: 0.23896\n",
      "Epoch: 17, series: 315, nllk loss: -0.81933, kernel loss: 0.21817\n",
      "Epoch: 17, series: 316, nllk loss: -2.05490, kernel loss: 0.20685\n",
      "Epoch: 17, series: 317, nllk loss: 0.54315, kernel loss: 0.06395\n",
      "Epoch: 17, series: 318, nllk loss: 1.34543, kernel loss: 0.16629\n",
      "Epoch: 17, series: 319, nllk loss: -0.96006, kernel loss: 0.19042\n",
      "Epoch: 17, series: 320, nllk loss: -0.86013, kernel loss: 0.10748\n",
      "Epoch: 17, total loss: -469.15944\n",
      "Epoch: 18, series: 0, nllk loss: 1.38296, kernel loss: 0.13746\n",
      "Epoch: 18, series: 1, nllk loss: -1.23240, kernel loss: 0.24735\n",
      "Epoch: 18, series: 2, nllk loss: -0.10403, kernel loss: 0.10441\n",
      "Epoch: 18, series: 3, nllk loss: -1.33454, kernel loss: 0.14871\n",
      "Epoch: 18, series: 4, nllk loss: -0.93937, kernel loss: 0.25277\n",
      "Epoch: 18, series: 5, nllk loss: -1.26508, kernel loss: 0.18591\n",
      "Epoch: 18, series: 6, nllk loss: -0.52293, kernel loss: 0.34851\n",
      "Epoch: 18, series: 7, nllk loss: -1.09123, kernel loss: 0.23218\n",
      "Epoch: 18, series: 8, nllk loss: -0.65898, kernel loss: 0.14292\n",
      "Epoch: 18, series: 9, nllk loss: -0.53887, kernel loss: 0.05666\n",
      "Epoch: 18, series: 10, nllk loss: -1.21041, kernel loss: 0.16554\n",
      "Epoch: 18, series: 11, nllk loss: -1.18738, kernel loss: 0.14463\n",
      "Epoch: 18, series: 12, nllk loss: -1.49831, kernel loss: 0.37980\n",
      "Epoch: 18, series: 13, nllk loss: -1.32303, kernel loss: 0.15686\n",
      "Epoch: 18, series: 14, nllk loss: -1.46064, kernel loss: 0.13949\n",
      "Epoch: 18, series: 15, nllk loss: -1.52026, kernel loss: 0.16599\n",
      "Epoch: 18, series: 16, nllk loss: -1.07763, kernel loss: 0.21317\n",
      "Epoch: 18, series: 17, nllk loss: -1.11461, kernel loss: 0.38790\n",
      "Epoch: 18, series: 18, nllk loss: -1.46219, kernel loss: 0.13540\n",
      "Epoch: 18, series: 19, nllk loss: -0.35799, kernel loss: 0.09932\n",
      "Epoch: 18, series: 20, nllk loss: -0.78258, kernel loss: 0.48714\n",
      "Epoch: 18, series: 21, nllk loss: -1.13999, kernel loss: 0.14160\n",
      "Epoch: 18, series: 22, nllk loss: -1.52659, kernel loss: 0.10013\n",
      "Epoch: 18, series: 23, nllk loss: -1.44563, kernel loss: 0.21742\n",
      "Epoch: 18, series: 24, nllk loss: -1.68212, kernel loss: 0.02921\n",
      "Epoch: 18, series: 25, nllk loss: -1.57348, kernel loss: 0.45644\n",
      "Epoch: 18, series: 26, nllk loss: -1.44830, kernel loss: 0.09082\n",
      "Epoch: 18, series: 27, nllk loss: -1.24943, kernel loss: 0.17103\n",
      "Epoch: 18, series: 28, nllk loss: -1.44822, kernel loss: 0.02893\n",
      "Epoch: 18, series: 29, nllk loss: -0.84752, kernel loss: 0.13898\n",
      "Epoch: 18, series: 30, nllk loss: -1.42531, kernel loss: 0.06874\n",
      "Epoch: 18, series: 31, nllk loss: -1.10152, kernel loss: 0.18793\n",
      "Epoch: 18, series: 32, nllk loss: -1.11598, kernel loss: 0.09633\n",
      "Epoch: 18, series: 33, nllk loss: -1.01452, kernel loss: 0.05305\n",
      "Epoch: 18, series: 34, nllk loss: -1.41517, kernel loss: 0.09991\n",
      "Epoch: 18, series: 35, nllk loss: -1.70326, kernel loss: 0.10147\n",
      "Epoch: 18, series: 36, nllk loss: -1.59027, kernel loss: 0.19355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, series: 37, nllk loss: -0.52886, kernel loss: 0.11864\n",
      "Epoch: 18, series: 38, nllk loss: -1.05091, kernel loss: 0.12454\n",
      "Epoch: 18, series: 39, nllk loss: -0.78932, kernel loss: 0.02324\n",
      "Epoch: 18, series: 40, nllk loss: -1.83136, kernel loss: 0.13965\n",
      "Epoch: 18, series: 41, nllk loss: -1.43116, kernel loss: 0.18332\n",
      "Epoch: 18, series: 42, nllk loss: -1.09233, kernel loss: 0.02889\n",
      "Epoch: 18, series: 43, nllk loss: -1.05404, kernel loss: 0.27036\n",
      "Epoch: 18, series: 44, nllk loss: -1.58915, kernel loss: 0.12521\n",
      "Epoch: 18, series: 45, nllk loss: -1.69967, kernel loss: 0.07056\n",
      "Epoch: 18, series: 46, nllk loss: -1.70378, kernel loss: 0.15876\n",
      "Epoch: 18, series: 47, nllk loss: -1.55550, kernel loss: 0.09689\n",
      "Epoch: 18, series: 48, nllk loss: -1.62872, kernel loss: 0.02405\n",
      "Epoch: 18, series: 49, nllk loss: -1.17456, kernel loss: 0.01753\n",
      "Epoch: 18, series: 50, nllk loss: -0.12126, kernel loss: 0.01538\n",
      "Epoch: 18, series: 51, nllk loss: -1.33807, kernel loss: 0.12455\n",
      "Epoch: 18, series: 52, nllk loss: -0.41540, kernel loss: 0.10862\n",
      "Epoch: 18, series: 53, nllk loss: -1.69967, kernel loss: 0.00000\n",
      "Epoch: 18, series: 54, nllk loss: -1.39364, kernel loss: 0.05442\n",
      "Epoch: 18, series: 55, nllk loss: -0.89214, kernel loss: 0.15595\n",
      "Epoch: 18, series: 56, nllk loss: -1.47997, kernel loss: 0.10113\n",
      "Epoch: 18, series: 57, nllk loss: -1.40777, kernel loss: 0.04243\n",
      "Epoch: 18, series: 58, nllk loss: -1.52393, kernel loss: 0.09744\n",
      "Epoch: 18, series: 59, nllk loss: -1.20904, kernel loss: 0.17266\n",
      "Epoch: 18, series: 60, nllk loss: -1.09192, kernel loss: 0.01453\n",
      "Epoch: 18, series: 61, nllk loss: -1.70888, kernel loss: 0.07049\n",
      "Epoch: 18, series: 62, nllk loss: -1.81784, kernel loss: 0.13838\n",
      "Epoch: 18, series: 63, nllk loss: -1.70399, kernel loss: 0.02010\n",
      "Epoch: 18, series: 64, nllk loss: -1.17061, kernel loss: 0.09800\n",
      "Epoch: 18, series: 65, nllk loss: -1.71292, kernel loss: 0.09528\n",
      "Epoch: 18, series: 66, nllk loss: -1.63110, kernel loss: 0.07926\n",
      "Epoch: 18, series: 67, nllk loss: -1.46018, kernel loss: 0.10451\n",
      "Epoch: 18, series: 68, nllk loss: -0.85485, kernel loss: 0.17531\n",
      "Epoch: 18, series: 69, nllk loss: -1.52532, kernel loss: 0.07786\n",
      "Epoch: 18, series: 70, nllk loss: -1.41565, kernel loss: 0.06896\n",
      "Epoch: 18, series: 71, nllk loss: -1.47086, kernel loss: 0.06125\n",
      "Epoch: 18, series: 72, nllk loss: -1.84121, kernel loss: 0.06604\n",
      "Epoch: 18, series: 73, nllk loss: -1.35537, kernel loss: 0.11954\n",
      "Epoch: 18, series: 74, nllk loss: -2.02583, kernel loss: 0.03041\n",
      "Epoch: 18, series: 75, nllk loss: -1.61459, kernel loss: 0.20336\n",
      "Epoch: 18, series: 76, nllk loss: -1.44393, kernel loss: 0.03704\n",
      "Epoch: 18, series: 77, nllk loss: -1.27715, kernel loss: 0.24057\n",
      "Epoch: 18, series: 78, nllk loss: -1.46009, kernel loss: 0.08294\n",
      "Epoch: 18, series: 79, nllk loss: -0.41296, kernel loss: 0.04573\n",
      "Epoch: 18, series: 80, nllk loss: -1.80648, kernel loss: 0.13701\n",
      "Epoch: 18, series: 81, nllk loss: -1.42243, kernel loss: 0.10308\n",
      "Epoch: 18, series: 82, nllk loss: -0.40946, kernel loss: 0.06988\n",
      "Epoch: 18, series: 83, nllk loss: -1.13588, kernel loss: 0.06258\n",
      "Epoch: 18, series: 84, nllk loss: -1.26238, kernel loss: 0.10478\n",
      "Epoch: 18, series: 85, nllk loss: -1.52009, kernel loss: 0.02095\n",
      "Epoch: 18, series: 86, nllk loss: -0.78603, kernel loss: 0.01791\n",
      "Epoch: 18, series: 87, nllk loss: -1.73572, kernel loss: 0.04824\n",
      "Epoch: 18, series: 88, nllk loss: -1.99898, kernel loss: 0.07470\n",
      "Epoch: 18, series: 89, nllk loss: -1.94768, kernel loss: 0.21778\n",
      "Epoch: 18, series: 90, nllk loss: -2.20668, kernel loss: 0.04413\n",
      "Epoch: 18, series: 91, nllk loss: -2.16365, kernel loss: 0.04137\n",
      "Epoch: 18, series: 92, nllk loss: 0.22989, kernel loss: 0.17368\n",
      "Epoch: 18, series: 93, nllk loss: -2.45006, kernel loss: 0.15663\n",
      "Epoch: 18, series: 94, nllk loss: -2.45290, kernel loss: 0.18230\n",
      "Epoch: 18, series: 95, nllk loss: -2.37509, kernel loss: 0.11291\n",
      "Epoch: 18, series: 96, nllk loss: -1.74859, kernel loss: 0.17519\n",
      "Epoch: 18, series: 97, nllk loss: -0.73761, kernel loss: 0.25118\n",
      "Epoch: 18, series: 98, nllk loss: -0.59934, kernel loss: 0.08857\n",
      "Epoch: 18, series: 99, nllk loss: -1.38610, kernel loss: 0.00122\n",
      "Epoch: 18, series: 100, nllk loss: -0.58397, kernel loss: 0.10625\n",
      "Epoch: 18, series: 101, nllk loss: -1.14085, kernel loss: 0.08387\n",
      "Epoch: 18, series: 102, nllk loss: -0.44088, kernel loss: 0.10654\n",
      "Epoch: 18, series: 103, nllk loss: -1.11671, kernel loss: 0.07668\n",
      "Epoch: 18, series: 104, nllk loss: 0.02293, kernel loss: 0.26808\n",
      "Epoch: 18, series: 105, nllk loss: -0.18982, kernel loss: 0.03616\n",
      "Epoch: 18, series: 106, nllk loss: -1.16197, kernel loss: 0.17348\n",
      "Epoch: 18, series: 107, nllk loss: -0.95619, kernel loss: 0.11525\n",
      "Epoch: 18, series: 108, nllk loss: -1.26350, kernel loss: 0.10112\n",
      "Epoch: 18, series: 109, nllk loss: -0.89659, kernel loss: 0.15341\n",
      "Epoch: 18, series: 110, nllk loss: -1.50004, kernel loss: 0.11414\n",
      "Epoch: 18, series: 111, nllk loss: -1.35953, kernel loss: 0.01709\n",
      "Epoch: 18, series: 112, nllk loss: -0.78669, kernel loss: 0.21794\n",
      "Epoch: 18, series: 113, nllk loss: -1.08306, kernel loss: 0.14044\n",
      "Epoch: 18, series: 114, nllk loss: -1.08457, kernel loss: 0.16343\n",
      "Epoch: 18, series: 115, nllk loss: -0.99188, kernel loss: 0.10199\n",
      "Epoch: 18, series: 116, nllk loss: -1.46939, kernel loss: 0.24286\n",
      "Epoch: 18, series: 117, nllk loss: -0.66084, kernel loss: 0.12754\n",
      "Epoch: 18, series: 118, nllk loss: -1.75944, kernel loss: 0.10566\n",
      "Epoch: 18, series: 119, nllk loss: -0.74295, kernel loss: 0.03234\n",
      "Epoch: 18, series: 120, nllk loss: -1.47964, kernel loss: 0.08110\n",
      "Epoch: 18, series: 121, nllk loss: -0.01712, kernel loss: 0.13725\n",
      "Epoch: 18, series: 122, nllk loss: -0.60275, kernel loss: 0.21355\n",
      "Epoch: 18, series: 123, nllk loss: -1.73218, kernel loss: 0.15765\n",
      "Epoch: 18, series: 124, nllk loss: -1.77294, kernel loss: 0.10850\n",
      "Epoch: 18, series: 125, nllk loss: -1.31699, kernel loss: 0.28410\n",
      "Epoch: 18, series: 126, nllk loss: -1.73390, kernel loss: 0.04780\n",
      "Epoch: 18, series: 127, nllk loss: -1.36957, kernel loss: 0.07349\n",
      "Epoch: 18, series: 128, nllk loss: -1.01693, kernel loss: 0.29804\n",
      "Epoch: 18, series: 129, nllk loss: -0.78592, kernel loss: 0.02486\n",
      "Epoch: 18, series: 130, nllk loss: -1.41688, kernel loss: 0.08870\n",
      "Epoch: 18, series: 131, nllk loss: 0.43307, kernel loss: 0.12521\n",
      "Epoch: 18, series: 132, nllk loss: 0.00560, kernel loss: 0.14880\n",
      "Epoch: 18, series: 133, nllk loss: -0.98159, kernel loss: 0.05915\n",
      "Epoch: 18, series: 134, nllk loss: -0.76908, kernel loss: 0.08463\n",
      "Epoch: 18, series: 135, nllk loss: -1.55944, kernel loss: 0.11597\n",
      "Epoch: 18, series: 136, nllk loss: -1.66522, kernel loss: 0.11490\n",
      "Epoch: 18, series: 137, nllk loss: -1.79994, kernel loss: 0.11483\n",
      "Epoch: 18, series: 138, nllk loss: -1.85288, kernel loss: 0.11130\n",
      "Epoch: 18, series: 139, nllk loss: -1.75392, kernel loss: 0.13293\n",
      "Epoch: 18, series: 140, nllk loss: -1.56229, kernel loss: 0.15190\n",
      "Epoch: 18, series: 141, nllk loss: -1.75269, kernel loss: 0.19728\n",
      "Epoch: 18, series: 142, nllk loss: -1.80553, kernel loss: 0.04034\n",
      "Epoch: 18, series: 143, nllk loss: -1.77516, kernel loss: 0.03236\n",
      "Epoch: 18, series: 144, nllk loss: -2.04079, kernel loss: 0.17927\n",
      "Epoch: 18, series: 145, nllk loss: -1.90608, kernel loss: 0.50559\n",
      "Epoch: 18, series: 146, nllk loss: 2.37626, kernel loss: 0.05477\n",
      "Epoch: 18, series: 147, nllk loss: -1.60452, kernel loss: 0.06975\n",
      "Epoch: 18, series: 148, nllk loss: -1.51616, kernel loss: 0.15186\n",
      "Epoch: 18, series: 149, nllk loss: -1.76536, kernel loss: 0.07170\n",
      "Epoch: 18, series: 150, nllk loss: -1.88880, kernel loss: 0.02006\n",
      "Epoch: 18, series: 151, nllk loss: -1.97063, kernel loss: 0.22902\n",
      "Epoch: 18, series: 152, nllk loss: -1.93260, kernel loss: 0.10443\n",
      "Epoch: 18, series: 153, nllk loss: -1.63517, kernel loss: 0.13017\n",
      "Epoch: 18, series: 154, nllk loss: -1.74992, kernel loss: 0.19367\n",
      "Epoch: 18, series: 155, nllk loss: -1.82167, kernel loss: 0.05077\n",
      "Epoch: 18, series: 156, nllk loss: -1.98992, kernel loss: 0.10061\n",
      "Epoch: 18, series: 157, nllk loss: -1.47324, kernel loss: 0.10232\n",
      "Epoch: 18, series: 158, nllk loss: -1.94839, kernel loss: 0.30780\n",
      "Epoch: 18, series: 159, nllk loss: -1.97380, kernel loss: 0.15938\n",
      "Epoch: 18, series: 160, nllk loss: -1.86046, kernel loss: 0.06386\n",
      "Epoch: 18, series: 161, nllk loss: -1.80002, kernel loss: 0.08752\n",
      "Epoch: 18, series: 162, nllk loss: -2.11215, kernel loss: 0.35536\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, series: 163, nllk loss: -2.33511, kernel loss: 0.12537\n",
      "Epoch: 18, series: 164, nllk loss: -1.87989, kernel loss: 0.07312\n",
      "Epoch: 18, series: 165, nllk loss: -1.93193, kernel loss: 0.04265\n",
      "Epoch: 18, series: 166, nllk loss: -1.35149, kernel loss: 0.20958\n",
      "Epoch: 18, series: 167, nllk loss: -2.50843, kernel loss: 0.06729\n",
      "Epoch: 18, series: 168, nllk loss: -2.14790, kernel loss: 0.03874\n",
      "Epoch: 18, series: 169, nllk loss: -2.34093, kernel loss: 0.11414\n",
      "Epoch: 18, series: 170, nllk loss: -1.97011, kernel loss: 0.15672\n",
      "Epoch: 18, series: 171, nllk loss: -2.42105, kernel loss: 0.14943\n",
      "Epoch: 18, series: 172, nllk loss: -2.04679, kernel loss: 0.09008\n",
      "Epoch: 18, series: 173, nllk loss: -2.52403, kernel loss: 0.14556\n",
      "Epoch: 18, series: 174, nllk loss: -2.19552, kernel loss: 0.20535\n",
      "Epoch: 18, series: 175, nllk loss: -2.52183, kernel loss: 0.24570\n",
      "Epoch: 18, series: 176, nllk loss: -2.10352, kernel loss: 0.07281\n",
      "Epoch: 18, series: 177, nllk loss: -1.95049, kernel loss: 0.19791\n",
      "Epoch: 18, series: 178, nllk loss: -1.74698, kernel loss: 0.06416\n",
      "Epoch: 18, series: 179, nllk loss: -2.21204, kernel loss: 0.06859\n",
      "Epoch: 18, series: 180, nllk loss: -2.23556, kernel loss: 0.01320\n",
      "Epoch: 18, series: 181, nllk loss: -2.50077, kernel loss: 0.09593\n",
      "Epoch: 18, series: 182, nllk loss: -2.20636, kernel loss: 0.10985\n",
      "Epoch: 18, series: 183, nllk loss: -1.92560, kernel loss: 0.16776\n",
      "Epoch: 18, series: 184, nllk loss: -1.96635, kernel loss: 0.12979\n",
      "Epoch: 18, series: 185, nllk loss: -1.62143, kernel loss: 0.22155\n",
      "Epoch: 18, series: 186, nllk loss: -2.56379, kernel loss: 0.27009\n",
      "Epoch: 18, series: 187, nllk loss: -2.65770, kernel loss: 0.07099\n",
      "Epoch: 18, series: 188, nllk loss: -1.58804, kernel loss: 0.16277\n",
      "Epoch: 18, series: 189, nllk loss: -1.49808, kernel loss: 0.08928\n",
      "Epoch: 18, series: 190, nllk loss: -1.99859, kernel loss: 0.05177\n",
      "Epoch: 18, series: 191, nllk loss: -1.89390, kernel loss: 0.22833\n",
      "Epoch: 18, series: 192, nllk loss: -2.10916, kernel loss: 0.19323\n",
      "Epoch: 18, series: 193, nllk loss: -1.61135, kernel loss: 0.12644\n",
      "Epoch: 18, series: 194, nllk loss: -1.50692, kernel loss: 0.06464\n",
      "Epoch: 18, series: 195, nllk loss: -2.26686, kernel loss: 0.15149\n",
      "Epoch: 18, series: 196, nllk loss: -1.88272, kernel loss: 0.20049\n",
      "Epoch: 18, series: 197, nllk loss: -2.15468, kernel loss: 0.12236\n",
      "Epoch: 18, series: 198, nllk loss: -2.20846, kernel loss: 0.06114\n",
      "Epoch: 18, series: 199, nllk loss: -1.93962, kernel loss: 0.24779\n",
      "Epoch: 18, series: 200, nllk loss: -2.27333, kernel loss: 0.02554\n",
      "Epoch: 18, series: 201, nllk loss: -2.33389, kernel loss: 0.15004\n",
      "Epoch: 18, series: 202, nllk loss: -2.11669, kernel loss: 0.16067\n",
      "Epoch: 18, series: 203, nllk loss: -1.87575, kernel loss: 0.20438\n",
      "Epoch: 18, series: 204, nllk loss: -0.86108, kernel loss: 0.13205\n",
      "Epoch: 18, series: 205, nllk loss: -2.09551, kernel loss: 0.14566\n",
      "Epoch: 18, series: 206, nllk loss: -2.24645, kernel loss: 0.11684\n",
      "Epoch: 18, series: 207, nllk loss: -1.05416, kernel loss: 0.24098\n",
      "Epoch: 18, series: 208, nllk loss: -2.46633, kernel loss: 0.08963\n",
      "Epoch: 18, series: 209, nllk loss: -1.77567, kernel loss: 0.18042\n",
      "Epoch: 18, series: 210, nllk loss: -2.61678, kernel loss: 0.06011\n",
      "Epoch: 18, series: 211, nllk loss: -2.06112, kernel loss: 0.16341\n",
      "Epoch: 18, series: 212, nllk loss: -1.41422, kernel loss: 0.01329\n",
      "Epoch: 18, series: 213, nllk loss: -2.09965, kernel loss: 0.15697\n",
      "Epoch: 18, series: 214, nllk loss: -2.02551, kernel loss: 0.22540\n",
      "Epoch: 18, series: 215, nllk loss: -2.32460, kernel loss: 0.03821\n",
      "Epoch: 18, series: 216, nllk loss: -1.33263, kernel loss: 0.02733\n",
      "Epoch: 18, series: 217, nllk loss: -1.96870, kernel loss: 0.01542\n",
      "Epoch: 18, series: 218, nllk loss: -1.51658, kernel loss: 0.25436\n",
      "Epoch: 18, series: 219, nllk loss: -1.99420, kernel loss: 0.08694\n",
      "Epoch: 18, series: 220, nllk loss: -2.07615, kernel loss: 0.09382\n",
      "Epoch: 18, series: 221, nllk loss: -2.36111, kernel loss: 0.08516\n",
      "Epoch: 18, series: 222, nllk loss: -2.25882, kernel loss: 0.26429\n",
      "Epoch: 18, series: 223, nllk loss: -1.59370, kernel loss: 0.07653\n",
      "Epoch: 18, series: 224, nllk loss: -2.45099, kernel loss: 0.16171\n",
      "Epoch: 18, series: 225, nllk loss: -2.27955, kernel loss: 0.05222\n",
      "Epoch: 18, series: 226, nllk loss: -1.86858, kernel loss: 0.25406\n",
      "Epoch: 18, series: 227, nllk loss: -2.03669, kernel loss: 0.20962\n",
      "Epoch: 18, series: 228, nllk loss: -2.09117, kernel loss: 0.08268\n",
      "Epoch: 18, series: 229, nllk loss: -1.97913, kernel loss: 0.08115\n",
      "Epoch: 18, series: 230, nllk loss: -2.40693, kernel loss: 0.08724\n",
      "Epoch: 18, series: 231, nllk loss: -1.97073, kernel loss: 0.07771\n",
      "Epoch: 18, series: 232, nllk loss: -2.61416, kernel loss: 0.29242\n",
      "Epoch: 18, series: 233, nllk loss: -2.50186, kernel loss: 0.15528\n",
      "Epoch: 18, series: 234, nllk loss: -2.00370, kernel loss: 0.17264\n",
      "Epoch: 18, series: 235, nllk loss: -2.63574, kernel loss: 0.16172\n",
      "Epoch: 18, series: 236, nllk loss: -1.60175, kernel loss: 0.05127\n",
      "Epoch: 18, series: 237, nllk loss: -2.13778, kernel loss: 0.18627\n",
      "Epoch: 18, series: 238, nllk loss: -1.95138, kernel loss: 0.13242\n",
      "Epoch: 18, series: 239, nllk loss: -2.24542, kernel loss: 0.09874\n",
      "Epoch: 18, series: 240, nllk loss: -1.06381, kernel loss: 0.10746\n",
      "Epoch: 18, series: 241, nllk loss: -2.02495, kernel loss: 0.41265\n",
      "Epoch: 18, series: 242, nllk loss: -2.10312, kernel loss: 0.52599\n",
      "Epoch: 18, series: 243, nllk loss: -2.33062, kernel loss: 0.09731\n",
      "Epoch: 18, series: 244, nllk loss: -2.02077, kernel loss: 0.18333\n",
      "Epoch: 18, series: 245, nllk loss: -2.23434, kernel loss: 0.07948\n",
      "Epoch: 18, series: 246, nllk loss: -0.02982, kernel loss: 0.15684\n",
      "Epoch: 18, series: 247, nllk loss: -1.74068, kernel loss: 0.10798\n",
      "Epoch: 18, series: 248, nllk loss: -2.06815, kernel loss: 0.12121\n",
      "Epoch: 18, series: 249, nllk loss: -1.94317, kernel loss: 0.06818\n",
      "Epoch: 18, series: 250, nllk loss: -1.67073, kernel loss: 0.08893\n",
      "Epoch: 18, series: 251, nllk loss: -1.13311, kernel loss: 0.04175\n",
      "Epoch: 18, series: 252, nllk loss: -1.35153, kernel loss: 0.01569\n",
      "Epoch: 18, series: 253, nllk loss: -1.78498, kernel loss: 0.08480\n",
      "Epoch: 18, series: 254, nllk loss: -2.24905, kernel loss: 0.18781\n",
      "Epoch: 18, series: 255, nllk loss: -2.07679, kernel loss: 0.11430\n",
      "Epoch: 18, series: 256, nllk loss: -1.92916, kernel loss: 0.02886\n",
      "Epoch: 18, series: 257, nllk loss: -2.09492, kernel loss: 0.12796\n",
      "Epoch: 18, series: 258, nllk loss: -2.12680, kernel loss: 0.10299\n",
      "Epoch: 18, series: 259, nllk loss: -1.88087, kernel loss: 0.08696\n",
      "Epoch: 18, series: 260, nllk loss: -2.02841, kernel loss: 0.22655\n",
      "Epoch: 18, series: 261, nllk loss: -1.98456, kernel loss: 0.07501\n",
      "Epoch: 18, series: 262, nllk loss: -2.63242, kernel loss: 0.14585\n",
      "Epoch: 18, series: 263, nllk loss: -0.64880, kernel loss: 0.06834\n",
      "Epoch: 18, series: 264, nllk loss: -2.03879, kernel loss: 0.08254\n",
      "Epoch: 18, series: 265, nllk loss: -1.70944, kernel loss: 0.09792\n",
      "Epoch: 18, series: 266, nllk loss: -2.31580, kernel loss: 0.04063\n",
      "Epoch: 18, series: 267, nllk loss: -2.14369, kernel loss: 0.14640\n",
      "Epoch: 18, series: 268, nllk loss: -2.16402, kernel loss: 0.03784\n",
      "Epoch: 18, series: 269, nllk loss: -1.87459, kernel loss: 0.19166\n",
      "Epoch: 18, series: 270, nllk loss: -1.85793, kernel loss: 0.07596\n",
      "Epoch: 18, series: 271, nllk loss: -1.98429, kernel loss: 0.26644\n",
      "Epoch: 18, series: 272, nllk loss: -1.80028, kernel loss: 0.21190\n",
      "Epoch: 18, series: 273, nllk loss: -2.06338, kernel loss: 0.19280\n",
      "Epoch: 18, series: 274, nllk loss: -1.60073, kernel loss: 0.06658\n",
      "Epoch: 18, series: 275, nllk loss: -1.90785, kernel loss: 0.09313\n",
      "Epoch: 18, series: 276, nllk loss: -1.32266, kernel loss: 0.21516\n",
      "Epoch: 18, series: 277, nllk loss: -2.14182, kernel loss: 0.13254\n",
      "Epoch: 18, series: 278, nllk loss: -1.88023, kernel loss: 0.04609\n",
      "Epoch: 18, series: 279, nllk loss: -2.34859, kernel loss: 0.04776\n",
      "Epoch: 18, series: 280, nllk loss: -2.10409, kernel loss: 0.15379\n",
      "Epoch: 18, series: 281, nllk loss: -2.33111, kernel loss: 0.08543\n",
      "Epoch: 18, series: 282, nllk loss: -2.17215, kernel loss: 0.01514\n",
      "Epoch: 18, series: 283, nllk loss: -2.12662, kernel loss: 0.19392\n",
      "Epoch: 18, series: 284, nllk loss: -1.63045, kernel loss: 0.04393\n",
      "Epoch: 18, series: 285, nllk loss: -1.94559, kernel loss: 0.15385\n",
      "Epoch: 18, series: 286, nllk loss: -2.19684, kernel loss: 0.15022\n",
      "Epoch: 18, series: 287, nllk loss: -2.49615, kernel loss: 0.06958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18, series: 288, nllk loss: -1.24770, kernel loss: 0.08684\n",
      "Epoch: 18, series: 289, nllk loss: -0.99223, kernel loss: 0.03857\n",
      "Epoch: 18, series: 290, nllk loss: -2.23116, kernel loss: 0.10409\n",
      "Epoch: 18, series: 291, nllk loss: -2.28099, kernel loss: 0.02713\n",
      "Epoch: 18, series: 292, nllk loss: -2.15640, kernel loss: 0.20645\n",
      "Epoch: 18, series: 293, nllk loss: -2.37996, kernel loss: 0.01800\n",
      "Epoch: 18, series: 294, nllk loss: -1.39237, kernel loss: 0.14618\n",
      "Epoch: 18, series: 295, nllk loss: -1.20774, kernel loss: 0.14012\n",
      "Epoch: 18, series: 296, nllk loss: -2.33627, kernel loss: 0.17440\n",
      "Epoch: 18, series: 297, nllk loss: -2.38896, kernel loss: 0.19926\n",
      "Epoch: 18, series: 298, nllk loss: 0.46869, kernel loss: 0.09700\n",
      "Epoch: 18, series: 299, nllk loss: -0.61618, kernel loss: 0.20368\n",
      "Epoch: 18, series: 300, nllk loss: -1.84958, kernel loss: 0.09863\n",
      "Epoch: 18, series: 301, nllk loss: -2.13754, kernel loss: 0.24238\n",
      "Epoch: 18, series: 302, nllk loss: -2.25896, kernel loss: 0.12134\n",
      "Epoch: 18, series: 303, nllk loss: -1.96322, kernel loss: 0.07781\n",
      "Epoch: 18, series: 304, nllk loss: -0.08014, kernel loss: 0.20397\n",
      "Epoch: 18, series: 305, nllk loss: -1.79122, kernel loss: 0.15596\n",
      "Epoch: 18, series: 306, nllk loss: -2.43888, kernel loss: 0.29169\n",
      "Epoch: 18, series: 307, nllk loss: -1.74019, kernel loss: 0.10464\n",
      "Epoch: 18, series: 308, nllk loss: -2.37438, kernel loss: 0.27288\n",
      "Epoch: 18, series: 309, nllk loss: -2.02317, kernel loss: 0.15786\n",
      "Epoch: 18, series: 310, nllk loss: -2.20569, kernel loss: 0.23316\n",
      "Epoch: 18, series: 311, nllk loss: -1.90681, kernel loss: 0.22507\n",
      "Epoch: 18, series: 312, nllk loss: -2.01629, kernel loss: 0.06149\n",
      "Epoch: 18, series: 313, nllk loss: -2.19222, kernel loss: 0.16402\n",
      "Epoch: 18, series: 314, nllk loss: -2.65398, kernel loss: 0.14719\n",
      "Epoch: 18, series: 315, nllk loss: -0.91834, kernel loss: 0.26580\n",
      "Epoch: 18, series: 316, nllk loss: -2.05861, kernel loss: 0.16212\n",
      "Epoch: 18, series: 317, nllk loss: 0.29349, kernel loss: 0.04348\n",
      "Epoch: 18, series: 318, nllk loss: 1.42998, kernel loss: 0.19451\n",
      "Epoch: 18, series: 319, nllk loss: -0.89557, kernel loss: 0.20655\n",
      "Epoch: 18, series: 320, nllk loss: -0.85275, kernel loss: 0.11818\n",
      "Epoch: 18, total loss: -466.94617\n",
      "Epoch: 19, series: 0, nllk loss: 1.32299, kernel loss: 0.05919\n",
      "Epoch: 19, series: 1, nllk loss: -1.08302, kernel loss: 0.27351\n",
      "Epoch: 19, series: 2, nllk loss: -0.00821, kernel loss: 0.11990\n",
      "Epoch: 19, series: 3, nllk loss: -1.33275, kernel loss: 0.12806\n",
      "Epoch: 19, series: 4, nllk loss: -0.94520, kernel loss: 0.27000\n",
      "Epoch: 19, series: 5, nllk loss: -1.31316, kernel loss: 0.22081\n",
      "Epoch: 19, series: 6, nllk loss: -0.60327, kernel loss: 0.20139\n",
      "Epoch: 19, series: 7, nllk loss: -1.21119, kernel loss: 0.10621\n",
      "Epoch: 19, series: 8, nllk loss: -0.58766, kernel loss: 0.21146\n",
      "Epoch: 19, series: 9, nllk loss: -0.56010, kernel loss: 0.13490\n",
      "Epoch: 19, series: 10, nllk loss: -1.35397, kernel loss: 0.14940\n",
      "Epoch: 19, series: 11, nllk loss: -1.09906, kernel loss: 0.03845\n",
      "Epoch: 19, series: 12, nllk loss: -1.46716, kernel loss: 0.01497\n",
      "Epoch: 19, series: 13, nllk loss: -1.42902, kernel loss: 0.05449\n",
      "Epoch: 19, series: 14, nllk loss: -1.57418, kernel loss: 0.13292\n",
      "Epoch: 19, series: 15, nllk loss: -1.60644, kernel loss: 0.05379\n",
      "Epoch: 19, series: 16, nllk loss: -1.11241, kernel loss: 0.14443\n",
      "Epoch: 19, series: 17, nllk loss: -1.22056, kernel loss: 0.22437\n",
      "Epoch: 19, series: 18, nllk loss: -1.44448, kernel loss: 0.19167\n",
      "Epoch: 19, series: 19, nllk loss: -0.35161, kernel loss: 0.20377\n",
      "Epoch: 19, series: 20, nllk loss: -0.81527, kernel loss: 0.17780\n",
      "Epoch: 19, series: 21, nllk loss: -1.11764, kernel loss: 0.12623\n",
      "Epoch: 19, series: 22, nllk loss: -1.51116, kernel loss: 0.05913\n",
      "Epoch: 19, series: 23, nllk loss: -1.49829, kernel loss: 0.01003\n",
      "Epoch: 19, series: 24, nllk loss: -1.73339, kernel loss: 0.01922\n",
      "Epoch: 19, series: 25, nllk loss: -1.63113, kernel loss: 0.13611\n",
      "Epoch: 19, series: 26, nllk loss: -1.46591, kernel loss: 0.06012\n",
      "Epoch: 19, series: 27, nllk loss: -1.23682, kernel loss: 0.19677\n",
      "Epoch: 19, series: 28, nllk loss: -1.47031, kernel loss: 0.17980\n",
      "Epoch: 19, series: 29, nllk loss: -0.92684, kernel loss: 0.22133\n",
      "Epoch: 19, series: 30, nllk loss: -1.49611, kernel loss: 0.15705\n",
      "Epoch: 19, series: 31, nllk loss: -1.17125, kernel loss: 0.08542\n",
      "Epoch: 19, series: 32, nllk loss: -1.14652, kernel loss: 0.09580\n",
      "Epoch: 19, series: 33, nllk loss: -1.08277, kernel loss: 0.04953\n",
      "Epoch: 19, series: 34, nllk loss: -1.48968, kernel loss: 0.04964\n",
      "Epoch: 19, series: 35, nllk loss: -1.71368, kernel loss: 0.14153\n",
      "Epoch: 19, series: 36, nllk loss: -1.58462, kernel loss: 0.02633\n",
      "Epoch: 19, series: 37, nllk loss: -0.51638, kernel loss: 0.08260\n",
      "Epoch: 19, series: 38, nllk loss: -1.08403, kernel loss: 0.02899\n",
      "Epoch: 19, series: 39, nllk loss: -0.83022, kernel loss: 0.05580\n",
      "Epoch: 19, series: 40, nllk loss: -1.92567, kernel loss: 0.13024\n",
      "Epoch: 19, series: 41, nllk loss: -1.42880, kernel loss: 0.17797\n",
      "Epoch: 19, series: 42, nllk loss: -1.11399, kernel loss: 0.09942\n",
      "Epoch: 19, series: 43, nllk loss: -1.09833, kernel loss: 0.14774\n",
      "Epoch: 19, series: 44, nllk loss: -1.67584, kernel loss: 0.14326\n",
      "Epoch: 19, series: 45, nllk loss: -1.66975, kernel loss: 0.00000\n",
      "Epoch: 19, series: 46, nllk loss: -1.70903, kernel loss: 0.09505\n",
      "Epoch: 19, series: 47, nllk loss: -1.60608, kernel loss: 0.01204\n",
      "Epoch: 19, series: 48, nllk loss: -1.66562, kernel loss: 0.14575\n",
      "Epoch: 19, series: 49, nllk loss: -1.21398, kernel loss: 0.15096\n",
      "Epoch: 19, series: 50, nllk loss: 0.05134, kernel loss: 0.07068\n",
      "Epoch: 19, series: 51, nllk loss: -1.29373, kernel loss: 0.12579\n",
      "Epoch: 19, series: 52, nllk loss: -0.37730, kernel loss: 0.20044\n",
      "Epoch: 19, series: 53, nllk loss: -1.72590, kernel loss: 0.14789\n",
      "Epoch: 19, series: 54, nllk loss: -1.37487, kernel loss: 0.14970\n",
      "Epoch: 19, series: 55, nllk loss: -0.89960, kernel loss: 0.27289\n",
      "Epoch: 19, series: 56, nllk loss: -1.38839, kernel loss: 0.03341\n",
      "Epoch: 19, series: 57, nllk loss: -1.37700, kernel loss: 0.09271\n",
      "Epoch: 19, series: 58, nllk loss: -1.54314, kernel loss: 0.02115\n",
      "Epoch: 19, series: 59, nllk loss: -1.17936, kernel loss: 0.20688\n",
      "Epoch: 19, series: 60, nllk loss: -1.08979, kernel loss: 0.23909\n",
      "Epoch: 19, series: 61, nllk loss: -1.71582, kernel loss: 0.07059\n",
      "Epoch: 19, series: 62, nllk loss: -1.78787, kernel loss: 0.04949\n",
      "Epoch: 19, series: 63, nllk loss: -1.65866, kernel loss: 0.00489\n",
      "Epoch: 19, series: 64, nllk loss: -1.17241, kernel loss: 0.03960\n",
      "Epoch: 19, series: 65, nllk loss: -1.71870, kernel loss: 0.01966\n",
      "Epoch: 19, series: 66, nllk loss: -1.65486, kernel loss: 0.01363\n",
      "Epoch: 19, series: 67, nllk loss: -1.46271, kernel loss: 0.17069\n",
      "Epoch: 19, series: 68, nllk loss: -0.84202, kernel loss: 0.00679\n",
      "Epoch: 19, series: 69, nllk loss: -1.52592, kernel loss: 0.00258\n",
      "Epoch: 19, series: 70, nllk loss: -1.41161, kernel loss: 0.21874\n",
      "Epoch: 19, series: 71, nllk loss: -1.55747, kernel loss: 0.10622\n",
      "Epoch: 19, series: 72, nllk loss: -1.87026, kernel loss: 0.11498\n",
      "Epoch: 19, series: 73, nllk loss: -1.40239, kernel loss: 0.15999\n",
      "Epoch: 19, series: 74, nllk loss: -1.99758, kernel loss: 0.08560\n",
      "Epoch: 19, series: 75, nllk loss: -1.54228, kernel loss: 0.10047\n",
      "Epoch: 19, series: 76, nllk loss: -1.48489, kernel loss: 0.13777\n",
      "Epoch: 19, series: 77, nllk loss: -1.28728, kernel loss: 0.15002\n",
      "Epoch: 19, series: 78, nllk loss: -1.40677, kernel loss: 0.14904\n",
      "Epoch: 19, series: 79, nllk loss: -0.57122, kernel loss: 0.03864\n",
      "Epoch: 19, series: 80, nllk loss: -1.81513, kernel loss: 0.05783\n",
      "Epoch: 19, series: 81, nllk loss: -1.47003, kernel loss: 0.07416\n",
      "Epoch: 19, series: 82, nllk loss: -0.33782, kernel loss: 0.09908\n",
      "Epoch: 19, series: 83, nllk loss: -1.16931, kernel loss: 0.04411\n",
      "Epoch: 19, series: 84, nllk loss: -1.22879, kernel loss: 0.04778\n",
      "Epoch: 19, series: 85, nllk loss: -1.52248, kernel loss: 0.07801\n",
      "Epoch: 19, series: 86, nllk loss: -0.79695, kernel loss: 0.07934\n",
      "Epoch: 19, series: 87, nllk loss: -1.74215, kernel loss: 0.03183\n",
      "Epoch: 19, series: 88, nllk loss: -1.93852, kernel loss: 0.22965\n",
      "Epoch: 19, series: 89, nllk loss: -1.91069, kernel loss: 0.03710\n",
      "Epoch: 19, series: 90, nllk loss: -2.12125, kernel loss: 0.20519\n",
      "Epoch: 19, series: 91, nllk loss: -2.14457, kernel loss: 0.08019\n",
      "Epoch: 19, series: 92, nllk loss: 0.03105, kernel loss: 0.10069\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, series: 93, nllk loss: -2.47568, kernel loss: 0.17031\n",
      "Epoch: 19, series: 94, nllk loss: -2.40395, kernel loss: 0.08046\n",
      "Epoch: 19, series: 95, nllk loss: -2.37017, kernel loss: 0.08979\n",
      "Epoch: 19, series: 96, nllk loss: -1.76870, kernel loss: 0.02646\n",
      "Epoch: 19, series: 97, nllk loss: -0.58734, kernel loss: 0.10369\n",
      "Epoch: 19, series: 98, nllk loss: -0.57769, kernel loss: 0.10919\n",
      "Epoch: 19, series: 99, nllk loss: -1.47748, kernel loss: 0.15097\n",
      "Epoch: 19, series: 100, nllk loss: -0.69717, kernel loss: 0.07375\n",
      "Epoch: 19, series: 101, nllk loss: -1.30022, kernel loss: 0.11094\n",
      "Epoch: 19, series: 102, nllk loss: -0.46318, kernel loss: 0.06520\n",
      "Epoch: 19, series: 103, nllk loss: -1.19846, kernel loss: 0.09152\n",
      "Epoch: 19, series: 104, nllk loss: 0.04965, kernel loss: 0.10174\n",
      "Epoch: 19, series: 105, nllk loss: -0.25235, kernel loss: 0.10259\n",
      "Epoch: 19, series: 106, nllk loss: -1.19780, kernel loss: 0.08965\n",
      "Epoch: 19, series: 107, nllk loss: -0.99981, kernel loss: 0.00000\n",
      "Epoch: 19, series: 108, nllk loss: -1.37205, kernel loss: 0.08855\n",
      "Epoch: 19, series: 109, nllk loss: -1.06519, kernel loss: 0.04848\n",
      "Epoch: 19, series: 110, nllk loss: -1.59443, kernel loss: 0.15624\n",
      "Epoch: 19, series: 111, nllk loss: -1.41636, kernel loss: 0.06760\n",
      "Epoch: 19, series: 112, nllk loss: -0.82420, kernel loss: 0.09124\n",
      "Epoch: 19, series: 113, nllk loss: -1.15297, kernel loss: 0.04825\n",
      "Epoch: 19, series: 114, nllk loss: -1.12954, kernel loss: 0.13805\n",
      "Epoch: 19, series: 115, nllk loss: -1.03026, kernel loss: 0.14891\n",
      "Epoch: 19, series: 116, nllk loss: -1.60846, kernel loss: 0.14597\n",
      "Epoch: 19, series: 117, nllk loss: -0.63092, kernel loss: 0.06620\n",
      "Epoch: 19, series: 118, nllk loss: -1.80289, kernel loss: 0.12124\n",
      "Epoch: 19, series: 119, nllk loss: -0.79304, kernel loss: 0.08517\n",
      "Epoch: 19, series: 120, nllk loss: -1.59604, kernel loss: 0.07619\n",
      "Epoch: 19, series: 121, nllk loss: 0.02082, kernel loss: 0.15207\n",
      "Epoch: 19, series: 122, nllk loss: -0.57412, kernel loss: 0.05321\n",
      "Epoch: 19, series: 123, nllk loss: -1.77500, kernel loss: 0.16064\n",
      "Epoch: 19, series: 124, nllk loss: -1.88744, kernel loss: 0.10081\n",
      "Epoch: 19, series: 125, nllk loss: -1.32598, kernel loss: 0.01211\n",
      "Epoch: 19, series: 126, nllk loss: -1.84644, kernel loss: 0.08743\n",
      "Epoch: 19, series: 127, nllk loss: -1.37825, kernel loss: 0.05909\n",
      "Epoch: 19, series: 128, nllk loss: -1.03960, kernel loss: 0.12982\n",
      "Epoch: 19, series: 129, nllk loss: -0.64301, kernel loss: 0.11636\n",
      "Epoch: 19, series: 130, nllk loss: -1.44449, kernel loss: 0.05323\n",
      "Epoch: 19, series: 131, nllk loss: 0.47083, kernel loss: 0.11075\n",
      "Epoch: 19, series: 132, nllk loss: 0.04172, kernel loss: 0.13214\n",
      "Epoch: 19, series: 133, nllk loss: -0.98624, kernel loss: 0.06240\n",
      "Epoch: 19, series: 134, nllk loss: -0.79116, kernel loss: 0.10355\n",
      "Epoch: 19, series: 135, nllk loss: -1.50709, kernel loss: 0.15209\n",
      "Epoch: 19, series: 136, nllk loss: -1.55612, kernel loss: 0.20151\n",
      "Epoch: 19, series: 137, nllk loss: -1.71868, kernel loss: 0.14780\n",
      "Epoch: 19, series: 138, nllk loss: -1.80928, kernel loss: 0.03113\n",
      "Epoch: 19, series: 139, nllk loss: -1.74898, kernel loss: 0.06380\n",
      "Epoch: 19, series: 140, nllk loss: -1.50795, kernel loss: 0.21362\n",
      "Epoch: 19, series: 141, nllk loss: -1.66344, kernel loss: 0.11348\n",
      "Epoch: 19, series: 142, nllk loss: -1.82808, kernel loss: 0.10108\n",
      "Epoch: 19, series: 143, nllk loss: -1.77696, kernel loss: 0.08505\n",
      "Epoch: 19, series: 144, nllk loss: -2.13451, kernel loss: 0.24712\n",
      "Epoch: 19, series: 145, nllk loss: -1.91954, kernel loss: 0.08013\n",
      "Epoch: 19, series: 146, nllk loss: 2.20174, kernel loss: 0.41492\n",
      "Epoch: 19, series: 147, nllk loss: -1.60637, kernel loss: 0.08769\n",
      "Epoch: 19, series: 148, nllk loss: -1.46910, kernel loss: 0.04918\n",
      "Epoch: 19, series: 149, nllk loss: -1.84013, kernel loss: 0.10370\n",
      "Epoch: 19, series: 150, nllk loss: -1.94700, kernel loss: 0.08166\n",
      "Epoch: 19, series: 151, nllk loss: -2.03467, kernel loss: 0.04292\n",
      "Epoch: 19, series: 152, nllk loss: -2.03812, kernel loss: 0.07454\n",
      "Epoch: 19, series: 153, nllk loss: -1.70122, kernel loss: 0.03477\n",
      "Epoch: 19, series: 154, nllk loss: -1.82698, kernel loss: 0.09277\n",
      "Epoch: 19, series: 155, nllk loss: -1.85765, kernel loss: 0.05286\n",
      "Epoch: 19, series: 156, nllk loss: -2.02291, kernel loss: 0.05878\n",
      "Epoch: 19, series: 157, nllk loss: -1.54411, kernel loss: 0.03661\n",
      "Epoch: 19, series: 158, nllk loss: -2.00225, kernel loss: 0.14754\n",
      "Epoch: 19, series: 159, nllk loss: -2.07004, kernel loss: 0.09002\n",
      "Epoch: 19, series: 160, nllk loss: -1.94196, kernel loss: 0.21698\n",
      "Epoch: 19, series: 161, nllk loss: -1.81338, kernel loss: 0.21725\n",
      "Epoch: 19, series: 162, nllk loss: -2.10363, kernel loss: 0.10564\n",
      "Epoch: 19, series: 163, nllk loss: -2.38295, kernel loss: 0.14204\n",
      "Epoch: 19, series: 164, nllk loss: -1.86110, kernel loss: 0.00831\n",
      "Epoch: 19, series: 165, nllk loss: -1.94141, kernel loss: 0.18737\n",
      "Epoch: 19, series: 166, nllk loss: -1.24292, kernel loss: 0.04491\n",
      "Epoch: 19, series: 167, nllk loss: -2.57964, kernel loss: 0.08492\n",
      "Epoch: 19, series: 168, nllk loss: -2.11315, kernel loss: 0.19881\n",
      "Epoch: 19, series: 169, nllk loss: -2.33056, kernel loss: 0.03265\n",
      "Epoch: 19, series: 170, nllk loss: -1.96860, kernel loss: 0.01967\n",
      "Epoch: 19, series: 171, nllk loss: -2.47046, kernel loss: 0.12637\n",
      "Epoch: 19, series: 172, nllk loss: -2.06145, kernel loss: 0.19309\n",
      "Epoch: 19, series: 173, nllk loss: -2.56702, kernel loss: 0.13812\n",
      "Epoch: 19, series: 174, nllk loss: -2.18772, kernel loss: 0.33488\n",
      "Epoch: 19, series: 175, nllk loss: -2.53541, kernel loss: 0.20657\n",
      "Epoch: 19, series: 176, nllk loss: -2.10472, kernel loss: 0.27279\n",
      "Epoch: 19, series: 177, nllk loss: -1.96483, kernel loss: 0.25453\n",
      "Epoch: 19, series: 178, nllk loss: -1.56903, kernel loss: 0.00301\n",
      "Epoch: 19, series: 179, nllk loss: -2.25642, kernel loss: 0.11775\n",
      "Epoch: 19, series: 180, nllk loss: -2.37841, kernel loss: 0.15495\n",
      "Epoch: 19, series: 181, nllk loss: -2.58193, kernel loss: 0.28801\n",
      "Epoch: 19, series: 182, nllk loss: -2.16788, kernel loss: 0.12598\n",
      "Epoch: 19, series: 183, nllk loss: -1.96524, kernel loss: 0.02414\n",
      "Epoch: 19, series: 184, nllk loss: -2.09864, kernel loss: 0.23966\n",
      "Epoch: 19, series: 185, nllk loss: -1.57547, kernel loss: 0.07752\n",
      "Epoch: 19, series: 186, nllk loss: -2.49204, kernel loss: 0.19747\n",
      "Epoch: 19, series: 187, nllk loss: -2.63986, kernel loss: 0.14417\n",
      "Epoch: 19, series: 188, nllk loss: -1.77087, kernel loss: 0.14914\n",
      "Epoch: 19, series: 189, nllk loss: -1.48894, kernel loss: 0.06994\n",
      "Epoch: 19, series: 190, nllk loss: -2.03756, kernel loss: 0.16901\n",
      "Epoch: 19, series: 191, nllk loss: -1.89951, kernel loss: 0.01335\n",
      "Epoch: 19, series: 192, nllk loss: -2.18644, kernel loss: 0.03514\n",
      "Epoch: 19, series: 193, nllk loss: -1.62225, kernel loss: 0.22657\n",
      "Epoch: 19, series: 194, nllk loss: -1.57470, kernel loss: 0.13273\n",
      "Epoch: 19, series: 195, nllk loss: -2.18310, kernel loss: 0.13454\n",
      "Epoch: 19, series: 196, nllk loss: -1.96130, kernel loss: 0.09428\n",
      "Epoch: 19, series: 197, nllk loss: -2.11317, kernel loss: 0.12247\n",
      "Epoch: 19, series: 198, nllk loss: -2.22442, kernel loss: 0.20222\n",
      "Epoch: 19, series: 199, nllk loss: -1.91696, kernel loss: 0.13357\n",
      "Epoch: 19, series: 200, nllk loss: -2.20979, kernel loss: 0.06782\n",
      "Epoch: 19, series: 201, nllk loss: -2.31590, kernel loss: 0.17246\n",
      "Epoch: 19, series: 202, nllk loss: -2.05800, kernel loss: 0.27615\n",
      "Epoch: 19, series: 203, nllk loss: -1.90605, kernel loss: 0.05058\n",
      "Epoch: 19, series: 204, nllk loss: -0.94232, kernel loss: 0.06683\n",
      "Epoch: 19, series: 205, nllk loss: -2.09096, kernel loss: 0.01585\n",
      "Epoch: 19, series: 206, nllk loss: -2.23001, kernel loss: 0.05204\n",
      "Epoch: 19, series: 207, nllk loss: -1.00318, kernel loss: 0.24576\n",
      "Epoch: 19, series: 208, nllk loss: -2.39330, kernel loss: 0.05148\n",
      "Epoch: 19, series: 209, nllk loss: -1.83746, kernel loss: 0.11239\n",
      "Epoch: 19, series: 210, nllk loss: -2.60133, kernel loss: 0.00743\n",
      "Epoch: 19, series: 211, nllk loss: -2.09435, kernel loss: 0.09665\n",
      "Epoch: 19, series: 212, nllk loss: -1.49790, kernel loss: 0.15994\n",
      "Epoch: 19, series: 213, nllk loss: -2.23979, kernel loss: 0.06130\n",
      "Epoch: 19, series: 214, nllk loss: -2.08487, kernel loss: 0.18209\n",
      "Epoch: 19, series: 215, nllk loss: -2.45226, kernel loss: 0.05024\n",
      "Epoch: 19, series: 216, nllk loss: -1.31337, kernel loss: 0.11896\n",
      "Epoch: 19, series: 217, nllk loss: -2.04444, kernel loss: 0.12042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19, series: 218, nllk loss: -1.55028, kernel loss: 0.14378\n",
      "Epoch: 19, series: 219, nllk loss: -2.05620, kernel loss: 0.17271\n",
      "Epoch: 19, series: 220, nllk loss: -2.11080, kernel loss: 0.07236\n",
      "Epoch: 19, series: 221, nllk loss: -2.42976, kernel loss: 0.23602\n",
      "Epoch: 19, series: 222, nllk loss: -2.30905, kernel loss: 0.17260\n",
      "Epoch: 19, series: 223, nllk loss: -1.74408, kernel loss: 0.08416\n",
      "Epoch: 19, series: 224, nllk loss: -2.54519, kernel loss: 0.15308\n",
      "Epoch: 19, series: 225, nllk loss: -2.28554, kernel loss: 0.03405\n",
      "Epoch: 19, series: 226, nllk loss: -1.84059, kernel loss: 0.12188\n",
      "Epoch: 19, series: 227, nllk loss: -2.09561, kernel loss: 0.03343\n",
      "Epoch: 19, series: 228, nllk loss: -2.21193, kernel loss: 0.04260\n",
      "Epoch: 19, series: 229, nllk loss: -2.08477, kernel loss: 0.10715\n",
      "Epoch: 19, series: 230, nllk loss: -2.50054, kernel loss: 0.06051\n",
      "Epoch: 19, series: 231, nllk loss: -1.90479, kernel loss: 0.14919\n",
      "Epoch: 19, series: 232, nllk loss: -2.57452, kernel loss: 0.06138\n",
      "Epoch: 19, series: 233, nllk loss: -2.50901, kernel loss: 0.22370\n",
      "Epoch: 19, series: 234, nllk loss: -2.17286, kernel loss: 0.09763\n",
      "Epoch: 19, series: 235, nllk loss: -2.67371, kernel loss: 0.15038\n",
      "Epoch: 19, series: 236, nllk loss: -1.58699, kernel loss: 0.02942\n",
      "Epoch: 19, series: 237, nllk loss: -2.11692, kernel loss: 0.14973\n",
      "Epoch: 19, series: 238, nllk loss: -2.00663, kernel loss: 0.04312\n",
      "Epoch: 19, series: 239, nllk loss: -2.30486, kernel loss: 0.09227\n",
      "Epoch: 19, series: 240, nllk loss: -0.77737, kernel loss: 0.31924\n",
      "Epoch: 19, series: 241, nllk loss: -1.86659, kernel loss: 0.15757\n",
      "Epoch: 19, series: 242, nllk loss: -2.06043, kernel loss: 0.13835\n",
      "Epoch: 19, series: 243, nllk loss: -2.39240, kernel loss: 0.01948\n",
      "Epoch: 19, series: 244, nllk loss: -1.99740, kernel loss: 0.18083\n",
      "Epoch: 19, series: 245, nllk loss: -2.16925, kernel loss: 0.16556\n",
      "Epoch: 19, series: 246, nllk loss: -0.33134, kernel loss: 0.29991\n",
      "Epoch: 19, series: 247, nllk loss: -1.80434, kernel loss: 0.18745\n",
      "Epoch: 19, series: 248, nllk loss: -2.09153, kernel loss: 0.04787\n",
      "Epoch: 19, series: 249, nllk loss: -1.87912, kernel loss: 0.02689\n",
      "Epoch: 19, series: 250, nllk loss: -1.66999, kernel loss: 0.03155\n",
      "Epoch: 19, series: 251, nllk loss: -1.16664, kernel loss: 0.25713\n",
      "Epoch: 19, series: 252, nllk loss: -1.40557, kernel loss: 0.00480\n",
      "Epoch: 19, series: 253, nllk loss: -1.78211, kernel loss: 0.03398\n",
      "Epoch: 19, series: 254, nllk loss: -2.37857, kernel loss: 0.19612\n",
      "Epoch: 19, series: 255, nllk loss: -2.15596, kernel loss: 0.01090\n",
      "Epoch: 19, series: 256, nllk loss: -1.87372, kernel loss: 0.07192\n",
      "Epoch: 19, series: 257, nllk loss: -2.09488, kernel loss: 0.06949\n",
      "Epoch: 19, series: 258, nllk loss: -2.09266, kernel loss: 0.05722\n",
      "Epoch: 19, series: 259, nllk loss: -1.86724, kernel loss: 0.12358\n",
      "Epoch: 19, series: 260, nllk loss: -1.98011, kernel loss: 0.30120\n",
      "Epoch: 19, series: 261, nllk loss: -2.01059, kernel loss: 0.00572\n",
      "Epoch: 19, series: 262, nllk loss: -2.58767, kernel loss: 0.14613\n",
      "Epoch: 19, series: 263, nllk loss: -0.65477, kernel loss: 0.15855\n",
      "Epoch: 19, series: 264, nllk loss: -2.08854, kernel loss: 0.09909\n",
      "Epoch: 19, series: 265, nllk loss: -1.81892, kernel loss: 0.10876\n",
      "Epoch: 19, series: 266, nllk loss: -2.29184, kernel loss: 0.07706\n",
      "Epoch: 19, series: 267, nllk loss: -2.06621, kernel loss: 0.04896\n",
      "Epoch: 19, series: 268, nllk loss: -2.06130, kernel loss: 0.07072\n",
      "Epoch: 19, series: 269, nllk loss: -1.74088, kernel loss: 0.19842\n",
      "Epoch: 19, series: 270, nllk loss: -1.92020, kernel loss: 0.08795\n",
      "Epoch: 19, series: 271, nllk loss: -2.02726, kernel loss: 0.07301\n",
      "Epoch: 19, series: 272, nllk loss: -1.90815, kernel loss: 0.14584\n",
      "Epoch: 19, series: 273, nllk loss: -2.01415, kernel loss: 0.05626\n",
      "Epoch: 19, series: 274, nllk loss: -1.52814, kernel loss: 0.10812\n",
      "Epoch: 19, series: 275, nllk loss: -2.04630, kernel loss: 0.06283\n",
      "Epoch: 19, series: 276, nllk loss: -1.36406, kernel loss: 0.13363\n",
      "Epoch: 19, series: 277, nllk loss: -2.08577, kernel loss: 0.12064\n",
      "Epoch: 19, series: 278, nllk loss: -1.97429, kernel loss: 0.06636\n",
      "Epoch: 19, series: 279, nllk loss: -2.35870, kernel loss: 0.07726\n",
      "Epoch: 19, series: 280, nllk loss: -2.10918, kernel loss: 0.18387\n",
      "Epoch: 19, series: 281, nllk loss: -2.36356, kernel loss: 0.14511\n",
      "Epoch: 19, series: 282, nllk loss: -2.20328, kernel loss: 0.05473\n",
      "Epoch: 19, series: 283, nllk loss: -2.13689, kernel loss: 0.08246\n",
      "Epoch: 19, series: 284, nllk loss: -1.68311, kernel loss: 0.06211\n",
      "Epoch: 19, series: 285, nllk loss: -1.97071, kernel loss: 0.12002\n",
      "Epoch: 19, series: 286, nllk loss: -2.23061, kernel loss: 0.19436\n",
      "Epoch: 19, series: 287, nllk loss: -2.47331, kernel loss: 0.25991\n",
      "Epoch: 19, series: 288, nllk loss: -1.23716, kernel loss: 0.08596\n",
      "Epoch: 19, series: 289, nllk loss: -1.15147, kernel loss: 0.12210\n",
      "Epoch: 19, series: 290, nllk loss: -2.33608, kernel loss: 0.16281\n",
      "Epoch: 19, series: 291, nllk loss: -2.34760, kernel loss: 0.07839\n",
      "Epoch: 19, series: 292, nllk loss: -2.25105, kernel loss: 0.08489\n",
      "Epoch: 19, series: 293, nllk loss: -2.45183, kernel loss: 0.12595\n",
      "Epoch: 19, series: 294, nllk loss: -1.30086, kernel loss: 0.24553\n",
      "Epoch: 19, series: 295, nllk loss: -1.30698, kernel loss: 0.15304\n",
      "Epoch: 19, series: 296, nllk loss: -2.45127, kernel loss: 0.23904\n",
      "Epoch: 19, series: 297, nllk loss: -2.54699, kernel loss: 0.14854\n",
      "Epoch: 19, series: 298, nllk loss: 0.72219, kernel loss: 0.30126\n",
      "Epoch: 19, series: 299, nllk loss: -0.61167, kernel loss: 0.20991\n",
      "Epoch: 19, series: 300, nllk loss: -2.15517, kernel loss: 0.25454\n",
      "Epoch: 19, series: 301, nllk loss: -2.44350, kernel loss: 0.19659\n",
      "Epoch: 19, series: 302, nllk loss: -2.33619, kernel loss: 0.06212\n",
      "Epoch: 19, series: 303, nllk loss: -1.83622, kernel loss: 0.10555\n",
      "Epoch: 19, series: 304, nllk loss: -0.00883, kernel loss: 0.05546\n",
      "Epoch: 19, series: 305, nllk loss: -1.88076, kernel loss: 0.16079\n",
      "Epoch: 19, series: 306, nllk loss: -2.33587, kernel loss: 0.05842\n",
      "Epoch: 19, series: 307, nllk loss: -1.60524, kernel loss: 0.24114\n",
      "Epoch: 19, series: 308, nllk loss: -2.31231, kernel loss: 0.24115\n",
      "Epoch: 19, series: 309, nllk loss: -2.00199, kernel loss: 0.21975\n",
      "Epoch: 19, series: 310, nllk loss: -2.22655, kernel loss: 0.13447\n",
      "Epoch: 19, series: 311, nllk loss: -1.98302, kernel loss: 0.04978\n",
      "Epoch: 19, series: 312, nllk loss: -2.00226, kernel loss: 0.14987\n",
      "Epoch: 19, series: 313, nllk loss: -2.30176, kernel loss: 0.10054\n",
      "Epoch: 19, series: 314, nllk loss: -2.67298, kernel loss: 0.13535\n",
      "Epoch: 19, series: 315, nllk loss: -0.83587, kernel loss: 0.07714\n",
      "Epoch: 19, series: 316, nllk loss: -2.10026, kernel loss: 0.10465\n",
      "Epoch: 19, series: 317, nllk loss: 0.37422, kernel loss: 0.15995\n",
      "Epoch: 19, series: 318, nllk loss: 1.00918, kernel loss: 0.28667\n",
      "Epoch: 19, series: 319, nllk loss: -0.99858, kernel loss: 0.08602\n",
      "Epoch: 19, series: 320, nllk loss: -0.86210, kernel loss: 0.10064\n",
      "Epoch: 19, total loss: -478.30248\n",
      "Epoch: 20, series: 0, nllk loss: 1.19446, kernel loss: 0.07031\n",
      "Epoch: 20, series: 1, nllk loss: -1.16920, kernel loss: 0.17163\n",
      "Epoch: 20, series: 2, nllk loss: -0.05320, kernel loss: 0.04108\n",
      "Epoch: 20, series: 3, nllk loss: -1.37912, kernel loss: 0.34379\n",
      "Epoch: 20, series: 4, nllk loss: -0.97352, kernel loss: 0.29465\n",
      "Epoch: 20, series: 5, nllk loss: -1.27499, kernel loss: 0.24147\n",
      "Epoch: 20, series: 6, nllk loss: -0.57156, kernel loss: 0.09497\n",
      "Epoch: 20, series: 7, nllk loss: -1.16370, kernel loss: 0.06814\n",
      "Epoch: 20, series: 8, nllk loss: -0.62881, kernel loss: 0.16984\n",
      "Epoch: 20, series: 9, nllk loss: -0.60792, kernel loss: 0.26651\n",
      "Epoch: 20, series: 10, nllk loss: -1.33575, kernel loss: 0.03765\n",
      "Epoch: 20, series: 11, nllk loss: -1.17625, kernel loss: 0.10219\n",
      "Epoch: 20, series: 12, nllk loss: -1.50031, kernel loss: 0.16403\n",
      "Epoch: 20, series: 13, nllk loss: -1.41293, kernel loss: 0.08659\n",
      "Epoch: 20, series: 14, nllk loss: -1.58841, kernel loss: 0.10901\n",
      "Epoch: 20, series: 15, nllk loss: -1.60939, kernel loss: 0.25684\n",
      "Epoch: 20, series: 16, nllk loss: -1.10118, kernel loss: 0.16877\n",
      "Epoch: 20, series: 17, nllk loss: -1.15174, kernel loss: 0.15254\n",
      "Epoch: 20, series: 18, nllk loss: -1.51461, kernel loss: 0.33890\n",
      "Epoch: 20, series: 19, nllk loss: -0.33187, kernel loss: 0.07955\n",
      "Epoch: 20, series: 20, nllk loss: -0.83940, kernel loss: 0.11388\n",
      "Epoch: 20, series: 21, nllk loss: -1.18019, kernel loss: 0.16667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, series: 22, nllk loss: -1.51179, kernel loss: 0.18418\n",
      "Epoch: 20, series: 23, nllk loss: -1.52463, kernel loss: 0.29560\n",
      "Epoch: 20, series: 24, nllk loss: -1.77933, kernel loss: 0.17097\n",
      "Epoch: 20, series: 25, nllk loss: -1.64364, kernel loss: 0.17446\n",
      "Epoch: 20, series: 26, nllk loss: -1.41718, kernel loss: 0.05098\n",
      "Epoch: 20, series: 27, nllk loss: -1.28821, kernel loss: 0.21485\n",
      "Epoch: 20, series: 28, nllk loss: -1.44253, kernel loss: 0.31493\n",
      "Epoch: 20, series: 29, nllk loss: -0.93579, kernel loss: 0.10383\n",
      "Epoch: 20, series: 30, nllk loss: -1.49184, kernel loss: 0.12434\n",
      "Epoch: 20, series: 31, nllk loss: -1.16295, kernel loss: 0.06974\n",
      "Epoch: 20, series: 32, nllk loss: -1.19201, kernel loss: 0.13166\n",
      "Epoch: 20, series: 33, nllk loss: -0.91881, kernel loss: 0.02661\n",
      "Epoch: 20, series: 34, nllk loss: -1.46315, kernel loss: 0.03458\n",
      "Epoch: 20, series: 35, nllk loss: -1.69741, kernel loss: 0.00000\n",
      "Epoch: 20, series: 36, nllk loss: -1.54742, kernel loss: 0.05968\n",
      "Epoch: 20, series: 37, nllk loss: -0.52295, kernel loss: 0.07651\n",
      "Epoch: 20, series: 38, nllk loss: -1.12078, kernel loss: 0.01924\n",
      "Epoch: 20, series: 39, nllk loss: -0.85881, kernel loss: 0.33084\n",
      "Epoch: 20, series: 40, nllk loss: -1.93946, kernel loss: 0.15756\n",
      "Epoch: 20, series: 41, nllk loss: -1.42500, kernel loss: 0.29305\n",
      "Epoch: 20, series: 42, nllk loss: -1.10254, kernel loss: 0.02169\n",
      "Epoch: 20, series: 43, nllk loss: -1.14173, kernel loss: 0.22623\n",
      "Epoch: 20, series: 44, nllk loss: -1.60477, kernel loss: 0.02121\n",
      "Epoch: 20, series: 45, nllk loss: -1.71635, kernel loss: 0.17618\n",
      "Epoch: 20, series: 46, nllk loss: -1.77889, kernel loss: 0.18516\n",
      "Epoch: 20, series: 47, nllk loss: -1.53378, kernel loss: 0.02215\n",
      "Epoch: 20, series: 48, nllk loss: -1.64683, kernel loss: 0.13205\n",
      "Epoch: 20, series: 49, nllk loss: -1.23985, kernel loss: 0.09088\n",
      "Epoch: 20, series: 50, nllk loss: -0.06247, kernel loss: 0.05077\n",
      "Epoch: 20, series: 51, nllk loss: -1.32905, kernel loss: 0.06728\n",
      "Epoch: 20, series: 52, nllk loss: -0.41697, kernel loss: 0.17059\n",
      "Epoch: 20, series: 53, nllk loss: -1.68423, kernel loss: 0.03489\n",
      "Epoch: 20, series: 54, nllk loss: -1.43846, kernel loss: 0.09872\n",
      "Epoch: 20, series: 55, nllk loss: -0.87980, kernel loss: 0.07449\n",
      "Epoch: 20, series: 56, nllk loss: -1.49611, kernel loss: 0.06950\n",
      "Epoch: 20, series: 57, nllk loss: -1.42378, kernel loss: 0.14456\n",
      "Epoch: 20, series: 58, nllk loss: -1.56323, kernel loss: 0.19967\n",
      "Epoch: 20, series: 59, nllk loss: -1.23702, kernel loss: 0.06313\n",
      "Epoch: 20, series: 60, nllk loss: -1.13390, kernel loss: 0.05911\n",
      "Epoch: 20, series: 61, nllk loss: -1.75303, kernel loss: 0.12994\n",
      "Epoch: 20, series: 62, nllk loss: -1.82766, kernel loss: 0.04594\n",
      "Epoch: 20, series: 63, nllk loss: -1.72735, kernel loss: 0.05096\n",
      "Epoch: 20, series: 64, nllk loss: -1.17459, kernel loss: 0.20735\n",
      "Epoch: 20, series: 65, nllk loss: -1.72447, kernel loss: 0.05654\n",
      "Epoch: 20, series: 66, nllk loss: -1.65157, kernel loss: 0.06123\n",
      "Epoch: 20, series: 67, nllk loss: -1.44183, kernel loss: 0.01704\n",
      "Epoch: 20, series: 68, nllk loss: -0.86415, kernel loss: 0.00848\n",
      "Epoch: 20, series: 69, nllk loss: -1.61372, kernel loss: 0.10858\n",
      "Epoch: 20, series: 70, nllk loss: -1.43310, kernel loss: 0.09056\n",
      "Epoch: 20, series: 71, nllk loss: -1.55461, kernel loss: 0.09163\n",
      "Epoch: 20, series: 72, nllk loss: -1.83867, kernel loss: 0.08046\n",
      "Epoch: 20, series: 73, nllk loss: -1.35786, kernel loss: 0.08236\n",
      "Epoch: 20, series: 74, nllk loss: -2.08136, kernel loss: 0.05690\n",
      "Epoch: 20, series: 75, nllk loss: -1.66948, kernel loss: 0.00311\n",
      "Epoch: 20, series: 76, nllk loss: -1.39305, kernel loss: 0.10836\n",
      "Epoch: 20, series: 77, nllk loss: -1.30610, kernel loss: 0.04361\n",
      "Epoch: 20, series: 78, nllk loss: -1.42281, kernel loss: 0.05990\n",
      "Epoch: 20, series: 79, nllk loss: -0.39069, kernel loss: 0.17827\n",
      "Epoch: 20, series: 80, nllk loss: -1.87083, kernel loss: 0.11009\n",
      "Epoch: 20, series: 81, nllk loss: -1.39512, kernel loss: 0.01438\n",
      "Epoch: 20, series: 82, nllk loss: -0.34586, kernel loss: 0.30143\n",
      "Epoch: 20, series: 83, nllk loss: -1.17966, kernel loss: 0.01520\n",
      "Epoch: 20, series: 84, nllk loss: -1.29013, kernel loss: 0.05965\n",
      "Epoch: 20, series: 85, nllk loss: -1.60975, kernel loss: 0.15399\n",
      "Epoch: 20, series: 86, nllk loss: -0.88917, kernel loss: 0.04523\n",
      "Epoch: 20, series: 87, nllk loss: -1.80626, kernel loss: 0.04279\n",
      "Epoch: 20, series: 88, nllk loss: -2.06427, kernel loss: 0.04686\n",
      "Epoch: 20, series: 89, nllk loss: -1.92380, kernel loss: 0.09385\n",
      "Epoch: 20, series: 90, nllk loss: -2.15045, kernel loss: 0.07519\n",
      "Epoch: 20, series: 91, nllk loss: -2.12854, kernel loss: 0.07113\n",
      "Epoch: 20, series: 92, nllk loss: 0.00112, kernel loss: 0.10605\n",
      "Epoch: 20, series: 93, nllk loss: -2.48662, kernel loss: 0.08241\n",
      "Epoch: 20, series: 94, nllk loss: -2.43910, kernel loss: 0.08984\n",
      "Epoch: 20, series: 95, nllk loss: -2.38012, kernel loss: 0.07202\n",
      "Epoch: 20, series: 96, nllk loss: -1.79746, kernel loss: 0.06481\n",
      "Epoch: 20, series: 97, nllk loss: -0.60950, kernel loss: 0.13802\n",
      "Epoch: 20, series: 98, nllk loss: -0.60089, kernel loss: 0.14165\n",
      "Epoch: 20, series: 99, nllk loss: -1.55914, kernel loss: 0.08132\n",
      "Epoch: 20, series: 100, nllk loss: -0.76459, kernel loss: 0.19291\n",
      "Epoch: 20, series: 101, nllk loss: -1.29562, kernel loss: 0.06088\n",
      "Epoch: 20, series: 102, nllk loss: -0.56907, kernel loss: 0.09879\n",
      "Epoch: 20, series: 103, nllk loss: -1.15459, kernel loss: 0.08594\n",
      "Epoch: 20, series: 104, nllk loss: -0.02239, kernel loss: 0.08862\n",
      "Epoch: 20, series: 105, nllk loss: -0.37578, kernel loss: 0.14331\n",
      "Epoch: 20, series: 106, nllk loss: -1.25081, kernel loss: 0.19586\n",
      "Epoch: 20, series: 107, nllk loss: -0.98729, kernel loss: 0.18548\n",
      "Epoch: 20, series: 108, nllk loss: -1.30693, kernel loss: 0.07516\n",
      "Epoch: 20, series: 109, nllk loss: -0.89853, kernel loss: 0.03131\n",
      "Epoch: 20, series: 110, nllk loss: -1.52543, kernel loss: 0.18330\n",
      "Epoch: 20, series: 111, nllk loss: -1.44519, kernel loss: 0.11093\n",
      "Epoch: 20, series: 112, nllk loss: -0.91344, kernel loss: 0.09795\n",
      "Epoch: 20, series: 113, nllk loss: -1.19643, kernel loss: 0.19802\n",
      "Epoch: 20, series: 114, nllk loss: -1.21243, kernel loss: 0.12095\n",
      "Epoch: 20, series: 115, nllk loss: -1.06658, kernel loss: 0.17978\n",
      "Epoch: 20, series: 116, nllk loss: -1.56892, kernel loss: 0.09530\n",
      "Epoch: 20, series: 117, nllk loss: -0.64461, kernel loss: 0.06562\n",
      "Epoch: 20, series: 118, nllk loss: -1.89479, kernel loss: 0.10171\n",
      "Epoch: 20, series: 119, nllk loss: -0.77410, kernel loss: 0.14278\n",
      "Epoch: 20, series: 120, nllk loss: -1.47608, kernel loss: 0.19021\n",
      "Epoch: 20, series: 121, nllk loss: 0.10688, kernel loss: 0.10332\n",
      "Epoch: 20, series: 122, nllk loss: -0.59892, kernel loss: 0.14341\n",
      "Epoch: 20, series: 123, nllk loss: -1.78588, kernel loss: 0.02289\n",
      "Epoch: 20, series: 124, nllk loss: -1.90389, kernel loss: 0.01748\n",
      "Epoch: 20, series: 125, nllk loss: -1.33126, kernel loss: 0.06631\n",
      "Epoch: 20, series: 126, nllk loss: -1.80302, kernel loss: 0.06624\n",
      "Epoch: 20, series: 127, nllk loss: -1.39229, kernel loss: 0.03543\n",
      "Epoch: 20, series: 128, nllk loss: -0.96403, kernel loss: 0.06668\n",
      "Epoch: 20, series: 129, nllk loss: -0.57775, kernel loss: 0.16105\n",
      "Epoch: 20, series: 130, nllk loss: -1.38935, kernel loss: 0.10858\n",
      "Epoch: 20, series: 131, nllk loss: 0.32989, kernel loss: 0.04107\n",
      "Epoch: 20, series: 132, nllk loss: 0.14850, kernel loss: 0.09399\n",
      "Epoch: 20, series: 133, nllk loss: -0.93354, kernel loss: 0.20930\n",
      "Epoch: 20, series: 134, nllk loss: -0.79642, kernel loss: 0.15411\n",
      "Epoch: 20, series: 135, nllk loss: -1.38040, kernel loss: 0.13705\n",
      "Epoch: 20, series: 136, nllk loss: -1.40718, kernel loss: 0.14268\n",
      "Epoch: 20, series: 137, nllk loss: -1.69091, kernel loss: 0.08104\n",
      "Epoch: 20, series: 138, nllk loss: -1.74405, kernel loss: 0.09472\n",
      "Epoch: 20, series: 139, nllk loss: -1.69329, kernel loss: 0.20203\n",
      "Epoch: 20, series: 140, nllk loss: -1.48154, kernel loss: 0.06219\n",
      "Epoch: 20, series: 141, nllk loss: -1.61334, kernel loss: 0.19443\n",
      "Epoch: 20, series: 142, nllk loss: -1.79226, kernel loss: 0.07165\n",
      "Epoch: 20, series: 143, nllk loss: -1.72536, kernel loss: 0.25879\n",
      "Epoch: 20, series: 144, nllk loss: -2.08782, kernel loss: 0.19693\n",
      "Epoch: 20, series: 145, nllk loss: -1.90511, kernel loss: 0.19699\n",
      "Epoch: 20, series: 146, nllk loss: 1.97491, kernel loss: 0.13550\n",
      "Epoch: 20, series: 147, nllk loss: -1.52713, kernel loss: 0.07653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, series: 148, nllk loss: -1.46385, kernel loss: 0.02167\n",
      "Epoch: 20, series: 149, nllk loss: -1.82972, kernel loss: 0.08675\n",
      "Epoch: 20, series: 150, nllk loss: -1.92380, kernel loss: 0.10425\n",
      "Epoch: 20, series: 151, nllk loss: -2.05255, kernel loss: 0.08965\n",
      "Epoch: 20, series: 152, nllk loss: -2.06088, kernel loss: 0.04275\n",
      "Epoch: 20, series: 153, nllk loss: -1.78160, kernel loss: 0.00000\n",
      "Epoch: 20, series: 154, nllk loss: -1.86705, kernel loss: 0.12841\n",
      "Epoch: 20, series: 155, nllk loss: -1.92519, kernel loss: 0.17405\n",
      "Epoch: 20, series: 156, nllk loss: -2.06100, kernel loss: 0.29554\n",
      "Epoch: 20, series: 157, nllk loss: -1.56485, kernel loss: 0.18548\n",
      "Epoch: 20, series: 158, nllk loss: -1.99191, kernel loss: 0.14326\n",
      "Epoch: 20, series: 159, nllk loss: -2.03197, kernel loss: 0.09340\n",
      "Epoch: 20, series: 160, nllk loss: -1.91820, kernel loss: 0.13009\n",
      "Epoch: 20, series: 161, nllk loss: -1.80688, kernel loss: 0.12211\n",
      "Epoch: 20, series: 162, nllk loss: -2.13510, kernel loss: 0.16436\n",
      "Epoch: 20, series: 163, nllk loss: -2.42669, kernel loss: 0.15676\n",
      "Epoch: 20, series: 164, nllk loss: -1.92045, kernel loss: 0.06112\n",
      "Epoch: 20, series: 165, nllk loss: -1.96850, kernel loss: 0.12262\n",
      "Epoch: 20, series: 166, nllk loss: -1.33897, kernel loss: 0.10082\n",
      "Epoch: 20, series: 167, nllk loss: -2.64363, kernel loss: 0.24316\n",
      "Epoch: 20, series: 168, nllk loss: -2.16622, kernel loss: 0.07444\n",
      "Epoch: 20, series: 169, nllk loss: -2.32696, kernel loss: 0.00155\n",
      "Epoch: 20, series: 170, nllk loss: -1.95901, kernel loss: 0.07337\n",
      "Epoch: 20, series: 171, nllk loss: -2.45063, kernel loss: 0.02103\n",
      "Epoch: 20, series: 172, nllk loss: -2.09286, kernel loss: 0.05723\n",
      "Epoch: 20, series: 173, nllk loss: -2.61691, kernel loss: 0.15758\n",
      "Epoch: 20, series: 174, nllk loss: -2.22272, kernel loss: 0.09863\n",
      "Epoch: 20, series: 175, nllk loss: -2.56182, kernel loss: 0.12595\n",
      "Epoch: 20, series: 176, nllk loss: -2.09993, kernel loss: 0.09355\n",
      "Epoch: 20, series: 177, nllk loss: -1.99498, kernel loss: 0.08973\n",
      "Epoch: 20, series: 178, nllk loss: -1.60508, kernel loss: 0.14965\n",
      "Epoch: 20, series: 179, nllk loss: -2.16733, kernel loss: 0.15886\n",
      "Epoch: 20, series: 180, nllk loss: -2.25828, kernel loss: 0.12910\n",
      "Epoch: 20, series: 181, nllk loss: -2.53288, kernel loss: 0.10491\n",
      "Epoch: 20, series: 182, nllk loss: -2.19892, kernel loss: 0.04124\n",
      "Epoch: 20, series: 183, nllk loss: -1.95262, kernel loss: 0.15328\n",
      "Epoch: 20, series: 184, nllk loss: -2.00720, kernel loss: 0.01745\n",
      "Epoch: 20, series: 185, nllk loss: -1.61119, kernel loss: 0.10776\n",
      "Epoch: 20, series: 186, nllk loss: -2.49043, kernel loss: 0.08207\n",
      "Epoch: 20, series: 187, nllk loss: -2.65521, kernel loss: 0.35627\n",
      "Epoch: 20, series: 188, nllk loss: -1.75326, kernel loss: 0.14636\n",
      "Epoch: 20, series: 189, nllk loss: -1.50577, kernel loss: 0.14827\n",
      "Epoch: 20, series: 190, nllk loss: -2.12632, kernel loss: 0.13059\n",
      "Epoch: 20, series: 191, nllk loss: -1.95563, kernel loss: 0.11673\n",
      "Epoch: 20, series: 192, nllk loss: -2.20350, kernel loss: 0.18026\n",
      "Epoch: 20, series: 193, nllk loss: -1.66097, kernel loss: 0.20292\n",
      "Epoch: 20, series: 194, nllk loss: -1.50760, kernel loss: 0.28923\n",
      "Epoch: 20, series: 195, nllk loss: -2.20615, kernel loss: 0.27891\n",
      "Epoch: 20, series: 196, nllk loss: -1.90212, kernel loss: 0.06116\n",
      "Epoch: 20, series: 197, nllk loss: -2.21153, kernel loss: 0.13701\n",
      "Epoch: 20, series: 198, nllk loss: -2.33189, kernel loss: 0.17590\n",
      "Epoch: 20, series: 199, nllk loss: -1.88089, kernel loss: 0.15374\n",
      "Epoch: 20, series: 200, nllk loss: -2.20323, kernel loss: 0.22327\n",
      "Epoch: 20, series: 201, nllk loss: -2.37783, kernel loss: 0.05648\n",
      "Epoch: 20, series: 202, nllk loss: -2.16207, kernel loss: 0.10703\n",
      "Epoch: 20, series: 203, nllk loss: -1.86597, kernel loss: 0.14299\n",
      "Epoch: 20, series: 204, nllk loss: -1.04366, kernel loss: 0.07999\n",
      "Epoch: 20, series: 205, nllk loss: -2.05441, kernel loss: 0.32585\n",
      "Epoch: 20, series: 206, nllk loss: -2.18760, kernel loss: 0.11596\n",
      "Epoch: 20, series: 207, nllk loss: -0.90461, kernel loss: 0.17140\n",
      "Epoch: 20, series: 208, nllk loss: -2.45965, kernel loss: 0.07877\n",
      "Epoch: 20, series: 209, nllk loss: -1.77831, kernel loss: 0.06740\n",
      "Epoch: 20, series: 210, nllk loss: -2.59274, kernel loss: 0.17871\n",
      "Epoch: 20, series: 211, nllk loss: -2.07855, kernel loss: 0.06107\n",
      "Epoch: 20, series: 212, nllk loss: -1.33912, kernel loss: 0.14129\n",
      "Epoch: 20, series: 213, nllk loss: -2.12088, kernel loss: 0.16252\n",
      "Epoch: 20, series: 214, nllk loss: -2.02847, kernel loss: 0.09899\n",
      "Epoch: 20, series: 215, nllk loss: -2.28667, kernel loss: 0.01944\n",
      "Epoch: 20, series: 216, nllk loss: -1.36635, kernel loss: 0.04503\n",
      "Epoch: 20, series: 217, nllk loss: -1.98297, kernel loss: 0.11887\n",
      "Epoch: 20, series: 218, nllk loss: -1.51406, kernel loss: 0.03333\n",
      "Epoch: 20, series: 219, nllk loss: -2.04798, kernel loss: 0.04573\n",
      "Epoch: 20, series: 220, nllk loss: -2.11791, kernel loss: 0.10161\n",
      "Epoch: 20, series: 221, nllk loss: -2.40797, kernel loss: 0.06435\n",
      "Epoch: 20, series: 222, nllk loss: -2.20531, kernel loss: 0.09962\n",
      "Epoch: 20, series: 223, nllk loss: -1.46268, kernel loss: 0.12006\n",
      "Epoch: 20, series: 224, nllk loss: -2.49002, kernel loss: 0.08675\n",
      "Epoch: 20, series: 225, nllk loss: -2.33516, kernel loss: 0.09417\n",
      "Epoch: 20, series: 226, nllk loss: -1.87717, kernel loss: 0.17026\n",
      "Epoch: 20, series: 227, nllk loss: -2.00174, kernel loss: 0.08815\n",
      "Epoch: 20, series: 228, nllk loss: -2.09566, kernel loss: 0.07067\n",
      "Epoch: 20, series: 229, nllk loss: -1.89176, kernel loss: 0.16509\n",
      "Epoch: 20, series: 230, nllk loss: -2.34638, kernel loss: 0.15512\n",
      "Epoch: 20, series: 231, nllk loss: -1.89656, kernel loss: 0.04790\n",
      "Epoch: 20, series: 232, nllk loss: -2.54305, kernel loss: 0.29679\n",
      "Epoch: 20, series: 233, nllk loss: -2.43630, kernel loss: 0.17130\n",
      "Epoch: 20, series: 234, nllk loss: -2.05966, kernel loss: 0.11087\n",
      "Epoch: 20, series: 235, nllk loss: -2.61045, kernel loss: 0.15250\n",
      "Epoch: 20, series: 236, nllk loss: -1.62836, kernel loss: 0.11229\n",
      "Epoch: 20, series: 237, nllk loss: -2.18937, kernel loss: 0.10048\n",
      "Epoch: 20, series: 238, nllk loss: -1.94643, kernel loss: 0.09411\n",
      "Epoch: 20, series: 239, nllk loss: -2.28223, kernel loss: 0.02533\n",
      "Epoch: 20, series: 240, nllk loss: -1.11518, kernel loss: 0.03994\n",
      "Epoch: 20, series: 241, nllk loss: -1.91206, kernel loss: 0.20013\n",
      "Epoch: 20, series: 242, nllk loss: -2.05050, kernel loss: 0.10564\n",
      "Epoch: 20, series: 243, nllk loss: -2.45838, kernel loss: 0.14603\n",
      "Epoch: 20, series: 244, nllk loss: -2.04995, kernel loss: 0.21589\n",
      "Epoch: 20, series: 245, nllk loss: -2.13545, kernel loss: 0.18141\n",
      "Epoch: 20, series: 246, nllk loss: -0.18917, kernel loss: 0.16169\n",
      "Epoch: 20, series: 247, nllk loss: -1.73912, kernel loss: 0.03741\n",
      "Epoch: 20, series: 248, nllk loss: -2.15389, kernel loss: 0.16130\n",
      "Epoch: 20, series: 249, nllk loss: -2.08477, kernel loss: 0.08938\n",
      "Epoch: 20, series: 250, nllk loss: -1.68832, kernel loss: 0.02350\n",
      "Epoch: 20, series: 251, nllk loss: -1.21803, kernel loss: 0.08647\n",
      "Epoch: 20, series: 252, nllk loss: -1.44613, kernel loss: 0.13381\n",
      "Epoch: 20, series: 253, nllk loss: -1.72834, kernel loss: 0.16378\n",
      "Epoch: 20, series: 254, nllk loss: -2.25118, kernel loss: 0.02894\n",
      "Epoch: 20, series: 255, nllk loss: -2.09987, kernel loss: 0.05516\n",
      "Epoch: 20, series: 256, nllk loss: -1.87617, kernel loss: 0.14332\n",
      "Epoch: 20, series: 257, nllk loss: -2.10161, kernel loss: 0.16026\n",
      "Epoch: 20, series: 258, nllk loss: -2.17826, kernel loss: 0.09357\n",
      "Epoch: 20, series: 259, nllk loss: -1.87788, kernel loss: 0.18183\n",
      "Epoch: 20, series: 260, nllk loss: -2.05446, kernel loss: 0.16948\n",
      "Epoch: 20, series: 261, nllk loss: -2.13829, kernel loss: 0.16621\n",
      "Epoch: 20, series: 262, nllk loss: -2.61877, kernel loss: 0.11517\n",
      "Epoch: 20, series: 263, nllk loss: -0.66517, kernel loss: 0.09214\n",
      "Epoch: 20, series: 264, nllk loss: -2.06369, kernel loss: 0.09966\n",
      "Epoch: 20, series: 265, nllk loss: -1.87705, kernel loss: 0.16265\n",
      "Epoch: 20, series: 266, nllk loss: -2.30717, kernel loss: 0.09839\n",
      "Epoch: 20, series: 267, nllk loss: -2.15670, kernel loss: 0.05352\n",
      "Epoch: 20, series: 268, nllk loss: -2.12834, kernel loss: 0.03600\n",
      "Epoch: 20, series: 269, nllk loss: -1.82623, kernel loss: 0.18983\n",
      "Epoch: 20, series: 270, nllk loss: -1.90127, kernel loss: 0.04004\n",
      "Epoch: 20, series: 271, nllk loss: -2.08141, kernel loss: 0.04450\n",
      "Epoch: 20, series: 272, nllk loss: -1.95729, kernel loss: 0.09881\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20, series: 273, nllk loss: -2.09119, kernel loss: 0.12132\n",
      "Epoch: 20, series: 274, nllk loss: -1.42805, kernel loss: 0.13313\n",
      "Epoch: 20, series: 275, nllk loss: -1.96801, kernel loss: 0.10748\n",
      "Epoch: 20, series: 276, nllk loss: -1.28154, kernel loss: 0.05731\n",
      "Epoch: 20, series: 277, nllk loss: -2.11705, kernel loss: 0.22440\n",
      "Epoch: 20, series: 278, nllk loss: -1.95703, kernel loss: 0.12044\n",
      "Epoch: 20, series: 279, nllk loss: -2.38834, kernel loss: 0.13731\n",
      "Epoch: 20, series: 280, nllk loss: -2.11234, kernel loss: 0.22481\n",
      "Epoch: 20, series: 281, nllk loss: -2.33648, kernel loss: 0.13463\n",
      "Epoch: 20, series: 282, nllk loss: -2.25244, kernel loss: 0.04585\n",
      "Epoch: 20, series: 283, nllk loss: -2.10815, kernel loss: 0.03915\n",
      "Epoch: 20, series: 284, nllk loss: -1.66823, kernel loss: 0.01684\n",
      "Epoch: 20, series: 285, nllk loss: -1.88696, kernel loss: 0.15962\n",
      "Epoch: 20, series: 286, nllk loss: -2.17635, kernel loss: 0.10804\n",
      "Epoch: 20, series: 287, nllk loss: -2.44284, kernel loss: 0.01451\n",
      "Epoch: 20, series: 288, nllk loss: -1.21475, kernel loss: 0.04414\n",
      "Epoch: 20, series: 289, nllk loss: -1.07740, kernel loss: 0.09638\n",
      "Epoch: 20, series: 290, nllk loss: -2.34796, kernel loss: 0.02128\n",
      "Epoch: 20, series: 291, nllk loss: -2.35804, kernel loss: 0.06615\n",
      "Epoch: 20, series: 292, nllk loss: -2.17221, kernel loss: 0.07351\n",
      "Epoch: 20, series: 293, nllk loss: -2.36218, kernel loss: 0.10333\n",
      "Epoch: 20, series: 294, nllk loss: -1.27288, kernel loss: 0.27153\n",
      "Epoch: 20, series: 295, nllk loss: -1.23617, kernel loss: 0.06855\n",
      "Epoch: 20, series: 296, nllk loss: -2.44237, kernel loss: 0.27969\n",
      "Epoch: 20, series: 297, nllk loss: -2.56438, kernel loss: 0.12672\n",
      "Epoch: 20, series: 298, nllk loss: 0.02213, kernel loss: 0.08089\n",
      "Epoch: 20, series: 299, nllk loss: -0.63310, kernel loss: 0.19457\n",
      "Epoch: 20, series: 300, nllk loss: -2.15375, kernel loss: 0.09085\n",
      "Epoch: 20, series: 301, nllk loss: -2.40546, kernel loss: 0.10272\n",
      "Epoch: 20, series: 302, nllk loss: -2.34732, kernel loss: 0.14853\n",
      "Epoch: 20, series: 303, nllk loss: -2.07534, kernel loss: 0.14150\n",
      "Epoch: 20, series: 304, nllk loss: 0.23058, kernel loss: 0.21390\n",
      "Epoch: 20, series: 305, nllk loss: -1.79517, kernel loss: 0.08263\n",
      "Epoch: 20, series: 306, nllk loss: -2.42075, kernel loss: 0.14671\n",
      "Epoch: 20, series: 307, nllk loss: -1.67707, kernel loss: 0.16560\n",
      "Epoch: 20, series: 308, nllk loss: -2.31695, kernel loss: 0.01268\n",
      "Epoch: 20, series: 309, nllk loss: -1.97979, kernel loss: 0.38770\n",
      "Epoch: 20, series: 310, nllk loss: -2.31389, kernel loss: 0.04204\n",
      "Epoch: 20, series: 311, nllk loss: -1.87290, kernel loss: 0.04483\n",
      "Epoch: 20, series: 312, nllk loss: -2.12781, kernel loss: 0.20624\n",
      "Epoch: 20, series: 313, nllk loss: -2.28228, kernel loss: 0.16977\n",
      "Epoch: 20, series: 314, nllk loss: -2.76059, kernel loss: 0.12893\n",
      "Epoch: 20, series: 315, nllk loss: -0.92636, kernel loss: 0.13082\n",
      "Epoch: 20, series: 316, nllk loss: -2.12091, kernel loss: 0.10369\n",
      "Epoch: 20, series: 317, nllk loss: 0.23634, kernel loss: 0.11616\n",
      "Epoch: 20, series: 318, nllk loss: 0.94103, kernel loss: 0.08374\n",
      "Epoch: 20, series: 319, nllk loss: -1.07459, kernel loss: 0.12477\n",
      "Epoch: 20, series: 320, nllk loss: -0.84276, kernel loss: 0.10921\n",
      "Epoch: 20, total loss: -479.84578\n",
      "Epoch: 21, series: 0, nllk loss: 0.98558, kernel loss: 0.26677\n",
      "Epoch: 21, series: 1, nllk loss: -1.02747, kernel loss: 0.22380\n",
      "Epoch: 21, series: 2, nllk loss: -0.14017, kernel loss: 0.13088\n",
      "Epoch: 21, series: 3, nllk loss: -1.32820, kernel loss: 0.24263\n",
      "Epoch: 21, series: 4, nllk loss: -0.96759, kernel loss: 0.09197\n",
      "Epoch: 21, series: 5, nllk loss: -1.36107, kernel loss: 0.25376\n",
      "Epoch: 21, series: 6, nllk loss: -0.53702, kernel loss: 0.35658\n",
      "Epoch: 21, series: 7, nllk loss: -1.11754, kernel loss: 0.30783\n",
      "Epoch: 21, series: 8, nllk loss: -0.59974, kernel loss: 0.06531\n",
      "Epoch: 21, series: 9, nllk loss: -0.63344, kernel loss: 0.05166\n",
      "Epoch: 21, series: 10, nllk loss: -1.31795, kernel loss: 0.13527\n",
      "Epoch: 21, series: 11, nllk loss: -1.23260, kernel loss: 0.33755\n",
      "Epoch: 21, series: 12, nllk loss: -1.57470, kernel loss: 0.10559\n",
      "Epoch: 21, series: 13, nllk loss: -1.45355, kernel loss: 0.13752\n",
      "Epoch: 21, series: 14, nllk loss: -1.63935, kernel loss: 0.04423\n",
      "Epoch: 21, series: 15, nllk loss: -1.58462, kernel loss: 0.05729\n",
      "Epoch: 21, series: 16, nllk loss: -1.11531, kernel loss: 0.02526\n",
      "Epoch: 21, series: 17, nllk loss: -1.20739, kernel loss: 0.12632\n",
      "Epoch: 21, series: 18, nllk loss: -1.50143, kernel loss: 0.04972\n",
      "Epoch: 21, series: 19, nllk loss: -0.32766, kernel loss: 0.02916\n",
      "Epoch: 21, series: 20, nllk loss: -0.83354, kernel loss: 0.10053\n",
      "Epoch: 21, series: 21, nllk loss: -1.15265, kernel loss: 0.05966\n",
      "Epoch: 21, series: 22, nllk loss: -1.53296, kernel loss: 0.09889\n",
      "Epoch: 21, series: 23, nllk loss: -1.54758, kernel loss: 0.13009\n",
      "Epoch: 21, series: 24, nllk loss: -1.80077, kernel loss: 0.04944\n",
      "Epoch: 21, series: 25, nllk loss: -1.68248, kernel loss: 0.07211\n",
      "Epoch: 21, series: 26, nllk loss: -1.38303, kernel loss: 0.13799\n",
      "Epoch: 21, series: 27, nllk loss: -1.25647, kernel loss: 0.02245\n",
      "Epoch: 21, series: 28, nllk loss: -1.41775, kernel loss: 0.21591\n",
      "Epoch: 21, series: 29, nllk loss: -0.94492, kernel loss: 0.10879\n",
      "Epoch: 21, series: 30, nllk loss: -1.48956, kernel loss: 0.06619\n",
      "Epoch: 21, series: 31, nllk loss: -1.07753, kernel loss: 0.17428\n",
      "Epoch: 21, series: 32, nllk loss: -1.21287, kernel loss: 0.06673\n",
      "Epoch: 21, series: 33, nllk loss: -1.01141, kernel loss: 0.09145\n",
      "Epoch: 21, series: 34, nllk loss: -1.43202, kernel loss: 0.02566\n",
      "Epoch: 21, series: 35, nllk loss: -1.68304, kernel loss: 0.14294\n",
      "Epoch: 21, series: 36, nllk loss: -1.65669, kernel loss: 0.27176\n",
      "Epoch: 21, series: 37, nllk loss: -0.58035, kernel loss: 0.01350\n",
      "Epoch: 21, series: 38, nllk loss: -1.08852, kernel loss: 0.08116\n",
      "Epoch: 21, series: 39, nllk loss: -0.82099, kernel loss: 0.10816\n",
      "Epoch: 21, series: 40, nllk loss: -1.93315, kernel loss: 0.09234\n",
      "Epoch: 21, series: 41, nllk loss: -1.40469, kernel loss: 0.02344\n",
      "Epoch: 21, series: 42, nllk loss: -1.14277, kernel loss: 0.11755\n",
      "Epoch: 21, series: 43, nllk loss: -1.10001, kernel loss: 0.04818\n",
      "Epoch: 21, series: 44, nllk loss: -1.68618, kernel loss: 0.03927\n",
      "Epoch: 21, series: 45, nllk loss: -1.76700, kernel loss: 0.15617\n",
      "Epoch: 21, series: 46, nllk loss: -1.76106, kernel loss: 0.29666\n",
      "Epoch: 21, series: 47, nllk loss: -1.62463, kernel loss: 0.11467\n",
      "Epoch: 21, series: 48, nllk loss: -1.73442, kernel loss: 0.15100\n",
      "Epoch: 21, series: 49, nllk loss: -1.30205, kernel loss: 0.08051\n",
      "Epoch: 21, series: 50, nllk loss: -0.17047, kernel loss: 0.08321\n",
      "Epoch: 21, series: 51, nllk loss: -1.40292, kernel loss: 0.14879\n",
      "Epoch: 21, series: 52, nllk loss: -0.42256, kernel loss: 0.07667\n",
      "Epoch: 21, series: 53, nllk loss: -1.73143, kernel loss: 0.12324\n",
      "Epoch: 21, series: 54, nllk loss: -1.43492, kernel loss: 0.17949\n",
      "Epoch: 21, series: 55, nllk loss: -0.84468, kernel loss: 0.06800\n",
      "Epoch: 21, series: 56, nllk loss: -1.53983, kernel loss: 0.07145\n",
      "Epoch: 21, series: 57, nllk loss: -1.43251, kernel loss: 0.03426\n",
      "Epoch: 21, series: 58, nllk loss: -1.56447, kernel loss: 0.18294\n",
      "Epoch: 21, series: 59, nllk loss: -1.26383, kernel loss: 0.19530\n",
      "Epoch: 21, series: 60, nllk loss: -1.12315, kernel loss: 0.10285\n",
      "Epoch: 21, series: 61, nllk loss: -1.74740, kernel loss: 0.08593\n",
      "Epoch: 21, series: 62, nllk loss: -1.85567, kernel loss: 0.03614\n",
      "Epoch: 21, series: 63, nllk loss: -1.70845, kernel loss: 0.07465\n",
      "Epoch: 21, series: 64, nllk loss: -1.20193, kernel loss: 0.03429\n",
      "Epoch: 21, series: 65, nllk loss: -1.73316, kernel loss: 0.03412\n",
      "Epoch: 21, series: 66, nllk loss: -1.70142, kernel loss: 0.13145\n",
      "Epoch: 21, series: 67, nllk loss: -1.47570, kernel loss: 0.02772\n",
      "Epoch: 21, series: 68, nllk loss: -0.86015, kernel loss: 0.10309\n",
      "Epoch: 21, series: 69, nllk loss: -1.60221, kernel loss: 0.04416\n",
      "Epoch: 21, series: 70, nllk loss: -1.45474, kernel loss: 0.10490\n",
      "Epoch: 21, series: 71, nllk loss: -1.54270, kernel loss: 0.09610\n",
      "Epoch: 21, series: 72, nllk loss: -1.83956, kernel loss: 0.01968\n",
      "Epoch: 21, series: 73, nllk loss: -1.38216, kernel loss: 0.08205\n",
      "Epoch: 21, series: 74, nllk loss: -2.06362, kernel loss: 0.12871\n",
      "Epoch: 21, series: 75, nllk loss: -1.63034, kernel loss: 0.05876\n",
      "Epoch: 21, series: 76, nllk loss: -1.46859, kernel loss: 0.14997\n",
      "Epoch: 21, series: 77, nllk loss: -1.39711, kernel loss: 0.04016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, series: 78, nllk loss: -1.48550, kernel loss: 0.14212\n",
      "Epoch: 21, series: 79, nllk loss: -0.49083, kernel loss: 0.02249\n",
      "Epoch: 21, series: 80, nllk loss: -1.81421, kernel loss: 0.19902\n",
      "Epoch: 21, series: 81, nllk loss: -1.44654, kernel loss: 0.08721\n",
      "Epoch: 21, series: 82, nllk loss: -0.37444, kernel loss: 0.08966\n",
      "Epoch: 21, series: 83, nllk loss: -1.16072, kernel loss: 0.08090\n",
      "Epoch: 21, series: 84, nllk loss: -1.28724, kernel loss: 0.16143\n",
      "Epoch: 21, series: 85, nllk loss: -1.57404, kernel loss: 0.11265\n",
      "Epoch: 21, series: 86, nllk loss: -0.84934, kernel loss: 0.14714\n",
      "Epoch: 21, series: 87, nllk loss: -1.82516, kernel loss: 0.03884\n",
      "Epoch: 21, series: 88, nllk loss: -2.09680, kernel loss: 0.05986\n",
      "Epoch: 21, series: 89, nllk loss: -1.97067, kernel loss: 0.04403\n",
      "Epoch: 21, series: 90, nllk loss: -2.21602, kernel loss: 0.12532\n",
      "Epoch: 21, series: 91, nllk loss: -2.22042, kernel loss: 0.04430\n",
      "Epoch: 21, series: 92, nllk loss: -0.17873, kernel loss: 0.07610\n",
      "Epoch: 21, series: 93, nllk loss: -2.55704, kernel loss: 0.08621\n",
      "Epoch: 21, series: 94, nllk loss: -2.50825, kernel loss: 0.14456\n",
      "Epoch: 21, series: 95, nllk loss: -2.41307, kernel loss: 0.29623\n",
      "Epoch: 21, series: 96, nllk loss: -1.73947, kernel loss: 0.05172\n",
      "Epoch: 21, series: 97, nllk loss: -0.61883, kernel loss: 0.26020\n",
      "Epoch: 21, series: 98, nllk loss: -0.67347, kernel loss: 0.14418\n",
      "Epoch: 21, series: 99, nllk loss: -1.47787, kernel loss: 0.08036\n",
      "Epoch: 21, series: 100, nllk loss: -0.76832, kernel loss: 0.10130\n",
      "Epoch: 21, series: 101, nllk loss: -1.21753, kernel loss: 0.25250\n",
      "Epoch: 21, series: 102, nllk loss: -0.33866, kernel loss: 0.15066\n",
      "Epoch: 21, series: 103, nllk loss: -1.10834, kernel loss: 0.06021\n",
      "Epoch: 21, series: 104, nllk loss: -0.04270, kernel loss: 0.07057\n",
      "Epoch: 21, series: 105, nllk loss: -0.42952, kernel loss: 0.04895\n",
      "Epoch: 21, series: 106, nllk loss: -1.27825, kernel loss: 0.18811\n",
      "Epoch: 21, series: 107, nllk loss: -0.95513, kernel loss: 0.02798\n",
      "Epoch: 21, series: 108, nllk loss: -1.29818, kernel loss: 0.19840\n",
      "Epoch: 21, series: 109, nllk loss: -1.08403, kernel loss: 0.13123\n",
      "Epoch: 21, series: 110, nllk loss: -1.57040, kernel loss: 0.11202\n",
      "Epoch: 21, series: 111, nllk loss: -1.44506, kernel loss: 0.08462\n",
      "Epoch: 21, series: 112, nllk loss: -0.90324, kernel loss: 0.07474\n",
      "Epoch: 21, series: 113, nllk loss: -1.19065, kernel loss: 0.04627\n",
      "Epoch: 21, series: 114, nllk loss: -1.20514, kernel loss: 0.21437\n",
      "Epoch: 21, series: 115, nllk loss: -1.05921, kernel loss: 0.19304\n",
      "Epoch: 21, series: 116, nllk loss: -1.61606, kernel loss: 0.12253\n",
      "Epoch: 21, series: 117, nllk loss: -0.65892, kernel loss: 0.15908\n",
      "Epoch: 21, series: 118, nllk loss: -1.80633, kernel loss: 0.19176\n",
      "Epoch: 21, series: 119, nllk loss: -0.86444, kernel loss: 0.19451\n",
      "Epoch: 21, series: 120, nllk loss: -1.59871, kernel loss: 0.01660\n",
      "Epoch: 21, series: 121, nllk loss: -0.06817, kernel loss: 0.09144\n",
      "Epoch: 21, series: 122, nllk loss: -0.65219, kernel loss: 0.14594\n",
      "Epoch: 21, series: 123, nllk loss: -1.75813, kernel loss: 0.00589\n",
      "Epoch: 21, series: 124, nllk loss: -1.87268, kernel loss: 0.11913\n",
      "Epoch: 21, series: 125, nllk loss: -1.33037, kernel loss: 0.25726\n",
      "Epoch: 21, series: 126, nllk loss: -1.84670, kernel loss: 0.04315\n",
      "Epoch: 21, series: 127, nllk loss: -1.34083, kernel loss: 0.03895\n",
      "Epoch: 21, series: 128, nllk loss: -1.00235, kernel loss: 0.23762\n",
      "Epoch: 21, series: 129, nllk loss: -0.63344, kernel loss: 0.01513\n",
      "Epoch: 21, series: 130, nllk loss: -1.48273, kernel loss: 0.08926\n",
      "Epoch: 21, series: 131, nllk loss: 0.36401, kernel loss: 0.10442\n",
      "Epoch: 21, series: 132, nllk loss: 0.09910, kernel loss: 0.14950\n",
      "Epoch: 21, series: 133, nllk loss: -1.00943, kernel loss: 0.15998\n",
      "Epoch: 21, series: 134, nllk loss: -0.77147, kernel loss: 0.10501\n",
      "Epoch: 21, series: 135, nllk loss: -1.60766, kernel loss: 0.03863\n",
      "Epoch: 21, series: 136, nllk loss: -1.67004, kernel loss: 0.01624\n",
      "Epoch: 21, series: 137, nllk loss: -1.76595, kernel loss: 0.10940\n",
      "Epoch: 21, series: 138, nllk loss: -1.82620, kernel loss: 0.20189\n",
      "Epoch: 21, series: 139, nllk loss: -1.72400, kernel loss: 0.10965\n",
      "Epoch: 21, series: 140, nllk loss: -1.53157, kernel loss: 0.06655\n",
      "Epoch: 21, series: 141, nllk loss: -1.75936, kernel loss: 0.21115\n",
      "Epoch: 21, series: 142, nllk loss: -1.87786, kernel loss: 0.07322\n",
      "Epoch: 21, series: 143, nllk loss: -1.81964, kernel loss: 0.03118\n",
      "Epoch: 21, series: 144, nllk loss: -2.16160, kernel loss: 0.05250\n",
      "Epoch: 21, series: 145, nllk loss: -1.90631, kernel loss: 0.10299\n",
      "Epoch: 21, series: 146, nllk loss: 1.78537, kernel loss: 0.07740\n",
      "Epoch: 21, series: 147, nllk loss: -1.60665, kernel loss: 0.11329\n",
      "Epoch: 21, series: 148, nllk loss: -1.48364, kernel loss: 0.10572\n",
      "Epoch: 21, series: 149, nllk loss: -1.88807, kernel loss: 0.03275\n",
      "Epoch: 21, series: 150, nllk loss: -1.94282, kernel loss: 0.11882\n",
      "Epoch: 21, series: 151, nllk loss: -2.07727, kernel loss: 0.14330\n",
      "Epoch: 21, series: 152, nllk loss: -2.07038, kernel loss: 0.11034\n",
      "Epoch: 21, series: 153, nllk loss: -1.73554, kernel loss: 0.08661\n",
      "Epoch: 21, series: 154, nllk loss: -1.84604, kernel loss: 0.11264\n",
      "Epoch: 21, series: 155, nllk loss: -1.92062, kernel loss: 0.08444\n",
      "Epoch: 21, series: 156, nllk loss: -2.06274, kernel loss: 0.04193\n",
      "Epoch: 21, series: 157, nllk loss: -1.59688, kernel loss: 0.11490\n",
      "Epoch: 21, series: 158, nllk loss: -2.05305, kernel loss: 0.04638\n",
      "Epoch: 21, series: 159, nllk loss: -2.07096, kernel loss: 0.09924\n",
      "Epoch: 21, series: 160, nllk loss: -1.92318, kernel loss: 0.08282\n",
      "Epoch: 21, series: 161, nllk loss: -1.83154, kernel loss: 0.06433\n",
      "Epoch: 21, series: 162, nllk loss: -2.15722, kernel loss: 0.03769\n",
      "Epoch: 21, series: 163, nllk loss: -2.42598, kernel loss: 0.05839\n",
      "Epoch: 21, series: 164, nllk loss: -1.86228, kernel loss: 0.05669\n",
      "Epoch: 21, series: 165, nllk loss: -1.95130, kernel loss: 0.23306\n",
      "Epoch: 21, series: 166, nllk loss: -1.34044, kernel loss: 0.06612\n",
      "Epoch: 21, series: 167, nllk loss: -2.62567, kernel loss: 0.09461\n",
      "Epoch: 21, series: 168, nllk loss: -2.13515, kernel loss: 0.18715\n",
      "Epoch: 21, series: 169, nllk loss: -2.34374, kernel loss: 0.18764\n",
      "Epoch: 21, series: 170, nllk loss: -1.99605, kernel loss: 0.10423\n",
      "Epoch: 21, series: 171, nllk loss: -2.51883, kernel loss: 0.07788\n",
      "Epoch: 21, series: 172, nllk loss: -2.10342, kernel loss: 0.10626\n",
      "Epoch: 21, series: 173, nllk loss: -2.61451, kernel loss: 0.14789\n",
      "Epoch: 21, series: 174, nllk loss: -2.24906, kernel loss: 0.04102\n",
      "Epoch: 21, series: 175, nllk loss: -2.57982, kernel loss: 0.00836\n",
      "Epoch: 21, series: 176, nllk loss: -2.06772, kernel loss: 0.07507\n",
      "Epoch: 21, series: 177, nllk loss: -2.02116, kernel loss: 0.11643\n",
      "Epoch: 21, series: 178, nllk loss: -1.70275, kernel loss: 0.14343\n",
      "Epoch: 21, series: 179, nllk loss: -2.23992, kernel loss: 0.08807\n",
      "Epoch: 21, series: 180, nllk loss: -2.39234, kernel loss: 0.08121\n",
      "Epoch: 21, series: 181, nllk loss: -2.55626, kernel loss: 0.09375\n",
      "Epoch: 21, series: 182, nllk loss: -2.24830, kernel loss: 0.08816\n",
      "Epoch: 21, series: 183, nllk loss: -1.98446, kernel loss: 0.06268\n",
      "Epoch: 21, series: 184, nllk loss: -2.00407, kernel loss: 0.23802\n",
      "Epoch: 21, series: 185, nllk loss: -1.62996, kernel loss: 0.09714\n",
      "Epoch: 21, series: 186, nllk loss: -2.61885, kernel loss: 0.06487\n",
      "Epoch: 21, series: 187, nllk loss: -2.75240, kernel loss: 0.22035\n",
      "Epoch: 21, series: 188, nllk loss: -1.64591, kernel loss: 0.15144\n",
      "Epoch: 21, series: 189, nllk loss: -1.40430, kernel loss: 0.13326\n",
      "Epoch: 21, series: 190, nllk loss: -2.01060, kernel loss: 0.02454\n",
      "Epoch: 21, series: 191, nllk loss: -1.94263, kernel loss: 0.14327\n",
      "Epoch: 21, series: 192, nllk loss: -2.20105, kernel loss: 0.20280\n",
      "Epoch: 21, series: 193, nllk loss: -1.53689, kernel loss: 0.04038\n",
      "Epoch: 21, series: 194, nllk loss: -1.51756, kernel loss: 0.20578\n",
      "Epoch: 21, series: 195, nllk loss: -2.24445, kernel loss: 0.06780\n",
      "Epoch: 21, series: 196, nllk loss: -1.93428, kernel loss: 0.27041\n",
      "Epoch: 21, series: 197, nllk loss: -2.18060, kernel loss: 0.03036\n",
      "Epoch: 21, series: 198, nllk loss: -2.28673, kernel loss: 0.05050\n",
      "Epoch: 21, series: 199, nllk loss: -1.96551, kernel loss: 0.15226\n",
      "Epoch: 21, series: 200, nllk loss: -2.22660, kernel loss: 0.10464\n",
      "Epoch: 21, series: 201, nllk loss: -2.32870, kernel loss: 0.01672\n",
      "Epoch: 21, series: 202, nllk loss: -2.12383, kernel loss: 0.06943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21, series: 203, nllk loss: -1.96829, kernel loss: 0.09953\n",
      "Epoch: 21, series: 204, nllk loss: -1.04818, kernel loss: 0.11331\n",
      "Epoch: 21, series: 205, nllk loss: -2.18252, kernel loss: 0.11149\n",
      "Epoch: 21, series: 206, nllk loss: -2.30869, kernel loss: 0.07271\n",
      "Epoch: 21, series: 207, nllk loss: -0.91054, kernel loss: 0.09395\n",
      "Epoch: 21, series: 208, nllk loss: -2.43792, kernel loss: 0.16964\n",
      "Epoch: 21, series: 209, nllk loss: -1.76592, kernel loss: 0.07960\n",
      "Epoch: 21, series: 210, nllk loss: -2.63789, kernel loss: 0.07375\n",
      "Epoch: 21, series: 211, nllk loss: -2.18138, kernel loss: 0.09556\n",
      "Epoch: 21, series: 212, nllk loss: -1.47379, kernel loss: 0.10504\n",
      "Epoch: 21, series: 213, nllk loss: -2.18433, kernel loss: 0.03470\n",
      "Epoch: 21, series: 214, nllk loss: -2.09865, kernel loss: 0.03645\n",
      "Epoch: 21, series: 215, nllk loss: -2.48467, kernel loss: 0.06664\n",
      "Epoch: 21, series: 216, nllk loss: -1.37255, kernel loss: 0.02352\n",
      "Epoch: 21, series: 217, nllk loss: -2.11370, kernel loss: 0.12022\n",
      "Epoch: 21, series: 218, nllk loss: -1.51158, kernel loss: 0.11559\n",
      "Epoch: 21, series: 219, nllk loss: -2.14236, kernel loss: 0.03186\n",
      "Epoch: 21, series: 220, nllk loss: -2.18434, kernel loss: 0.09320\n",
      "Epoch: 21, series: 221, nllk loss: -2.53711, kernel loss: 0.12999\n",
      "Epoch: 21, series: 222, nllk loss: -2.26964, kernel loss: 0.12390\n",
      "Epoch: 21, series: 223, nllk loss: -1.67366, kernel loss: 0.04896\n",
      "Epoch: 21, series: 224, nllk loss: -2.59864, kernel loss: 0.00809\n",
      "Epoch: 21, series: 225, nllk loss: -2.37434, kernel loss: 0.07883\n",
      "Epoch: 21, series: 226, nllk loss: -1.90124, kernel loss: 0.21890\n",
      "Epoch: 21, series: 227, nllk loss: -2.10962, kernel loss: 0.09020\n",
      "Epoch: 21, series: 228, nllk loss: -2.30637, kernel loss: 0.12412\n",
      "Epoch: 21, series: 229, nllk loss: -2.09279, kernel loss: 0.14176\n",
      "Epoch: 21, series: 230, nllk loss: -2.47684, kernel loss: 0.08739\n",
      "Epoch: 21, series: 231, nllk loss: -1.94553, kernel loss: 0.18173\n",
      "Epoch: 21, series: 232, nllk loss: -2.60801, kernel loss: 0.11464\n",
      "Epoch: 21, series: 233, nllk loss: -2.50066, kernel loss: 0.09244\n",
      "Epoch: 21, series: 234, nllk loss: -2.01980, kernel loss: 0.04401\n",
      "Epoch: 21, series: 235, nllk loss: -2.70421, kernel loss: 0.00336\n",
      "Epoch: 21, series: 236, nllk loss: -1.57715, kernel loss: 0.01032\n",
      "Epoch: 21, series: 237, nllk loss: -2.23732, kernel loss: 0.29847\n",
      "Epoch: 21, series: 238, nllk loss: -2.07193, kernel loss: 0.04745\n",
      "Epoch: 21, series: 239, nllk loss: -2.40063, kernel loss: 0.22418\n",
      "Epoch: 21, series: 240, nllk loss: -0.68557, kernel loss: 0.11428\n",
      "Epoch: 21, series: 241, nllk loss: -2.00902, kernel loss: 0.11036\n",
      "Epoch: 21, series: 242, nllk loss: -2.16276, kernel loss: 0.01412\n",
      "Epoch: 21, series: 243, nllk loss: -2.48632, kernel loss: 0.08953\n",
      "Epoch: 21, series: 244, nllk loss: -2.05725, kernel loss: 0.14161\n",
      "Epoch: 21, series: 245, nllk loss: -2.23186, kernel loss: 0.18762\n",
      "Epoch: 21, series: 246, nllk loss: -0.21653, kernel loss: 0.12611\n",
      "Epoch: 21, series: 247, nllk loss: -1.78193, kernel loss: 0.14570\n",
      "Epoch: 21, series: 248, nllk loss: -2.15790, kernel loss: 0.09047\n",
      "Epoch: 21, series: 249, nllk loss: -2.00506, kernel loss: 0.04326\n",
      "Epoch: 21, series: 250, nllk loss: -1.69103, kernel loss: 0.01928\n",
      "Epoch: 21, series: 251, nllk loss: -1.15340, kernel loss: 0.11563\n",
      "Epoch: 21, series: 252, nllk loss: -1.43602, kernel loss: 0.20934\n",
      "Epoch: 21, series: 253, nllk loss: -1.83711, kernel loss: 0.06139\n",
      "Epoch: 21, series: 254, nllk loss: -2.36380, kernel loss: 0.12104\n",
      "Epoch: 21, series: 255, nllk loss: -2.13681, kernel loss: 0.06321\n",
      "Epoch: 21, series: 256, nllk loss: -1.89928, kernel loss: 0.13369\n",
      "Epoch: 21, series: 257, nllk loss: -2.10051, kernel loss: 0.01193\n",
      "Epoch: 21, series: 258, nllk loss: -2.14944, kernel loss: 0.18866\n",
      "Epoch: 21, series: 259, nllk loss: -1.87923, kernel loss: 0.12702\n",
      "Epoch: 21, series: 260, nllk loss: -2.05896, kernel loss: 0.18398\n",
      "Epoch: 21, series: 261, nllk loss: -2.06021, kernel loss: 0.08031\n",
      "Epoch: 21, series: 262, nllk loss: -2.57916, kernel loss: 0.14861\n",
      "Epoch: 21, series: 263, nllk loss: -0.59394, kernel loss: 0.18102\n",
      "Epoch: 21, series: 264, nllk loss: -2.03353, kernel loss: 0.00000\n",
      "Epoch: 21, series: 265, nllk loss: -1.89081, kernel loss: 0.08392\n",
      "Epoch: 21, series: 266, nllk loss: -2.31923, kernel loss: 0.14397\n",
      "Epoch: 21, series: 267, nllk loss: -2.13940, kernel loss: 0.09380\n",
      "Epoch: 21, series: 268, nllk loss: -2.16475, kernel loss: 0.02936\n",
      "Epoch: 21, series: 269, nllk loss: -1.84917, kernel loss: 0.15512\n",
      "Epoch: 21, series: 270, nllk loss: -1.91489, kernel loss: 0.13634\n",
      "Epoch: 21, series: 271, nllk loss: -2.09954, kernel loss: 0.13353\n",
      "Epoch: 21, series: 272, nllk loss: -2.01115, kernel loss: 0.00871\n",
      "Epoch: 21, series: 273, nllk loss: -2.07108, kernel loss: 0.08965\n",
      "Epoch: 21, series: 274, nllk loss: -1.37504, kernel loss: 0.02388\n",
      "Epoch: 21, series: 275, nllk loss: -2.01118, kernel loss: 0.04537\n",
      "Epoch: 21, series: 276, nllk loss: -1.39389, kernel loss: 0.00460\n",
      "Epoch: 21, series: 277, nllk loss: -2.20622, kernel loss: 0.03345\n",
      "Epoch: 21, series: 278, nllk loss: -1.90330, kernel loss: 0.11753\n",
      "Epoch: 21, series: 279, nllk loss: -2.41236, kernel loss: 0.02825\n",
      "Epoch: 21, series: 280, nllk loss: -2.15168, kernel loss: 0.10087\n",
      "Epoch: 21, series: 281, nllk loss: -2.36534, kernel loss: 0.02098\n",
      "Epoch: 21, series: 282, nllk loss: -2.26619, kernel loss: 0.07662\n",
      "Epoch: 21, series: 283, nllk loss: -2.19188, kernel loss: 0.13279\n",
      "Epoch: 21, series: 284, nllk loss: -1.69820, kernel loss: 0.02856\n",
      "Epoch: 21, series: 285, nllk loss: -1.97708, kernel loss: 0.04282\n",
      "Epoch: 21, series: 286, nllk loss: -2.16828, kernel loss: 0.07492\n",
      "Epoch: 21, series: 287, nllk loss: -2.48789, kernel loss: 0.09302\n",
      "Epoch: 21, series: 288, nllk loss: -1.25976, kernel loss: 0.04821\n",
      "Epoch: 21, series: 289, nllk loss: -1.20059, kernel loss: 0.05725\n",
      "Epoch: 21, series: 290, nllk loss: -2.27428, kernel loss: 0.10027\n",
      "Epoch: 21, series: 291, nllk loss: -2.31918, kernel loss: 0.27279\n",
      "Epoch: 21, series: 292, nllk loss: -2.23348, kernel loss: 0.16060\n",
      "Epoch: 21, series: 293, nllk loss: -2.43402, kernel loss: 0.16852\n",
      "Epoch: 21, series: 294, nllk loss: -1.36651, kernel loss: 0.12870\n",
      "Epoch: 21, series: 295, nllk loss: -1.35648, kernel loss: 0.09622\n",
      "Epoch: 21, series: 296, nllk loss: -2.56452, kernel loss: 0.07252\n",
      "Epoch: 21, series: 297, nllk loss: -2.55627, kernel loss: 0.15607\n",
      "Epoch: 21, series: 298, nllk loss: 0.03414, kernel loss: 0.10540\n",
      "Epoch: 21, series: 299, nllk loss: -0.69235, kernel loss: 0.11431\n",
      "Epoch: 21, series: 300, nllk loss: -2.11653, kernel loss: 0.07159\n",
      "Epoch: 21, series: 301, nllk loss: -2.44930, kernel loss: 0.10515\n",
      "Epoch: 21, series: 302, nllk loss: -2.30468, kernel loss: 0.04834\n",
      "Epoch: 21, series: 303, nllk loss: -1.92097, kernel loss: 0.13142\n",
      "Epoch: 21, series: 304, nllk loss: 0.12345, kernel loss: 0.22233\n",
      "Epoch: 21, series: 305, nllk loss: -1.95770, kernel loss: 0.28701\n",
      "Epoch: 21, series: 306, nllk loss: -2.49320, kernel loss: 0.17114\n",
      "Epoch: 21, series: 307, nllk loss: -1.73309, kernel loss: 0.10175\n",
      "Epoch: 21, series: 308, nllk loss: -2.40346, kernel loss: 0.07837\n",
      "Epoch: 21, series: 309, nllk loss: -2.03056, kernel loss: 0.09314\n",
      "Epoch: 21, series: 310, nllk loss: -2.39897, kernel loss: 0.15222\n",
      "Epoch: 21, series: 311, nllk loss: -1.96877, kernel loss: 0.06139\n",
      "Epoch: 21, series: 312, nllk loss: -2.08793, kernel loss: 0.15234\n",
      "Epoch: 21, series: 313, nllk loss: -2.31008, kernel loss: 0.07190\n",
      "Epoch: 21, series: 314, nllk loss: -2.82694, kernel loss: 0.05147\n",
      "Epoch: 21, series: 315, nllk loss: -0.88658, kernel loss: 0.12719\n",
      "Epoch: 21, series: 316, nllk loss: -2.17978, kernel loss: 0.08566\n",
      "Epoch: 21, series: 317, nllk loss: 0.42071, kernel loss: 0.11757\n",
      "Epoch: 21, series: 318, nllk loss: 0.99761, kernel loss: 0.14805\n",
      "Epoch: 21, series: 319, nllk loss: -1.06065, kernel loss: 0.12190\n",
      "Epoch: 21, series: 320, nllk loss: -0.89702, kernel loss: 0.13518\n",
      "Epoch: 21, total loss: -492.33496\n",
      "Epoch: 22, series: 0, nllk loss: 1.05012, kernel loss: 0.13856\n",
      "Epoch: 22, series: 1, nllk loss: -1.12158, kernel loss: 0.00968\n",
      "Epoch: 22, series: 2, nllk loss: -0.06162, kernel loss: 0.12581\n",
      "Epoch: 22, series: 3, nllk loss: -1.36084, kernel loss: 0.10714\n",
      "Epoch: 22, series: 4, nllk loss: -0.98953, kernel loss: 0.27205\n",
      "Epoch: 22, series: 5, nllk loss: -1.24120, kernel loss: 0.28078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, series: 6, nllk loss: -0.58858, kernel loss: 0.02904\n",
      "Epoch: 22, series: 7, nllk loss: -1.13441, kernel loss: 0.18443\n",
      "Epoch: 22, series: 8, nllk loss: -0.56150, kernel loss: 0.01993\n",
      "Epoch: 22, series: 9, nllk loss: -0.63220, kernel loss: 0.10619\n",
      "Epoch: 22, series: 10, nllk loss: -1.32168, kernel loss: 0.22817\n",
      "Epoch: 22, series: 11, nllk loss: -1.25122, kernel loss: 0.14589\n",
      "Epoch: 22, series: 12, nllk loss: -1.60084, kernel loss: 0.15180\n",
      "Epoch: 22, series: 13, nllk loss: -1.46109, kernel loss: 0.11421\n",
      "Epoch: 22, series: 14, nllk loss: -1.70914, kernel loss: 0.22412\n",
      "Epoch: 22, series: 15, nllk loss: -1.64120, kernel loss: 0.31162\n",
      "Epoch: 22, series: 16, nllk loss: -1.13006, kernel loss: 0.13138\n",
      "Epoch: 22, series: 17, nllk loss: -1.20997, kernel loss: 0.11364\n",
      "Epoch: 22, series: 18, nllk loss: -1.48603, kernel loss: 0.15460\n",
      "Epoch: 22, series: 19, nllk loss: -0.32380, kernel loss: 0.07607\n",
      "Epoch: 22, series: 20, nllk loss: -0.80262, kernel loss: 0.00529\n",
      "Epoch: 22, series: 21, nllk loss: -1.19115, kernel loss: 0.16723\n",
      "Epoch: 22, series: 22, nllk loss: -1.59598, kernel loss: 0.19217\n",
      "Epoch: 22, series: 23, nllk loss: -1.56548, kernel loss: 0.15577\n",
      "Epoch: 22, series: 24, nllk loss: -1.81699, kernel loss: 0.15413\n",
      "Epoch: 22, series: 25, nllk loss: -1.74901, kernel loss: 0.01182\n",
      "Epoch: 22, series: 26, nllk loss: -1.45338, kernel loss: 0.06701\n",
      "Epoch: 22, series: 27, nllk loss: -1.30172, kernel loss: 0.09310\n",
      "Epoch: 22, series: 28, nllk loss: -1.41396, kernel loss: 0.15479\n",
      "Epoch: 22, series: 29, nllk loss: -0.98132, kernel loss: 0.18644\n",
      "Epoch: 22, series: 30, nllk loss: -1.48515, kernel loss: 0.11671\n",
      "Epoch: 22, series: 31, nllk loss: -1.12451, kernel loss: 0.10940\n",
      "Epoch: 22, series: 32, nllk loss: -1.20107, kernel loss: 0.19907\n",
      "Epoch: 22, series: 33, nllk loss: -1.02118, kernel loss: 0.11966\n",
      "Epoch: 22, series: 34, nllk loss: -1.44957, kernel loss: 0.06941\n",
      "Epoch: 22, series: 35, nllk loss: -1.71264, kernel loss: 0.17914\n",
      "Epoch: 22, series: 36, nllk loss: -1.69700, kernel loss: 0.15056\n",
      "Epoch: 22, series: 37, nllk loss: -0.61418, kernel loss: 0.10578\n",
      "Epoch: 22, series: 38, nllk loss: -1.00745, kernel loss: 0.12497\n",
      "Epoch: 22, series: 39, nllk loss: -0.80743, kernel loss: 0.23362\n",
      "Epoch: 22, series: 40, nllk loss: -1.99442, kernel loss: 0.19520\n",
      "Epoch: 22, series: 41, nllk loss: -1.40793, kernel loss: 0.05591\n",
      "Epoch: 22, series: 42, nllk loss: -1.08227, kernel loss: 0.16335\n",
      "Epoch: 22, series: 43, nllk loss: -1.11609, kernel loss: 0.09991\n",
      "Epoch: 22, series: 44, nllk loss: -1.61237, kernel loss: 0.03706\n",
      "Epoch: 22, series: 45, nllk loss: -1.73202, kernel loss: 0.06387\n",
      "Epoch: 22, series: 46, nllk loss: -1.79070, kernel loss: 0.07783\n",
      "Epoch: 22, series: 47, nllk loss: -1.64989, kernel loss: 0.02562\n",
      "Epoch: 22, series: 48, nllk loss: -1.69652, kernel loss: 0.08812\n",
      "Epoch: 22, series: 49, nllk loss: -1.19009, kernel loss: 0.12219\n",
      "Epoch: 22, series: 50, nllk loss: -0.15468, kernel loss: 0.04237\n",
      "Epoch: 22, series: 51, nllk loss: -1.27218, kernel loss: 0.16053\n",
      "Epoch: 22, series: 52, nllk loss: -0.36971, kernel loss: 0.16196\n",
      "Epoch: 22, series: 53, nllk loss: -1.70972, kernel loss: 0.12716\n",
      "Epoch: 22, series: 54, nllk loss: -1.43418, kernel loss: 0.13399\n",
      "Epoch: 22, series: 55, nllk loss: -0.88324, kernel loss: 0.03070\n",
      "Epoch: 22, series: 56, nllk loss: -1.51016, kernel loss: 0.03743\n",
      "Epoch: 22, series: 57, nllk loss: -1.42000, kernel loss: 0.17967\n",
      "Epoch: 22, series: 58, nllk loss: -1.60579, kernel loss: 0.11015\n",
      "Epoch: 22, series: 59, nllk loss: -1.27476, kernel loss: 0.14578\n",
      "Epoch: 22, series: 60, nllk loss: -1.10113, kernel loss: 0.22995\n",
      "Epoch: 22, series: 61, nllk loss: -1.74374, kernel loss: 0.20535\n",
      "Epoch: 22, series: 62, nllk loss: -1.85276, kernel loss: 0.02741\n",
      "Epoch: 22, series: 63, nllk loss: -1.73655, kernel loss: 0.09956\n",
      "Epoch: 22, series: 64, nllk loss: -1.10484, kernel loss: 0.06758\n",
      "Epoch: 22, series: 65, nllk loss: -1.72978, kernel loss: 0.03601\n",
      "Epoch: 22, series: 66, nllk loss: -1.74668, kernel loss: 0.12142\n",
      "Epoch: 22, series: 67, nllk loss: -1.50296, kernel loss: 0.27852\n",
      "Epoch: 22, series: 68, nllk loss: -0.87314, kernel loss: 0.10642\n",
      "Epoch: 22, series: 69, nllk loss: -1.63220, kernel loss: 0.11638\n",
      "Epoch: 22, series: 70, nllk loss: -1.43726, kernel loss: 0.16271\n",
      "Epoch: 22, series: 71, nllk loss: -1.53889, kernel loss: 0.16355\n",
      "Epoch: 22, series: 72, nllk loss: -1.90621, kernel loss: 0.07609\n",
      "Epoch: 22, series: 73, nllk loss: -1.38819, kernel loss: 0.15699\n",
      "Epoch: 22, series: 74, nllk loss: -2.03918, kernel loss: 0.03739\n",
      "Epoch: 22, series: 75, nllk loss: -1.61163, kernel loss: 0.08813\n",
      "Epoch: 22, series: 76, nllk loss: -1.50916, kernel loss: 0.14355\n",
      "Epoch: 22, series: 77, nllk loss: -1.34107, kernel loss: 0.08933\n",
      "Epoch: 22, series: 78, nllk loss: -1.45531, kernel loss: 0.10609\n",
      "Epoch: 22, series: 79, nllk loss: -0.43540, kernel loss: 0.05787\n",
      "Epoch: 22, series: 80, nllk loss: -1.88238, kernel loss: 0.07919\n",
      "Epoch: 22, series: 81, nllk loss: -1.48603, kernel loss: 0.09080\n",
      "Epoch: 22, series: 82, nllk loss: -0.35901, kernel loss: 0.08376\n",
      "Epoch: 22, series: 83, nllk loss: -1.23197, kernel loss: 0.04044\n",
      "Epoch: 22, series: 84, nllk loss: -1.28804, kernel loss: 0.09676\n",
      "Epoch: 22, series: 85, nllk loss: -1.69634, kernel loss: 0.04778\n",
      "Epoch: 22, series: 86, nllk loss: -0.88269, kernel loss: 0.03887\n",
      "Epoch: 22, series: 87, nllk loss: -1.88799, kernel loss: 0.13338\n",
      "Epoch: 22, series: 88, nllk loss: -2.04272, kernel loss: 0.05079\n",
      "Epoch: 22, series: 89, nllk loss: -1.93496, kernel loss: 0.14033\n",
      "Epoch: 22, series: 90, nllk loss: -2.18484, kernel loss: 0.01669\n",
      "Epoch: 22, series: 91, nllk loss: -2.15455, kernel loss: 0.00660\n",
      "Epoch: 22, series: 92, nllk loss: -0.12103, kernel loss: 0.05598\n",
      "Epoch: 22, series: 93, nllk loss: -2.53886, kernel loss: 0.22060\n",
      "Epoch: 22, series: 94, nllk loss: -2.44685, kernel loss: 0.14849\n",
      "Epoch: 22, series: 95, nllk loss: -2.41786, kernel loss: 0.13272\n",
      "Epoch: 22, series: 96, nllk loss: -1.76253, kernel loss: 0.13141\n",
      "Epoch: 22, series: 97, nllk loss: -0.65431, kernel loss: 0.11974\n",
      "Epoch: 22, series: 98, nllk loss: -0.61992, kernel loss: 0.06367\n",
      "Epoch: 22, series: 99, nllk loss: -1.58417, kernel loss: 0.00499\n",
      "Epoch: 22, series: 100, nllk loss: -0.89914, kernel loss: 0.02281\n",
      "Epoch: 22, series: 101, nllk loss: -1.40560, kernel loss: 0.17368\n",
      "Epoch: 22, series: 102, nllk loss: -0.54992, kernel loss: 0.06374\n",
      "Epoch: 22, series: 103, nllk loss: -1.14127, kernel loss: 0.12417\n",
      "Epoch: 22, series: 104, nllk loss: -0.05080, kernel loss: 0.15269\n",
      "Epoch: 22, series: 105, nllk loss: -0.40947, kernel loss: 0.12479\n",
      "Epoch: 22, series: 106, nllk loss: -1.20130, kernel loss: 0.11835\n",
      "Epoch: 22, series: 107, nllk loss: -1.05629, kernel loss: 0.10508\n",
      "Epoch: 22, series: 108, nllk loss: -1.28658, kernel loss: 0.09802\n",
      "Epoch: 22, series: 109, nllk loss: -1.17998, kernel loss: 0.09715\n",
      "Epoch: 22, series: 110, nllk loss: -1.64409, kernel loss: 0.13074\n",
      "Epoch: 22, series: 111, nllk loss: -1.48647, kernel loss: 0.08404\n",
      "Epoch: 22, series: 112, nllk loss: -0.98137, kernel loss: 0.04248\n",
      "Epoch: 22, series: 113, nllk loss: -1.23102, kernel loss: 0.19767\n",
      "Epoch: 22, series: 114, nllk loss: -1.21781, kernel loss: 0.09718\n",
      "Epoch: 22, series: 115, nllk loss: -1.02767, kernel loss: 0.18300\n",
      "Epoch: 22, series: 116, nllk loss: -1.62378, kernel loss: 0.16181\n",
      "Epoch: 22, series: 117, nllk loss: -0.72065, kernel loss: 0.19878\n",
      "Epoch: 22, series: 118, nllk loss: -1.88804, kernel loss: 0.11932\n",
      "Epoch: 22, series: 119, nllk loss: -0.80631, kernel loss: 0.03188\n",
      "Epoch: 22, series: 120, nllk loss: -1.63154, kernel loss: 0.06528\n",
      "Epoch: 22, series: 121, nllk loss: -0.10857, kernel loss: 0.04999\n",
      "Epoch: 22, series: 122, nllk loss: -0.64652, kernel loss: 0.11199\n",
      "Epoch: 22, series: 123, nllk loss: -1.79536, kernel loss: 0.05782\n",
      "Epoch: 22, series: 124, nllk loss: -2.00697, kernel loss: 0.06699\n",
      "Epoch: 22, series: 125, nllk loss: -1.35345, kernel loss: 0.16124\n",
      "Epoch: 22, series: 126, nllk loss: -1.92685, kernel loss: 0.12560\n",
      "Epoch: 22, series: 127, nllk loss: -1.35237, kernel loss: 0.07899\n",
      "Epoch: 22, series: 128, nllk loss: -1.02457, kernel loss: 0.09622\n",
      "Epoch: 22, series: 129, nllk loss: -0.80567, kernel loss: 0.01936\n",
      "Epoch: 22, series: 130, nllk loss: -1.58448, kernel loss: 0.27806\n",
      "Epoch: 22, series: 131, nllk loss: 0.33901, kernel loss: 0.24582\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, series: 132, nllk loss: -0.11365, kernel loss: 0.06174\n",
      "Epoch: 22, series: 133, nllk loss: -0.98327, kernel loss: 0.10715\n",
      "Epoch: 22, series: 134, nllk loss: -0.70620, kernel loss: 0.09817\n",
      "Epoch: 22, series: 135, nllk loss: -1.60381, kernel loss: 0.06606\n",
      "Epoch: 22, series: 136, nllk loss: -1.73836, kernel loss: 0.06364\n",
      "Epoch: 22, series: 137, nllk loss: -1.91296, kernel loss: 0.12855\n",
      "Epoch: 22, series: 138, nllk loss: -1.86079, kernel loss: 0.13046\n",
      "Epoch: 22, series: 139, nllk loss: -1.82449, kernel loss: 0.06837\n",
      "Epoch: 22, series: 140, nllk loss: -1.52224, kernel loss: 0.03194\n",
      "Epoch: 22, series: 141, nllk loss: -1.82064, kernel loss: 0.06465\n",
      "Epoch: 22, series: 142, nllk loss: -1.89714, kernel loss: 0.06770\n",
      "Epoch: 22, series: 143, nllk loss: -1.82123, kernel loss: 0.10200\n",
      "Epoch: 22, series: 144, nllk loss: -2.15898, kernel loss: 0.08998\n",
      "Epoch: 22, series: 145, nllk loss: -1.93742, kernel loss: 0.11186\n",
      "Epoch: 22, series: 146, nllk loss: 1.47536, kernel loss: 0.05372\n",
      "Epoch: 22, series: 147, nllk loss: -1.76403, kernel loss: 0.07782\n",
      "Epoch: 22, series: 148, nllk loss: -1.54072, kernel loss: 0.03100\n",
      "Epoch: 22, series: 149, nllk loss: -1.93879, kernel loss: 0.17037\n",
      "Epoch: 22, series: 150, nllk loss: -2.04390, kernel loss: 0.09025\n",
      "Epoch: 22, series: 151, nllk loss: -2.08231, kernel loss: 0.00518\n",
      "Epoch: 22, series: 152, nllk loss: -2.07577, kernel loss: 0.15437\n",
      "Epoch: 22, series: 153, nllk loss: -1.76809, kernel loss: 0.13528\n",
      "Epoch: 22, series: 154, nllk loss: -1.90454, kernel loss: 0.09745\n",
      "Epoch: 22, series: 155, nllk loss: -2.00630, kernel loss: 0.08742\n",
      "Epoch: 22, series: 156, nllk loss: -2.15462, kernel loss: 0.15748\n",
      "Epoch: 22, series: 157, nllk loss: -1.63647, kernel loss: 0.14530\n",
      "Epoch: 22, series: 158, nllk loss: -2.10871, kernel loss: 0.04154\n",
      "Epoch: 22, series: 159, nllk loss: -2.13423, kernel loss: 0.00573\n",
      "Epoch: 22, series: 160, nllk loss: -1.94539, kernel loss: 0.17943\n",
      "Epoch: 22, series: 161, nllk loss: -1.85471, kernel loss: 0.17152\n",
      "Epoch: 22, series: 162, nllk loss: -2.35149, kernel loss: 0.08196\n",
      "Epoch: 22, series: 163, nllk loss: -2.46606, kernel loss: 0.12720\n",
      "Epoch: 22, series: 164, nllk loss: -1.84142, kernel loss: 0.08351\n",
      "Epoch: 22, series: 165, nllk loss: -1.98829, kernel loss: 0.26729\n",
      "Epoch: 22, series: 166, nllk loss: -1.38591, kernel loss: 0.09286\n",
      "Epoch: 22, series: 167, nllk loss: -2.58705, kernel loss: 0.00349\n",
      "Epoch: 22, series: 168, nllk loss: -2.11559, kernel loss: 0.10170\n",
      "Epoch: 22, series: 169, nllk loss: -2.36796, kernel loss: 0.15496\n",
      "Epoch: 22, series: 170, nllk loss: -2.00545, kernel loss: 0.01611\n",
      "Epoch: 22, series: 171, nllk loss: -2.56757, kernel loss: 0.03789\n",
      "Epoch: 22, series: 172, nllk loss: -2.13976, kernel loss: 0.30008\n",
      "Epoch: 22, series: 173, nllk loss: -2.58847, kernel loss: 0.14190\n",
      "Epoch: 22, series: 174, nllk loss: -2.25475, kernel loss: 0.11577\n",
      "Epoch: 22, series: 175, nllk loss: -2.58920, kernel loss: 0.05475\n",
      "Epoch: 22, series: 176, nllk loss: -1.99262, kernel loss: 0.12820\n",
      "Epoch: 22, series: 177, nllk loss: -2.05029, kernel loss: 0.11778\n",
      "Epoch: 22, series: 178, nllk loss: -1.78975, kernel loss: 0.04779\n",
      "Epoch: 22, series: 179, nllk loss: -2.19908, kernel loss: 0.11131\n",
      "Epoch: 22, series: 180, nllk loss: -2.35301, kernel loss: 0.30834\n",
      "Epoch: 22, series: 181, nllk loss: -2.61185, kernel loss: 0.09385\n",
      "Epoch: 22, series: 182, nllk loss: -2.22293, kernel loss: 0.07247\n",
      "Epoch: 22, series: 183, nllk loss: -2.04190, kernel loss: 0.18695\n",
      "Epoch: 22, series: 184, nllk loss: -2.10002, kernel loss: 0.10582\n",
      "Epoch: 22, series: 185, nllk loss: -1.71752, kernel loss: 0.09858\n",
      "Epoch: 22, series: 186, nllk loss: -2.58473, kernel loss: 0.13631\n",
      "Epoch: 22, series: 187, nllk loss: -2.72172, kernel loss: 0.18548\n",
      "Epoch: 22, series: 188, nllk loss: -1.69405, kernel loss: 0.06598\n",
      "Epoch: 22, series: 189, nllk loss: -1.48701, kernel loss: 0.07333\n",
      "Epoch: 22, series: 190, nllk loss: -2.11740, kernel loss: 0.24444\n",
      "Epoch: 22, series: 191, nllk loss: -1.96496, kernel loss: 0.15619\n",
      "Epoch: 22, series: 192, nllk loss: -2.22422, kernel loss: 0.03825\n",
      "Epoch: 22, series: 193, nllk loss: -1.54938, kernel loss: 0.08083\n",
      "Epoch: 22, series: 194, nllk loss: -1.50386, kernel loss: 0.13279\n",
      "Epoch: 22, series: 195, nllk loss: -2.21265, kernel loss: 0.08609\n",
      "Epoch: 22, series: 196, nllk loss: -1.95769, kernel loss: 0.04075\n",
      "Epoch: 22, series: 197, nllk loss: -2.21100, kernel loss: 0.25931\n",
      "Epoch: 22, series: 198, nllk loss: -2.28990, kernel loss: 0.06308\n",
      "Epoch: 22, series: 199, nllk loss: -1.94365, kernel loss: 0.03978\n",
      "Epoch: 22, series: 200, nllk loss: -2.15828, kernel loss: 0.08749\n",
      "Epoch: 22, series: 201, nllk loss: -2.38961, kernel loss: 0.17732\n",
      "Epoch: 22, series: 202, nllk loss: -2.10550, kernel loss: 0.19332\n",
      "Epoch: 22, series: 203, nllk loss: -1.82032, kernel loss: 0.17764\n",
      "Epoch: 22, series: 204, nllk loss: -0.82216, kernel loss: 0.04380\n",
      "Epoch: 22, series: 205, nllk loss: -2.08560, kernel loss: 0.06457\n",
      "Epoch: 22, series: 206, nllk loss: -2.14449, kernel loss: 0.16761\n",
      "Epoch: 22, series: 207, nllk loss: -0.84824, kernel loss: 0.08789\n",
      "Epoch: 22, series: 208, nllk loss: -2.34861, kernel loss: 0.14649\n",
      "Epoch: 22, series: 209, nllk loss: -1.77046, kernel loss: 0.06562\n",
      "Epoch: 22, series: 210, nllk loss: -2.61146, kernel loss: 0.04874\n",
      "Epoch: 22, series: 211, nllk loss: -1.95140, kernel loss: 0.29183\n",
      "Epoch: 22, series: 212, nllk loss: -1.48195, kernel loss: 0.11108\n",
      "Epoch: 22, series: 213, nllk loss: -2.19139, kernel loss: 0.18726\n",
      "Epoch: 22, series: 214, nllk loss: -2.17797, kernel loss: 0.11845\n",
      "Epoch: 22, series: 215, nllk loss: -2.49609, kernel loss: 0.08057\n",
      "Epoch: 22, series: 216, nllk loss: -1.37304, kernel loss: 0.05631\n",
      "Epoch: 22, series: 217, nllk loss: -2.04862, kernel loss: 0.11022\n",
      "Epoch: 22, series: 218, nllk loss: -1.54122, kernel loss: 0.07254\n",
      "Epoch: 22, series: 219, nllk loss: -2.12721, kernel loss: 0.07277\n",
      "Epoch: 22, series: 220, nllk loss: -2.18826, kernel loss: 0.28356\n",
      "Epoch: 22, series: 221, nllk loss: -2.49695, kernel loss: 0.05896\n",
      "Epoch: 22, series: 222, nllk loss: -2.22388, kernel loss: 0.03095\n",
      "Epoch: 22, series: 223, nllk loss: -1.63987, kernel loss: 0.09163\n",
      "Epoch: 22, series: 224, nllk loss: -2.48140, kernel loss: 0.26362\n",
      "Epoch: 22, series: 225, nllk loss: -2.37528, kernel loss: 0.21571\n",
      "Epoch: 22, series: 226, nllk loss: -1.86792, kernel loss: 0.10794\n",
      "Epoch: 22, series: 227, nllk loss: -2.08004, kernel loss: 0.08243\n",
      "Epoch: 22, series: 228, nllk loss: -2.11337, kernel loss: 0.16754\n",
      "Epoch: 22, series: 229, nllk loss: -2.06284, kernel loss: 0.07186\n",
      "Epoch: 22, series: 230, nllk loss: -2.52335, kernel loss: 0.10247\n",
      "Epoch: 22, series: 231, nllk loss: -1.94992, kernel loss: 0.11485\n",
      "Epoch: 22, series: 232, nllk loss: -2.52272, kernel loss: 0.03858\n",
      "Epoch: 22, series: 233, nllk loss: -2.50613, kernel loss: 0.21803\n",
      "Epoch: 22, series: 234, nllk loss: -2.09122, kernel loss: 0.15480\n",
      "Epoch: 22, series: 235, nllk loss: -2.67252, kernel loss: 0.15786\n",
      "Epoch: 22, series: 236, nllk loss: -1.66437, kernel loss: 0.03611\n",
      "Epoch: 22, series: 237, nllk loss: -2.13919, kernel loss: 0.05800\n",
      "Epoch: 22, series: 238, nllk loss: -1.98073, kernel loss: 0.17467\n",
      "Epoch: 22, series: 239, nllk loss: -2.17890, kernel loss: 0.27545\n",
      "Epoch: 22, series: 240, nllk loss: -1.24138, kernel loss: 0.10498\n",
      "Epoch: 22, series: 241, nllk loss: -2.04692, kernel loss: 0.09765\n",
      "Epoch: 22, series: 242, nllk loss: -2.06189, kernel loss: 0.07003\n",
      "Epoch: 22, series: 243, nllk loss: -2.46860, kernel loss: 0.11411\n",
      "Epoch: 22, series: 244, nllk loss: -2.15892, kernel loss: 0.11389\n",
      "Epoch: 22, series: 245, nllk loss: -2.22332, kernel loss: 0.08577\n",
      "Epoch: 22, series: 246, nllk loss: -0.17367, kernel loss: 0.15093\n",
      "Epoch: 22, series: 247, nllk loss: -1.71478, kernel loss: 0.08040\n",
      "Epoch: 22, series: 248, nllk loss: -2.15087, kernel loss: 0.03275\n",
      "Epoch: 22, series: 249, nllk loss: -2.07261, kernel loss: 0.05100\n",
      "Epoch: 22, series: 250, nllk loss: -1.68415, kernel loss: 0.06590\n",
      "Epoch: 22, series: 251, nllk loss: -1.20111, kernel loss: 0.03660\n",
      "Epoch: 22, series: 252, nllk loss: -1.49123, kernel loss: 0.07996\n",
      "Epoch: 22, series: 253, nllk loss: -1.72220, kernel loss: 0.11751\n",
      "Epoch: 22, series: 254, nllk loss: -2.28954, kernel loss: 0.07407\n",
      "Epoch: 22, series: 255, nllk loss: -2.10866, kernel loss: 0.27770\n",
      "Epoch: 22, series: 256, nllk loss: -1.91370, kernel loss: 0.08939\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22, series: 257, nllk loss: -2.10008, kernel loss: 0.06094\n",
      "Epoch: 22, series: 258, nllk loss: -2.11882, kernel loss: 0.30556\n",
      "Epoch: 22, series: 259, nllk loss: -1.87406, kernel loss: 0.16358\n",
      "Epoch: 22, series: 260, nllk loss: -2.05831, kernel loss: 0.35907\n",
      "Epoch: 22, series: 261, nllk loss: -2.12047, kernel loss: 0.11824\n",
      "Epoch: 22, series: 262, nllk loss: -2.60566, kernel loss: 0.04681\n",
      "Epoch: 22, series: 263, nllk loss: -0.69966, kernel loss: 0.00602\n",
      "Epoch: 22, series: 264, nllk loss: -1.97640, kernel loss: 0.05849\n",
      "Epoch: 22, series: 265, nllk loss: -1.92729, kernel loss: 0.15410\n",
      "Epoch: 22, series: 266, nllk loss: -2.32007, kernel loss: 0.04375\n",
      "Epoch: 22, series: 267, nllk loss: -2.18239, kernel loss: 0.03704\n",
      "Epoch: 22, series: 268, nllk loss: -2.19117, kernel loss: 0.07799\n",
      "Epoch: 22, series: 269, nllk loss: -1.88593, kernel loss: 0.13273\n",
      "Epoch: 22, series: 270, nllk loss: -1.93498, kernel loss: 0.04146\n",
      "Epoch: 22, series: 271, nllk loss: -2.06968, kernel loss: 0.20615\n",
      "Epoch: 22, series: 272, nllk loss: -1.92847, kernel loss: 0.16154\n",
      "Epoch: 22, series: 273, nllk loss: -2.08855, kernel loss: 0.00421\n",
      "Epoch: 22, series: 274, nllk loss: -1.38057, kernel loss: 0.09016\n",
      "Epoch: 22, series: 275, nllk loss: -1.95264, kernel loss: 0.13661\n",
      "Epoch: 22, series: 276, nllk loss: -1.36397, kernel loss: 0.00000\n",
      "Epoch: 22, series: 277, nllk loss: -2.27471, kernel loss: 0.17269\n",
      "Epoch: 22, series: 278, nllk loss: -1.92461, kernel loss: 0.08622\n",
      "Epoch: 22, series: 279, nllk loss: -2.41524, kernel loss: 0.02978\n",
      "Epoch: 22, series: 280, nllk loss: -2.15684, kernel loss: 0.23772\n",
      "Epoch: 22, series: 281, nllk loss: -2.40955, kernel loss: 0.04067\n",
      "Epoch: 22, series: 282, nllk loss: -2.20652, kernel loss: 0.03469\n",
      "Epoch: 22, series: 283, nllk loss: -2.19938, kernel loss: 0.10633\n",
      "Epoch: 22, series: 284, nllk loss: -1.65346, kernel loss: 0.02143\n",
      "Epoch: 22, series: 285, nllk loss: -1.93278, kernel loss: 0.14994\n",
      "Epoch: 22, series: 286, nllk loss: -2.17789, kernel loss: 0.12148\n",
      "Epoch: 22, series: 287, nllk loss: -2.48215, kernel loss: 0.09807\n",
      "Epoch: 22, series: 288, nllk loss: -1.26751, kernel loss: 0.08451\n",
      "Epoch: 22, series: 289, nllk loss: -1.23927, kernel loss: 0.13026\n",
      "Epoch: 22, series: 290, nllk loss: -2.31872, kernel loss: 0.07677\n",
      "Epoch: 22, series: 291, nllk loss: -2.36871, kernel loss: 0.25565\n",
      "Epoch: 22, series: 292, nllk loss: -2.26549, kernel loss: 0.05777\n",
      "Epoch: 22, series: 293, nllk loss: -2.44976, kernel loss: 0.15865\n",
      "Epoch: 22, series: 294, nllk loss: -1.47761, kernel loss: 0.02975\n",
      "Epoch: 22, series: 295, nllk loss: -1.23141, kernel loss: 0.18257\n",
      "Epoch: 22, series: 296, nllk loss: -2.47081, kernel loss: 0.21250\n",
      "Epoch: 22, series: 297, nllk loss: -2.53900, kernel loss: 0.12285\n",
      "Epoch: 22, series: 298, nllk loss: -0.10078, kernel loss: 0.19022\n",
      "Epoch: 22, series: 299, nllk loss: -0.84621, kernel loss: 0.09257\n",
      "Epoch: 22, series: 300, nllk loss: -2.16034, kernel loss: 0.05357\n",
      "Epoch: 22, series: 301, nllk loss: -2.43132, kernel loss: 0.07383\n",
      "Epoch: 22, series: 302, nllk loss: -2.28794, kernel loss: 0.02984\n",
      "Epoch: 22, series: 303, nllk loss: -2.00043, kernel loss: 0.13841\n",
      "Epoch: 22, series: 304, nllk loss: -0.07248, kernel loss: 0.15054\n",
      "Epoch: 22, series: 305, nllk loss: -1.69924, kernel loss: 0.09283\n",
      "Epoch: 22, series: 306, nllk loss: -2.47387, kernel loss: 0.14153\n",
      "Epoch: 22, series: 307, nllk loss: -1.70989, kernel loss: 0.06963\n",
      "Epoch: 22, series: 308, nllk loss: -2.34828, kernel loss: 0.10344\n",
      "Epoch: 22, series: 309, nllk loss: -1.98208, kernel loss: 0.14423\n",
      "Epoch: 22, series: 310, nllk loss: -2.28616, kernel loss: 0.11469\n",
      "Epoch: 22, series: 311, nllk loss: -1.97052, kernel loss: 0.10547\n",
      "Epoch: 22, series: 312, nllk loss: -1.98621, kernel loss: 0.09610\n",
      "Epoch: 22, series: 313, nllk loss: -2.30303, kernel loss: 0.14343\n",
      "Epoch: 22, series: 314, nllk loss: -2.76248, kernel loss: 0.08439\n",
      "Epoch: 22, series: 315, nllk loss: -0.93976, kernel loss: 0.01991\n",
      "Epoch: 22, series: 316, nllk loss: -2.13988, kernel loss: 0.12442\n",
      "Epoch: 22, series: 317, nllk loss: 0.18227, kernel loss: 0.06351\n",
      "Epoch: 22, series: 318, nllk loss: 0.71812, kernel loss: 0.07817\n",
      "Epoch: 22, series: 319, nllk loss: -1.12359, kernel loss: 0.12220\n",
      "Epoch: 22, series: 320, nllk loss: -0.92490, kernel loss: 0.13311\n",
      "Epoch: 22, total loss: -494.00587\n",
      "Epoch: 23, series: 0, nllk loss: 0.98383, kernel loss: 0.16017\n",
      "Epoch: 23, series: 1, nllk loss: -1.06491, kernel loss: 0.41349\n",
      "Epoch: 23, series: 2, nllk loss: 0.04638, kernel loss: 0.10079\n",
      "Epoch: 23, series: 3, nllk loss: -1.34823, kernel loss: 0.12387\n",
      "Epoch: 23, series: 4, nllk loss: -1.01304, kernel loss: 0.00755\n",
      "Epoch: 23, series: 5, nllk loss: -1.35877, kernel loss: 0.18910\n",
      "Epoch: 23, series: 6, nllk loss: -0.67191, kernel loss: 0.20750\n",
      "Epoch: 23, series: 7, nllk loss: -1.13868, kernel loss: 0.09482\n",
      "Epoch: 23, series: 8, nllk loss: -0.54038, kernel loss: 0.30642\n",
      "Epoch: 23, series: 9, nllk loss: -0.62440, kernel loss: 0.29152\n",
      "Epoch: 23, series: 10, nllk loss: -1.30787, kernel loss: 0.13485\n",
      "Epoch: 23, series: 11, nllk loss: -1.16812, kernel loss: 0.45686\n",
      "Epoch: 23, series: 12, nllk loss: -1.54822, kernel loss: 0.22992\n",
      "Epoch: 23, series: 13, nllk loss: -1.39692, kernel loss: 0.31582\n",
      "Epoch: 23, series: 14, nllk loss: -1.66801, kernel loss: 0.10676\n",
      "Epoch: 23, series: 15, nllk loss: -1.62119, kernel loss: 0.12881\n",
      "Epoch: 23, series: 16, nllk loss: -1.11270, kernel loss: 0.07502\n",
      "Epoch: 23, series: 17, nllk loss: -1.18910, kernel loss: 0.15530\n",
      "Epoch: 23, series: 18, nllk loss: -1.38912, kernel loss: 0.07303\n",
      "Epoch: 23, series: 19, nllk loss: -0.25686, kernel loss: 0.14381\n",
      "Epoch: 23, series: 20, nllk loss: -0.85544, kernel loss: 0.14987\n",
      "Epoch: 23, series: 21, nllk loss: -1.15419, kernel loss: 0.19103\n",
      "Epoch: 23, series: 22, nllk loss: -1.61042, kernel loss: 0.04519\n",
      "Epoch: 23, series: 23, nllk loss: -1.54138, kernel loss: 0.17464\n",
      "Epoch: 23, series: 24, nllk loss: -1.81956, kernel loss: 0.03516\n",
      "Epoch: 23, series: 25, nllk loss: -1.67648, kernel loss: 0.08594\n",
      "Epoch: 23, series: 26, nllk loss: -1.49878, kernel loss: 0.12659\n",
      "Epoch: 23, series: 27, nllk loss: -1.29649, kernel loss: 0.10025\n",
      "Epoch: 23, series: 28, nllk loss: -1.47734, kernel loss: 0.14393\n",
      "Epoch: 23, series: 29, nllk loss: -0.94672, kernel loss: 0.19027\n",
      "Epoch: 23, series: 30, nllk loss: -1.59522, kernel loss: 0.12091\n",
      "Epoch: 23, series: 31, nllk loss: -1.15481, kernel loss: 0.05915\n",
      "Epoch: 23, series: 32, nllk loss: -1.19696, kernel loss: 0.07419\n",
      "Epoch: 23, series: 33, nllk loss: -0.97081, kernel loss: 0.00199\n",
      "Epoch: 23, series: 34, nllk loss: -1.47660, kernel loss: 0.09632\n",
      "Epoch: 23, series: 35, nllk loss: -1.72503, kernel loss: 0.00697\n",
      "Epoch: 23, series: 36, nllk loss: -1.64203, kernel loss: 0.15989\n",
      "Epoch: 23, series: 37, nllk loss: -0.62968, kernel loss: 0.17949\n",
      "Epoch: 23, series: 38, nllk loss: -1.11955, kernel loss: 0.03595\n",
      "Epoch: 23, series: 39, nllk loss: -0.81331, kernel loss: 0.05420\n",
      "Epoch: 23, series: 40, nllk loss: -1.94273, kernel loss: 0.21040\n",
      "Epoch: 23, series: 41, nllk loss: -1.39912, kernel loss: 0.10412\n",
      "Epoch: 23, series: 42, nllk loss: -1.09009, kernel loss: 0.08054\n",
      "Epoch: 23, series: 43, nllk loss: -1.16890, kernel loss: 0.18919\n",
      "Epoch: 23, series: 44, nllk loss: -1.66336, kernel loss: 0.03940\n",
      "Epoch: 23, series: 45, nllk loss: -1.77350, kernel loss: 0.34580\n",
      "Epoch: 23, series: 46, nllk loss: -1.81550, kernel loss: 0.03276\n",
      "Epoch: 23, series: 47, nllk loss: -1.61015, kernel loss: 0.08244\n",
      "Epoch: 23, series: 48, nllk loss: -1.69915, kernel loss: 0.03306\n",
      "Epoch: 23, series: 49, nllk loss: -1.18352, kernel loss: 0.10478\n",
      "Epoch: 23, series: 50, nllk loss: -0.07911, kernel loss: 0.03742\n",
      "Epoch: 23, series: 51, nllk loss: -1.40217, kernel loss: 0.07580\n",
      "Epoch: 23, series: 52, nllk loss: -0.37361, kernel loss: 0.05047\n",
      "Epoch: 23, series: 53, nllk loss: -1.70834, kernel loss: 0.12389\n",
      "Epoch: 23, series: 54, nllk loss: -1.39203, kernel loss: 0.18012\n",
      "Epoch: 23, series: 55, nllk loss: -0.84540, kernel loss: 0.25695\n",
      "Epoch: 23, series: 56, nllk loss: -1.47418, kernel loss: 0.07560\n",
      "Epoch: 23, series: 57, nllk loss: -1.40434, kernel loss: 0.09015\n",
      "Epoch: 23, series: 58, nllk loss: -1.52840, kernel loss: 0.10110\n",
      "Epoch: 23, series: 59, nllk loss: -1.24213, kernel loss: 0.10075\n",
      "Epoch: 23, series: 60, nllk loss: -1.11178, kernel loss: 0.09564\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, series: 61, nllk loss: -1.76878, kernel loss: 0.12425\n",
      "Epoch: 23, series: 62, nllk loss: -1.83656, kernel loss: 0.09904\n",
      "Epoch: 23, series: 63, nllk loss: -1.71925, kernel loss: 0.11834\n",
      "Epoch: 23, series: 64, nllk loss: -1.18326, kernel loss: 0.15972\n",
      "Epoch: 23, series: 65, nllk loss: -1.67435, kernel loss: 0.06418\n",
      "Epoch: 23, series: 66, nllk loss: -1.64987, kernel loss: 0.05260\n",
      "Epoch: 23, series: 67, nllk loss: -1.50443, kernel loss: 0.10353\n",
      "Epoch: 23, series: 68, nllk loss: -0.88203, kernel loss: 0.03919\n",
      "Epoch: 23, series: 69, nllk loss: -1.55512, kernel loss: 0.03803\n",
      "Epoch: 23, series: 70, nllk loss: -1.47095, kernel loss: 0.17846\n",
      "Epoch: 23, series: 71, nllk loss: -1.52668, kernel loss: 0.05729\n",
      "Epoch: 23, series: 72, nllk loss: -1.89906, kernel loss: 0.02669\n",
      "Epoch: 23, series: 73, nllk loss: -1.40850, kernel loss: 0.06241\n",
      "Epoch: 23, series: 74, nllk loss: -2.02832, kernel loss: 0.14595\n",
      "Epoch: 23, series: 75, nllk loss: -1.57845, kernel loss: 0.08629\n",
      "Epoch: 23, series: 76, nllk loss: -1.40832, kernel loss: 0.03294\n",
      "Epoch: 23, series: 77, nllk loss: -1.40701, kernel loss: 0.21980\n",
      "Epoch: 23, series: 78, nllk loss: -1.45014, kernel loss: 0.10199\n",
      "Epoch: 23, series: 79, nllk loss: -0.42070, kernel loss: 0.12205\n",
      "Epoch: 23, series: 80, nllk loss: -1.76117, kernel loss: 0.02062\n",
      "Epoch: 23, series: 81, nllk loss: -1.59481, kernel loss: 0.09576\n",
      "Epoch: 23, series: 82, nllk loss: -0.35233, kernel loss: 0.09420\n",
      "Epoch: 23, series: 83, nllk loss: -1.28404, kernel loss: 0.19623\n",
      "Epoch: 23, series: 84, nllk loss: -1.31305, kernel loss: 0.08233\n",
      "Epoch: 23, series: 85, nllk loss: -1.64967, kernel loss: 0.12621\n",
      "Epoch: 23, series: 86, nllk loss: -0.95185, kernel loss: 0.11869\n",
      "Epoch: 23, series: 87, nllk loss: -1.87353, kernel loss: 0.03894\n",
      "Epoch: 23, series: 88, nllk loss: -2.00176, kernel loss: 0.05011\n",
      "Epoch: 23, series: 89, nllk loss: -1.83863, kernel loss: 0.11911\n",
      "Epoch: 23, series: 90, nllk loss: -2.16571, kernel loss: 0.04047\n",
      "Epoch: 23, series: 91, nllk loss: -2.16425, kernel loss: 0.09981\n",
      "Epoch: 23, series: 92, nllk loss: 0.05880, kernel loss: 0.04478\n",
      "Epoch: 23, series: 93, nllk loss: -2.50467, kernel loss: 0.04811\n",
      "Epoch: 23, series: 94, nllk loss: -2.32045, kernel loss: 0.09074\n",
      "Epoch: 23, series: 95, nllk loss: -2.40720, kernel loss: 0.17199\n",
      "Epoch: 23, series: 96, nllk loss: -1.76020, kernel loss: 0.01242\n",
      "Epoch: 23, series: 97, nllk loss: -0.62396, kernel loss: 0.08786\n",
      "Epoch: 23, series: 98, nllk loss: -0.75624, kernel loss: 0.09733\n",
      "Epoch: 23, series: 99, nllk loss: -1.45369, kernel loss: 0.12783\n",
      "Epoch: 23, series: 100, nllk loss: -0.82830, kernel loss: 0.04319\n",
      "Epoch: 23, series: 101, nllk loss: -1.36994, kernel loss: 0.01876\n",
      "Epoch: 23, series: 102, nllk loss: -0.56635, kernel loss: 0.24785\n",
      "Epoch: 23, series: 103, nllk loss: -1.12798, kernel loss: 0.12283\n",
      "Epoch: 23, series: 104, nllk loss: -0.02983, kernel loss: 0.11123\n",
      "Epoch: 23, series: 105, nllk loss: -0.28984, kernel loss: 0.02851\n",
      "Epoch: 23, series: 106, nllk loss: -1.21044, kernel loss: 0.10137\n",
      "Epoch: 23, series: 107, nllk loss: -1.10040, kernel loss: 0.18583\n",
      "Epoch: 23, series: 108, nllk loss: -1.32620, kernel loss: 0.05871\n",
      "Epoch: 23, series: 109, nllk loss: -1.17289, kernel loss: 0.03803\n",
      "Epoch: 23, series: 110, nllk loss: -1.65700, kernel loss: 0.13041\n",
      "Epoch: 23, series: 111, nllk loss: -1.48721, kernel loss: 0.04984\n",
      "Epoch: 23, series: 112, nllk loss: -0.92107, kernel loss: 0.15133\n",
      "Epoch: 23, series: 113, nllk loss: -1.18086, kernel loss: 0.09733\n",
      "Epoch: 23, series: 114, nllk loss: -1.17164, kernel loss: 0.12860\n",
      "Epoch: 23, series: 115, nllk loss: -1.10162, kernel loss: 0.19872\n",
      "Epoch: 23, series: 116, nllk loss: -1.55425, kernel loss: 0.16023\n",
      "Epoch: 23, series: 117, nllk loss: -0.59798, kernel loss: 0.20308\n",
      "Epoch: 23, series: 118, nllk loss: -1.85069, kernel loss: 0.02906\n",
      "Epoch: 23, series: 119, nllk loss: -0.75110, kernel loss: 0.01520\n",
      "Epoch: 23, series: 120, nllk loss: -1.63603, kernel loss: 0.12426\n",
      "Epoch: 23, series: 121, nllk loss: -0.08050, kernel loss: 0.18265\n",
      "Epoch: 23, series: 122, nllk loss: -0.65200, kernel loss: 0.11777\n",
      "Epoch: 23, series: 123, nllk loss: -1.83086, kernel loss: 0.07355\n",
      "Epoch: 23, series: 124, nllk loss: -1.96653, kernel loss: 0.00145\n",
      "Epoch: 23, series: 125, nllk loss: -1.31532, kernel loss: 0.04909\n",
      "Epoch: 23, series: 126, nllk loss: -1.88438, kernel loss: 0.17439\n",
      "Epoch: 23, series: 127, nllk loss: -1.35232, kernel loss: 0.09183\n",
      "Epoch: 23, series: 128, nllk loss: -1.00039, kernel loss: 0.15514\n",
      "Epoch: 23, series: 129, nllk loss: -0.80629, kernel loss: 0.11816\n",
      "Epoch: 23, series: 130, nllk loss: -1.57583, kernel loss: 0.03828\n",
      "Epoch: 23, series: 131, nllk loss: 0.31642, kernel loss: 0.04717\n",
      "Epoch: 23, series: 132, nllk loss: -0.12898, kernel loss: 0.08277\n",
      "Epoch: 23, series: 133, nllk loss: -0.94827, kernel loss: 0.05042\n",
      "Epoch: 23, series: 134, nllk loss: -0.79004, kernel loss: 0.07338\n",
      "Epoch: 23, series: 135, nllk loss: -1.60938, kernel loss: 0.04641\n",
      "Epoch: 23, series: 136, nllk loss: -1.70557, kernel loss: 0.05013\n",
      "Epoch: 23, series: 137, nllk loss: -1.83026, kernel loss: 0.13343\n",
      "Epoch: 23, series: 138, nllk loss: -1.88986, kernel loss: 0.10652\n",
      "Epoch: 23, series: 139, nllk loss: -1.81138, kernel loss: 0.06808\n",
      "Epoch: 23, series: 140, nllk loss: -1.54050, kernel loss: 0.18958\n",
      "Epoch: 23, series: 141, nllk loss: -1.82246, kernel loss: 0.06374\n",
      "Epoch: 23, series: 142, nllk loss: -1.88697, kernel loss: 0.07679\n",
      "Epoch: 23, series: 143, nllk loss: -1.82709, kernel loss: 0.09337\n",
      "Epoch: 23, series: 144, nllk loss: -2.19551, kernel loss: 0.25071\n",
      "Epoch: 23, series: 145, nllk loss: -1.92848, kernel loss: 0.17064\n",
      "Epoch: 23, series: 146, nllk loss: 1.56138, kernel loss: 0.16401\n",
      "Epoch: 23, series: 147, nllk loss: -1.65214, kernel loss: 0.21759\n",
      "Epoch: 23, series: 148, nllk loss: -1.48744, kernel loss: 0.01440\n",
      "Epoch: 23, series: 149, nllk loss: -1.88713, kernel loss: 0.15610\n",
      "Epoch: 23, series: 150, nllk loss: -2.00462, kernel loss: 0.14347\n",
      "Epoch: 23, series: 151, nllk loss: -2.10367, kernel loss: 0.05869\n",
      "Epoch: 23, series: 152, nllk loss: -2.06474, kernel loss: 0.19879\n",
      "Epoch: 23, series: 153, nllk loss: -1.73888, kernel loss: 0.05151\n",
      "Epoch: 23, series: 154, nllk loss: -1.90696, kernel loss: 0.16025\n",
      "Epoch: 23, series: 155, nllk loss: -1.96116, kernel loss: 0.12089\n",
      "Epoch: 23, series: 156, nllk loss: -2.13214, kernel loss: 0.12509\n",
      "Epoch: 23, series: 157, nllk loss: -1.65074, kernel loss: 0.01096\n",
      "Epoch: 23, series: 158, nllk loss: -2.04977, kernel loss: 0.01463\n",
      "Epoch: 23, series: 159, nllk loss: -2.08518, kernel loss: 0.08469\n",
      "Epoch: 23, series: 160, nllk loss: -1.95555, kernel loss: 0.16999\n",
      "Epoch: 23, series: 161, nllk loss: -1.89145, kernel loss: 0.09725\n",
      "Epoch: 23, series: 162, nllk loss: -2.25840, kernel loss: 0.16059\n",
      "Epoch: 23, series: 163, nllk loss: -2.44112, kernel loss: 0.09372\n",
      "Epoch: 23, series: 164, nllk loss: -1.76325, kernel loss: 0.06016\n",
      "Epoch: 23, series: 165, nllk loss: -1.96351, kernel loss: 0.06867\n",
      "Epoch: 23, series: 166, nllk loss: -1.36625, kernel loss: 0.14736\n",
      "Epoch: 23, series: 167, nllk loss: -2.65012, kernel loss: 0.11861\n",
      "Epoch: 23, series: 168, nllk loss: -2.16674, kernel loss: 0.18006\n",
      "Epoch: 23, series: 169, nllk loss: -2.36915, kernel loss: 0.07405\n",
      "Epoch: 23, series: 170, nllk loss: -1.97906, kernel loss: 0.09427\n",
      "Epoch: 23, series: 171, nllk loss: -2.53509, kernel loss: 0.15977\n",
      "Epoch: 23, series: 172, nllk loss: -2.09403, kernel loss: 0.09272\n",
      "Epoch: 23, series: 173, nllk loss: -2.57530, kernel loss: 0.10859\n",
      "Epoch: 23, series: 174, nllk loss: -2.26395, kernel loss: 0.32366\n",
      "Epoch: 23, series: 175, nllk loss: -2.64537, kernel loss: 0.07246\n",
      "Epoch: 23, series: 176, nllk loss: -2.04879, kernel loss: 0.11534\n",
      "Epoch: 23, series: 177, nllk loss: -2.04853, kernel loss: 0.20736\n",
      "Epoch: 23, series: 178, nllk loss: -1.79254, kernel loss: 0.13662\n",
      "Epoch: 23, series: 179, nllk loss: -2.25797, kernel loss: 0.00409\n",
      "Epoch: 23, series: 180, nllk loss: -2.35592, kernel loss: 0.11876\n",
      "Epoch: 23, series: 181, nllk loss: -2.57432, kernel loss: 0.18382\n",
      "Epoch: 23, series: 182, nllk loss: -2.31777, kernel loss: 0.00979\n",
      "Epoch: 23, series: 183, nllk loss: -2.01604, kernel loss: 0.16953\n",
      "Epoch: 23, series: 184, nllk loss: -2.05848, kernel loss: 0.03618\n",
      "Epoch: 23, series: 185, nllk loss: -1.68958, kernel loss: 0.10667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, series: 186, nllk loss: -2.59896, kernel loss: 0.16685\n",
      "Epoch: 23, series: 187, nllk loss: -2.70509, kernel loss: 0.17099\n",
      "Epoch: 23, series: 188, nllk loss: -1.68490, kernel loss: 0.17165\n",
      "Epoch: 23, series: 189, nllk loss: -1.53391, kernel loss: 0.20510\n",
      "Epoch: 23, series: 190, nllk loss: -2.22039, kernel loss: 0.07413\n",
      "Epoch: 23, series: 191, nllk loss: -1.99018, kernel loss: 0.16012\n",
      "Epoch: 23, series: 192, nllk loss: -2.11326, kernel loss: 0.09396\n",
      "Epoch: 23, series: 193, nllk loss: -1.45946, kernel loss: 0.15797\n",
      "Epoch: 23, series: 194, nllk loss: -1.59048, kernel loss: 0.26998\n",
      "Epoch: 23, series: 195, nllk loss: -2.35821, kernel loss: 0.15701\n",
      "Epoch: 23, series: 196, nllk loss: -1.94982, kernel loss: 0.06121\n",
      "Epoch: 23, series: 197, nllk loss: -2.18398, kernel loss: 0.23817\n",
      "Epoch: 23, series: 198, nllk loss: -2.23496, kernel loss: 0.13300\n",
      "Epoch: 23, series: 199, nllk loss: -1.99577, kernel loss: 0.14658\n",
      "Epoch: 23, series: 200, nllk loss: -2.32327, kernel loss: 0.06637\n",
      "Epoch: 23, series: 201, nllk loss: -2.36574, kernel loss: 0.06137\n",
      "Epoch: 23, series: 202, nllk loss: -2.11362, kernel loss: 0.02052\n",
      "Epoch: 23, series: 203, nllk loss: -1.87474, kernel loss: 0.03149\n",
      "Epoch: 23, series: 204, nllk loss: -1.01257, kernel loss: 0.04512\n",
      "Epoch: 23, series: 205, nllk loss: -2.22074, kernel loss: 0.11968\n",
      "Epoch: 23, series: 206, nllk loss: -2.31761, kernel loss: 0.09299\n",
      "Epoch: 23, series: 207, nllk loss: -0.94048, kernel loss: 0.03430\n",
      "Epoch: 23, series: 208, nllk loss: -2.42666, kernel loss: 0.17044\n",
      "Epoch: 23, series: 209, nllk loss: -1.83437, kernel loss: 0.17771\n",
      "Epoch: 23, series: 210, nllk loss: -2.70406, kernel loss: 0.17448\n",
      "Epoch: 23, series: 211, nllk loss: -2.14530, kernel loss: 0.19928\n",
      "Epoch: 23, series: 212, nllk loss: -1.28779, kernel loss: 0.05969\n",
      "Epoch: 23, series: 213, nllk loss: -2.19999, kernel loss: 0.04985\n",
      "Epoch: 23, series: 214, nllk loss: -2.22096, kernel loss: 0.07948\n",
      "Epoch: 23, series: 215, nllk loss: -2.57303, kernel loss: 0.10388\n",
      "Epoch: 23, series: 216, nllk loss: -1.42205, kernel loss: 0.03351\n",
      "Epoch: 23, series: 217, nllk loss: -2.07141, kernel loss: 0.08238\n",
      "Epoch: 23, series: 218, nllk loss: -1.59565, kernel loss: 0.18883\n",
      "Epoch: 23, series: 219, nllk loss: -2.20893, kernel loss: 0.12565\n",
      "Epoch: 23, series: 220, nllk loss: -2.17703, kernel loss: 0.06804\n",
      "Epoch: 23, series: 221, nllk loss: -2.49159, kernel loss: 0.10787\n",
      "Epoch: 23, series: 222, nllk loss: -2.27946, kernel loss: 0.10365\n",
      "Epoch: 23, series: 223, nllk loss: -1.65598, kernel loss: 0.02850\n",
      "Epoch: 23, series: 224, nllk loss: -2.45757, kernel loss: 0.22461\n",
      "Epoch: 23, series: 225, nllk loss: -2.40281, kernel loss: 0.07130\n",
      "Epoch: 23, series: 226, nllk loss: -1.93282, kernel loss: 0.18470\n",
      "Epoch: 23, series: 227, nllk loss: -2.07406, kernel loss: 0.09288\n",
      "Epoch: 23, series: 228, nllk loss: -2.13632, kernel loss: 0.08271\n",
      "Epoch: 23, series: 229, nllk loss: -2.02995, kernel loss: 0.02090\n",
      "Epoch: 23, series: 230, nllk loss: -2.49665, kernel loss: 0.09446\n",
      "Epoch: 23, series: 231, nllk loss: -1.99736, kernel loss: 0.05124\n",
      "Epoch: 23, series: 232, nllk loss: -2.58935, kernel loss: 0.08166\n",
      "Epoch: 23, series: 233, nllk loss: -2.49981, kernel loss: 0.02941\n",
      "Epoch: 23, series: 234, nllk loss: -2.16458, kernel loss: 0.20662\n",
      "Epoch: 23, series: 235, nllk loss: -2.66579, kernel loss: 0.19253\n",
      "Epoch: 23, series: 236, nllk loss: -1.66910, kernel loss: 0.12660\n",
      "Epoch: 23, series: 237, nllk loss: -2.19923, kernel loss: 0.14792\n",
      "Epoch: 23, series: 238, nllk loss: -2.04264, kernel loss: 0.04716\n",
      "Epoch: 23, series: 239, nllk loss: -2.33554, kernel loss: 0.12140\n",
      "Epoch: 23, series: 240, nllk loss: -1.02041, kernel loss: 0.17686\n",
      "Epoch: 23, series: 241, nllk loss: -2.08445, kernel loss: 0.06537\n",
      "Epoch: 23, series: 242, nllk loss: -2.16294, kernel loss: 0.07552\n",
      "Epoch: 23, series: 243, nllk loss: -2.44375, kernel loss: 0.05831\n",
      "Epoch: 23, series: 244, nllk loss: -2.06535, kernel loss: 0.10793\n",
      "Epoch: 23, series: 245, nllk loss: -2.14035, kernel loss: 0.06580\n",
      "Epoch: 23, series: 246, nllk loss: -0.28378, kernel loss: 0.18597\n",
      "Epoch: 23, series: 247, nllk loss: -1.68020, kernel loss: 0.11297\n",
      "Epoch: 23, series: 248, nllk loss: -2.17540, kernel loss: 0.11842\n",
      "Epoch: 23, series: 249, nllk loss: -2.09723, kernel loss: 0.11714\n",
      "Epoch: 23, series: 250, nllk loss: -1.68745, kernel loss: 0.16258\n",
      "Epoch: 23, series: 251, nllk loss: -1.21189, kernel loss: 0.01835\n",
      "Epoch: 23, series: 252, nllk loss: -1.41642, kernel loss: 0.18101\n",
      "Epoch: 23, series: 253, nllk loss: -1.75576, kernel loss: 0.05116\n",
      "Epoch: 23, series: 254, nllk loss: -2.32790, kernel loss: 0.03517\n",
      "Epoch: 23, series: 255, nllk loss: -2.15641, kernel loss: 0.06993\n",
      "Epoch: 23, series: 256, nllk loss: -1.97788, kernel loss: 0.06137\n",
      "Epoch: 23, series: 257, nllk loss: -2.09976, kernel loss: 0.12432\n",
      "Epoch: 23, series: 258, nllk loss: -2.20190, kernel loss: 0.23471\n",
      "Epoch: 23, series: 259, nllk loss: -1.94424, kernel loss: 0.06263\n",
      "Epoch: 23, series: 260, nllk loss: -2.10764, kernel loss: 0.09883\n",
      "Epoch: 23, series: 261, nllk loss: -2.11662, kernel loss: 0.17699\n",
      "Epoch: 23, series: 262, nllk loss: -2.66369, kernel loss: 0.07920\n",
      "Epoch: 23, series: 263, nllk loss: -0.66084, kernel loss: 0.18193\n",
      "Epoch: 23, series: 264, nllk loss: -2.01960, kernel loss: 0.09088\n",
      "Epoch: 23, series: 265, nllk loss: -1.94137, kernel loss: 0.12990\n",
      "Epoch: 23, series: 266, nllk loss: -2.34053, kernel loss: 0.06710\n",
      "Epoch: 23, series: 267, nllk loss: -2.19074, kernel loss: 0.02145\n",
      "Epoch: 23, series: 268, nllk loss: -2.22764, kernel loss: 0.12261\n",
      "Epoch: 23, series: 269, nllk loss: -1.92716, kernel loss: 0.07844\n",
      "Epoch: 23, series: 270, nllk loss: -1.94322, kernel loss: 0.06783\n",
      "Epoch: 23, series: 271, nllk loss: -2.10943, kernel loss: 0.13542\n",
      "Epoch: 23, series: 272, nllk loss: -1.95522, kernel loss: 0.11775\n",
      "Epoch: 23, series: 273, nllk loss: -2.01799, kernel loss: 0.06491\n",
      "Epoch: 23, series: 274, nllk loss: -1.55562, kernel loss: 0.00924\n",
      "Epoch: 23, series: 275, nllk loss: -2.00253, kernel loss: 0.12687\n",
      "Epoch: 23, series: 276, nllk loss: -1.40663, kernel loss: 0.20018\n",
      "Epoch: 23, series: 277, nllk loss: -2.28953, kernel loss: 0.04408\n",
      "Epoch: 23, series: 278, nllk loss: -1.94624, kernel loss: 0.04382\n",
      "Epoch: 23, series: 279, nllk loss: -2.45557, kernel loss: 0.23725\n",
      "Epoch: 23, series: 280, nllk loss: -2.13124, kernel loss: 0.12352\n",
      "Epoch: 23, series: 281, nllk loss: -2.38814, kernel loss: 0.07600\n",
      "Epoch: 23, series: 282, nllk loss: -2.30079, kernel loss: 0.04852\n",
      "Epoch: 23, series: 283, nllk loss: -2.28140, kernel loss: 0.08506\n",
      "Epoch: 23, series: 284, nllk loss: -1.69321, kernel loss: 0.08421\n",
      "Epoch: 23, series: 285, nllk loss: -1.98272, kernel loss: 0.21615\n",
      "Epoch: 23, series: 286, nllk loss: -2.23283, kernel loss: 0.04710\n",
      "Epoch: 23, series: 287, nllk loss: -2.53221, kernel loss: 0.10752\n",
      "Epoch: 23, series: 288, nllk loss: -1.41082, kernel loss: 0.22041\n",
      "Epoch: 23, series: 289, nllk loss: -1.16813, kernel loss: 0.05388\n",
      "Epoch: 23, series: 290, nllk loss: -2.34161, kernel loss: 0.24241\n",
      "Epoch: 23, series: 291, nllk loss: -2.34735, kernel loss: 0.00460\n",
      "Epoch: 23, series: 292, nllk loss: -2.29178, kernel loss: 0.19200\n",
      "Epoch: 23, series: 293, nllk loss: -2.51650, kernel loss: 0.05826\n",
      "Epoch: 23, series: 294, nllk loss: -1.39185, kernel loss: 0.08751\n",
      "Epoch: 23, series: 295, nllk loss: -1.25990, kernel loss: 0.03849\n",
      "Epoch: 23, series: 296, nllk loss: -2.56372, kernel loss: 0.04197\n",
      "Epoch: 23, series: 297, nllk loss: -2.60041, kernel loss: 0.14291\n",
      "Epoch: 23, series: 298, nllk loss: -0.05772, kernel loss: 0.12921\n",
      "Epoch: 23, series: 299, nllk loss: -0.80099, kernel loss: 0.10411\n",
      "Epoch: 23, series: 300, nllk loss: -2.19038, kernel loss: 0.02153\n",
      "Epoch: 23, series: 301, nllk loss: -2.50813, kernel loss: 0.12236\n",
      "Epoch: 23, series: 302, nllk loss: -2.32713, kernel loss: 0.07816\n",
      "Epoch: 23, series: 303, nllk loss: -1.97048, kernel loss: 0.20837\n",
      "Epoch: 23, series: 304, nllk loss: -0.09134, kernel loss: 0.15319\n",
      "Epoch: 23, series: 305, nllk loss: -1.82898, kernel loss: 0.05978\n",
      "Epoch: 23, series: 306, nllk loss: -2.51227, kernel loss: 0.11207\n",
      "Epoch: 23, series: 307, nllk loss: -1.70188, kernel loss: 0.10753\n",
      "Epoch: 23, series: 308, nllk loss: -2.40219, kernel loss: 0.21610\n",
      "Epoch: 23, series: 309, nllk loss: -1.96847, kernel loss: 0.12717\n",
      "Epoch: 23, series: 310, nllk loss: -2.37896, kernel loss: 0.12251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23, series: 311, nllk loss: -2.03413, kernel loss: 0.08655\n",
      "Epoch: 23, series: 312, nllk loss: -2.12329, kernel loss: 0.17124\n",
      "Epoch: 23, series: 313, nllk loss: -2.21558, kernel loss: 0.21493\n",
      "Epoch: 23, series: 314, nllk loss: -2.69788, kernel loss: 0.12442\n",
      "Epoch: 23, series: 315, nllk loss: -0.85840, kernel loss: 0.13844\n",
      "Epoch: 23, series: 316, nllk loss: -2.10114, kernel loss: 0.03774\n",
      "Epoch: 23, series: 317, nllk loss: 0.13566, kernel loss: 0.10852\n",
      "Epoch: 23, series: 318, nllk loss: 0.68918, kernel loss: 0.17707\n",
      "Epoch: 23, series: 319, nllk loss: -1.10434, kernel loss: 0.10044\n",
      "Epoch: 23, series: 320, nllk loss: -0.81815, kernel loss: 0.11101\n",
      "Epoch: 23, total loss: -495.48539\n",
      "Epoch: 24, series: 0, nllk loss: 0.82948, kernel loss: 0.12726\n",
      "Epoch: 24, series: 1, nllk loss: -1.12877, kernel loss: 0.22066\n",
      "Epoch: 24, series: 2, nllk loss: 0.03573, kernel loss: 0.24018\n",
      "Epoch: 24, series: 3, nllk loss: -1.34757, kernel loss: 0.08400\n",
      "Epoch: 24, series: 4, nllk loss: -1.02347, kernel loss: 0.09468\n",
      "Epoch: 24, series: 5, nllk loss: -1.33503, kernel loss: 0.20950\n",
      "Epoch: 24, series: 6, nllk loss: -0.58498, kernel loss: 0.14708\n",
      "Epoch: 24, series: 7, nllk loss: -1.08428, kernel loss: 0.31578\n",
      "Epoch: 24, series: 8, nllk loss: -0.59948, kernel loss: 0.25329\n",
      "Epoch: 24, series: 9, nllk loss: -0.55998, kernel loss: 0.26596\n",
      "Epoch: 24, series: 10, nllk loss: -1.40007, kernel loss: 0.28005\n",
      "Epoch: 24, series: 11, nllk loss: -1.28931, kernel loss: 0.19458\n",
      "Epoch: 24, series: 12, nllk loss: -1.65913, kernel loss: 0.02338\n",
      "Epoch: 24, series: 13, nllk loss: -1.45281, kernel loss: 0.32919\n",
      "Epoch: 24, series: 14, nllk loss: -1.57360, kernel loss: 0.14532\n",
      "Epoch: 24, series: 15, nllk loss: -1.55035, kernel loss: 0.16819\n",
      "Epoch: 24, series: 16, nllk loss: -1.13187, kernel loss: 0.09995\n",
      "Epoch: 24, series: 17, nllk loss: -1.08239, kernel loss: 0.23490\n",
      "Epoch: 24, series: 18, nllk loss: -1.50704, kernel loss: 0.06620\n",
      "Epoch: 24, series: 19, nllk loss: -0.19077, kernel loss: 0.11067\n",
      "Epoch: 24, series: 20, nllk loss: -0.92161, kernel loss: 0.07500\n",
      "Epoch: 24, series: 21, nllk loss: -1.15124, kernel loss: 0.16178\n",
      "Epoch: 24, series: 22, nllk loss: -1.55599, kernel loss: 0.05884\n",
      "Epoch: 24, series: 23, nllk loss: -1.54504, kernel loss: 0.06357\n",
      "Epoch: 24, series: 24, nllk loss: -1.76624, kernel loss: 0.19299\n",
      "Epoch: 24, series: 25, nllk loss: -1.73023, kernel loss: 0.07177\n",
      "Epoch: 24, series: 26, nllk loss: -1.40586, kernel loss: 0.01830\n",
      "Epoch: 24, series: 27, nllk loss: -1.29204, kernel loss: 0.08981\n",
      "Epoch: 24, series: 28, nllk loss: -1.44254, kernel loss: 0.12643\n",
      "Epoch: 24, series: 29, nllk loss: -1.00776, kernel loss: 0.02940\n",
      "Epoch: 24, series: 30, nllk loss: -1.47579, kernel loss: 0.08922\n",
      "Epoch: 24, series: 31, nllk loss: -1.14610, kernel loss: 0.11131\n",
      "Epoch: 24, series: 32, nllk loss: -1.20179, kernel loss: 0.06478\n",
      "Epoch: 24, series: 33, nllk loss: -0.99207, kernel loss: 0.05328\n",
      "Epoch: 24, series: 34, nllk loss: -1.41698, kernel loss: 0.06425\n",
      "Epoch: 24, series: 35, nllk loss: -1.68259, kernel loss: 0.05776\n",
      "Epoch: 24, series: 36, nllk loss: -1.65826, kernel loss: 0.06561\n",
      "Epoch: 24, series: 37, nllk loss: -0.62898, kernel loss: 0.05453\n",
      "Epoch: 24, series: 38, nllk loss: -1.08382, kernel loss: 0.21251\n",
      "Epoch: 24, series: 39, nllk loss: -0.79214, kernel loss: 0.13221\n",
      "Epoch: 24, series: 40, nllk loss: -1.92561, kernel loss: 0.02423\n",
      "Epoch: 24, series: 41, nllk loss: -1.42003, kernel loss: 0.06701\n",
      "Epoch: 24, series: 42, nllk loss: -1.11793, kernel loss: 0.07751\n",
      "Epoch: 24, series: 43, nllk loss: -1.09735, kernel loss: 0.11239\n",
      "Epoch: 24, series: 44, nllk loss: -1.68051, kernel loss: 0.30126\n",
      "Epoch: 24, series: 45, nllk loss: -1.76290, kernel loss: 0.12255\n",
      "Epoch: 24, series: 46, nllk loss: -1.78935, kernel loss: 0.00286\n",
      "Epoch: 24, series: 47, nllk loss: -1.65236, kernel loss: 0.04882\n",
      "Epoch: 24, series: 48, nllk loss: -1.70392, kernel loss: 0.07298\n",
      "Epoch: 24, series: 49, nllk loss: -1.20581, kernel loss: 0.22902\n",
      "Epoch: 24, series: 50, nllk loss: -0.11843, kernel loss: 0.11698\n",
      "Epoch: 24, series: 51, nllk loss: -1.36292, kernel loss: 0.00396\n",
      "Epoch: 24, series: 52, nllk loss: -0.41869, kernel loss: 0.01240\n",
      "Epoch: 24, series: 53, nllk loss: -1.70004, kernel loss: 0.24254\n",
      "Epoch: 24, series: 54, nllk loss: -1.43447, kernel loss: 0.13079\n",
      "Epoch: 24, series: 55, nllk loss: -0.86499, kernel loss: 0.02581\n",
      "Epoch: 24, series: 56, nllk loss: -1.50558, kernel loss: 0.01314\n",
      "Epoch: 24, series: 57, nllk loss: -1.46975, kernel loss: 0.15402\n",
      "Epoch: 24, series: 58, nllk loss: -1.59440, kernel loss: 0.15145\n",
      "Epoch: 24, series: 59, nllk loss: -1.24888, kernel loss: 0.00000\n",
      "Epoch: 24, series: 60, nllk loss: -1.13692, kernel loss: 0.12858\n",
      "Epoch: 24, series: 61, nllk loss: -1.80436, kernel loss: 0.27808\n",
      "Epoch: 24, series: 62, nllk loss: -1.90630, kernel loss: 0.08072\n",
      "Epoch: 24, series: 63, nllk loss: -1.76433, kernel loss: 0.11443\n",
      "Epoch: 24, series: 64, nllk loss: -1.21199, kernel loss: 0.09378\n",
      "Epoch: 24, series: 65, nllk loss: -1.77129, kernel loss: 0.16057\n",
      "Epoch: 24, series: 66, nllk loss: -1.75032, kernel loss: 0.11699\n",
      "Epoch: 24, series: 67, nllk loss: -1.53851, kernel loss: 0.10697\n",
      "Epoch: 24, series: 68, nllk loss: -0.93574, kernel loss: 0.07813\n",
      "Epoch: 24, series: 69, nllk loss: -1.62139, kernel loss: 0.07263\n",
      "Epoch: 24, series: 70, nllk loss: -1.48480, kernel loss: 0.01951\n",
      "Epoch: 24, series: 71, nllk loss: -1.61070, kernel loss: 0.07854\n",
      "Epoch: 24, series: 72, nllk loss: -1.88912, kernel loss: 0.08938\n",
      "Epoch: 24, series: 73, nllk loss: -1.42871, kernel loss: 0.01641\n",
      "Epoch: 24, series: 74, nllk loss: -2.06613, kernel loss: 0.05723\n",
      "Epoch: 24, series: 75, nllk loss: -1.63614, kernel loss: 0.12910\n",
      "Epoch: 24, series: 76, nllk loss: -1.50449, kernel loss: 0.18645\n",
      "Epoch: 24, series: 77, nllk loss: -1.39784, kernel loss: 0.09104\n",
      "Epoch: 24, series: 78, nllk loss: -1.46719, kernel loss: 0.05122\n",
      "Epoch: 24, series: 79, nllk loss: -0.36517, kernel loss: 0.10008\n",
      "Epoch: 24, series: 80, nllk loss: -1.86382, kernel loss: 0.03888\n",
      "Epoch: 24, series: 81, nllk loss: -1.52729, kernel loss: 0.12499\n",
      "Epoch: 24, series: 82, nllk loss: -0.36388, kernel loss: 0.08837\n",
      "Epoch: 24, series: 83, nllk loss: -1.22492, kernel loss: 0.05140\n",
      "Epoch: 24, series: 84, nllk loss: -1.32065, kernel loss: 0.08568\n",
      "Epoch: 24, series: 85, nllk loss: -1.69526, kernel loss: 0.21314\n",
      "Epoch: 24, series: 86, nllk loss: -1.00823, kernel loss: 0.09933\n",
      "Epoch: 24, series: 87, nllk loss: -1.87939, kernel loss: 0.11261\n",
      "Epoch: 24, series: 88, nllk loss: -2.08006, kernel loss: 0.12110\n",
      "Epoch: 24, series: 89, nllk loss: -1.92035, kernel loss: 0.12993\n",
      "Epoch: 24, series: 90, nllk loss: -2.19264, kernel loss: 0.10409\n",
      "Epoch: 24, series: 91, nllk loss: -2.15363, kernel loss: 0.06549\n",
      "Epoch: 24, series: 92, nllk loss: -0.17189, kernel loss: 0.12009\n",
      "Epoch: 24, series: 93, nllk loss: -2.59797, kernel loss: 0.00489\n",
      "Epoch: 24, series: 94, nllk loss: -2.50674, kernel loss: 0.08354\n",
      "Epoch: 24, series: 95, nllk loss: -2.51951, kernel loss: 0.03787\n",
      "Epoch: 24, series: 96, nllk loss: -1.73609, kernel loss: 0.14791\n",
      "Epoch: 24, series: 97, nllk loss: -0.63672, kernel loss: 0.15360\n",
      "Epoch: 24, series: 98, nllk loss: -0.65165, kernel loss: 0.06070\n",
      "Epoch: 24, series: 99, nllk loss: -1.55475, kernel loss: 0.07553\n",
      "Epoch: 24, series: 100, nllk loss: -0.89245, kernel loss: 0.05763\n",
      "Epoch: 24, series: 101, nllk loss: -1.50426, kernel loss: 0.12425\n",
      "Epoch: 24, series: 102, nllk loss: -0.65130, kernel loss: 0.03525\n",
      "Epoch: 24, series: 103, nllk loss: -1.12346, kernel loss: 0.06609\n",
      "Epoch: 24, series: 104, nllk loss: -0.11164, kernel loss: 0.05372\n",
      "Epoch: 24, series: 105, nllk loss: -0.45870, kernel loss: 0.13413\n",
      "Epoch: 24, series: 106, nllk loss: -1.21331, kernel loss: 0.12627\n",
      "Epoch: 24, series: 107, nllk loss: -1.08563, kernel loss: 0.04774\n",
      "Epoch: 24, series: 108, nllk loss: -1.32568, kernel loss: 0.16683\n",
      "Epoch: 24, series: 109, nllk loss: -1.36829, kernel loss: 0.14028\n",
      "Epoch: 24, series: 110, nllk loss: -1.68313, kernel loss: 0.06665\n",
      "Epoch: 24, series: 111, nllk loss: -1.52712, kernel loss: 0.05897\n",
      "Epoch: 24, series: 112, nllk loss: -0.90860, kernel loss: 0.41244\n",
      "Epoch: 24, series: 113, nllk loss: -1.25894, kernel loss: 0.10630\n",
      "Epoch: 24, series: 114, nllk loss: -1.24939, kernel loss: 0.20888\n",
      "Epoch: 24, series: 115, nllk loss: -1.11054, kernel loss: 0.11638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, series: 116, nllk loss: -1.65577, kernel loss: 0.21401\n",
      "Epoch: 24, series: 117, nllk loss: -0.64274, kernel loss: 0.00833\n",
      "Epoch: 24, series: 118, nllk loss: -1.87696, kernel loss: 0.10513\n",
      "Epoch: 24, series: 119, nllk loss: -0.76355, kernel loss: 0.06039\n",
      "Epoch: 24, series: 120, nllk loss: -1.64187, kernel loss: 0.14953\n",
      "Epoch: 24, series: 121, nllk loss: -0.04330, kernel loss: 0.08300\n",
      "Epoch: 24, series: 122, nllk loss: -0.67682, kernel loss: 0.06711\n",
      "Epoch: 24, series: 123, nllk loss: -1.89828, kernel loss: 0.00985\n",
      "Epoch: 24, series: 124, nllk loss: -2.07708, kernel loss: 0.16262\n",
      "Epoch: 24, series: 125, nllk loss: -1.36459, kernel loss: 0.10944\n",
      "Epoch: 24, series: 126, nllk loss: -2.01499, kernel loss: 0.05396\n",
      "Epoch: 24, series: 127, nllk loss: -1.36794, kernel loss: 0.02816\n",
      "Epoch: 24, series: 128, nllk loss: -1.01017, kernel loss: 0.12988\n",
      "Epoch: 24, series: 129, nllk loss: -0.85784, kernel loss: 0.11689\n",
      "Epoch: 24, series: 130, nllk loss: -1.61912, kernel loss: 0.02023\n",
      "Epoch: 24, series: 131, nllk loss: 0.34586, kernel loss: 0.10264\n",
      "Epoch: 24, series: 132, nllk loss: -0.09738, kernel loss: 0.15708\n",
      "Epoch: 24, series: 133, nllk loss: -1.01047, kernel loss: 0.11559\n",
      "Epoch: 24, series: 134, nllk loss: -0.77642, kernel loss: 0.11106\n",
      "Epoch: 24, series: 135, nllk loss: -1.66789, kernel loss: 0.02792\n",
      "Epoch: 24, series: 136, nllk loss: -1.78667, kernel loss: 0.08298\n",
      "Epoch: 24, series: 137, nllk loss: -1.95507, kernel loss: 0.07091\n",
      "Epoch: 24, series: 138, nllk loss: -1.89390, kernel loss: 0.20498\n",
      "Epoch: 24, series: 139, nllk loss: -1.87171, kernel loss: 0.17971\n",
      "Epoch: 24, series: 140, nllk loss: -1.53424, kernel loss: 0.02788\n",
      "Epoch: 24, series: 141, nllk loss: -1.80587, kernel loss: 0.02543\n",
      "Epoch: 24, series: 142, nllk loss: -1.93626, kernel loss: 0.10589\n",
      "Epoch: 24, series: 143, nllk loss: -1.75355, kernel loss: 0.06239\n",
      "Epoch: 24, series: 144, nllk loss: -2.14279, kernel loss: 0.10407\n",
      "Epoch: 24, series: 145, nllk loss: -1.92720, kernel loss: 0.15737\n",
      "Epoch: 24, series: 146, nllk loss: 1.30730, kernel loss: 0.04665\n",
      "Epoch: 24, series: 147, nllk loss: -1.82212, kernel loss: 0.15995\n",
      "Epoch: 24, series: 148, nllk loss: -1.38403, kernel loss: 0.05865\n",
      "Epoch: 24, series: 149, nllk loss: -1.92497, kernel loss: 0.00467\n",
      "Epoch: 24, series: 150, nllk loss: -1.96332, kernel loss: 0.10162\n",
      "Epoch: 24, series: 151, nllk loss: -2.05875, kernel loss: 0.08203\n",
      "Epoch: 24, series: 152, nllk loss: -2.10484, kernel loss: 0.01207\n",
      "Epoch: 24, series: 153, nllk loss: -1.77455, kernel loss: 0.08063\n",
      "Epoch: 24, series: 154, nllk loss: -1.87920, kernel loss: 0.04502\n",
      "Epoch: 24, series: 155, nllk loss: -1.95844, kernel loss: 0.03467\n",
      "Epoch: 24, series: 156, nllk loss: -2.11905, kernel loss: 0.02184\n",
      "Epoch: 24, series: 157, nllk loss: -1.66834, kernel loss: 0.12368\n",
      "Epoch: 24, series: 158, nllk loss: -2.08097, kernel loss: 0.17558\n",
      "Epoch: 24, series: 159, nllk loss: -2.16220, kernel loss: 0.10496\n",
      "Epoch: 24, series: 160, nllk loss: -1.96041, kernel loss: 0.02195\n",
      "Epoch: 24, series: 161, nllk loss: -1.90596, kernel loss: 0.08207\n",
      "Epoch: 24, series: 162, nllk loss: -2.29747, kernel loss: 0.07727\n",
      "Epoch: 24, series: 163, nllk loss: -2.46171, kernel loss: 0.05170\n",
      "Epoch: 24, series: 164, nllk loss: -1.89145, kernel loss: 0.06197\n",
      "Epoch: 24, series: 165, nllk loss: -2.02644, kernel loss: 0.22175\n",
      "Epoch: 24, series: 166, nllk loss: -1.38522, kernel loss: 0.09430\n",
      "Epoch: 24, series: 167, nllk loss: -2.68453, kernel loss: 0.03054\n",
      "Epoch: 24, series: 168, nllk loss: -2.16844, kernel loss: 0.22625\n",
      "Epoch: 24, series: 169, nllk loss: -2.37141, kernel loss: 0.05042\n",
      "Epoch: 24, series: 170, nllk loss: -2.05705, kernel loss: 0.05728\n",
      "Epoch: 24, series: 171, nllk loss: -2.56079, kernel loss: 0.03853\n",
      "Epoch: 24, series: 172, nllk loss: -2.11847, kernel loss: 0.06653\n",
      "Epoch: 24, series: 173, nllk loss: -2.54724, kernel loss: 0.05389\n",
      "Epoch: 24, series: 174, nllk loss: -2.32842, kernel loss: 0.18786\n",
      "Epoch: 24, series: 175, nllk loss: -2.58732, kernel loss: 0.04377\n",
      "Epoch: 24, series: 176, nllk loss: -2.08314, kernel loss: 0.08728\n",
      "Epoch: 24, series: 177, nllk loss: -2.07349, kernel loss: 0.01533\n",
      "Epoch: 24, series: 178, nllk loss: -1.77625, kernel loss: 0.07862\n",
      "Epoch: 24, series: 179, nllk loss: -2.19554, kernel loss: 0.16962\n",
      "Epoch: 24, series: 180, nllk loss: -2.47280, kernel loss: 0.06717\n",
      "Epoch: 24, series: 181, nllk loss: -2.66847, kernel loss: 0.07338\n",
      "Epoch: 24, series: 182, nllk loss: -2.36616, kernel loss: 0.12388\n",
      "Epoch: 24, series: 183, nllk loss: -2.06162, kernel loss: 0.09974\n",
      "Epoch: 24, series: 184, nllk loss: -2.04565, kernel loss: 0.08753\n",
      "Epoch: 24, series: 185, nllk loss: -1.71912, kernel loss: 0.09951\n",
      "Epoch: 24, series: 186, nllk loss: -2.70177, kernel loss: 0.00314\n",
      "Epoch: 24, series: 187, nllk loss: -2.78632, kernel loss: 0.19531\n",
      "Epoch: 24, series: 188, nllk loss: -1.67777, kernel loss: 0.00235\n",
      "Epoch: 24, series: 189, nllk loss: -1.46057, kernel loss: 0.03818\n",
      "Epoch: 24, series: 190, nllk loss: -2.25271, kernel loss: 0.15425\n",
      "Epoch: 24, series: 191, nllk loss: -2.11205, kernel loss: 0.16544\n",
      "Epoch: 24, series: 192, nllk loss: -2.19046, kernel loss: 0.21765\n",
      "Epoch: 24, series: 193, nllk loss: -1.58155, kernel loss: 0.07591\n",
      "Epoch: 24, series: 194, nllk loss: -1.52482, kernel loss: 0.14876\n",
      "Epoch: 24, series: 195, nllk loss: -2.31204, kernel loss: 0.05247\n",
      "Epoch: 24, series: 196, nllk loss: -1.94895, kernel loss: 0.01111\n",
      "Epoch: 24, series: 197, nllk loss: -2.23691, kernel loss: 0.11364\n",
      "Epoch: 24, series: 198, nllk loss: -2.33334, kernel loss: 0.06877\n",
      "Epoch: 24, series: 199, nllk loss: -2.00038, kernel loss: 0.09598\n",
      "Epoch: 24, series: 200, nllk loss: -2.34878, kernel loss: 0.09904\n",
      "Epoch: 24, series: 201, nllk loss: -2.36624, kernel loss: 0.11213\n",
      "Epoch: 24, series: 202, nllk loss: -2.17427, kernel loss: 0.08982\n",
      "Epoch: 24, series: 203, nllk loss: -1.89909, kernel loss: 0.07020\n",
      "Epoch: 24, series: 204, nllk loss: -1.15045, kernel loss: 0.04970\n",
      "Epoch: 24, series: 205, nllk loss: -2.19473, kernel loss: 0.13910\n",
      "Epoch: 24, series: 206, nllk loss: -2.27744, kernel loss: 0.04440\n",
      "Epoch: 24, series: 207, nllk loss: -0.83653, kernel loss: 0.05487\n",
      "Epoch: 24, series: 208, nllk loss: -2.46545, kernel loss: 0.05334\n",
      "Epoch: 24, series: 209, nllk loss: -1.88514, kernel loss: 0.01315\n",
      "Epoch: 24, series: 210, nllk loss: -2.72539, kernel loss: 0.17463\n",
      "Epoch: 24, series: 211, nllk loss: -2.14637, kernel loss: 0.10275\n",
      "Epoch: 24, series: 212, nllk loss: -1.19308, kernel loss: 0.02897\n",
      "Epoch: 24, series: 213, nllk loss: -2.21856, kernel loss: 0.12254\n",
      "Epoch: 24, series: 214, nllk loss: -2.10458, kernel loss: 0.16918\n",
      "Epoch: 24, series: 215, nllk loss: -2.44739, kernel loss: 0.02081\n",
      "Epoch: 24, series: 216, nllk loss: -1.44879, kernel loss: 0.17725\n",
      "Epoch: 24, series: 217, nllk loss: -2.01176, kernel loss: 0.20690\n",
      "Epoch: 24, series: 218, nllk loss: -1.61682, kernel loss: 0.06231\n",
      "Epoch: 24, series: 219, nllk loss: -2.19812, kernel loss: 0.19398\n",
      "Epoch: 24, series: 220, nllk loss: -2.16501, kernel loss: 0.06684\n",
      "Epoch: 24, series: 221, nllk loss: -2.47094, kernel loss: 0.03619\n",
      "Epoch: 24, series: 222, nllk loss: -2.22934, kernel loss: 0.14682\n",
      "Epoch: 24, series: 223, nllk loss: -1.62672, kernel loss: 0.05536\n",
      "Epoch: 24, series: 224, nllk loss: -2.52139, kernel loss: 0.06953\n",
      "Epoch: 24, series: 225, nllk loss: -2.38033, kernel loss: 0.12100\n",
      "Epoch: 24, series: 226, nllk loss: -1.95256, kernel loss: 0.04306\n",
      "Epoch: 24, series: 227, nllk loss: -2.07479, kernel loss: 0.15237\n",
      "Epoch: 24, series: 228, nllk loss: -2.20218, kernel loss: 0.31377\n",
      "Epoch: 24, series: 229, nllk loss: -2.02752, kernel loss: 0.38666\n",
      "Epoch: 24, series: 230, nllk loss: -2.51588, kernel loss: 0.03498\n",
      "Epoch: 24, series: 231, nllk loss: -2.03123, kernel loss: 0.31779\n",
      "Epoch: 24, series: 232, nllk loss: -2.61470, kernel loss: 0.18941\n",
      "Epoch: 24, series: 233, nllk loss: -2.49821, kernel loss: 0.18860\n",
      "Epoch: 24, series: 234, nllk loss: -2.12203, kernel loss: 0.09444\n",
      "Epoch: 24, series: 235, nllk loss: -2.67995, kernel loss: 0.05151\n",
      "Epoch: 24, series: 236, nllk loss: -1.66073, kernel loss: 0.11486\n",
      "Epoch: 24, series: 237, nllk loss: -2.23841, kernel loss: 0.07591\n",
      "Epoch: 24, series: 238, nllk loss: -1.94276, kernel loss: 0.25343\n",
      "Epoch: 24, series: 239, nllk loss: -2.24744, kernel loss: 0.13898\n",
      "Epoch: 24, series: 240, nllk loss: -1.26591, kernel loss: 0.23889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24, series: 241, nllk loss: -2.06612, kernel loss: 0.05909\n",
      "Epoch: 24, series: 242, nllk loss: -2.15503, kernel loss: 0.27694\n",
      "Epoch: 24, series: 243, nllk loss: -2.41594, kernel loss: 0.17382\n",
      "Epoch: 24, series: 244, nllk loss: -2.08281, kernel loss: 0.07389\n",
      "Epoch: 24, series: 245, nllk loss: -2.14098, kernel loss: 0.04909\n",
      "Epoch: 24, series: 246, nllk loss: -0.43136, kernel loss: 0.01669\n",
      "Epoch: 24, series: 247, nllk loss: -1.79775, kernel loss: 0.07531\n",
      "Epoch: 24, series: 248, nllk loss: -2.17126, kernel loss: 0.16998\n",
      "Epoch: 24, series: 249, nllk loss: -2.10993, kernel loss: 0.21751\n",
      "Epoch: 24, series: 250, nllk loss: -1.70203, kernel loss: 0.08447\n",
      "Epoch: 24, series: 251, nllk loss: -1.23664, kernel loss: 0.05735\n",
      "Epoch: 24, series: 252, nllk loss: -1.55496, kernel loss: 0.11082\n",
      "Epoch: 24, series: 253, nllk loss: -1.78344, kernel loss: 0.04369\n",
      "Epoch: 24, series: 254, nllk loss: -2.29777, kernel loss: 0.08689\n",
      "Epoch: 24, series: 255, nllk loss: -2.15251, kernel loss: 0.10564\n",
      "Epoch: 24, series: 256, nllk loss: -1.89609, kernel loss: 0.06904\n",
      "Epoch: 24, series: 257, nllk loss: -2.11016, kernel loss: 0.09888\n",
      "Epoch: 24, series: 258, nllk loss: -2.20609, kernel loss: 0.22875\n",
      "Epoch: 24, series: 259, nllk loss: -1.87545, kernel loss: 0.10569\n",
      "Epoch: 24, series: 260, nllk loss: -1.99067, kernel loss: 0.11765\n",
      "Epoch: 24, series: 261, nllk loss: -2.26317, kernel loss: 0.09649\n",
      "Epoch: 24, series: 262, nllk loss: -2.68972, kernel loss: 0.18007\n",
      "Epoch: 24, series: 263, nllk loss: -0.69184, kernel loss: 0.10443\n",
      "Epoch: 24, series: 264, nllk loss: -2.00543, kernel loss: 0.03647\n",
      "Epoch: 24, series: 265, nllk loss: -1.75929, kernel loss: 0.08225\n",
      "Epoch: 24, series: 266, nllk loss: -2.39483, kernel loss: 0.10794\n",
      "Epoch: 24, series: 267, nllk loss: -2.05530, kernel loss: 0.02097\n",
      "Epoch: 24, series: 268, nllk loss: -2.11647, kernel loss: 0.10024\n",
      "Epoch: 24, series: 269, nllk loss: -1.91085, kernel loss: 0.13065\n",
      "Epoch: 24, series: 270, nllk loss: -1.91305, kernel loss: 0.05250\n",
      "Epoch: 24, series: 271, nllk loss: -2.04653, kernel loss: 0.02678\n",
      "Epoch: 24, series: 272, nllk loss: -1.80524, kernel loss: 0.19940\n",
      "Epoch: 24, series: 273, nllk loss: -1.98920, kernel loss: 0.10471\n",
      "Epoch: 24, series: 274, nllk loss: -1.62350, kernel loss: 0.00706\n",
      "Epoch: 24, series: 275, nllk loss: -1.95449, kernel loss: 0.14393\n",
      "Epoch: 24, series: 276, nllk loss: -1.37839, kernel loss: 0.19189\n",
      "Epoch: 24, series: 277, nllk loss: -2.30009, kernel loss: 0.10496\n",
      "Epoch: 24, series: 278, nllk loss: -1.82148, kernel loss: 0.05885\n",
      "Epoch: 24, series: 279, nllk loss: -2.35710, kernel loss: 0.03499\n",
      "Epoch: 24, series: 280, nllk loss: -2.14747, kernel loss: 0.21161\n",
      "Epoch: 24, series: 281, nllk loss: -2.43506, kernel loss: 0.00348\n",
      "Epoch: 24, series: 282, nllk loss: -2.27411, kernel loss: 0.01393\n",
      "Epoch: 24, series: 283, nllk loss: -2.16981, kernel loss: 0.04193\n",
      "Epoch: 24, series: 284, nllk loss: -1.68610, kernel loss: 0.07033\n",
      "Epoch: 24, series: 285, nllk loss: -1.89986, kernel loss: 0.08137\n",
      "Epoch: 24, series: 286, nllk loss: -2.03774, kernel loss: 0.12922\n",
      "Epoch: 24, series: 287, nllk loss: -2.51370, kernel loss: 0.01554\n",
      "Epoch: 24, series: 288, nllk loss: -1.23320, kernel loss: 0.26942\n",
      "Epoch: 24, series: 289, nllk loss: -1.09282, kernel loss: 0.15275\n",
      "Epoch: 24, series: 290, nllk loss: -2.28519, kernel loss: 0.07174\n",
      "Epoch: 24, series: 291, nllk loss: -2.30955, kernel loss: 0.06525\n",
      "Epoch: 24, series: 292, nllk loss: -2.20275, kernel loss: 0.07761\n",
      "Epoch: 24, series: 293, nllk loss: -2.32850, kernel loss: 0.09602\n",
      "Epoch: 24, series: 294, nllk loss: -1.12789, kernel loss: 0.15404\n",
      "Epoch: 24, series: 295, nllk loss: -1.28685, kernel loss: 0.03832\n",
      "Epoch: 24, series: 296, nllk loss: -2.56923, kernel loss: 0.20939\n",
      "Epoch: 24, series: 297, nllk loss: -2.64383, kernel loss: 0.12945\n",
      "Epoch: 24, series: 298, nllk loss: 0.00716, kernel loss: 0.03935\n",
      "Epoch: 24, series: 299, nllk loss: -0.77073, kernel loss: 0.07949\n",
      "Epoch: 24, series: 300, nllk loss: -2.20403, kernel loss: 0.03504\n",
      "Epoch: 24, series: 301, nllk loss: -2.48184, kernel loss: 0.08653\n",
      "Epoch: 24, series: 302, nllk loss: -2.32320, kernel loss: 0.09822\n",
      "Epoch: 24, series: 303, nllk loss: -1.99385, kernel loss: 0.10276\n",
      "Epoch: 24, series: 304, nllk loss: -0.21913, kernel loss: 0.17848\n",
      "Epoch: 24, series: 305, nllk loss: -2.02988, kernel loss: 0.13381\n",
      "Epoch: 24, series: 306, nllk loss: -2.46681, kernel loss: 0.05537\n",
      "Epoch: 24, series: 307, nllk loss: -1.74075, kernel loss: 0.23885\n",
      "Epoch: 24, series: 308, nllk loss: -2.44574, kernel loss: 0.24394\n",
      "Epoch: 24, series: 309, nllk loss: -1.98615, kernel loss: 0.08208\n",
      "Epoch: 24, series: 310, nllk loss: -2.49889, kernel loss: 0.12028\n",
      "Epoch: 24, series: 311, nllk loss: -1.98881, kernel loss: 0.08054\n",
      "Epoch: 24, series: 312, nllk loss: -2.23113, kernel loss: 0.22231\n",
      "Epoch: 24, series: 313, nllk loss: -2.38039, kernel loss: 0.08983\n",
      "Epoch: 24, series: 314, nllk loss: -2.90011, kernel loss: 0.01526\n",
      "Epoch: 24, series: 315, nllk loss: -0.95576, kernel loss: 0.14600\n",
      "Epoch: 24, series: 316, nllk loss: -2.20618, kernel loss: 0.12530\n",
      "Epoch: 24, series: 317, nllk loss: 0.28205, kernel loss: 0.16640\n",
      "Epoch: 24, series: 318, nllk loss: 0.84714, kernel loss: 0.05147\n",
      "Epoch: 24, series: 319, nllk loss: -1.18237, kernel loss: 0.27008\n",
      "Epoch: 24, series: 320, nllk loss: -0.84518, kernel loss: 0.22157\n",
      "Epoch: 24, total loss: -501.69857\n",
      "Epoch: 25, series: 0, nllk loss: 0.97234, kernel loss: 0.07662\n",
      "Epoch: 25, series: 1, nllk loss: -1.19966, kernel loss: 0.16015\n",
      "Epoch: 25, series: 2, nllk loss: -0.03806, kernel loss: 0.27667\n",
      "Epoch: 25, series: 3, nllk loss: -1.30635, kernel loss: 0.08253\n",
      "Epoch: 25, series: 4, nllk loss: -0.99327, kernel loss: 0.47737\n",
      "Epoch: 25, series: 5, nllk loss: -1.37639, kernel loss: 0.11811\n",
      "Epoch: 25, series: 6, nllk loss: -0.65434, kernel loss: 0.03766\n",
      "Epoch: 25, series: 7, nllk loss: -1.21482, kernel loss: 0.18775\n",
      "Epoch: 25, series: 8, nllk loss: -0.51850, kernel loss: 0.11926\n",
      "Epoch: 25, series: 9, nllk loss: -0.65974, kernel loss: 0.22881\n",
      "Epoch: 25, series: 10, nllk loss: -1.27251, kernel loss: 0.20605\n",
      "Epoch: 25, series: 11, nllk loss: -1.25893, kernel loss: 0.22438\n",
      "Epoch: 25, series: 12, nllk loss: -1.59256, kernel loss: 0.00494\n",
      "Epoch: 25, series: 13, nllk loss: -1.47739, kernel loss: 0.21264\n",
      "Epoch: 25, series: 14, nllk loss: -1.68943, kernel loss: 0.19828\n",
      "Epoch: 25, series: 15, nllk loss: -1.65687, kernel loss: 0.10006\n",
      "Epoch: 25, series: 16, nllk loss: -1.19903, kernel loss: 0.09910\n",
      "Epoch: 25, series: 17, nllk loss: -1.28430, kernel loss: 0.10740\n",
      "Epoch: 25, series: 18, nllk loss: -1.39677, kernel loss: 0.11606\n",
      "Epoch: 25, series: 19, nllk loss: -0.30485, kernel loss: 0.28897\n",
      "Epoch: 25, series: 20, nllk loss: -0.78932, kernel loss: 0.11874\n",
      "Epoch: 25, series: 21, nllk loss: -1.17194, kernel loss: 0.16581\n",
      "Epoch: 25, series: 22, nllk loss: -1.59908, kernel loss: 0.06350\n",
      "Epoch: 25, series: 23, nllk loss: -1.57011, kernel loss: 0.17378\n",
      "Epoch: 25, series: 24, nllk loss: -1.85819, kernel loss: 0.01588\n",
      "Epoch: 25, series: 25, nllk loss: -1.75617, kernel loss: 0.16640\n",
      "Epoch: 25, series: 26, nllk loss: -1.45874, kernel loss: 0.06154\n",
      "Epoch: 25, series: 27, nllk loss: -1.32968, kernel loss: 0.10218\n",
      "Epoch: 25, series: 28, nllk loss: -1.46732, kernel loss: 0.16236\n",
      "Epoch: 25, series: 29, nllk loss: -0.97695, kernel loss: 0.07140\n",
      "Epoch: 25, series: 30, nllk loss: -1.51164, kernel loss: 0.05317\n",
      "Epoch: 25, series: 31, nllk loss: -1.16264, kernel loss: 0.18269\n",
      "Epoch: 25, series: 32, nllk loss: -1.17329, kernel loss: 0.12677\n",
      "Epoch: 25, series: 33, nllk loss: -1.02340, kernel loss: 0.11707\n",
      "Epoch: 25, series: 34, nllk loss: -1.50653, kernel loss: 0.09694\n",
      "Epoch: 25, series: 35, nllk loss: -1.72062, kernel loss: 0.13207\n",
      "Epoch: 25, series: 36, nllk loss: -1.72022, kernel loss: 0.08051\n",
      "Epoch: 25, series: 37, nllk loss: -0.68342, kernel loss: 0.22564\n",
      "Epoch: 25, series: 38, nllk loss: -1.09326, kernel loss: 0.10487\n",
      "Epoch: 25, series: 39, nllk loss: -0.76741, kernel loss: 0.11601\n",
      "Epoch: 25, series: 40, nllk loss: -1.97135, kernel loss: 0.07628\n",
      "Epoch: 25, series: 41, nllk loss: -1.39754, kernel loss: 0.06799\n",
      "Epoch: 25, series: 42, nllk loss: -1.12776, kernel loss: 0.17341\n",
      "Epoch: 25, series: 43, nllk loss: -1.16409, kernel loss: 0.03404\n",
      "Epoch: 25, series: 44, nllk loss: -1.67692, kernel loss: 0.16882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, series: 45, nllk loss: -1.81691, kernel loss: 0.03602\n",
      "Epoch: 25, series: 46, nllk loss: -1.82640, kernel loss: 0.12170\n",
      "Epoch: 25, series: 47, nllk loss: -1.65126, kernel loss: 0.07604\n",
      "Epoch: 25, series: 48, nllk loss: -1.68591, kernel loss: 0.11298\n",
      "Epoch: 25, series: 49, nllk loss: -1.12048, kernel loss: 0.28373\n",
      "Epoch: 25, series: 50, nllk loss: -0.13615, kernel loss: 0.18854\n",
      "Epoch: 25, series: 51, nllk loss: -1.34081, kernel loss: 0.12142\n",
      "Epoch: 25, series: 52, nllk loss: -0.48381, kernel loss: 0.09506\n",
      "Epoch: 25, series: 53, nllk loss: -1.64374, kernel loss: 0.03210\n",
      "Epoch: 25, series: 54, nllk loss: -1.33866, kernel loss: 0.10627\n",
      "Epoch: 25, series: 55, nllk loss: -0.87656, kernel loss: 0.12385\n",
      "Epoch: 25, series: 56, nllk loss: -1.41008, kernel loss: 0.08502\n",
      "Epoch: 25, series: 57, nllk loss: -1.39477, kernel loss: 0.02981\n",
      "Epoch: 25, series: 58, nllk loss: -1.51487, kernel loss: 0.02467\n",
      "Epoch: 25, series: 59, nllk loss: -1.33764, kernel loss: 0.03841\n",
      "Epoch: 25, series: 60, nllk loss: -1.07856, kernel loss: 0.17950\n",
      "Epoch: 25, series: 61, nllk loss: -1.79828, kernel loss: 0.24266\n",
      "Epoch: 25, series: 62, nllk loss: -1.84632, kernel loss: 0.06609\n",
      "Epoch: 25, series: 63, nllk loss: -1.74544, kernel loss: 0.01506\n",
      "Epoch: 25, series: 64, nllk loss: -1.30826, kernel loss: 0.00000\n",
      "Epoch: 25, series: 65, nllk loss: -1.75853, kernel loss: 0.19273\n",
      "Epoch: 25, series: 66, nllk loss: -1.69903, kernel loss: 0.00000\n",
      "Epoch: 25, series: 67, nllk loss: -1.48727, kernel loss: 0.09962\n",
      "Epoch: 25, series: 68, nllk loss: -0.91483, kernel loss: 0.09495\n",
      "Epoch: 25, series: 69, nllk loss: -1.63942, kernel loss: 0.08393\n",
      "Epoch: 25, series: 70, nllk loss: -1.41858, kernel loss: 0.15336\n",
      "Epoch: 25, series: 71, nllk loss: -1.51726, kernel loss: 0.02926\n",
      "Epoch: 25, series: 72, nllk loss: -1.93213, kernel loss: 0.03682\n",
      "Epoch: 25, series: 73, nllk loss: -1.41800, kernel loss: 0.12550\n",
      "Epoch: 25, series: 74, nllk loss: -2.16620, kernel loss: 0.13559\n",
      "Epoch: 25, series: 75, nllk loss: -1.74352, kernel loss: 0.08298\n",
      "Epoch: 25, series: 76, nllk loss: -1.45752, kernel loss: 0.03325\n",
      "Epoch: 25, series: 77, nllk loss: -1.41151, kernel loss: 0.04935\n",
      "Epoch: 25, series: 78, nllk loss: -1.45789, kernel loss: 0.08212\n",
      "Epoch: 25, series: 79, nllk loss: -0.32740, kernel loss: 0.09716\n",
      "Epoch: 25, series: 80, nllk loss: -1.84836, kernel loss: 0.05906\n",
      "Epoch: 25, series: 81, nllk loss: -1.63088, kernel loss: 0.07688\n",
      "Epoch: 25, series: 82, nllk loss: -0.49700, kernel loss: 0.02513\n",
      "Epoch: 25, series: 83, nllk loss: -1.32972, kernel loss: 0.15850\n",
      "Epoch: 25, series: 84, nllk loss: -1.37120, kernel loss: 0.04868\n",
      "Epoch: 25, series: 85, nllk loss: -1.68017, kernel loss: 0.05708\n",
      "Epoch: 25, series: 86, nllk loss: -0.98725, kernel loss: 0.08790\n",
      "Epoch: 25, series: 87, nllk loss: -1.96318, kernel loss: 0.04298\n",
      "Epoch: 25, series: 88, nllk loss: -2.15690, kernel loss: 0.03844\n",
      "Epoch: 25, series: 89, nllk loss: -1.94375, kernel loss: 0.34761\n",
      "Epoch: 25, series: 90, nllk loss: -2.27090, kernel loss: 0.04011\n",
      "Epoch: 25, series: 91, nllk loss: -2.20295, kernel loss: 0.11284\n",
      "Epoch: 25, series: 92, nllk loss: -0.16545, kernel loss: 0.23383\n",
      "Epoch: 25, series: 93, nllk loss: -2.63941, kernel loss: 0.10629\n",
      "Epoch: 25, series: 94, nllk loss: -2.55765, kernel loss: 0.18095\n",
      "Epoch: 25, series: 95, nllk loss: -2.50410, kernel loss: 0.15480\n",
      "Epoch: 25, series: 96, nllk loss: -1.81820, kernel loss: 0.02878\n",
      "Epoch: 25, series: 97, nllk loss: -0.68194, kernel loss: 0.13615\n",
      "Epoch: 25, series: 98, nllk loss: -0.60631, kernel loss: 0.03887\n",
      "Epoch: 25, series: 99, nllk loss: -1.52442, kernel loss: 0.01833\n",
      "Epoch: 25, series: 100, nllk loss: -0.87557, kernel loss: 0.26240\n",
      "Epoch: 25, series: 101, nllk loss: -1.41729, kernel loss: 0.08666\n",
      "Epoch: 25, series: 102, nllk loss: -0.62680, kernel loss: 0.10540\n",
      "Epoch: 25, series: 103, nllk loss: -1.10511, kernel loss: 0.07656\n",
      "Epoch: 25, series: 104, nllk loss: -0.11757, kernel loss: 0.13392\n",
      "Epoch: 25, series: 105, nllk loss: -0.52701, kernel loss: 0.10624\n",
      "Epoch: 25, series: 106, nllk loss: -1.19967, kernel loss: 0.17514\n",
      "Epoch: 25, series: 107, nllk loss: -1.13421, kernel loss: 0.13366\n",
      "Epoch: 25, series: 108, nllk loss: -1.36865, kernel loss: 0.11369\n",
      "Epoch: 25, series: 109, nllk loss: -1.16193, kernel loss: 0.07944\n",
      "Epoch: 25, series: 110, nllk loss: -1.70989, kernel loss: 0.08085\n",
      "Epoch: 25, series: 111, nllk loss: -1.54215, kernel loss: 0.16397\n",
      "Epoch: 25, series: 112, nllk loss: -0.94808, kernel loss: 0.05490\n",
      "Epoch: 25, series: 113, nllk loss: -1.23166, kernel loss: 0.06931\n",
      "Epoch: 25, series: 114, nllk loss: -1.22244, kernel loss: 0.02709\n",
      "Epoch: 25, series: 115, nllk loss: -1.14205, kernel loss: 0.11063\n",
      "Epoch: 25, series: 116, nllk loss: -1.61578, kernel loss: 0.01556\n",
      "Epoch: 25, series: 117, nllk loss: -0.65918, kernel loss: 0.05305\n",
      "Epoch: 25, series: 118, nllk loss: -1.92663, kernel loss: 0.06625\n",
      "Epoch: 25, series: 119, nllk loss: -0.74698, kernel loss: 0.04912\n",
      "Epoch: 25, series: 120, nllk loss: -1.60345, kernel loss: 0.10485\n",
      "Epoch: 25, series: 121, nllk loss: -0.03230, kernel loss: 0.27113\n",
      "Epoch: 25, series: 122, nllk loss: -0.68070, kernel loss: 0.17532\n",
      "Epoch: 25, series: 123, nllk loss: -1.96232, kernel loss: 0.05542\n",
      "Epoch: 25, series: 124, nllk loss: -2.09304, kernel loss: 0.13008\n",
      "Epoch: 25, series: 125, nllk loss: -1.32746, kernel loss: 0.08325\n",
      "Epoch: 25, series: 126, nllk loss: -1.99270, kernel loss: 0.02596\n",
      "Epoch: 25, series: 127, nllk loss: -1.40013, kernel loss: 0.03833\n",
      "Epoch: 25, series: 128, nllk loss: -1.00731, kernel loss: 0.06596\n",
      "Epoch: 25, series: 129, nllk loss: -0.81044, kernel loss: 0.00000\n",
      "Epoch: 25, series: 130, nllk loss: -1.54755, kernel loss: 0.08508\n",
      "Epoch: 25, series: 131, nllk loss: 0.32539, kernel loss: 0.02280\n",
      "Epoch: 25, series: 132, nllk loss: -0.24223, kernel loss: 0.11938\n",
      "Epoch: 25, series: 133, nllk loss: -1.07841, kernel loss: 0.09725\n",
      "Epoch: 25, series: 134, nllk loss: -0.81562, kernel loss: 0.10892\n",
      "Epoch: 25, series: 135, nllk loss: -1.65135, kernel loss: 0.15945\n",
      "Epoch: 25, series: 136, nllk loss: -1.76571, kernel loss: 0.22613\n",
      "Epoch: 25, series: 137, nllk loss: -1.88024, kernel loss: 0.09526\n",
      "Epoch: 25, series: 138, nllk loss: -1.91498, kernel loss: 0.06915\n",
      "Epoch: 25, series: 139, nllk loss: -1.80644, kernel loss: 0.12227\n",
      "Epoch: 25, series: 140, nllk loss: -1.52513, kernel loss: 0.05527\n",
      "Epoch: 25, series: 141, nllk loss: -1.86168, kernel loss: 0.14740\n",
      "Epoch: 25, series: 142, nllk loss: -1.96914, kernel loss: 0.05306\n",
      "Epoch: 25, series: 143, nllk loss: -1.82097, kernel loss: 0.10172\n",
      "Epoch: 25, series: 144, nllk loss: -2.18508, kernel loss: 0.03139\n",
      "Epoch: 25, series: 145, nllk loss: -1.89239, kernel loss: 0.16406\n",
      "Epoch: 25, series: 146, nllk loss: 1.18587, kernel loss: 0.21690\n",
      "Epoch: 25, series: 147, nllk loss: -1.78783, kernel loss: 0.10339\n",
      "Epoch: 25, series: 148, nllk loss: -1.44025, kernel loss: 0.22623\n",
      "Epoch: 25, series: 149, nllk loss: -1.92033, kernel loss: 0.06204\n",
      "Epoch: 25, series: 150, nllk loss: -2.01607, kernel loss: 0.08650\n",
      "Epoch: 25, series: 151, nllk loss: -2.11556, kernel loss: 0.13228\n",
      "Epoch: 25, series: 152, nllk loss: -2.10445, kernel loss: 0.01224\n",
      "Epoch: 25, series: 153, nllk loss: -1.74021, kernel loss: 0.03720\n",
      "Epoch: 25, series: 154, nllk loss: -1.83556, kernel loss: 0.08834\n",
      "Epoch: 25, series: 155, nllk loss: -2.01038, kernel loss: 0.03447\n",
      "Epoch: 25, series: 156, nllk loss: -2.12869, kernel loss: 0.10106\n",
      "Epoch: 25, series: 157, nllk loss: -1.65365, kernel loss: 0.11676\n",
      "Epoch: 25, series: 158, nllk loss: -2.09659, kernel loss: 0.01758\n",
      "Epoch: 25, series: 159, nllk loss: -2.16769, kernel loss: 0.03891\n",
      "Epoch: 25, series: 160, nllk loss: -2.00209, kernel loss: 0.16655\n",
      "Epoch: 25, series: 161, nllk loss: -1.86491, kernel loss: 0.00801\n",
      "Epoch: 25, series: 162, nllk loss: -2.24654, kernel loss: 0.07996\n",
      "Epoch: 25, series: 163, nllk loss: -2.43251, kernel loss: 0.18487\n",
      "Epoch: 25, series: 164, nllk loss: -1.83404, kernel loss: 0.01144\n",
      "Epoch: 25, series: 165, nllk loss: -1.99398, kernel loss: 0.06047\n",
      "Epoch: 25, series: 166, nllk loss: -1.38538, kernel loss: 0.05016\n",
      "Epoch: 25, series: 167, nllk loss: -2.69255, kernel loss: 0.06843\n",
      "Epoch: 25, series: 168, nllk loss: -2.15873, kernel loss: 0.06226\n",
      "Epoch: 25, series: 169, nllk loss: -2.38991, kernel loss: 0.11276\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, series: 170, nllk loss: -2.06844, kernel loss: 0.06250\n",
      "Epoch: 25, series: 171, nllk loss: -2.56497, kernel loss: 0.18764\n",
      "Epoch: 25, series: 172, nllk loss: -2.14012, kernel loss: 0.12235\n",
      "Epoch: 25, series: 173, nllk loss: -2.58994, kernel loss: 0.06060\n",
      "Epoch: 25, series: 174, nllk loss: -2.32851, kernel loss: 0.04715\n",
      "Epoch: 25, series: 175, nllk loss: -2.63680, kernel loss: 0.06001\n",
      "Epoch: 25, series: 176, nllk loss: -1.98343, kernel loss: 0.10438\n",
      "Epoch: 25, series: 177, nllk loss: -2.10384, kernel loss: 0.06662\n",
      "Epoch: 25, series: 178, nllk loss: -1.78046, kernel loss: 0.07767\n",
      "Epoch: 25, series: 179, nllk loss: -2.20179, kernel loss: 0.02020\n",
      "Epoch: 25, series: 180, nllk loss: -2.40505, kernel loss: 0.03644\n",
      "Epoch: 25, series: 181, nllk loss: -2.61455, kernel loss: 0.21915\n",
      "Epoch: 25, series: 182, nllk loss: -2.33654, kernel loss: 0.17307\n",
      "Epoch: 25, series: 183, nllk loss: -2.07220, kernel loss: 0.07158\n",
      "Epoch: 25, series: 184, nllk loss: -2.09661, kernel loss: 0.15767\n",
      "Epoch: 25, series: 185, nllk loss: -1.75268, kernel loss: 0.05976\n",
      "Epoch: 25, series: 186, nllk loss: -2.69737, kernel loss: 0.04552\n",
      "Epoch: 25, series: 187, nllk loss: -2.81731, kernel loss: 0.11190\n",
      "Epoch: 25, series: 188, nllk loss: -1.62009, kernel loss: 0.06345\n",
      "Epoch: 25, series: 189, nllk loss: -1.45243, kernel loss: 0.10306\n",
      "Epoch: 25, series: 190, nllk loss: -2.28739, kernel loss: 0.14363\n",
      "Epoch: 25, series: 191, nllk loss: -2.11282, kernel loss: 0.14253\n",
      "Epoch: 25, series: 192, nllk loss: -2.18083, kernel loss: 0.10116\n",
      "Epoch: 25, series: 193, nllk loss: -1.50324, kernel loss: 0.24452\n",
      "Epoch: 25, series: 194, nllk loss: -1.51796, kernel loss: 0.17340\n",
      "Epoch: 25, series: 195, nllk loss: -2.31961, kernel loss: 0.05042\n",
      "Epoch: 25, series: 196, nllk loss: -1.97176, kernel loss: 0.02386\n",
      "Epoch: 25, series: 197, nllk loss: -2.25234, kernel loss: 0.05903\n",
      "Epoch: 25, series: 198, nllk loss: -2.33652, kernel loss: 0.04754\n",
      "Epoch: 25, series: 199, nllk loss: -2.05622, kernel loss: 0.15478\n",
      "Epoch: 25, series: 200, nllk loss: -2.37858, kernel loss: 0.08086\n",
      "Epoch: 25, series: 201, nllk loss: -2.38917, kernel loss: 0.11288\n",
      "Epoch: 25, series: 202, nllk loss: -2.11364, kernel loss: 0.11963\n",
      "Epoch: 25, series: 203, nllk loss: -1.81058, kernel loss: 0.12323\n",
      "Epoch: 25, series: 204, nllk loss: -0.90334, kernel loss: 0.04689\n",
      "Epoch: 25, series: 205, nllk loss: -2.21701, kernel loss: 0.13715\n",
      "Epoch: 25, series: 206, nllk loss: -2.25115, kernel loss: 0.04590\n",
      "Epoch: 25, series: 207, nllk loss: -0.97724, kernel loss: 0.03596\n",
      "Epoch: 25, series: 208, nllk loss: -2.32012, kernel loss: 0.15154\n",
      "Epoch: 25, series: 209, nllk loss: -1.81732, kernel loss: 0.20866\n",
      "Epoch: 25, series: 210, nllk loss: -2.66600, kernel loss: 0.13577\n",
      "Epoch: 25, series: 211, nllk loss: -2.19372, kernel loss: 0.27665\n",
      "Epoch: 25, series: 212, nllk loss: -1.52872, kernel loss: 0.17257\n",
      "Epoch: 25, series: 213, nllk loss: -2.26460, kernel loss: 0.12391\n",
      "Epoch: 25, series: 214, nllk loss: -2.27374, kernel loss: 0.04140\n",
      "Epoch: 25, series: 215, nllk loss: -2.72460, kernel loss: 0.06385\n",
      "Epoch: 25, series: 216, nllk loss: -1.37445, kernel loss: 0.15016\n",
      "Epoch: 25, series: 217, nllk loss: -2.09665, kernel loss: 0.17108\n",
      "Epoch: 25, series: 218, nllk loss: -1.48878, kernel loss: 0.01470\n",
      "Epoch: 25, series: 219, nllk loss: -2.21912, kernel loss: 0.16081\n",
      "Epoch: 25, series: 220, nllk loss: -2.25558, kernel loss: 0.18339\n",
      "Epoch: 25, series: 221, nllk loss: -2.58550, kernel loss: 0.17166\n",
      "Epoch: 25, series: 222, nllk loss: -2.25428, kernel loss: 0.06280\n",
      "Epoch: 25, series: 223, nllk loss: -1.58839, kernel loss: 0.10264\n",
      "Epoch: 25, series: 224, nllk loss: -2.56311, kernel loss: 0.07979\n",
      "Epoch: 25, series: 225, nllk loss: -2.44700, kernel loss: 0.01283\n",
      "Epoch: 25, series: 226, nllk loss: -1.93938, kernel loss: 0.10073\n",
      "Epoch: 25, series: 227, nllk loss: -2.06349, kernel loss: 0.16822\n",
      "Epoch: 25, series: 228, nllk loss: -2.16422, kernel loss: 0.10619\n",
      "Epoch: 25, series: 229, nllk loss: -1.95732, kernel loss: 0.11231\n",
      "Epoch: 25, series: 230, nllk loss: -2.50494, kernel loss: 0.06886\n",
      "Epoch: 25, series: 231, nllk loss: -1.93265, kernel loss: 0.12434\n",
      "Epoch: 25, series: 232, nllk loss: -2.65321, kernel loss: 0.04708\n",
      "Epoch: 25, series: 233, nllk loss: -2.50446, kernel loss: 0.06607\n",
      "Epoch: 25, series: 234, nllk loss: -2.03593, kernel loss: 0.26396\n",
      "Epoch: 25, series: 235, nllk loss: -2.72801, kernel loss: 0.09882\n",
      "Epoch: 25, series: 236, nllk loss: -1.60744, kernel loss: 0.17422\n",
      "Epoch: 25, series: 237, nllk loss: -2.23206, kernel loss: 0.17310\n",
      "Epoch: 25, series: 238, nllk loss: -2.05856, kernel loss: 0.15634\n",
      "Epoch: 25, series: 239, nllk loss: -2.36452, kernel loss: 0.10611\n",
      "Epoch: 25, series: 240, nllk loss: -0.95115, kernel loss: 0.05304\n",
      "Epoch: 25, series: 241, nllk loss: -2.08189, kernel loss: 0.04626\n",
      "Epoch: 25, series: 242, nllk loss: -2.18375, kernel loss: 0.03549\n",
      "Epoch: 25, series: 243, nllk loss: -2.39924, kernel loss: 0.05641\n",
      "Epoch: 25, series: 244, nllk loss: -2.04000, kernel loss: 0.04786\n",
      "Epoch: 25, series: 245, nllk loss: -2.14999, kernel loss: 0.04361\n",
      "Epoch: 25, series: 246, nllk loss: -0.50654, kernel loss: 0.01861\n",
      "Epoch: 25, series: 247, nllk loss: -1.82909, kernel loss: 0.06948\n",
      "Epoch: 25, series: 248, nllk loss: -2.23152, kernel loss: 0.04328\n",
      "Epoch: 25, series: 249, nllk loss: -2.11878, kernel loss: 0.09785\n",
      "Epoch: 25, series: 250, nllk loss: -1.68186, kernel loss: 0.16805\n",
      "Epoch: 25, series: 251, nllk loss: -1.28818, kernel loss: 0.05219\n",
      "Epoch: 25, series: 252, nllk loss: -1.50080, kernel loss: 0.06614\n",
      "Epoch: 25, series: 253, nllk loss: -1.83266, kernel loss: 0.12746\n",
      "Epoch: 25, series: 254, nllk loss: -2.34020, kernel loss: 0.06996\n",
      "Epoch: 25, series: 255, nllk loss: -2.16053, kernel loss: 0.08011\n",
      "Epoch: 25, series: 256, nllk loss: -1.87388, kernel loss: 0.24994\n",
      "Epoch: 25, series: 257, nllk loss: -2.15300, kernel loss: 0.08433\n",
      "Epoch: 25, series: 258, nllk loss: -2.20757, kernel loss: 0.12461\n",
      "Epoch: 25, series: 259, nllk loss: -1.93935, kernel loss: 0.23037\n",
      "Epoch: 25, series: 260, nllk loss: -2.02489, kernel loss: 0.03299\n",
      "Epoch: 25, series: 261, nllk loss: -2.19786, kernel loss: 0.13814\n",
      "Epoch: 25, series: 262, nllk loss: -2.68760, kernel loss: 0.06402\n",
      "Epoch: 25, series: 263, nllk loss: -0.69328, kernel loss: 0.06546\n",
      "Epoch: 25, series: 264, nllk loss: -2.00137, kernel loss: 0.09710\n",
      "Epoch: 25, series: 265, nllk loss: -1.89675, kernel loss: 0.07771\n",
      "Epoch: 25, series: 266, nllk loss: -2.38495, kernel loss: 0.14844\n",
      "Epoch: 25, series: 267, nllk loss: -2.07563, kernel loss: 0.03832\n",
      "Epoch: 25, series: 268, nllk loss: -2.07345, kernel loss: 0.22773\n",
      "Epoch: 25, series: 269, nllk loss: -1.86131, kernel loss: 0.05115\n",
      "Epoch: 25, series: 270, nllk loss: -1.97566, kernel loss: 0.03518\n",
      "Epoch: 25, series: 271, nllk loss: -2.06717, kernel loss: 0.15776\n",
      "Epoch: 25, series: 272, nllk loss: -1.90205, kernel loss: 0.17946\n",
      "Epoch: 25, series: 273, nllk loss: -1.92245, kernel loss: 0.09442\n",
      "Epoch: 25, series: 274, nllk loss: -1.61455, kernel loss: 0.07918\n",
      "Epoch: 25, series: 275, nllk loss: -2.06137, kernel loss: 0.13832\n",
      "Epoch: 25, series: 276, nllk loss: -1.42443, kernel loss: 0.15918\n",
      "Epoch: 25, series: 277, nllk loss: -2.31096, kernel loss: 0.02024\n",
      "Epoch: 25, series: 278, nllk loss: -1.99503, kernel loss: 0.04906\n",
      "Epoch: 25, series: 279, nllk loss: -2.40122, kernel loss: 0.03591\n",
      "Epoch: 25, series: 280, nllk loss: -2.13185, kernel loss: 0.07676\n",
      "Epoch: 25, series: 281, nllk loss: -2.37012, kernel loss: 0.21435\n",
      "Epoch: 25, series: 282, nllk loss: -2.30029, kernel loss: 0.12279\n",
      "Epoch: 25, series: 283, nllk loss: -2.23020, kernel loss: 0.04313\n",
      "Epoch: 25, series: 284, nllk loss: -1.74924, kernel loss: 0.14426\n",
      "Epoch: 25, series: 285, nllk loss: -1.95371, kernel loss: 0.08810\n",
      "Epoch: 25, series: 286, nllk loss: -2.26428, kernel loss: 0.00425\n",
      "Epoch: 25, series: 287, nllk loss: -2.54574, kernel loss: 0.08370\n",
      "Epoch: 25, series: 288, nllk loss: -1.33667, kernel loss: 0.07092\n",
      "Epoch: 25, series: 289, nllk loss: -1.26959, kernel loss: 0.06586\n",
      "Epoch: 25, series: 290, nllk loss: -2.36369, kernel loss: 0.04121\n",
      "Epoch: 25, series: 291, nllk loss: -2.48555, kernel loss: 0.03335\n",
      "Epoch: 25, series: 292, nllk loss: -2.33196, kernel loss: 0.13228\n",
      "Epoch: 25, series: 293, nllk loss: -2.51415, kernel loss: 0.01197\n",
      "Epoch: 25, series: 294, nllk loss: -1.22790, kernel loss: 0.11271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25, series: 295, nllk loss: -1.21776, kernel loss: 0.04279\n",
      "Epoch: 25, series: 296, nllk loss: -2.61153, kernel loss: 0.04394\n",
      "Epoch: 25, series: 297, nllk loss: -2.65980, kernel loss: 0.04922\n",
      "Epoch: 25, series: 298, nllk loss: -0.28366, kernel loss: 0.14605\n",
      "Epoch: 25, series: 299, nllk loss: -0.85299, kernel loss: 0.10792\n",
      "Epoch: 25, series: 300, nllk loss: -2.22839, kernel loss: 0.07019\n",
      "Epoch: 25, series: 301, nllk loss: -2.54118, kernel loss: 0.09083\n",
      "Epoch: 25, series: 302, nllk loss: -2.38233, kernel loss: 0.08871\n",
      "Epoch: 25, series: 303, nllk loss: -2.01862, kernel loss: 0.15170\n",
      "Epoch: 25, series: 304, nllk loss: 0.03835, kernel loss: 0.22170\n",
      "Epoch: 25, series: 305, nllk loss: -2.00219, kernel loss: 0.19312\n",
      "Epoch: 25, series: 306, nllk loss: -2.56682, kernel loss: 0.14535\n",
      "Epoch: 25, series: 307, nllk loss: -1.80621, kernel loss: 0.08099\n",
      "Epoch: 25, series: 308, nllk loss: -2.48914, kernel loss: 0.09890\n",
      "Epoch: 25, series: 309, nllk loss: -2.04158, kernel loss: 0.06794\n",
      "Epoch: 25, series: 310, nllk loss: -2.40528, kernel loss: 0.12059\n",
      "Epoch: 25, series: 311, nllk loss: -2.07418, kernel loss: 0.10421\n",
      "Epoch: 25, series: 312, nllk loss: -2.06533, kernel loss: 0.17064\n",
      "Epoch: 25, series: 313, nllk loss: -2.25847, kernel loss: 0.10209\n",
      "Epoch: 25, series: 314, nllk loss: -2.77943, kernel loss: 0.18568\n",
      "Epoch: 25, series: 315, nllk loss: -0.95537, kernel loss: 0.04379\n",
      "Epoch: 25, series: 316, nllk loss: -2.14522, kernel loss: 0.21296\n",
      "Epoch: 25, series: 317, nllk loss: 0.04119, kernel loss: 0.13521\n",
      "Epoch: 25, series: 318, nllk loss: 0.52583, kernel loss: 0.13382\n",
      "Epoch: 25, series: 319, nllk loss: -1.12145, kernel loss: 0.05257\n",
      "Epoch: 25, series: 320, nllk loss: -0.98002, kernel loss: 0.05974\n",
      "Epoch: 25, total loss: -507.11694\n",
      "Epoch: 26, series: 0, nllk loss: 0.77647, kernel loss: 0.19718\n",
      "Epoch: 26, series: 1, nllk loss: -1.18665, kernel loss: 0.21068\n",
      "Epoch: 26, series: 2, nllk loss: -0.07332, kernel loss: 0.08491\n",
      "Epoch: 26, series: 3, nllk loss: -1.49239, kernel loss: 0.09131\n",
      "Epoch: 26, series: 4, nllk loss: -1.09163, kernel loss: 0.27498\n",
      "Epoch: 26, series: 5, nllk loss: -1.37997, kernel loss: 0.10168\n",
      "Epoch: 26, series: 6, nllk loss: -0.66175, kernel loss: 0.20487\n",
      "Epoch: 26, series: 7, nllk loss: -1.15518, kernel loss: 0.09423\n",
      "Epoch: 26, series: 8, nllk loss: -0.57033, kernel loss: 0.20227\n",
      "Epoch: 26, series: 9, nllk loss: -0.61798, kernel loss: 0.12598\n",
      "Epoch: 26, series: 10, nllk loss: -1.43074, kernel loss: 0.10454\n",
      "Epoch: 26, series: 11, nllk loss: -1.30874, kernel loss: 0.14974\n",
      "Epoch: 26, series: 12, nllk loss: -1.68141, kernel loss: 0.20210\n",
      "Epoch: 26, series: 13, nllk loss: -1.49242, kernel loss: 0.04062\n",
      "Epoch: 26, series: 14, nllk loss: -1.67714, kernel loss: 0.07765\n",
      "Epoch: 26, series: 15, nllk loss: -1.60836, kernel loss: 0.09564\n",
      "Epoch: 26, series: 16, nllk loss: -1.14182, kernel loss: 0.08597\n",
      "Epoch: 26, series: 17, nllk loss: -1.27006, kernel loss: 0.05755\n",
      "Epoch: 26, series: 18, nllk loss: -1.49321, kernel loss: 0.13756\n",
      "Epoch: 26, series: 19, nllk loss: -0.44114, kernel loss: 0.10832\n",
      "Epoch: 26, series: 20, nllk loss: -0.92985, kernel loss: 0.06959\n",
      "Epoch: 26, series: 21, nllk loss: -1.16022, kernel loss: 0.03759\n",
      "Epoch: 26, series: 22, nllk loss: -1.61409, kernel loss: 0.12115\n",
      "Epoch: 26, series: 23, nllk loss: -1.58902, kernel loss: 0.20359\n",
      "Epoch: 26, series: 24, nllk loss: -1.82300, kernel loss: 0.12350\n",
      "Epoch: 26, series: 25, nllk loss: -1.81158, kernel loss: 0.06594\n",
      "Epoch: 26, series: 26, nllk loss: -1.42644, kernel loss: 0.06482\n",
      "Epoch: 26, series: 27, nllk loss: -1.34827, kernel loss: 0.08739\n",
      "Epoch: 26, series: 28, nllk loss: -1.36443, kernel loss: 0.05416\n",
      "Epoch: 26, series: 29, nllk loss: -1.03523, kernel loss: 0.14710\n",
      "Epoch: 26, series: 30, nllk loss: -1.56070, kernel loss: 0.12068\n",
      "Epoch: 26, series: 31, nllk loss: -1.09318, kernel loss: 0.18946\n",
      "Epoch: 26, series: 32, nllk loss: -1.20839, kernel loss: 0.06898\n",
      "Epoch: 26, series: 33, nllk loss: -0.98598, kernel loss: 0.14320\n",
      "Epoch: 26, series: 34, nllk loss: -1.52193, kernel loss: 0.05364\n",
      "Epoch: 26, series: 35, nllk loss: -1.78049, kernel loss: 0.02910\n",
      "Epoch: 26, series: 36, nllk loss: -1.71724, kernel loss: 0.13406\n",
      "Epoch: 26, series: 37, nllk loss: -0.64270, kernel loss: 0.11823\n",
      "Epoch: 26, series: 38, nllk loss: -0.94697, kernel loss: 0.13143\n",
      "Epoch: 26, series: 39, nllk loss: -0.80132, kernel loss: 0.03350\n",
      "Epoch: 26, series: 40, nllk loss: -1.96623, kernel loss: 0.06554\n",
      "Epoch: 26, series: 41, nllk loss: -1.42873, kernel loss: 0.17993\n",
      "Epoch: 26, series: 42, nllk loss: -1.15694, kernel loss: 0.03566\n",
      "Epoch: 26, series: 43, nllk loss: -1.19429, kernel loss: 0.14679\n",
      "Epoch: 26, series: 44, nllk loss: -1.67886, kernel loss: 0.13520\n",
      "Epoch: 26, series: 45, nllk loss: -1.77586, kernel loss: 0.03726\n",
      "Epoch: 26, series: 46, nllk loss: -1.73434, kernel loss: 0.10509\n",
      "Epoch: 26, series: 47, nllk loss: -1.56194, kernel loss: 0.17017\n",
      "Epoch: 26, series: 48, nllk loss: -1.70274, kernel loss: 0.10505\n",
      "Epoch: 26, series: 49, nllk loss: -1.28021, kernel loss: 0.11952\n",
      "Epoch: 26, series: 50, nllk loss: -0.18771, kernel loss: 0.13345\n",
      "Epoch: 26, series: 51, nllk loss: -1.38403, kernel loss: 0.08359\n",
      "Epoch: 26, series: 52, nllk loss: -0.56266, kernel loss: 0.10196\n",
      "Epoch: 26, series: 53, nllk loss: -1.73772, kernel loss: 0.06185\n",
      "Epoch: 26, series: 54, nllk loss: -1.53373, kernel loss: 0.05268\n",
      "Epoch: 26, series: 55, nllk loss: -0.85073, kernel loss: 0.12725\n",
      "Epoch: 26, series: 56, nllk loss: -1.53490, kernel loss: 0.07164\n",
      "Epoch: 26, series: 57, nllk loss: -1.46149, kernel loss: 0.08520\n",
      "Epoch: 26, series: 58, nllk loss: -1.59405, kernel loss: 0.20008\n",
      "Epoch: 26, series: 59, nllk loss: -1.28255, kernel loss: 0.14921\n",
      "Epoch: 26, series: 60, nllk loss: -1.16790, kernel loss: 0.06204\n",
      "Epoch: 26, series: 61, nllk loss: -1.87727, kernel loss: 0.06512\n",
      "Epoch: 26, series: 62, nllk loss: -1.91509, kernel loss: 0.15381\n",
      "Epoch: 26, series: 63, nllk loss: -1.81725, kernel loss: 0.08940\n",
      "Epoch: 26, series: 64, nllk loss: -1.27768, kernel loss: 0.07692\n",
      "Epoch: 26, series: 65, nllk loss: -1.78151, kernel loss: 0.17223\n",
      "Epoch: 26, series: 66, nllk loss: -1.74111, kernel loss: 0.05223\n",
      "Epoch: 26, series: 67, nllk loss: -1.52800, kernel loss: 0.03417\n",
      "Epoch: 26, series: 68, nllk loss: -0.97746, kernel loss: 0.07130\n",
      "Epoch: 26, series: 69, nllk loss: -1.62733, kernel loss: 0.14970\n",
      "Epoch: 26, series: 70, nllk loss: -1.41526, kernel loss: 0.08019\n",
      "Epoch: 26, series: 71, nllk loss: -1.54151, kernel loss: 0.07173\n",
      "Epoch: 26, series: 72, nllk loss: -1.91689, kernel loss: 0.06996\n",
      "Epoch: 26, series: 73, nllk loss: -1.39505, kernel loss: 0.05324\n",
      "Epoch: 26, series: 74, nllk loss: -2.09039, kernel loss: 0.10627\n",
      "Epoch: 26, series: 75, nllk loss: -1.69648, kernel loss: 0.05335\n",
      "Epoch: 26, series: 76, nllk loss: -1.44636, kernel loss: 0.06839\n",
      "Epoch: 26, series: 77, nllk loss: -1.37124, kernel loss: 0.06356\n",
      "Epoch: 26, series: 78, nllk loss: -1.54145, kernel loss: 0.09003\n",
      "Epoch: 26, series: 79, nllk loss: -0.37914, kernel loss: 0.02856\n",
      "Epoch: 26, series: 80, nllk loss: -1.88947, kernel loss: 0.02027\n",
      "Epoch: 26, series: 81, nllk loss: -1.70389, kernel loss: 0.01666\n",
      "Epoch: 26, series: 82, nllk loss: -0.48035, kernel loss: 0.00804\n",
      "Epoch: 26, series: 83, nllk loss: -1.37770, kernel loss: 0.15431\n",
      "Epoch: 26, series: 84, nllk loss: -1.42724, kernel loss: 0.09152\n",
      "Epoch: 26, series: 85, nllk loss: -1.72395, kernel loss: 0.01023\n",
      "Epoch: 26, series: 86, nllk loss: -0.97295, kernel loss: 0.06122\n",
      "Epoch: 26, series: 87, nllk loss: -1.98787, kernel loss: 0.00210\n",
      "Epoch: 26, series: 88, nllk loss: -2.26235, kernel loss: 0.05904\n",
      "Epoch: 26, series: 89, nllk loss: -2.02804, kernel loss: 0.12179\n",
      "Epoch: 26, series: 90, nllk loss: -2.40576, kernel loss: 0.06848\n",
      "Epoch: 26, series: 91, nllk loss: -2.25651, kernel loss: 0.05154\n",
      "Epoch: 26, series: 92, nllk loss: 0.03359, kernel loss: 0.15725\n",
      "Epoch: 26, series: 93, nllk loss: -2.67627, kernel loss: 0.08379\n",
      "Epoch: 26, series: 94, nllk loss: -2.63428, kernel loss: 0.11351\n",
      "Epoch: 26, series: 95, nllk loss: -2.55026, kernel loss: 0.12073\n",
      "Epoch: 26, series: 96, nllk loss: -1.89335, kernel loss: 0.04841\n",
      "Epoch: 26, series: 97, nllk loss: -0.68508, kernel loss: 0.15815\n",
      "Epoch: 26, series: 98, nllk loss: -0.62804, kernel loss: 0.12711\n",
      "Epoch: 26, series: 99, nllk loss: -1.49507, kernel loss: 0.12312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, series: 100, nllk loss: -0.89152, kernel loss: 0.12833\n",
      "Epoch: 26, series: 101, nllk loss: -1.30576, kernel loss: 0.04961\n",
      "Epoch: 26, series: 102, nllk loss: -0.64430, kernel loss: 0.13014\n",
      "Epoch: 26, series: 103, nllk loss: -1.18038, kernel loss: 0.14363\n",
      "Epoch: 26, series: 104, nllk loss: -0.18700, kernel loss: 0.04278\n",
      "Epoch: 26, series: 105, nllk loss: -0.54776, kernel loss: 0.17414\n",
      "Epoch: 26, series: 106, nllk loss: -1.17265, kernel loss: 0.11226\n",
      "Epoch: 26, series: 107, nllk loss: -1.06899, kernel loss: 0.20643\n",
      "Epoch: 26, series: 108, nllk loss: -1.31169, kernel loss: 0.16211\n",
      "Epoch: 26, series: 109, nllk loss: -1.35659, kernel loss: 0.06314\n",
      "Epoch: 26, series: 110, nllk loss: -1.77282, kernel loss: 0.10712\n",
      "Epoch: 26, series: 111, nllk loss: -1.56935, kernel loss: 0.03599\n",
      "Epoch: 26, series: 112, nllk loss: -0.95940, kernel loss: 0.08390\n",
      "Epoch: 26, series: 113, nllk loss: -1.24316, kernel loss: 0.05183\n",
      "Epoch: 26, series: 114, nllk loss: -1.27958, kernel loss: 0.13510\n",
      "Epoch: 26, series: 115, nllk loss: -1.08570, kernel loss: 0.01529\n",
      "Epoch: 26, series: 116, nllk loss: -1.61910, kernel loss: 0.10330\n",
      "Epoch: 26, series: 117, nllk loss: -0.67234, kernel loss: 0.16346\n",
      "Epoch: 26, series: 118, nllk loss: -1.86845, kernel loss: 0.11569\n",
      "Epoch: 26, series: 119, nllk loss: -0.80998, kernel loss: 0.03700\n",
      "Epoch: 26, series: 120, nllk loss: -1.60098, kernel loss: 0.09255\n",
      "Epoch: 26, series: 121, nllk loss: -0.12106, kernel loss: 0.22686\n",
      "Epoch: 26, series: 122, nllk loss: -0.63939, kernel loss: 0.08852\n",
      "Epoch: 26, series: 123, nllk loss: -1.87064, kernel loss: 0.04721\n",
      "Epoch: 26, series: 124, nllk loss: -2.04284, kernel loss: 0.05875\n",
      "Epoch: 26, series: 125, nllk loss: -1.28268, kernel loss: 0.03942\n",
      "Epoch: 26, series: 126, nllk loss: -1.92952, kernel loss: 0.04879\n",
      "Epoch: 26, series: 127, nllk loss: -1.37305, kernel loss: 0.13347\n",
      "Epoch: 26, series: 128, nllk loss: -1.04998, kernel loss: 0.06940\n",
      "Epoch: 26, series: 129, nllk loss: -0.89317, kernel loss: 0.08788\n",
      "Epoch: 26, series: 130, nllk loss: -1.61223, kernel loss: 0.02740\n",
      "Epoch: 26, series: 131, nllk loss: 0.19423, kernel loss: 0.10063\n",
      "Epoch: 26, series: 132, nllk loss: -0.21279, kernel loss: 0.14354\n",
      "Epoch: 26, series: 133, nllk loss: -1.07152, kernel loss: 0.12377\n",
      "Epoch: 26, series: 134, nllk loss: -0.77227, kernel loss: 0.04182\n",
      "Epoch: 26, series: 135, nllk loss: -1.67035, kernel loss: 0.03232\n",
      "Epoch: 26, series: 136, nllk loss: -1.82066, kernel loss: 0.02478\n",
      "Epoch: 26, series: 137, nllk loss: -1.99651, kernel loss: 0.17124\n",
      "Epoch: 26, series: 138, nllk loss: -1.91371, kernel loss: 0.11225\n",
      "Epoch: 26, series: 139, nllk loss: -1.86109, kernel loss: 0.04224\n",
      "Epoch: 26, series: 140, nllk loss: -1.47001, kernel loss: 0.13963\n",
      "Epoch: 26, series: 141, nllk loss: -1.80508, kernel loss: 0.08267\n",
      "Epoch: 26, series: 142, nllk loss: -2.00885, kernel loss: 0.16378\n",
      "Epoch: 26, series: 143, nllk loss: -1.80383, kernel loss: 0.00000\n",
      "Epoch: 26, series: 144, nllk loss: -2.21489, kernel loss: 0.06487\n",
      "Epoch: 26, series: 145, nllk loss: -1.92573, kernel loss: 0.07623\n",
      "Epoch: 26, series: 146, nllk loss: 1.13595, kernel loss: 0.13558\n",
      "Epoch: 26, series: 147, nllk loss: -1.77072, kernel loss: 0.21162\n",
      "Epoch: 26, series: 148, nllk loss: -1.39709, kernel loss: 0.01334\n",
      "Epoch: 26, series: 149, nllk loss: -1.96645, kernel loss: 0.08641\n",
      "Epoch: 26, series: 150, nllk loss: -2.05842, kernel loss: 0.15828\n",
      "Epoch: 26, series: 151, nllk loss: -2.13315, kernel loss: 0.08274\n",
      "Epoch: 26, series: 152, nllk loss: -2.16936, kernel loss: 0.07703\n",
      "Epoch: 26, series: 153, nllk loss: -1.80930, kernel loss: 0.15489\n",
      "Epoch: 26, series: 154, nllk loss: -1.90194, kernel loss: 0.06919\n",
      "Epoch: 26, series: 155, nllk loss: -2.06107, kernel loss: 0.03517\n",
      "Epoch: 26, series: 156, nllk loss: -2.16617, kernel loss: 0.09753\n",
      "Epoch: 26, series: 157, nllk loss: -1.73071, kernel loss: 0.15375\n",
      "Epoch: 26, series: 158, nllk loss: -2.09502, kernel loss: 0.03771\n",
      "Epoch: 26, series: 159, nllk loss: -2.23041, kernel loss: 0.11623\n",
      "Epoch: 26, series: 160, nllk loss: -2.05838, kernel loss: 0.13064\n",
      "Epoch: 26, series: 161, nllk loss: -1.92327, kernel loss: 0.17365\n",
      "Epoch: 26, series: 162, nllk loss: -2.31390, kernel loss: 0.05339\n",
      "Epoch: 26, series: 163, nllk loss: -2.48194, kernel loss: 0.18452\n",
      "Epoch: 26, series: 164, nllk loss: -1.80629, kernel loss: 0.05777\n",
      "Epoch: 26, series: 165, nllk loss: -2.04381, kernel loss: 0.09487\n",
      "Epoch: 26, series: 166, nllk loss: -1.52496, kernel loss: 0.17228\n",
      "Epoch: 26, series: 167, nllk loss: -2.67614, kernel loss: 0.06435\n",
      "Epoch: 26, series: 168, nllk loss: -2.15463, kernel loss: 0.13390\n",
      "Epoch: 26, series: 169, nllk loss: -2.38437, kernel loss: 0.16710\n",
      "Epoch: 26, series: 170, nllk loss: -1.92866, kernel loss: 0.15644\n",
      "Epoch: 26, series: 171, nllk loss: -2.57206, kernel loss: 0.05226\n",
      "Epoch: 26, series: 172, nllk loss: -2.13377, kernel loss: 0.16720\n",
      "Epoch: 26, series: 173, nllk loss: -2.62616, kernel loss: 0.13119\n",
      "Epoch: 26, series: 174, nllk loss: -2.33794, kernel loss: 0.10933\n",
      "Epoch: 26, series: 175, nllk loss: -2.58762, kernel loss: 0.00059\n",
      "Epoch: 26, series: 176, nllk loss: -2.07167, kernel loss: 0.12676\n",
      "Epoch: 26, series: 177, nllk loss: -2.11952, kernel loss: 0.08564\n",
      "Epoch: 26, series: 178, nllk loss: -1.76432, kernel loss: 0.19582\n",
      "Epoch: 26, series: 179, nllk loss: -2.21486, kernel loss: 0.15498\n",
      "Epoch: 26, series: 180, nllk loss: -2.38275, kernel loss: 0.16588\n",
      "Epoch: 26, series: 181, nllk loss: -2.62372, kernel loss: 0.06829\n",
      "Epoch: 26, series: 182, nllk loss: -2.33023, kernel loss: 0.05805\n",
      "Epoch: 26, series: 183, nllk loss: -2.05923, kernel loss: 0.19220\n",
      "Epoch: 26, series: 184, nllk loss: -2.20447, kernel loss: 0.13309\n",
      "Epoch: 26, series: 185, nllk loss: -1.80636, kernel loss: 0.07298\n",
      "Epoch: 26, series: 186, nllk loss: -2.71738, kernel loss: 0.10337\n",
      "Epoch: 26, series: 187, nllk loss: -2.80229, kernel loss: 0.01313\n",
      "Epoch: 26, series: 188, nllk loss: -1.69295, kernel loss: 0.15024\n",
      "Epoch: 26, series: 189, nllk loss: -1.50956, kernel loss: 0.07031\n",
      "Epoch: 26, series: 190, nllk loss: -2.42258, kernel loss: 0.13502\n",
      "Epoch: 26, series: 191, nllk loss: -2.16282, kernel loss: 0.08524\n",
      "Epoch: 26, series: 192, nllk loss: -2.23019, kernel loss: 0.11278\n",
      "Epoch: 26, series: 193, nllk loss: -1.59674, kernel loss: 0.28402\n",
      "Epoch: 26, series: 194, nllk loss: -1.59197, kernel loss: 0.11135\n",
      "Epoch: 26, series: 195, nllk loss: -2.26919, kernel loss: 0.09896\n",
      "Epoch: 26, series: 196, nllk loss: -1.95030, kernel loss: 0.13657\n",
      "Epoch: 26, series: 197, nllk loss: -2.18874, kernel loss: 0.05533\n",
      "Epoch: 26, series: 198, nllk loss: -2.43223, kernel loss: 0.04607\n",
      "Epoch: 26, series: 199, nllk loss: -1.96986, kernel loss: 0.08010\n",
      "Epoch: 26, series: 200, nllk loss: -2.27012, kernel loss: 0.17089\n",
      "Epoch: 26, series: 201, nllk loss: -2.36552, kernel loss: 0.11070\n",
      "Epoch: 26, series: 202, nllk loss: -2.12748, kernel loss: 0.04552\n",
      "Epoch: 26, series: 203, nllk loss: -1.86061, kernel loss: 0.03047\n",
      "Epoch: 26, series: 204, nllk loss: -1.02911, kernel loss: 0.15727\n",
      "Epoch: 26, series: 205, nllk loss: -2.18865, kernel loss: 0.00796\n",
      "Epoch: 26, series: 206, nllk loss: -2.20787, kernel loss: 0.13890\n",
      "Epoch: 26, series: 207, nllk loss: -1.01544, kernel loss: 0.04392\n",
      "Epoch: 26, series: 208, nllk loss: -2.31786, kernel loss: 0.04456\n",
      "Epoch: 26, series: 209, nllk loss: -1.82981, kernel loss: 0.04833\n",
      "Epoch: 26, series: 210, nllk loss: -2.64524, kernel loss: 0.06150\n",
      "Epoch: 26, series: 211, nllk loss: -2.14893, kernel loss: 0.11171\n",
      "Epoch: 26, series: 212, nllk loss: -1.44712, kernel loss: 0.07126\n",
      "Epoch: 26, series: 213, nllk loss: -2.29802, kernel loss: 0.07701\n",
      "Epoch: 26, series: 214, nllk loss: -2.27810, kernel loss: 0.02271\n",
      "Epoch: 26, series: 215, nllk loss: -2.67821, kernel loss: 0.07560\n",
      "Epoch: 26, series: 216, nllk loss: -1.40936, kernel loss: 0.11546\n",
      "Epoch: 26, series: 217, nllk loss: -2.08411, kernel loss: 0.17425\n",
      "Epoch: 26, series: 218, nllk loss: -1.56763, kernel loss: 0.11916\n",
      "Epoch: 26, series: 219, nllk loss: -2.27901, kernel loss: 0.08214\n",
      "Epoch: 26, series: 220, nllk loss: -2.23531, kernel loss: 0.01262\n",
      "Epoch: 26, series: 221, nllk loss: -2.51661, kernel loss: 0.16943\n",
      "Epoch: 26, series: 222, nllk loss: -2.23350, kernel loss: 0.02867\n",
      "Epoch: 26, series: 223, nllk loss: -1.58577, kernel loss: 0.07835\n",
      "Epoch: 26, series: 224, nllk loss: -2.56428, kernel loss: 0.04850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26, series: 225, nllk loss: -2.45345, kernel loss: 0.10977\n",
      "Epoch: 26, series: 226, nllk loss: -1.97146, kernel loss: 0.07485\n",
      "Epoch: 26, series: 227, nllk loss: -2.15956, kernel loss: 0.05022\n",
      "Epoch: 26, series: 228, nllk loss: -2.22865, kernel loss: 0.13133\n",
      "Epoch: 26, series: 229, nllk loss: -2.03629, kernel loss: 0.01824\n",
      "Epoch: 26, series: 230, nllk loss: -2.50620, kernel loss: 0.09931\n",
      "Epoch: 26, series: 231, nllk loss: -1.94034, kernel loss: 0.08473\n",
      "Epoch: 26, series: 232, nllk loss: -2.66045, kernel loss: 0.08298\n",
      "Epoch: 26, series: 233, nllk loss: -2.49385, kernel loss: 0.12231\n",
      "Epoch: 26, series: 234, nllk loss: -2.03471, kernel loss: 0.16819\n",
      "Epoch: 26, series: 235, nllk loss: -2.71383, kernel loss: 0.11362\n",
      "Epoch: 26, series: 236, nllk loss: -1.71734, kernel loss: 0.22930\n",
      "Epoch: 26, series: 237, nllk loss: -2.27119, kernel loss: 0.07546\n",
      "Epoch: 26, series: 238, nllk loss: -2.04176, kernel loss: 0.24033\n",
      "Epoch: 26, series: 239, nllk loss: -2.28988, kernel loss: 0.10559\n",
      "Epoch: 26, series: 240, nllk loss: -1.13192, kernel loss: 0.05355\n",
      "Epoch: 26, series: 241, nllk loss: -2.02886, kernel loss: 0.15001\n",
      "Epoch: 26, series: 242, nllk loss: -2.13402, kernel loss: 0.10135\n",
      "Epoch: 26, series: 243, nllk loss: -2.56289, kernel loss: 0.03248\n",
      "Epoch: 26, series: 244, nllk loss: -2.17639, kernel loss: 0.06585\n",
      "Epoch: 26, series: 245, nllk loss: -2.15982, kernel loss: 0.09479\n",
      "Epoch: 26, series: 246, nllk loss: -0.50049, kernel loss: 0.01254\n",
      "Epoch: 26, series: 247, nllk loss: -1.85559, kernel loss: 0.07125\n",
      "Epoch: 26, series: 248, nllk loss: -2.22407, kernel loss: 0.15190\n",
      "Epoch: 26, series: 249, nllk loss: -2.15681, kernel loss: 0.17929\n",
      "Epoch: 26, series: 250, nllk loss: -1.68363, kernel loss: 0.00113\n",
      "Epoch: 26, series: 251, nllk loss: -1.26012, kernel loss: 0.06007\n",
      "Epoch: 26, series: 252, nllk loss: -1.50589, kernel loss: 0.06583\n",
      "Epoch: 26, series: 253, nllk loss: -1.83835, kernel loss: 0.03215\n",
      "Epoch: 26, series: 254, nllk loss: -2.33980, kernel loss: 0.14739\n",
      "Epoch: 26, series: 255, nllk loss: -2.14405, kernel loss: 0.02391\n",
      "Epoch: 26, series: 256, nllk loss: -1.95874, kernel loss: 0.08013\n",
      "Epoch: 26, series: 257, nllk loss: -2.18822, kernel loss: 0.04172\n",
      "Epoch: 26, series: 258, nllk loss: -2.20036, kernel loss: 0.11663\n",
      "Epoch: 26, series: 259, nllk loss: -1.90790, kernel loss: 0.18848\n",
      "Epoch: 26, series: 260, nllk loss: -2.05635, kernel loss: 0.00780\n",
      "Epoch: 26, series: 261, nllk loss: -2.21073, kernel loss: 0.09415\n",
      "Epoch: 26, series: 262, nllk loss: -2.65610, kernel loss: 0.30040\n",
      "Epoch: 26, series: 263, nllk loss: -0.64744, kernel loss: 0.14773\n",
      "Epoch: 26, series: 264, nllk loss: -2.02256, kernel loss: 0.06510\n",
      "Epoch: 26, series: 265, nllk loss: -1.99345, kernel loss: 0.08732\n",
      "Epoch: 26, series: 266, nllk loss: -2.40702, kernel loss: 0.09324\n",
      "Epoch: 26, series: 267, nllk loss: -2.23444, kernel loss: 0.04594\n",
      "Epoch: 26, series: 268, nllk loss: -2.17625, kernel loss: 0.00498\n",
      "Epoch: 26, series: 269, nllk loss: -1.89362, kernel loss: 0.01832\n",
      "Epoch: 26, series: 270, nllk loss: -1.96712, kernel loss: 0.13464\n",
      "Epoch: 26, series: 271, nllk loss: -2.14516, kernel loss: 0.10874\n",
      "Epoch: 26, series: 272, nllk loss: -2.07238, kernel loss: 0.02862\n",
      "Epoch: 26, series: 273, nllk loss: -2.08348, kernel loss: 0.06293\n",
      "Epoch: 26, series: 274, nllk loss: -1.47876, kernel loss: 0.12029\n",
      "Epoch: 26, series: 275, nllk loss: -2.14850, kernel loss: 0.04821\n",
      "Epoch: 26, series: 276, nllk loss: -1.44417, kernel loss: 0.12735\n",
      "Epoch: 26, series: 277, nllk loss: -2.30548, kernel loss: 0.00378\n",
      "Epoch: 26, series: 278, nllk loss: -2.03341, kernel loss: 0.02015\n",
      "Epoch: 26, series: 279, nllk loss: -2.50824, kernel loss: 0.03886\n",
      "Epoch: 26, series: 280, nllk loss: -2.18949, kernel loss: 0.02532\n",
      "Epoch: 26, series: 281, nllk loss: -2.41023, kernel loss: 0.16431\n",
      "Epoch: 26, series: 282, nllk loss: -2.37994, kernel loss: 0.04429\n",
      "Epoch: 26, series: 283, nllk loss: -2.21714, kernel loss: 0.06819\n",
      "Epoch: 26, series: 284, nllk loss: -1.65427, kernel loss: 0.18820\n",
      "Epoch: 26, series: 285, nllk loss: -1.96353, kernel loss: 0.08205\n",
      "Epoch: 26, series: 286, nllk loss: -2.25841, kernel loss: 0.03030\n",
      "Epoch: 26, series: 287, nllk loss: -2.53174, kernel loss: 0.11301\n",
      "Epoch: 26, series: 288, nllk loss: -1.20064, kernel loss: 0.03947\n",
      "Epoch: 26, series: 289, nllk loss: -1.20825, kernel loss: 0.04767\n",
      "Epoch: 26, series: 290, nllk loss: -2.44320, kernel loss: 0.13488\n",
      "Epoch: 26, series: 291, nllk loss: -2.46070, kernel loss: 0.10673\n",
      "Epoch: 26, series: 292, nllk loss: -2.38342, kernel loss: 0.04828\n",
      "Epoch: 26, series: 293, nllk loss: -2.54958, kernel loss: 0.15024\n",
      "Epoch: 26, series: 294, nllk loss: -1.47101, kernel loss: 0.11102\n",
      "Epoch: 26, series: 295, nllk loss: -1.35028, kernel loss: 0.15903\n",
      "Epoch: 26, series: 296, nllk loss: -2.57964, kernel loss: 0.14617\n",
      "Epoch: 26, series: 297, nllk loss: -2.66433, kernel loss: 0.20741\n",
      "Epoch: 26, series: 298, nllk loss: -0.48662, kernel loss: 0.09567\n",
      "Epoch: 26, series: 299, nllk loss: -0.97465, kernel loss: 0.17296\n",
      "Epoch: 26, series: 300, nllk loss: -2.24653, kernel loss: 0.22900\n",
      "Epoch: 26, series: 301, nllk loss: -2.65738, kernel loss: 0.02450\n",
      "Epoch: 26, series: 302, nllk loss: -2.48066, kernel loss: 0.09379\n",
      "Epoch: 26, series: 303, nllk loss: -2.14257, kernel loss: 0.18233\n",
      "Epoch: 26, series: 304, nllk loss: -0.31640, kernel loss: 0.07338\n",
      "Epoch: 26, series: 305, nllk loss: -2.02307, kernel loss: 0.10672\n",
      "Epoch: 26, series: 306, nllk loss: -2.64611, kernel loss: 0.09887\n",
      "Epoch: 26, series: 307, nllk loss: -1.90301, kernel loss: 0.24250\n",
      "Epoch: 26, series: 308, nllk loss: -2.63624, kernel loss: 0.06714\n",
      "Epoch: 26, series: 309, nllk loss: -2.02725, kernel loss: 0.11202\n",
      "Epoch: 26, series: 310, nllk loss: -2.55297, kernel loss: 0.02823\n",
      "Epoch: 26, series: 311, nllk loss: -2.05427, kernel loss: 0.09940\n",
      "Epoch: 26, series: 312, nllk loss: -2.24739, kernel loss: 0.30352\n",
      "Epoch: 26, series: 313, nllk loss: -2.33371, kernel loss: 0.15238\n",
      "Epoch: 26, series: 314, nllk loss: -2.83697, kernel loss: 0.11770\n",
      "Epoch: 26, series: 315, nllk loss: -1.00632, kernel loss: 0.07683\n",
      "Epoch: 26, series: 316, nllk loss: -2.25645, kernel loss: 0.11695\n",
      "Epoch: 26, series: 317, nllk loss: -0.04137, kernel loss: 0.07828\n",
      "Epoch: 26, series: 318, nllk loss: 0.52763, kernel loss: 0.06270\n",
      "Epoch: 26, series: 319, nllk loss: -1.13240, kernel loss: 0.24791\n",
      "Epoch: 26, series: 320, nllk loss: -0.87289, kernel loss: 0.12681\n",
      "Epoch: 26, total loss: -517.16692\n",
      "Epoch: 27, series: 0, nllk loss: 0.77110, kernel loss: 0.12180\n",
      "Epoch: 27, series: 1, nllk loss: -0.98109, kernel loss: 0.18176\n",
      "Epoch: 27, series: 2, nllk loss: -0.01415, kernel loss: 0.06645\n",
      "Epoch: 27, series: 3, nllk loss: -1.61672, kernel loss: 0.09354\n",
      "Epoch: 27, series: 4, nllk loss: -1.22430, kernel loss: 0.04375\n",
      "Epoch: 27, series: 5, nllk loss: -1.49491, kernel loss: 0.11723\n",
      "Epoch: 27, series: 6, nllk loss: -0.72985, kernel loss: 0.22722\n",
      "Epoch: 27, series: 7, nllk loss: -1.14582, kernel loss: 0.09994\n",
      "Epoch: 27, series: 8, nllk loss: -0.53365, kernel loss: 0.18864\n",
      "Epoch: 27, series: 9, nllk loss: -0.64937, kernel loss: 0.12485\n",
      "Epoch: 27, series: 10, nllk loss: -1.48659, kernel loss: 0.25572\n",
      "Epoch: 27, series: 11, nllk loss: -1.25896, kernel loss: 0.03792\n",
      "Epoch: 27, series: 12, nllk loss: -1.64108, kernel loss: 0.20549\n",
      "Epoch: 27, series: 13, nllk loss: -1.44641, kernel loss: 0.16097\n",
      "Epoch: 27, series: 14, nllk loss: -1.73719, kernel loss: 0.07148\n",
      "Epoch: 27, series: 15, nllk loss: -1.66856, kernel loss: 0.17623\n",
      "Epoch: 27, series: 16, nllk loss: -1.21233, kernel loss: 0.09377\n",
      "Epoch: 27, series: 17, nllk loss: -1.29293, kernel loss: 0.04252\n",
      "Epoch: 27, series: 18, nllk loss: -1.48989, kernel loss: 0.04412\n",
      "Epoch: 27, series: 19, nllk loss: -0.29858, kernel loss: 0.05693\n",
      "Epoch: 27, series: 20, nllk loss: -0.89522, kernel loss: 0.10039\n",
      "Epoch: 27, series: 21, nllk loss: -1.12980, kernel loss: 0.05018\n",
      "Epoch: 27, series: 22, nllk loss: -1.62656, kernel loss: 0.26954\n",
      "Epoch: 27, series: 23, nllk loss: -1.57067, kernel loss: 0.06887\n",
      "Epoch: 27, series: 24, nllk loss: -1.82890, kernel loss: 0.14438\n",
      "Epoch: 27, series: 25, nllk loss: -1.87054, kernel loss: 0.06621\n",
      "Epoch: 27, series: 26, nllk loss: -1.49403, kernel loss: 0.14818\n",
      "Epoch: 27, series: 27, nllk loss: -1.32784, kernel loss: 0.06577\n",
      "Epoch: 27, series: 28, nllk loss: -1.38813, kernel loss: 0.04592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, series: 29, nllk loss: -1.09095, kernel loss: 0.09234\n",
      "Epoch: 27, series: 30, nllk loss: -1.51228, kernel loss: 0.23955\n",
      "Epoch: 27, series: 31, nllk loss: -1.13234, kernel loss: 0.29367\n",
      "Epoch: 27, series: 32, nllk loss: -1.24704, kernel loss: 0.07659\n",
      "Epoch: 27, series: 33, nllk loss: -1.08996, kernel loss: 0.04338\n",
      "Epoch: 27, series: 34, nllk loss: -1.52472, kernel loss: 0.00393\n",
      "Epoch: 27, series: 35, nllk loss: -1.72763, kernel loss: 0.07854\n",
      "Epoch: 27, series: 36, nllk loss: -1.78727, kernel loss: 0.07640\n",
      "Epoch: 27, series: 37, nllk loss: -0.65522, kernel loss: 0.05142\n",
      "Epoch: 27, series: 38, nllk loss: -1.08033, kernel loss: 0.05934\n",
      "Epoch: 27, series: 39, nllk loss: -0.79631, kernel loss: 0.12500\n",
      "Epoch: 27, series: 40, nllk loss: -2.03108, kernel loss: 0.04329\n",
      "Epoch: 27, series: 41, nllk loss: -1.44627, kernel loss: 0.12826\n",
      "Epoch: 27, series: 42, nllk loss: -1.13617, kernel loss: 0.06761\n",
      "Epoch: 27, series: 43, nllk loss: -1.16421, kernel loss: 0.18880\n",
      "Epoch: 27, series: 44, nllk loss: -1.64580, kernel loss: 0.13651\n",
      "Epoch: 27, series: 45, nllk loss: -1.75015, kernel loss: 0.04767\n",
      "Epoch: 27, series: 46, nllk loss: -1.80005, kernel loss: 0.03612\n",
      "Epoch: 27, series: 47, nllk loss: -1.61348, kernel loss: 0.05817\n",
      "Epoch: 27, series: 48, nllk loss: -1.71156, kernel loss: 0.05742\n",
      "Epoch: 27, series: 49, nllk loss: -1.23657, kernel loss: 0.08297\n",
      "Epoch: 27, series: 50, nllk loss: -0.12575, kernel loss: 0.07650\n",
      "Epoch: 27, series: 51, nllk loss: -1.32743, kernel loss: 0.03568\n",
      "Epoch: 27, series: 52, nllk loss: -0.43108, kernel loss: 0.11521\n",
      "Epoch: 27, series: 53, nllk loss: -1.77546, kernel loss: 0.07250\n",
      "Epoch: 27, series: 54, nllk loss: -1.51781, kernel loss: 0.08071\n",
      "Epoch: 27, series: 55, nllk loss: -0.82910, kernel loss: 0.00313\n",
      "Epoch: 27, series: 56, nllk loss: -1.53063, kernel loss: 0.05651\n",
      "Epoch: 27, series: 57, nllk loss: -1.44992, kernel loss: 0.00363\n",
      "Epoch: 27, series: 58, nllk loss: -1.59147, kernel loss: 0.00990\n",
      "Epoch: 27, series: 59, nllk loss: -1.31919, kernel loss: 0.05072\n",
      "Epoch: 27, series: 60, nllk loss: -1.12326, kernel loss: 0.01846\n",
      "Epoch: 27, series: 61, nllk loss: -1.85260, kernel loss: 0.08081\n",
      "Epoch: 27, series: 62, nllk loss: -1.91120, kernel loss: 0.03877\n",
      "Epoch: 27, series: 63, nllk loss: -1.79663, kernel loss: 0.13908\n",
      "Epoch: 27, series: 64, nllk loss: -1.29388, kernel loss: 0.06316\n",
      "Epoch: 27, series: 65, nllk loss: -1.78012, kernel loss: 0.07157\n",
      "Epoch: 27, series: 66, nllk loss: -1.76796, kernel loss: 0.09953\n",
      "Epoch: 27, series: 67, nllk loss: -1.54081, kernel loss: 0.02309\n",
      "Epoch: 27, series: 68, nllk loss: -0.97009, kernel loss: 0.24333\n",
      "Epoch: 27, series: 69, nllk loss: -1.66640, kernel loss: 0.09933\n",
      "Epoch: 27, series: 70, nllk loss: -1.46435, kernel loss: 0.01034\n",
      "Epoch: 27, series: 71, nllk loss: -1.55900, kernel loss: 0.13015\n",
      "Epoch: 27, series: 72, nllk loss: -1.89850, kernel loss: 0.14188\n",
      "Epoch: 27, series: 73, nllk loss: -1.44064, kernel loss: 0.09373\n",
      "Epoch: 27, series: 74, nllk loss: -2.12446, kernel loss: 0.02817\n",
      "Epoch: 27, series: 75, nllk loss: -1.72031, kernel loss: 0.03349\n",
      "Epoch: 27, series: 76, nllk loss: -1.46985, kernel loss: 0.17018\n",
      "Epoch: 27, series: 77, nllk loss: -1.43847, kernel loss: 0.01670\n",
      "Epoch: 27, series: 78, nllk loss: -1.52370, kernel loss: 0.11546\n",
      "Epoch: 27, series: 79, nllk loss: -0.25084, kernel loss: 0.03171\n",
      "Epoch: 27, series: 80, nllk loss: -1.91355, kernel loss: 0.20204\n",
      "Epoch: 27, series: 81, nllk loss: -1.67121, kernel loss: 0.07205\n",
      "Epoch: 27, series: 82, nllk loss: -0.57008, kernel loss: 0.07762\n",
      "Epoch: 27, series: 83, nllk loss: -1.37063, kernel loss: 0.04525\n",
      "Epoch: 27, series: 84, nllk loss: -1.37962, kernel loss: 0.07554\n",
      "Epoch: 27, series: 85, nllk loss: -1.69988, kernel loss: 0.10272\n",
      "Epoch: 27, series: 86, nllk loss: -0.99870, kernel loss: 0.12262\n",
      "Epoch: 27, series: 87, nllk loss: -1.95772, kernel loss: 0.05916\n",
      "Epoch: 27, series: 88, nllk loss: -2.28624, kernel loss: 0.09355\n",
      "Epoch: 27, series: 89, nllk loss: -2.03710, kernel loss: 0.14764\n",
      "Epoch: 27, series: 90, nllk loss: -2.41875, kernel loss: 0.03068\n",
      "Epoch: 27, series: 91, nllk loss: -2.23312, kernel loss: 0.01881\n",
      "Epoch: 27, series: 92, nllk loss: -0.06265, kernel loss: 0.08100\n",
      "Epoch: 27, series: 93, nllk loss: -2.71208, kernel loss: 0.11026\n",
      "Epoch: 27, series: 94, nllk loss: -2.60347, kernel loss: 0.04943\n",
      "Epoch: 27, series: 95, nllk loss: -2.60660, kernel loss: 0.07844\n",
      "Epoch: 27, series: 96, nllk loss: -1.81988, kernel loss: 0.03792\n",
      "Epoch: 27, series: 97, nllk loss: -0.76262, kernel loss: 0.06527\n",
      "Epoch: 27, series: 98, nllk loss: -0.73621, kernel loss: 0.16970\n",
      "Epoch: 27, series: 99, nllk loss: -1.56945, kernel loss: 0.08127\n",
      "Epoch: 27, series: 100, nllk loss: -1.05431, kernel loss: 0.04666\n",
      "Epoch: 27, series: 101, nllk loss: -1.48410, kernel loss: 0.07795\n",
      "Epoch: 27, series: 102, nllk loss: -0.83117, kernel loss: 0.07248\n",
      "Epoch: 27, series: 103, nllk loss: -1.13472, kernel loss: 0.08293\n",
      "Epoch: 27, series: 104, nllk loss: -0.05375, kernel loss: 0.22870\n",
      "Epoch: 27, series: 105, nllk loss: -0.61091, kernel loss: 0.19364\n",
      "Epoch: 27, series: 106, nllk loss: -1.24721, kernel loss: 0.09892\n",
      "Epoch: 27, series: 107, nllk loss: -1.10936, kernel loss: 0.08699\n",
      "Epoch: 27, series: 108, nllk loss: -1.25274, kernel loss: 0.03911\n",
      "Epoch: 27, series: 109, nllk loss: -1.34493, kernel loss: 0.01641\n",
      "Epoch: 27, series: 110, nllk loss: -1.84813, kernel loss: 0.14399\n",
      "Epoch: 27, series: 111, nllk loss: -1.59856, kernel loss: 0.19173\n",
      "Epoch: 27, series: 112, nllk loss: -0.84581, kernel loss: 0.04056\n",
      "Epoch: 27, series: 113, nllk loss: -1.22115, kernel loss: 0.08789\n",
      "Epoch: 27, series: 114, nllk loss: -1.17223, kernel loss: 0.14331\n",
      "Epoch: 27, series: 115, nllk loss: -1.00747, kernel loss: 0.09652\n",
      "Epoch: 27, series: 116, nllk loss: -1.65906, kernel loss: 0.07403\n",
      "Epoch: 27, series: 117, nllk loss: -0.69366, kernel loss: 0.07068\n",
      "Epoch: 27, series: 118, nllk loss: -1.87979, kernel loss: 0.04701\n",
      "Epoch: 27, series: 119, nllk loss: -0.94660, kernel loss: 0.15847\n",
      "Epoch: 27, series: 120, nllk loss: -1.66796, kernel loss: 0.16666\n",
      "Epoch: 27, series: 121, nllk loss: -0.12941, kernel loss: 0.07025\n",
      "Epoch: 27, series: 122, nllk loss: -0.65389, kernel loss: 0.00367\n",
      "Epoch: 27, series: 123, nllk loss: -1.96189, kernel loss: 0.00171\n",
      "Epoch: 27, series: 124, nllk loss: -2.18246, kernel loss: 0.24557\n",
      "Epoch: 27, series: 125, nllk loss: -1.25858, kernel loss: 0.06172\n",
      "Epoch: 27, series: 126, nllk loss: -2.09510, kernel loss: 0.04844\n",
      "Epoch: 27, series: 127, nllk loss: -1.34572, kernel loss: 0.09270\n",
      "Epoch: 27, series: 128, nllk loss: -1.03252, kernel loss: 0.00076\n",
      "Epoch: 27, series: 129, nllk loss: -0.78075, kernel loss: 0.15022\n",
      "Epoch: 27, series: 130, nllk loss: -1.68525, kernel loss: 0.03646\n",
      "Epoch: 27, series: 131, nllk loss: 0.27497, kernel loss: 0.06873\n",
      "Epoch: 27, series: 132, nllk loss: -0.32451, kernel loss: 0.03620\n",
      "Epoch: 27, series: 133, nllk loss: -1.00223, kernel loss: 0.04961\n",
      "Epoch: 27, series: 134, nllk loss: -0.78657, kernel loss: 0.14939\n",
      "Epoch: 27, series: 135, nllk loss: -1.68757, kernel loss: 0.04380\n",
      "Epoch: 27, series: 136, nllk loss: -1.80376, kernel loss: 0.07878\n",
      "Epoch: 27, series: 137, nllk loss: -2.04253, kernel loss: 0.06589\n",
      "Epoch: 27, series: 138, nllk loss: -1.96963, kernel loss: 0.11742\n",
      "Epoch: 27, series: 139, nllk loss: -1.85002, kernel loss: 0.00728\n",
      "Epoch: 27, series: 140, nllk loss: -1.45301, kernel loss: 0.11567\n",
      "Epoch: 27, series: 141, nllk loss: -1.76198, kernel loss: 0.07277\n",
      "Epoch: 27, series: 142, nllk loss: -1.98576, kernel loss: 0.14849\n",
      "Epoch: 27, series: 143, nllk loss: -1.74176, kernel loss: 0.05421\n",
      "Epoch: 27, series: 144, nllk loss: -2.15607, kernel loss: 0.12264\n",
      "Epoch: 27, series: 145, nllk loss: -1.92860, kernel loss: 0.22403\n",
      "Epoch: 27, series: 146, nllk loss: 0.86090, kernel loss: 0.01285\n",
      "Epoch: 27, series: 147, nllk loss: -1.84428, kernel loss: 0.06187\n",
      "Epoch: 27, series: 148, nllk loss: -1.33465, kernel loss: 0.11321\n",
      "Epoch: 27, series: 149, nllk loss: -1.93606, kernel loss: 0.19139\n",
      "Epoch: 27, series: 150, nllk loss: -2.01823, kernel loss: 0.10422\n",
      "Epoch: 27, series: 151, nllk loss: -2.13234, kernel loss: 0.21992\n",
      "Epoch: 27, series: 152, nllk loss: -2.15593, kernel loss: 0.12209\n",
      "Epoch: 27, series: 153, nllk loss: -1.84849, kernel loss: 0.03720\n",
      "Epoch: 27, series: 154, nllk loss: -1.90600, kernel loss: 0.05746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, series: 155, nllk loss: -2.10334, kernel loss: 0.05782\n",
      "Epoch: 27, series: 156, nllk loss: -2.16896, kernel loss: 0.06971\n",
      "Epoch: 27, series: 157, nllk loss: -1.70002, kernel loss: 0.05506\n",
      "Epoch: 27, series: 158, nllk loss: -2.17378, kernel loss: 0.28879\n",
      "Epoch: 27, series: 159, nllk loss: -2.16510, kernel loss: 0.03996\n",
      "Epoch: 27, series: 160, nllk loss: -2.02364, kernel loss: 0.20160\n",
      "Epoch: 27, series: 161, nllk loss: -1.86113, kernel loss: 0.11880\n",
      "Epoch: 27, series: 162, nllk loss: -2.32386, kernel loss: 0.10446\n",
      "Epoch: 27, series: 163, nllk loss: -2.52083, kernel loss: 0.05152\n",
      "Epoch: 27, series: 164, nllk loss: -1.87689, kernel loss: 0.09351\n",
      "Epoch: 27, series: 165, nllk loss: -2.04700, kernel loss: 0.15794\n",
      "Epoch: 27, series: 166, nllk loss: -1.39443, kernel loss: 0.09638\n",
      "Epoch: 27, series: 167, nllk loss: -2.70726, kernel loss: 0.15588\n",
      "Epoch: 27, series: 168, nllk loss: -2.16940, kernel loss: 0.08976\n",
      "Epoch: 27, series: 169, nllk loss: -2.36973, kernel loss: 0.03780\n",
      "Epoch: 27, series: 170, nllk loss: -2.03339, kernel loss: 0.11979\n",
      "Epoch: 27, series: 171, nllk loss: -2.57240, kernel loss: 0.06041\n",
      "Epoch: 27, series: 172, nllk loss: -2.16343, kernel loss: 0.07500\n",
      "Epoch: 27, series: 173, nllk loss: -2.62880, kernel loss: 0.01888\n",
      "Epoch: 27, series: 174, nllk loss: -2.36505, kernel loss: 0.02913\n",
      "Epoch: 27, series: 175, nllk loss: -2.64256, kernel loss: 0.10465\n",
      "Epoch: 27, series: 176, nllk loss: -2.01132, kernel loss: 0.19603\n",
      "Epoch: 27, series: 177, nllk loss: -2.11924, kernel loss: 0.08659\n",
      "Epoch: 27, series: 178, nllk loss: -1.79397, kernel loss: 0.23116\n",
      "Epoch: 27, series: 179, nllk loss: -2.25385, kernel loss: 0.05327\n",
      "Epoch: 27, series: 180, nllk loss: -2.39932, kernel loss: 0.04837\n",
      "Epoch: 27, series: 181, nllk loss: -2.67106, kernel loss: 0.06100\n",
      "Epoch: 27, series: 182, nllk loss: -2.28713, kernel loss: 0.14819\n",
      "Epoch: 27, series: 183, nllk loss: -2.06025, kernel loss: 0.06981\n",
      "Epoch: 27, series: 184, nllk loss: -2.14022, kernel loss: 0.03993\n",
      "Epoch: 27, series: 185, nllk loss: -1.84889, kernel loss: 0.06501\n",
      "Epoch: 27, series: 186, nllk loss: -2.73212, kernel loss: 0.17668\n",
      "Epoch: 27, series: 187, nllk loss: -2.77574, kernel loss: 0.09466\n",
      "Epoch: 27, series: 188, nllk loss: -1.77785, kernel loss: 0.06003\n",
      "Epoch: 27, series: 189, nllk loss: -1.59018, kernel loss: 0.12229\n",
      "Epoch: 27, series: 190, nllk loss: -2.34329, kernel loss: 0.02614\n",
      "Epoch: 27, series: 191, nllk loss: -2.13224, kernel loss: 0.15883\n",
      "Epoch: 27, series: 192, nllk loss: -2.28746, kernel loss: 0.09184\n",
      "Epoch: 27, series: 193, nllk loss: -1.59800, kernel loss: 0.14993\n",
      "Epoch: 27, series: 194, nllk loss: -1.59714, kernel loss: 0.19715\n",
      "Epoch: 27, series: 195, nllk loss: -2.26134, kernel loss: 0.14875\n",
      "Epoch: 27, series: 196, nllk loss: -1.97206, kernel loss: 0.10221\n",
      "Epoch: 27, series: 197, nllk loss: -2.16142, kernel loss: 0.06856\n",
      "Epoch: 27, series: 198, nllk loss: -2.43145, kernel loss: 0.28191\n",
      "Epoch: 27, series: 199, nllk loss: -1.93129, kernel loss: 0.03512\n",
      "Epoch: 27, series: 200, nllk loss: -2.32402, kernel loss: 0.05191\n",
      "Epoch: 27, series: 201, nllk loss: -2.33974, kernel loss: 0.13851\n",
      "Epoch: 27, series: 202, nllk loss: -2.14279, kernel loss: 0.05130\n",
      "Epoch: 27, series: 203, nllk loss: -1.89543, kernel loss: 0.06021\n",
      "Epoch: 27, series: 204, nllk loss: -1.17991, kernel loss: 0.05396\n",
      "Epoch: 27, series: 205, nllk loss: -2.24403, kernel loss: 0.11081\n",
      "Epoch: 27, series: 206, nllk loss: -2.30571, kernel loss: 0.11610\n",
      "Epoch: 27, series: 207, nllk loss: -1.00074, kernel loss: 0.10396\n",
      "Epoch: 27, series: 208, nllk loss: -2.41065, kernel loss: 0.13693\n",
      "Epoch: 27, series: 209, nllk loss: -1.82708, kernel loss: 0.08927\n",
      "Epoch: 27, series: 210, nllk loss: -2.73870, kernel loss: 0.14658\n",
      "Epoch: 27, series: 211, nllk loss: -2.33041, kernel loss: 0.05515\n",
      "Epoch: 27, series: 212, nllk loss: -1.33765, kernel loss: 0.16569\n",
      "Epoch: 27, series: 213, nllk loss: -2.27857, kernel loss: 0.02005\n",
      "Epoch: 27, series: 214, nllk loss: -2.31186, kernel loss: 0.04317\n",
      "Epoch: 27, series: 215, nllk loss: -2.64721, kernel loss: 0.15482\n",
      "Epoch: 27, series: 216, nllk loss: -1.42733, kernel loss: 0.05619\n",
      "Epoch: 27, series: 217, nllk loss: -2.06423, kernel loss: 0.10179\n",
      "Epoch: 27, series: 218, nllk loss: -1.65781, kernel loss: 0.11130\n",
      "Epoch: 27, series: 219, nllk loss: -2.31491, kernel loss: 0.10977\n",
      "Epoch: 27, series: 220, nllk loss: -2.29570, kernel loss: 0.14637\n",
      "Epoch: 27, series: 221, nllk loss: -2.61232, kernel loss: 0.15877\n",
      "Epoch: 27, series: 222, nllk loss: -2.27308, kernel loss: 0.18918\n",
      "Epoch: 27, series: 223, nllk loss: -1.75347, kernel loss: 0.07072\n",
      "Epoch: 27, series: 224, nllk loss: -2.62833, kernel loss: 0.06080\n",
      "Epoch: 27, series: 225, nllk loss: -2.48499, kernel loss: 0.07937\n",
      "Epoch: 27, series: 226, nllk loss: -1.96352, kernel loss: 0.02290\n",
      "Epoch: 27, series: 227, nllk loss: -2.24039, kernel loss: 0.11086\n",
      "Epoch: 27, series: 228, nllk loss: -2.40564, kernel loss: 0.04170\n",
      "Epoch: 27, series: 229, nllk loss: -2.16235, kernel loss: 0.10393\n",
      "Epoch: 27, series: 230, nllk loss: -2.58221, kernel loss: 0.04786\n",
      "Epoch: 27, series: 231, nllk loss: -1.98771, kernel loss: 0.07505\n",
      "Epoch: 27, series: 232, nllk loss: -2.74471, kernel loss: 0.13342\n",
      "Epoch: 27, series: 233, nllk loss: -2.51920, kernel loss: 0.18311\n",
      "Epoch: 27, series: 234, nllk loss: -1.98831, kernel loss: 0.07419\n",
      "Epoch: 27, series: 235, nllk loss: -2.68439, kernel loss: 0.08006\n",
      "Epoch: 27, series: 236, nllk loss: -1.69922, kernel loss: 0.04737\n",
      "Epoch: 27, series: 237, nllk loss: -2.35526, kernel loss: 0.05999\n",
      "Epoch: 27, series: 238, nllk loss: -2.17083, kernel loss: 0.07397\n",
      "Epoch: 27, series: 239, nllk loss: -2.49821, kernel loss: 0.09031\n",
      "Epoch: 27, series: 240, nllk loss: -0.92550, kernel loss: 0.07371\n",
      "Epoch: 27, series: 241, nllk loss: -2.14063, kernel loss: 0.09976\n",
      "Epoch: 27, series: 242, nllk loss: -2.19526, kernel loss: 0.04097\n",
      "Epoch: 27, series: 243, nllk loss: -2.49066, kernel loss: 0.07653\n",
      "Epoch: 27, series: 244, nllk loss: -2.17954, kernel loss: 0.14302\n",
      "Epoch: 27, series: 245, nllk loss: -2.26780, kernel loss: 0.16150\n",
      "Epoch: 27, series: 246, nllk loss: -0.43318, kernel loss: 0.04703\n",
      "Epoch: 27, series: 247, nllk loss: -1.76576, kernel loss: 0.11644\n",
      "Epoch: 27, series: 248, nllk loss: -2.17544, kernel loss: 0.24321\n",
      "Epoch: 27, series: 249, nllk loss: -2.05955, kernel loss: 0.08528\n",
      "Epoch: 27, series: 250, nllk loss: -1.74016, kernel loss: 0.10029\n",
      "Epoch: 27, series: 251, nllk loss: -1.26294, kernel loss: 0.12805\n",
      "Epoch: 27, series: 252, nllk loss: -1.53208, kernel loss: 0.01958\n",
      "Epoch: 27, series: 253, nllk loss: -1.90755, kernel loss: 0.07079\n",
      "Epoch: 27, series: 254, nllk loss: -2.36946, kernel loss: 0.03898\n",
      "Epoch: 27, series: 255, nllk loss: -2.17187, kernel loss: 0.03821\n",
      "Epoch: 27, series: 256, nllk loss: -1.92900, kernel loss: 0.08875\n",
      "Epoch: 27, series: 257, nllk loss: -2.20375, kernel loss: 0.13585\n",
      "Epoch: 27, series: 258, nllk loss: -2.23760, kernel loss: 0.07240\n",
      "Epoch: 27, series: 259, nllk loss: -1.96335, kernel loss: 0.04298\n",
      "Epoch: 27, series: 260, nllk loss: -2.04345, kernel loss: 0.15153\n",
      "Epoch: 27, series: 261, nllk loss: -2.03749, kernel loss: 0.09592\n",
      "Epoch: 27, series: 262, nllk loss: -2.67765, kernel loss: 0.13694\n",
      "Epoch: 27, series: 263, nllk loss: -0.74563, kernel loss: 0.16130\n",
      "Epoch: 27, series: 264, nllk loss: -2.02437, kernel loss: 0.04843\n",
      "Epoch: 27, series: 265, nllk loss: -1.94500, kernel loss: 0.07598\n",
      "Epoch: 27, series: 266, nllk loss: -2.37599, kernel loss: 0.11834\n",
      "Epoch: 27, series: 267, nllk loss: -2.14029, kernel loss: 0.10145\n",
      "Epoch: 27, series: 268, nllk loss: -2.13510, kernel loss: 0.02528\n",
      "Epoch: 27, series: 269, nllk loss: -1.86567, kernel loss: 0.07667\n",
      "Epoch: 27, series: 270, nllk loss: -1.98745, kernel loss: 0.05261\n",
      "Epoch: 27, series: 271, nllk loss: -2.17004, kernel loss: 0.14268\n",
      "Epoch: 27, series: 272, nllk loss: -1.98406, kernel loss: 0.08246\n",
      "Epoch: 27, series: 273, nllk loss: -2.07009, kernel loss: 0.06795\n",
      "Epoch: 27, series: 274, nllk loss: -1.62548, kernel loss: 0.01784\n",
      "Epoch: 27, series: 275, nllk loss: -2.08310, kernel loss: 0.06785\n",
      "Epoch: 27, series: 276, nllk loss: -1.40504, kernel loss: 0.14897\n",
      "Epoch: 27, series: 277, nllk loss: -2.28659, kernel loss: 0.07908\n",
      "Epoch: 27, series: 278, nllk loss: -2.05860, kernel loss: 0.15560\n",
      "Epoch: 27, series: 279, nllk loss: -2.40177, kernel loss: 0.13660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27, series: 280, nllk loss: -2.15537, kernel loss: 0.07099\n",
      "Epoch: 27, series: 281, nllk loss: -2.41528, kernel loss: 0.21660\n",
      "Epoch: 27, series: 282, nllk loss: -2.33673, kernel loss: 0.01709\n",
      "Epoch: 27, series: 283, nllk loss: -2.33938, kernel loss: 0.02536\n",
      "Epoch: 27, series: 284, nllk loss: -1.73067, kernel loss: 0.15067\n",
      "Epoch: 27, series: 285, nllk loss: -1.99872, kernel loss: 0.15089\n",
      "Epoch: 27, series: 286, nllk loss: -2.24560, kernel loss: 0.16303\n",
      "Epoch: 27, series: 287, nllk loss: -2.56331, kernel loss: 0.20308\n",
      "Epoch: 27, series: 288, nllk loss: -1.26725, kernel loss: 0.18583\n",
      "Epoch: 27, series: 289, nllk loss: -1.27375, kernel loss: 0.10026\n",
      "Epoch: 27, series: 290, nllk loss: -2.34125, kernel loss: 0.11151\n",
      "Epoch: 27, series: 291, nllk loss: -2.52589, kernel loss: 0.05809\n",
      "Epoch: 27, series: 292, nllk loss: -2.45879, kernel loss: 0.17876\n",
      "Epoch: 27, series: 293, nllk loss: -2.55130, kernel loss: 0.08041\n",
      "Epoch: 27, series: 294, nllk loss: -1.44805, kernel loss: 0.03850\n",
      "Epoch: 27, series: 295, nllk loss: -1.32354, kernel loss: 0.04082\n",
      "Epoch: 27, series: 296, nllk loss: -2.69772, kernel loss: 0.01531\n",
      "Epoch: 27, series: 297, nllk loss: -2.72242, kernel loss: 0.16054\n",
      "Epoch: 27, series: 298, nllk loss: -0.30116, kernel loss: 0.06110\n",
      "Epoch: 27, series: 299, nllk loss: -0.92012, kernel loss: 0.11152\n",
      "Epoch: 27, series: 300, nllk loss: -2.31355, kernel loss: 0.05563\n",
      "Epoch: 27, series: 301, nllk loss: -2.76907, kernel loss: 0.19717\n",
      "Epoch: 27, series: 302, nllk loss: -2.44536, kernel loss: 0.12926\n",
      "Epoch: 27, series: 303, nllk loss: -2.16946, kernel loss: 0.09828\n",
      "Epoch: 27, series: 304, nllk loss: -0.25900, kernel loss: 0.04466\n",
      "Epoch: 27, series: 305, nllk loss: -2.15702, kernel loss: 0.04250\n",
      "Epoch: 27, series: 306, nllk loss: -2.70315, kernel loss: 0.07623\n",
      "Epoch: 27, series: 307, nllk loss: -1.91348, kernel loss: 0.19653\n",
      "Epoch: 27, series: 308, nllk loss: -2.70121, kernel loss: 0.12716\n",
      "Epoch: 27, series: 309, nllk loss: -2.12519, kernel loss: 0.11405\n",
      "Epoch: 27, series: 310, nllk loss: -2.51425, kernel loss: 0.18167\n",
      "Epoch: 27, series: 311, nllk loss: -2.05679, kernel loss: 0.07429\n",
      "Epoch: 27, series: 312, nllk loss: -2.16377, kernel loss: 0.10158\n",
      "Epoch: 27, series: 313, nllk loss: -2.31762, kernel loss: 0.18204\n",
      "Epoch: 27, series: 314, nllk loss: -2.92345, kernel loss: 0.10542\n",
      "Epoch: 27, series: 315, nllk loss: -0.99735, kernel loss: 0.12839\n",
      "Epoch: 27, series: 316, nllk loss: -2.23700, kernel loss: 0.13584\n",
      "Epoch: 27, series: 317, nllk loss: -0.01706, kernel loss: 0.10688\n",
      "Epoch: 27, series: 318, nllk loss: 0.48705, kernel loss: 0.09149\n",
      "Epoch: 27, series: 319, nllk loss: -1.10872, kernel loss: 0.12707\n",
      "Epoch: 27, series: 320, nllk loss: -0.93505, kernel loss: 0.04504\n",
      "Epoch: 27, total loss: -522.55474\n",
      "Epoch: 28, series: 0, nllk loss: 0.74649, kernel loss: 0.17606\n",
      "Epoch: 28, series: 1, nllk loss: -0.99913, kernel loss: 0.20229\n",
      "Epoch: 28, series: 2, nllk loss: -0.06431, kernel loss: 0.10871\n",
      "Epoch: 28, series: 3, nllk loss: -1.49780, kernel loss: 0.17155\n",
      "Epoch: 28, series: 4, nllk loss: -1.09581, kernel loss: 0.05345\n",
      "Epoch: 28, series: 5, nllk loss: -1.36594, kernel loss: 0.19142\n",
      "Epoch: 28, series: 6, nllk loss: -0.65467, kernel loss: 0.20432\n",
      "Epoch: 28, series: 7, nllk loss: -1.08283, kernel loss: 0.06173\n",
      "Epoch: 28, series: 8, nllk loss: -0.56902, kernel loss: 0.13362\n",
      "Epoch: 28, series: 9, nllk loss: -0.63771, kernel loss: 0.10211\n",
      "Epoch: 28, series: 10, nllk loss: -1.46873, kernel loss: 0.07021\n",
      "Epoch: 28, series: 11, nllk loss: -1.26231, kernel loss: 0.17583\n",
      "Epoch: 28, series: 12, nllk loss: -1.72070, kernel loss: 0.24021\n",
      "Epoch: 28, series: 13, nllk loss: -1.46407, kernel loss: 0.03028\n",
      "Epoch: 28, series: 14, nllk loss: -1.70469, kernel loss: 0.15835\n",
      "Epoch: 28, series: 15, nllk loss: -1.75652, kernel loss: 0.09529\n",
      "Epoch: 28, series: 16, nllk loss: -1.24211, kernel loss: 0.18404\n",
      "Epoch: 28, series: 17, nllk loss: -1.30308, kernel loss: 0.10637\n",
      "Epoch: 28, series: 18, nllk loss: -1.53456, kernel loss: 0.05481\n",
      "Epoch: 28, series: 19, nllk loss: -0.31514, kernel loss: 0.13767\n",
      "Epoch: 28, series: 20, nllk loss: -0.85611, kernel loss: 0.07827\n",
      "Epoch: 28, series: 21, nllk loss: -1.15886, kernel loss: 0.01885\n",
      "Epoch: 28, series: 22, nllk loss: -1.61729, kernel loss: 0.08229\n",
      "Epoch: 28, series: 23, nllk loss: -1.63790, kernel loss: 0.16697\n",
      "Epoch: 28, series: 24, nllk loss: -1.94559, kernel loss: 0.06376\n",
      "Epoch: 28, series: 25, nllk loss: -1.77777, kernel loss: 0.04690\n",
      "Epoch: 28, series: 26, nllk loss: -1.38614, kernel loss: 0.07897\n",
      "Epoch: 28, series: 27, nllk loss: -1.30629, kernel loss: 0.11148\n",
      "Epoch: 28, series: 28, nllk loss: -1.37600, kernel loss: 0.12406\n",
      "Epoch: 28, series: 29, nllk loss: -1.11524, kernel loss: 0.08620\n",
      "Epoch: 28, series: 30, nllk loss: -1.56918, kernel loss: 0.07903\n",
      "Epoch: 28, series: 31, nllk loss: -1.18258, kernel loss: 0.09011\n",
      "Epoch: 28, series: 32, nllk loss: -1.19007, kernel loss: 0.06180\n",
      "Epoch: 28, series: 33, nllk loss: -1.07414, kernel loss: 0.01691\n",
      "Epoch: 28, series: 34, nllk loss: -1.48973, kernel loss: 0.11800\n",
      "Epoch: 28, series: 35, nllk loss: -1.75263, kernel loss: 0.03884\n",
      "Epoch: 28, series: 36, nllk loss: -1.80697, kernel loss: 0.08415\n",
      "Epoch: 28, series: 37, nllk loss: -0.62856, kernel loss: 0.07158\n",
      "Epoch: 28, series: 38, nllk loss: -1.08919, kernel loss: 0.19765\n",
      "Epoch: 28, series: 39, nllk loss: -0.79661, kernel loss: 0.06692\n",
      "Epoch: 28, series: 40, nllk loss: -2.01817, kernel loss: 0.07040\n",
      "Epoch: 28, series: 41, nllk loss: -1.43121, kernel loss: 0.01641\n",
      "Epoch: 28, series: 42, nllk loss: -1.12016, kernel loss: 0.11447\n",
      "Epoch: 28, series: 43, nllk loss: -1.19680, kernel loss: 0.14767\n",
      "Epoch: 28, series: 44, nllk loss: -1.69839, kernel loss: 0.06681\n",
      "Epoch: 28, series: 45, nllk loss: -1.79809, kernel loss: 0.07346\n",
      "Epoch: 28, series: 46, nllk loss: -1.82845, kernel loss: 0.11374\n",
      "Epoch: 28, series: 47, nllk loss: -1.65734, kernel loss: 0.07839\n",
      "Epoch: 28, series: 48, nllk loss: -1.75760, kernel loss: 0.09581\n",
      "Epoch: 28, series: 49, nllk loss: -1.19014, kernel loss: 0.17626\n",
      "Epoch: 28, series: 50, nllk loss: -0.16294, kernel loss: 0.07120\n",
      "Epoch: 28, series: 51, nllk loss: -1.36284, kernel loss: 0.11312\n",
      "Epoch: 28, series: 52, nllk loss: -0.40088, kernel loss: 0.10047\n",
      "Epoch: 28, series: 53, nllk loss: -1.73440, kernel loss: 0.05232\n",
      "Epoch: 28, series: 54, nllk loss: -1.46833, kernel loss: 0.10586\n",
      "Epoch: 28, series: 55, nllk loss: -0.72798, kernel loss: 0.11450\n",
      "Epoch: 28, series: 56, nllk loss: -1.50769, kernel loss: 0.06850\n",
      "Epoch: 28, series: 57, nllk loss: -1.45892, kernel loss: 0.07826\n",
      "Epoch: 28, series: 58, nllk loss: -1.61696, kernel loss: 0.05995\n",
      "Epoch: 28, series: 59, nllk loss: -1.24814, kernel loss: 0.14331\n",
      "Epoch: 28, series: 60, nllk loss: -1.17895, kernel loss: 0.05920\n",
      "Epoch: 28, series: 61, nllk loss: -1.87614, kernel loss: 0.08091\n",
      "Epoch: 28, series: 62, nllk loss: -1.89466, kernel loss: 0.08361\n",
      "Epoch: 28, series: 63, nllk loss: -1.83767, kernel loss: 0.04419\n",
      "Epoch: 28, series: 64, nllk loss: -1.30011, kernel loss: 0.09700\n",
      "Epoch: 28, series: 65, nllk loss: -1.74873, kernel loss: 0.05915\n",
      "Epoch: 28, series: 66, nllk loss: -1.76044, kernel loss: 0.30328\n",
      "Epoch: 28, series: 67, nllk loss: -1.51522, kernel loss: 0.11044\n",
      "Epoch: 28, series: 68, nllk loss: -0.94836, kernel loss: 0.02554\n",
      "Epoch: 28, series: 69, nllk loss: -1.64678, kernel loss: 0.10297\n",
      "Epoch: 28, series: 70, nllk loss: -1.43870, kernel loss: 0.03962\n",
      "Epoch: 28, series: 71, nllk loss: -1.55165, kernel loss: 0.04558\n",
      "Epoch: 28, series: 72, nllk loss: -1.90045, kernel loss: 0.07217\n",
      "Epoch: 28, series: 73, nllk loss: -1.45373, kernel loss: 0.05383\n",
      "Epoch: 28, series: 74, nllk loss: -2.14372, kernel loss: 0.16349\n",
      "Epoch: 28, series: 75, nllk loss: -1.74261, kernel loss: 0.05398\n",
      "Epoch: 28, series: 76, nllk loss: -1.43006, kernel loss: 0.09586\n",
      "Epoch: 28, series: 77, nllk loss: -1.42649, kernel loss: 0.07123\n",
      "Epoch: 28, series: 78, nllk loss: -1.56706, kernel loss: 0.06999\n",
      "Epoch: 28, series: 79, nllk loss: -0.45586, kernel loss: 0.04890\n",
      "Epoch: 28, series: 80, nllk loss: -1.84219, kernel loss: 0.07264\n",
      "Epoch: 28, series: 81, nllk loss: -1.66433, kernel loss: 0.01870\n",
      "Epoch: 28, series: 82, nllk loss: -0.45849, kernel loss: 0.08360\n",
      "Epoch: 28, series: 83, nllk loss: -1.34635, kernel loss: 0.04028\n",
      "Epoch: 28, series: 84, nllk loss: -1.44206, kernel loss: 0.11248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, series: 85, nllk loss: -1.67136, kernel loss: 0.07476\n",
      "Epoch: 28, series: 86, nllk loss: -0.97005, kernel loss: 0.03326\n",
      "Epoch: 28, series: 87, nllk loss: -1.97937, kernel loss: 0.05444\n",
      "Epoch: 28, series: 88, nllk loss: -2.29771, kernel loss: 0.21887\n",
      "Epoch: 28, series: 89, nllk loss: -2.02905, kernel loss: 0.02540\n",
      "Epoch: 28, series: 90, nllk loss: -2.42878, kernel loss: 0.07128\n",
      "Epoch: 28, series: 91, nllk loss: -2.31116, kernel loss: 0.09153\n",
      "Epoch: 28, series: 92, nllk loss: 0.00602, kernel loss: 0.03710\n",
      "Epoch: 28, series: 93, nllk loss: -2.70498, kernel loss: 0.12474\n",
      "Epoch: 28, series: 94, nllk loss: -2.59398, kernel loss: 0.11255\n",
      "Epoch: 28, series: 95, nllk loss: -2.57495, kernel loss: 0.17729\n",
      "Epoch: 28, series: 96, nllk loss: -1.84436, kernel loss: 0.00305\n",
      "Epoch: 28, series: 97, nllk loss: -0.83361, kernel loss: 0.08532\n",
      "Epoch: 28, series: 98, nllk loss: -0.74443, kernel loss: 0.03549\n",
      "Epoch: 28, series: 99, nllk loss: -1.53470, kernel loss: 0.27540\n",
      "Epoch: 28, series: 100, nllk loss: -1.07767, kernel loss: 0.11407\n",
      "Epoch: 28, series: 101, nllk loss: -1.51123, kernel loss: 0.14606\n",
      "Epoch: 28, series: 102, nllk loss: -0.86894, kernel loss: 0.13579\n",
      "Epoch: 28, series: 103, nllk loss: -1.21438, kernel loss: 0.06155\n",
      "Epoch: 28, series: 104, nllk loss: -0.19358, kernel loss: 0.35845\n",
      "Epoch: 28, series: 105, nllk loss: -0.65620, kernel loss: 0.15323\n",
      "Epoch: 28, series: 106, nllk loss: -1.24522, kernel loss: 0.04529\n",
      "Epoch: 28, series: 107, nllk loss: -1.11229, kernel loss: 0.16540\n",
      "Epoch: 28, series: 108, nllk loss: -1.38885, kernel loss: 0.11243\n",
      "Epoch: 28, series: 109, nllk loss: -1.34671, kernel loss: 0.10909\n",
      "Epoch: 28, series: 110, nllk loss: -1.83697, kernel loss: 0.09156\n",
      "Epoch: 28, series: 111, nllk loss: -1.61989, kernel loss: 0.02664\n",
      "Epoch: 28, series: 112, nllk loss: -0.98503, kernel loss: 0.11684\n",
      "Epoch: 28, series: 113, nllk loss: -1.30271, kernel loss: 0.14791\n",
      "Epoch: 28, series: 114, nllk loss: -1.32986, kernel loss: 0.10865\n",
      "Epoch: 28, series: 115, nllk loss: -1.19229, kernel loss: 0.07432\n",
      "Epoch: 28, series: 116, nllk loss: -1.70335, kernel loss: 0.00885\n",
      "Epoch: 28, series: 117, nllk loss: -0.72570, kernel loss: 0.10428\n",
      "Epoch: 28, series: 118, nllk loss: -2.20905, kernel loss: 0.19488\n",
      "Epoch: 28, series: 119, nllk loss: -0.88500, kernel loss: 0.12551\n",
      "Epoch: 28, series: 120, nllk loss: -1.67137, kernel loss: 0.09944\n",
      "Epoch: 28, series: 121, nllk loss: -0.18535, kernel loss: 0.14660\n",
      "Epoch: 28, series: 122, nllk loss: -0.59693, kernel loss: 0.05401\n",
      "Epoch: 28, series: 123, nllk loss: -2.01566, kernel loss: 0.20991\n",
      "Epoch: 28, series: 124, nllk loss: -2.27843, kernel loss: 0.08075\n",
      "Epoch: 28, series: 125, nllk loss: -1.26594, kernel loss: 0.06302\n",
      "Epoch: 28, series: 126, nllk loss: -2.16386, kernel loss: 0.11312\n",
      "Epoch: 28, series: 127, nllk loss: -1.36199, kernel loss: 0.11612\n",
      "Epoch: 28, series: 128, nllk loss: -0.96993, kernel loss: 0.14063\n",
      "Epoch: 28, series: 129, nllk loss: -1.00264, kernel loss: 0.05257\n",
      "Epoch: 28, series: 130, nllk loss: -1.70016, kernel loss: 0.09900\n",
      "Epoch: 28, series: 131, nllk loss: 0.18534, kernel loss: 0.10110\n",
      "Epoch: 28, series: 132, nllk loss: -0.34360, kernel loss: 0.03206\n",
      "Epoch: 28, series: 133, nllk loss: -1.09645, kernel loss: 0.11740\n",
      "Epoch: 28, series: 134, nllk loss: -0.77900, kernel loss: 0.12029\n",
      "Epoch: 28, series: 135, nllk loss: -1.74943, kernel loss: 0.04269\n",
      "Epoch: 28, series: 136, nllk loss: -1.84180, kernel loss: 0.10842\n",
      "Epoch: 28, series: 137, nllk loss: -2.05172, kernel loss: 0.16969\n",
      "Epoch: 28, series: 138, nllk loss: -1.90847, kernel loss: 0.05699\n",
      "Epoch: 28, series: 139, nllk loss: -1.85152, kernel loss: 0.00801\n",
      "Epoch: 28, series: 140, nllk loss: -1.55062, kernel loss: 0.02057\n",
      "Epoch: 28, series: 141, nllk loss: -1.90969, kernel loss: 0.02279\n",
      "Epoch: 28, series: 142, nllk loss: -2.00472, kernel loss: 0.05799\n",
      "Epoch: 28, series: 143, nllk loss: -1.79196, kernel loss: 0.13177\n",
      "Epoch: 28, series: 144, nllk loss: -2.13010, kernel loss: 0.20231\n",
      "Epoch: 28, series: 145, nllk loss: -1.99522, kernel loss: 0.19988\n",
      "Epoch: 28, series: 146, nllk loss: 0.85774, kernel loss: 0.10717\n",
      "Epoch: 28, series: 147, nllk loss: -1.82840, kernel loss: 0.13672\n",
      "Epoch: 28, series: 148, nllk loss: -1.34213, kernel loss: 0.11494\n",
      "Epoch: 28, series: 149, nllk loss: -2.00656, kernel loss: 0.09684\n",
      "Epoch: 28, series: 150, nllk loss: -2.06125, kernel loss: 0.10893\n",
      "Epoch: 28, series: 151, nllk loss: -2.15263, kernel loss: 0.06795\n",
      "Epoch: 28, series: 152, nllk loss: -2.11383, kernel loss: 0.07314\n",
      "Epoch: 28, series: 153, nllk loss: -1.83626, kernel loss: 0.06122\n",
      "Epoch: 28, series: 154, nllk loss: -1.84177, kernel loss: 0.01068\n",
      "Epoch: 28, series: 155, nllk loss: -2.04750, kernel loss: 0.15444\n",
      "Epoch: 28, series: 156, nllk loss: -2.13554, kernel loss: 0.01595\n",
      "Epoch: 28, series: 157, nllk loss: -1.69101, kernel loss: 0.07142\n",
      "Epoch: 28, series: 158, nllk loss: -2.17902, kernel loss: 0.01763\n",
      "Epoch: 28, series: 159, nllk loss: -2.15065, kernel loss: 0.20136\n",
      "Epoch: 28, series: 160, nllk loss: -2.00548, kernel loss: 0.09818\n",
      "Epoch: 28, series: 161, nllk loss: -1.84100, kernel loss: 0.08978\n",
      "Epoch: 28, series: 162, nllk loss: -2.36380, kernel loss: 0.03072\n",
      "Epoch: 28, series: 163, nllk loss: -2.48577, kernel loss: 0.05716\n",
      "Epoch: 28, series: 164, nllk loss: -1.81896, kernel loss: 0.13485\n",
      "Epoch: 28, series: 165, nllk loss: -2.04151, kernel loss: 0.10242\n",
      "Epoch: 28, series: 166, nllk loss: -1.57189, kernel loss: 0.05847\n",
      "Epoch: 28, series: 167, nllk loss: -2.69548, kernel loss: 0.07594\n",
      "Epoch: 28, series: 168, nllk loss: -2.19426, kernel loss: 0.06926\n",
      "Epoch: 28, series: 169, nllk loss: -2.39853, kernel loss: 0.02888\n",
      "Epoch: 28, series: 170, nllk loss: -2.03525, kernel loss: 0.13153\n",
      "Epoch: 28, series: 171, nllk loss: -2.55651, kernel loss: 0.12565\n",
      "Epoch: 28, series: 172, nllk loss: -2.12142, kernel loss: 0.06936\n",
      "Epoch: 28, series: 173, nllk loss: -2.60910, kernel loss: 0.06340\n",
      "Epoch: 28, series: 174, nllk loss: -2.43114, kernel loss: 0.08776\n",
      "Epoch: 28, series: 175, nllk loss: -2.59594, kernel loss: 0.09558\n",
      "Epoch: 28, series: 176, nllk loss: -2.05050, kernel loss: 0.00724\n",
      "Epoch: 28, series: 177, nllk loss: -2.16906, kernel loss: 0.14464\n",
      "Epoch: 28, series: 178, nllk loss: -1.76817, kernel loss: 0.14146\n",
      "Epoch: 28, series: 179, nllk loss: -2.22889, kernel loss: 0.15259\n",
      "Epoch: 28, series: 180, nllk loss: -2.51164, kernel loss: 0.21870\n",
      "Epoch: 28, series: 181, nllk loss: -2.66633, kernel loss: 0.13055\n",
      "Epoch: 28, series: 182, nllk loss: -2.34664, kernel loss: 0.07342\n",
      "Epoch: 28, series: 183, nllk loss: -2.15253, kernel loss: 0.10670\n",
      "Epoch: 28, series: 184, nllk loss: -2.21159, kernel loss: 0.01098\n",
      "Epoch: 28, series: 185, nllk loss: -1.79009, kernel loss: 0.09737\n",
      "Epoch: 28, series: 186, nllk loss: -2.73622, kernel loss: 0.03895\n",
      "Epoch: 28, series: 187, nllk loss: -2.84943, kernel loss: 0.06840\n",
      "Epoch: 28, series: 188, nllk loss: -1.66621, kernel loss: 0.00571\n",
      "Epoch: 28, series: 189, nllk loss: -1.44029, kernel loss: 0.12793\n",
      "Epoch: 28, series: 190, nllk loss: -2.34827, kernel loss: 0.03656\n",
      "Epoch: 28, series: 191, nllk loss: -2.13195, kernel loss: 0.11260\n",
      "Epoch: 28, series: 192, nllk loss: -2.31912, kernel loss: 0.15539\n",
      "Epoch: 28, series: 193, nllk loss: -1.70190, kernel loss: 0.07329\n",
      "Epoch: 28, series: 194, nllk loss: -1.52655, kernel loss: 0.09623\n",
      "Epoch: 28, series: 195, nllk loss: -2.26357, kernel loss: 0.16128\n",
      "Epoch: 28, series: 196, nllk loss: -1.94240, kernel loss: 0.16739\n",
      "Epoch: 28, series: 197, nllk loss: -2.23191, kernel loss: 0.10969\n",
      "Epoch: 28, series: 198, nllk loss: -2.45959, kernel loss: 0.12825\n",
      "Epoch: 28, series: 199, nllk loss: -1.97724, kernel loss: 0.18901\n",
      "Epoch: 28, series: 200, nllk loss: -2.33916, kernel loss: 0.16551\n",
      "Epoch: 28, series: 201, nllk loss: -2.37244, kernel loss: 0.06335\n",
      "Epoch: 28, series: 202, nllk loss: -2.08117, kernel loss: 0.08072\n",
      "Epoch: 28, series: 203, nllk loss: -1.75778, kernel loss: 0.14723\n",
      "Epoch: 28, series: 204, nllk loss: -0.77842, kernel loss: 0.13288\n",
      "Epoch: 28, series: 205, nllk loss: -2.14057, kernel loss: 0.05409\n",
      "Epoch: 28, series: 206, nllk loss: -2.13672, kernel loss: 0.16704\n",
      "Epoch: 28, series: 207, nllk loss: -0.99397, kernel loss: 0.06330\n",
      "Epoch: 28, series: 208, nllk loss: -2.39931, kernel loss: 0.15942\n",
      "Epoch: 28, series: 209, nllk loss: -1.77540, kernel loss: 0.05522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28, series: 210, nllk loss: -2.65192, kernel loss: 0.15790\n",
      "Epoch: 28, series: 211, nllk loss: -2.06577, kernel loss: 0.10478\n",
      "Epoch: 28, series: 212, nllk loss: -1.62178, kernel loss: 0.34765\n",
      "Epoch: 28, series: 213, nllk loss: -2.21853, kernel loss: 0.08710\n",
      "Epoch: 28, series: 214, nllk loss: -2.36275, kernel loss: 0.03592\n",
      "Epoch: 28, series: 215, nllk loss: -2.70250, kernel loss: 0.01958\n",
      "Epoch: 28, series: 216, nllk loss: -1.44353, kernel loss: 0.04649\n",
      "Epoch: 28, series: 217, nllk loss: -2.13781, kernel loss: 0.05987\n",
      "Epoch: 28, series: 218, nllk loss: -1.49658, kernel loss: 0.14575\n",
      "Epoch: 28, series: 219, nllk loss: -2.18886, kernel loss: 0.10945\n",
      "Epoch: 28, series: 220, nllk loss: -2.28921, kernel loss: 0.06264\n",
      "Epoch: 28, series: 221, nllk loss: -2.57649, kernel loss: 0.04757\n",
      "Epoch: 28, series: 222, nllk loss: -2.24426, kernel loss: 0.12338\n",
      "Epoch: 28, series: 223, nllk loss: -1.63609, kernel loss: 0.06177\n",
      "Epoch: 28, series: 224, nllk loss: -2.57460, kernel loss: 0.22857\n",
      "Epoch: 28, series: 225, nllk loss: -2.55179, kernel loss: 0.02760\n",
      "Epoch: 28, series: 226, nllk loss: -2.04061, kernel loss: 0.02026\n",
      "Epoch: 28, series: 227, nllk loss: -2.19938, kernel loss: 0.09299\n",
      "Epoch: 28, series: 228, nllk loss: -2.24690, kernel loss: 0.09916\n",
      "Epoch: 28, series: 229, nllk loss: -2.06429, kernel loss: 0.22936\n",
      "Epoch: 28, series: 230, nllk loss: -2.56083, kernel loss: 0.06718\n",
      "Epoch: 28, series: 231, nllk loss: -2.05878, kernel loss: 0.30689\n",
      "Epoch: 28, series: 232, nllk loss: -2.68891, kernel loss: 0.02419\n",
      "Epoch: 28, series: 233, nllk loss: -2.49798, kernel loss: 0.00000\n",
      "Epoch: 28, series: 234, nllk loss: -1.97521, kernel loss: 0.21948\n",
      "Epoch: 28, series: 235, nllk loss: -2.72743, kernel loss: 0.10804\n",
      "Epoch: 28, series: 236, nllk loss: -1.70308, kernel loss: 0.21253\n",
      "Epoch: 28, series: 237, nllk loss: -2.32680, kernel loss: 0.11312\n",
      "Epoch: 28, series: 238, nllk loss: -2.15080, kernel loss: 0.16359\n",
      "Epoch: 28, series: 239, nllk loss: -2.47415, kernel loss: 0.12556\n",
      "Epoch: 28, series: 240, nllk loss: -1.24287, kernel loss: 0.03858\n",
      "Epoch: 28, series: 241, nllk loss: -2.19451, kernel loss: 0.08222\n",
      "Epoch: 28, series: 242, nllk loss: -2.17175, kernel loss: 0.09120\n",
      "Epoch: 28, series: 243, nllk loss: -2.41068, kernel loss: 0.02406\n",
      "Epoch: 28, series: 244, nllk loss: -2.08289, kernel loss: 0.08011\n",
      "Epoch: 28, series: 245, nllk loss: -2.19900, kernel loss: 0.07710\n",
      "Epoch: 28, series: 246, nllk loss: -0.48878, kernel loss: 0.05470\n",
      "Epoch: 28, series: 247, nllk loss: -1.82805, kernel loss: 0.09796\n",
      "Epoch: 28, series: 248, nllk loss: -2.23542, kernel loss: 0.06433\n",
      "Epoch: 28, series: 249, nllk loss: -2.14054, kernel loss: 0.28579\n",
      "Epoch: 28, series: 250, nllk loss: -1.65794, kernel loss: 0.12474\n",
      "Epoch: 28, series: 251, nllk loss: -1.29219, kernel loss: 0.02713\n",
      "Epoch: 28, series: 252, nllk loss: -1.58549, kernel loss: 0.04357\n",
      "Epoch: 28, series: 253, nllk loss: -1.77690, kernel loss: 0.05577\n",
      "Epoch: 28, series: 254, nllk loss: -2.35017, kernel loss: 0.01882\n",
      "Epoch: 28, series: 255, nllk loss: -2.18701, kernel loss: 0.09609\n",
      "Epoch: 28, series: 256, nllk loss: -1.89831, kernel loss: 0.08254\n",
      "Epoch: 28, series: 257, nllk loss: -2.12748, kernel loss: 0.16547\n",
      "Epoch: 28, series: 258, nllk loss: -2.22578, kernel loss: 0.02224\n",
      "Epoch: 28, series: 259, nllk loss: -1.87186, kernel loss: 0.12994\n",
      "Epoch: 28, series: 260, nllk loss: -2.01331, kernel loss: 0.08693\n",
      "Epoch: 28, series: 261, nllk loss: -2.23111, kernel loss: 0.23252\n",
      "Epoch: 28, series: 262, nllk loss: -2.67480, kernel loss: 0.05134\n",
      "Epoch: 28, series: 263, nllk loss: -0.69491, kernel loss: 0.00181\n",
      "Epoch: 28, series: 264, nllk loss: -1.93953, kernel loss: 0.01886\n",
      "Epoch: 28, series: 265, nllk loss: -1.95878, kernel loss: 0.09366\n",
      "Epoch: 28, series: 266, nllk loss: -2.38746, kernel loss: 0.04276\n",
      "Epoch: 28, series: 267, nllk loss: -2.16270, kernel loss: 0.09678\n",
      "Epoch: 28, series: 268, nllk loss: -2.12935, kernel loss: 0.01312\n",
      "Epoch: 28, series: 269, nllk loss: -1.84137, kernel loss: 0.05240\n",
      "Epoch: 28, series: 270, nllk loss: -2.02640, kernel loss: 0.09316\n",
      "Epoch: 28, series: 271, nllk loss: -2.12855, kernel loss: 0.08688\n",
      "Epoch: 28, series: 272, nllk loss: -2.03402, kernel loss: 0.18598\n",
      "Epoch: 28, series: 273, nllk loss: -2.03570, kernel loss: 0.03411\n",
      "Epoch: 28, series: 274, nllk loss: -1.57519, kernel loss: 0.12561\n",
      "Epoch: 28, series: 275, nllk loss: -2.05718, kernel loss: 0.06880\n",
      "Epoch: 28, series: 276, nllk loss: -1.40262, kernel loss: 0.04849\n",
      "Epoch: 28, series: 277, nllk loss: -2.40974, kernel loss: 0.18796\n",
      "Epoch: 28, series: 278, nllk loss: -2.05441, kernel loss: 0.17118\n",
      "Epoch: 28, series: 279, nllk loss: -2.51095, kernel loss: 0.05198\n",
      "Epoch: 28, series: 280, nllk loss: -2.20656, kernel loss: 0.06304\n",
      "Epoch: 28, series: 281, nllk loss: -2.46438, kernel loss: 0.07710\n",
      "Epoch: 28, series: 282, nllk loss: -2.33236, kernel loss: 0.03085\n",
      "Epoch: 28, series: 283, nllk loss: -2.33965, kernel loss: 0.04508\n",
      "Epoch: 28, series: 284, nllk loss: -1.69569, kernel loss: 0.04307\n",
      "Epoch: 28, series: 285, nllk loss: -1.93989, kernel loss: 0.13916\n",
      "Epoch: 28, series: 286, nllk loss: -2.22417, kernel loss: 0.01652\n",
      "Epoch: 28, series: 287, nllk loss: -2.59240, kernel loss: 0.15536\n",
      "Epoch: 28, series: 288, nllk loss: -1.26231, kernel loss: 0.00603\n",
      "Epoch: 28, series: 289, nllk loss: -1.22724, kernel loss: 0.05215\n",
      "Epoch: 28, series: 290, nllk loss: -2.36259, kernel loss: 0.09025\n",
      "Epoch: 28, series: 291, nllk loss: -2.50562, kernel loss: 0.02898\n",
      "Epoch: 28, series: 292, nllk loss: -2.39531, kernel loss: 0.03391\n",
      "Epoch: 28, series: 293, nllk loss: -2.54528, kernel loss: 0.07495\n",
      "Epoch: 28, series: 294, nllk loss: -1.42697, kernel loss: 0.02059\n",
      "Epoch: 28, series: 295, nllk loss: -1.30063, kernel loss: 0.16405\n",
      "Epoch: 28, series: 296, nllk loss: -2.60214, kernel loss: 0.03870\n",
      "Epoch: 28, series: 297, nllk loss: -2.61802, kernel loss: 0.08347\n",
      "Epoch: 28, series: 298, nllk loss: -0.42162, kernel loss: 0.34259\n",
      "Epoch: 28, series: 299, nllk loss: -0.88828, kernel loss: 0.01016\n",
      "Epoch: 28, series: 300, nllk loss: -2.35702, kernel loss: 0.12135\n",
      "Epoch: 28, series: 301, nllk loss: -2.66933, kernel loss: 0.08973\n",
      "Epoch: 28, series: 302, nllk loss: -2.46084, kernel loss: 0.13531\n",
      "Epoch: 28, series: 303, nllk loss: -2.09580, kernel loss: 0.23622\n",
      "Epoch: 28, series: 304, nllk loss: -0.55378, kernel loss: 0.12098\n",
      "Epoch: 28, series: 305, nllk loss: -2.18534, kernel loss: 0.04977\n",
      "Epoch: 28, series: 306, nllk loss: -2.63746, kernel loss: 0.21209\n",
      "Epoch: 28, series: 307, nllk loss: -1.91735, kernel loss: 0.14388\n",
      "Epoch: 28, series: 308, nllk loss: -2.68857, kernel loss: 0.11561\n",
      "Epoch: 28, series: 309, nllk loss: -2.01726, kernel loss: 0.14739\n",
      "Epoch: 28, series: 310, nllk loss: -2.57814, kernel loss: 0.11047\n",
      "Epoch: 28, series: 311, nllk loss: -2.00963, kernel loss: 0.17649\n",
      "Epoch: 28, series: 312, nllk loss: -2.20715, kernel loss: 0.14992\n",
      "Epoch: 28, series: 313, nllk loss: -2.24348, kernel loss: 0.03835\n",
      "Epoch: 28, series: 314, nllk loss: -2.83709, kernel loss: 0.04505\n",
      "Epoch: 28, series: 315, nllk loss: -1.01808, kernel loss: 0.12055\n",
      "Epoch: 28, series: 316, nllk loss: -2.22178, kernel loss: 0.04680\n",
      "Epoch: 28, series: 317, nllk loss: -0.07115, kernel loss: 0.03115\n",
      "Epoch: 28, series: 318, nllk loss: 0.40448, kernel loss: 0.01420\n",
      "Epoch: 28, series: 319, nllk loss: -1.12614, kernel loss: 0.11866\n",
      "Epoch: 28, series: 320, nllk loss: -0.84932, kernel loss: 0.05699\n",
      "Epoch: 28, total loss: -523.16739\n",
      "Epoch: 29, series: 0, nllk loss: 0.66556, kernel loss: 0.00000\n",
      "Epoch: 29, series: 1, nllk loss: -1.11475, kernel loss: 0.21102\n",
      "Epoch: 29, series: 2, nllk loss: 0.02698, kernel loss: 0.19475\n",
      "Epoch: 29, series: 3, nllk loss: -1.49925, kernel loss: 0.13401\n",
      "Epoch: 29, series: 4, nllk loss: -1.06544, kernel loss: 0.13758\n",
      "Epoch: 29, series: 5, nllk loss: -1.45070, kernel loss: 0.11446\n",
      "Epoch: 29, series: 6, nllk loss: -0.72064, kernel loss: 0.18772\n",
      "Epoch: 29, series: 7, nllk loss: -1.15463, kernel loss: 0.14733\n",
      "Epoch: 29, series: 8, nllk loss: -0.53852, kernel loss: 0.16539\n",
      "Epoch: 29, series: 9, nllk loss: -0.61341, kernel loss: 0.24435\n",
      "Epoch: 29, series: 10, nllk loss: -1.46809, kernel loss: 0.20813\n",
      "Epoch: 29, series: 11, nllk loss: -1.35902, kernel loss: 0.00373\n",
      "Epoch: 29, series: 12, nllk loss: -1.81683, kernel loss: 0.24545\n",
      "Epoch: 29, series: 13, nllk loss: -1.51585, kernel loss: 0.14015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, series: 14, nllk loss: -1.86402, kernel loss: 0.05650\n",
      "Epoch: 29, series: 15, nllk loss: -1.82849, kernel loss: 0.16061\n",
      "Epoch: 29, series: 16, nllk loss: -1.13341, kernel loss: 0.09952\n",
      "Epoch: 29, series: 17, nllk loss: -1.23108, kernel loss: 0.09018\n",
      "Epoch: 29, series: 18, nllk loss: -1.41462, kernel loss: 0.11603\n",
      "Epoch: 29, series: 19, nllk loss: -0.33342, kernel loss: 0.13282\n",
      "Epoch: 29, series: 20, nllk loss: -0.93736, kernel loss: 0.12193\n",
      "Epoch: 29, series: 21, nllk loss: -1.19555, kernel loss: 0.11807\n",
      "Epoch: 29, series: 22, nllk loss: -1.71222, kernel loss: 0.05181\n",
      "Epoch: 29, series: 23, nllk loss: -1.65154, kernel loss: 0.07608\n",
      "Epoch: 29, series: 24, nllk loss: -1.94888, kernel loss: 0.17135\n",
      "Epoch: 29, series: 25, nllk loss: -1.86057, kernel loss: 0.03816\n",
      "Epoch: 29, series: 26, nllk loss: -1.45114, kernel loss: 0.00520\n",
      "Epoch: 29, series: 27, nllk loss: -1.35184, kernel loss: 0.09833\n",
      "Epoch: 29, series: 28, nllk loss: -1.44313, kernel loss: 0.08820\n",
      "Epoch: 29, series: 29, nllk loss: -1.16222, kernel loss: 0.10747\n",
      "Epoch: 29, series: 30, nllk loss: -1.56611, kernel loss: 0.12936\n",
      "Epoch: 29, series: 31, nllk loss: -1.08990, kernel loss: 0.23092\n",
      "Epoch: 29, series: 32, nllk loss: -1.18526, kernel loss: 0.03221\n",
      "Epoch: 29, series: 33, nllk loss: -1.10719, kernel loss: 0.14912\n",
      "Epoch: 29, series: 34, nllk loss: -1.54916, kernel loss: 0.11285\n",
      "Epoch: 29, series: 35, nllk loss: -1.78352, kernel loss: 0.32330\n",
      "Epoch: 29, series: 36, nllk loss: -1.84620, kernel loss: 0.00245\n",
      "Epoch: 29, series: 37, nllk loss: -0.67181, kernel loss: 0.09798\n",
      "Epoch: 29, series: 38, nllk loss: -1.14882, kernel loss: 0.06043\n",
      "Epoch: 29, series: 39, nllk loss: -0.84751, kernel loss: 0.02664\n",
      "Epoch: 29, series: 40, nllk loss: -2.03711, kernel loss: 0.04719\n",
      "Epoch: 29, series: 41, nllk loss: -1.46354, kernel loss: 0.11672\n",
      "Epoch: 29, series: 42, nllk loss: -1.10387, kernel loss: 0.13097\n",
      "Epoch: 29, series: 43, nllk loss: -1.18985, kernel loss: 0.08328\n",
      "Epoch: 29, series: 44, nllk loss: -1.81355, kernel loss: 0.04316\n",
      "Epoch: 29, series: 45, nllk loss: -1.85246, kernel loss: 0.15943\n",
      "Epoch: 29, series: 46, nllk loss: -1.87726, kernel loss: 0.02810\n",
      "Epoch: 29, series: 47, nllk loss: -1.70212, kernel loss: 0.12669\n",
      "Epoch: 29, series: 48, nllk loss: -1.72594, kernel loss: 0.18090\n",
      "Epoch: 29, series: 49, nllk loss: -1.20126, kernel loss: 0.05581\n",
      "Epoch: 29, series: 50, nllk loss: -0.26040, kernel loss: 0.01556\n",
      "Epoch: 29, series: 51, nllk loss: -1.36587, kernel loss: 0.15158\n",
      "Epoch: 29, series: 52, nllk loss: -0.56875, kernel loss: 0.04484\n",
      "Epoch: 29, series: 53, nllk loss: -1.71464, kernel loss: 0.11537\n",
      "Epoch: 29, series: 54, nllk loss: -1.51741, kernel loss: 0.04425\n",
      "Epoch: 29, series: 55, nllk loss: -0.83648, kernel loss: 0.11480\n",
      "Epoch: 29, series: 56, nllk loss: -1.58693, kernel loss: 0.08351\n",
      "Epoch: 29, series: 57, nllk loss: -1.51979, kernel loss: 0.04175\n",
      "Epoch: 29, series: 58, nllk loss: -1.59044, kernel loss: 0.07132\n",
      "Epoch: 29, series: 59, nllk loss: -1.32504, kernel loss: 0.22307\n",
      "Epoch: 29, series: 60, nllk loss: -1.17948, kernel loss: 0.15089\n",
      "Epoch: 29, series: 61, nllk loss: -1.92479, kernel loss: 0.03115\n",
      "Epoch: 29, series: 62, nllk loss: -1.91404, kernel loss: 0.03691\n",
      "Epoch: 29, series: 63, nllk loss: -1.84062, kernel loss: 0.15584\n",
      "Epoch: 29, series: 64, nllk loss: -1.21401, kernel loss: 0.05207\n",
      "Epoch: 29, series: 65, nllk loss: -1.76746, kernel loss: 0.10461\n",
      "Epoch: 29, series: 66, nllk loss: -1.75849, kernel loss: 0.05454\n",
      "Epoch: 29, series: 67, nllk loss: -1.50002, kernel loss: 0.10348\n",
      "Epoch: 29, series: 68, nllk loss: -0.96574, kernel loss: 0.07247\n",
      "Epoch: 29, series: 69, nllk loss: -1.66255, kernel loss: 0.12327\n",
      "Epoch: 29, series: 70, nllk loss: -1.41352, kernel loss: 0.19014\n",
      "Epoch: 29, series: 71, nllk loss: -1.48726, kernel loss: 0.10511\n",
      "Epoch: 29, series: 72, nllk loss: -1.94556, kernel loss: 0.09441\n",
      "Epoch: 29, series: 73, nllk loss: -1.43744, kernel loss: 0.10842\n",
      "Epoch: 29, series: 74, nllk loss: -2.12255, kernel loss: 0.03391\n",
      "Epoch: 29, series: 75, nllk loss: -1.62101, kernel loss: 0.11681\n",
      "Epoch: 29, series: 76, nllk loss: -1.41467, kernel loss: 0.11509\n",
      "Epoch: 29, series: 77, nllk loss: -1.42610, kernel loss: 0.10702\n",
      "Epoch: 29, series: 78, nllk loss: -1.51069, kernel loss: 0.08878\n",
      "Epoch: 29, series: 79, nllk loss: -0.46340, kernel loss: 0.05175\n",
      "Epoch: 29, series: 80, nllk loss: -1.87224, kernel loss: 0.14708\n",
      "Epoch: 29, series: 81, nllk loss: -1.74688, kernel loss: 0.11054\n",
      "Epoch: 29, series: 82, nllk loss: -0.56409, kernel loss: 0.00358\n",
      "Epoch: 29, series: 83, nllk loss: -1.37026, kernel loss: 0.07150\n",
      "Epoch: 29, series: 84, nllk loss: -1.38366, kernel loss: 0.14979\n",
      "Epoch: 29, series: 85, nllk loss: -1.72321, kernel loss: 0.19262\n",
      "Epoch: 29, series: 86, nllk loss: -0.99668, kernel loss: 0.18423\n",
      "Epoch: 29, series: 87, nllk loss: -2.03744, kernel loss: 0.02344\n",
      "Epoch: 29, series: 88, nllk loss: -2.36115, kernel loss: 0.10418\n",
      "Epoch: 29, series: 89, nllk loss: -2.04028, kernel loss: 0.12146\n",
      "Epoch: 29, series: 90, nllk loss: -2.47956, kernel loss: 0.16171\n",
      "Epoch: 29, series: 91, nllk loss: -2.31351, kernel loss: 0.10841\n",
      "Epoch: 29, series: 92, nllk loss: -0.23178, kernel loss: 0.11173\n",
      "Epoch: 29, series: 93, nllk loss: -2.84089, kernel loss: 0.02487\n",
      "Epoch: 29, series: 94, nllk loss: -2.72303, kernel loss: 0.19430\n",
      "Epoch: 29, series: 95, nllk loss: -2.66305, kernel loss: 0.01611\n",
      "Epoch: 29, series: 96, nllk loss: -1.82522, kernel loss: 0.09972\n",
      "Epoch: 29, series: 97, nllk loss: -0.76225, kernel loss: 0.17652\n",
      "Epoch: 29, series: 98, nllk loss: -0.39262, kernel loss: 0.10754\n",
      "Epoch: 29, series: 99, nllk loss: -1.35846, kernel loss: 0.16669\n",
      "Epoch: 29, series: 100, nllk loss: -1.02641, kernel loss: 0.07340\n",
      "Epoch: 29, series: 101, nllk loss: -1.42336, kernel loss: 0.10279\n",
      "Epoch: 29, series: 102, nllk loss: -0.86628, kernel loss: 0.08001\n",
      "Epoch: 29, series: 103, nllk loss: -1.12362, kernel loss: 0.18391\n",
      "Epoch: 29, series: 104, nllk loss: -0.21238, kernel loss: 0.24667\n",
      "Epoch: 29, series: 105, nllk loss: -0.44616, kernel loss: 0.05757\n",
      "Epoch: 29, series: 106, nllk loss: -1.14326, kernel loss: 0.22347\n",
      "Epoch: 29, series: 107, nllk loss: -1.05921, kernel loss: 0.10209\n",
      "Epoch: 29, series: 108, nllk loss: -1.39382, kernel loss: 0.04140\n",
      "Epoch: 29, series: 109, nllk loss: -1.16696, kernel loss: 0.08035\n",
      "Epoch: 29, series: 110, nllk loss: -1.72708, kernel loss: 0.04037\n",
      "Epoch: 29, series: 111, nllk loss: -1.55278, kernel loss: 0.02892\n",
      "Epoch: 29, series: 112, nllk loss: -0.93856, kernel loss: 0.09938\n",
      "Epoch: 29, series: 113, nllk loss: -1.14842, kernel loss: 0.23726\n",
      "Epoch: 29, series: 114, nllk loss: -1.27634, kernel loss: 0.07176\n",
      "Epoch: 29, series: 115, nllk loss: -1.13788, kernel loss: 0.04699\n",
      "Epoch: 29, series: 116, nllk loss: -1.56986, kernel loss: 0.13633\n",
      "Epoch: 29, series: 117, nllk loss: -0.69871, kernel loss: 0.08935\n",
      "Epoch: 29, series: 118, nllk loss: -2.13897, kernel loss: 0.13654\n",
      "Epoch: 29, series: 119, nllk loss: -0.79939, kernel loss: 0.07904\n",
      "Epoch: 29, series: 120, nllk loss: -1.60441, kernel loss: 0.02986\n",
      "Epoch: 29, series: 121, nllk loss: -0.14686, kernel loss: 0.10865\n",
      "Epoch: 29, series: 122, nllk loss: -0.60214, kernel loss: 0.05782\n",
      "Epoch: 29, series: 123, nllk loss: -2.01823, kernel loss: 0.07640\n",
      "Epoch: 29, series: 124, nllk loss: -2.12412, kernel loss: 0.03196\n",
      "Epoch: 29, series: 125, nllk loss: -1.32364, kernel loss: 0.04825\n",
      "Epoch: 29, series: 126, nllk loss: -2.02149, kernel loss: 0.23715\n",
      "Epoch: 29, series: 127, nllk loss: -1.35664, kernel loss: 0.04723\n",
      "Epoch: 29, series: 128, nllk loss: -1.05042, kernel loss: 0.08202\n",
      "Epoch: 29, series: 129, nllk loss: -1.02826, kernel loss: 0.17375\n",
      "Epoch: 29, series: 130, nllk loss: -1.67398, kernel loss: 0.04970\n",
      "Epoch: 29, series: 131, nllk loss: 0.09916, kernel loss: 0.05587\n",
      "Epoch: 29, series: 132, nllk loss: -0.43458, kernel loss: 0.03301\n",
      "Epoch: 29, series: 133, nllk loss: -1.15353, kernel loss: 0.09264\n",
      "Epoch: 29, series: 134, nllk loss: -0.80237, kernel loss: 0.11784\n",
      "Epoch: 29, series: 135, nllk loss: -1.74574, kernel loss: 0.09195\n",
      "Epoch: 29, series: 136, nllk loss: -1.91298, kernel loss: 0.07809\n",
      "Epoch: 29, series: 137, nllk loss: -2.10422, kernel loss: 0.06558\n",
      "Epoch: 29, series: 138, nllk loss: -1.97477, kernel loss: 0.09637\n",
      "Epoch: 29, series: 139, nllk loss: -1.86885, kernel loss: 0.09096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, series: 140, nllk loss: -1.48348, kernel loss: 0.07557\n",
      "Epoch: 29, series: 141, nllk loss: -1.88199, kernel loss: 0.07518\n",
      "Epoch: 29, series: 142, nllk loss: -2.08783, kernel loss: 0.05902\n",
      "Epoch: 29, series: 143, nllk loss: -1.82257, kernel loss: 0.07992\n",
      "Epoch: 29, series: 144, nllk loss: -2.23504, kernel loss: 0.17068\n",
      "Epoch: 29, series: 145, nllk loss: -1.91159, kernel loss: 0.10073\n",
      "Epoch: 29, series: 146, nllk loss: 0.83977, kernel loss: 0.04732\n",
      "Epoch: 29, series: 147, nllk loss: -1.72225, kernel loss: 0.09122\n",
      "Epoch: 29, series: 148, nllk loss: -1.54150, kernel loss: 0.19530\n",
      "Epoch: 29, series: 149, nllk loss: -2.04348, kernel loss: 0.16347\n",
      "Epoch: 29, series: 150, nllk loss: -2.11196, kernel loss: 0.11210\n",
      "Epoch: 29, series: 151, nllk loss: -2.17791, kernel loss: 0.04626\n",
      "Epoch: 29, series: 152, nllk loss: -2.18845, kernel loss: 0.07798\n",
      "Epoch: 29, series: 153, nllk loss: -1.85900, kernel loss: 0.14322\n",
      "Epoch: 29, series: 154, nllk loss: -1.86156, kernel loss: 0.10630\n",
      "Epoch: 29, series: 155, nllk loss: -2.09728, kernel loss: 0.05956\n",
      "Epoch: 29, series: 156, nllk loss: -2.24257, kernel loss: 0.06390\n",
      "Epoch: 29, series: 157, nllk loss: -1.67373, kernel loss: 0.14557\n",
      "Epoch: 29, series: 158, nllk loss: -2.11225, kernel loss: 0.13318\n",
      "Epoch: 29, series: 159, nllk loss: -2.19428, kernel loss: 0.10623\n",
      "Epoch: 29, series: 160, nllk loss: -2.06545, kernel loss: 0.22693\n",
      "Epoch: 29, series: 161, nllk loss: -1.85962, kernel loss: 0.18354\n",
      "Epoch: 29, series: 162, nllk loss: -2.45145, kernel loss: 0.14241\n",
      "Epoch: 29, series: 163, nllk loss: -2.48679, kernel loss: 0.01343\n",
      "Epoch: 29, series: 164, nllk loss: -1.77619, kernel loss: 0.01186\n",
      "Epoch: 29, series: 165, nllk loss: -2.01873, kernel loss: 0.12820\n",
      "Epoch: 29, series: 166, nllk loss: -1.53381, kernel loss: 0.08735\n",
      "Epoch: 29, series: 167, nllk loss: -2.70966, kernel loss: 0.09041\n",
      "Epoch: 29, series: 168, nllk loss: -2.24470, kernel loss: 0.05111\n",
      "Epoch: 29, series: 169, nllk loss: -2.43741, kernel loss: 0.03287\n",
      "Epoch: 29, series: 170, nllk loss: -2.02827, kernel loss: 0.14610\n",
      "Epoch: 29, series: 171, nllk loss: -2.60343, kernel loss: 0.10439\n",
      "Epoch: 29, series: 172, nllk loss: -2.14210, kernel loss: 0.00626\n",
      "Epoch: 29, series: 173, nllk loss: -2.66124, kernel loss: 0.04847\n",
      "Epoch: 29, series: 174, nllk loss: -2.36166, kernel loss: 0.16424\n",
      "Epoch: 29, series: 175, nllk loss: -2.61965, kernel loss: 0.06382\n",
      "Epoch: 29, series: 176, nllk loss: -2.14059, kernel loss: 0.05263\n",
      "Epoch: 29, series: 177, nllk loss: -2.21319, kernel loss: 0.21952\n",
      "Epoch: 29, series: 178, nllk loss: -1.84480, kernel loss: 0.09629\n",
      "Epoch: 29, series: 179, nllk loss: -2.24076, kernel loss: 0.01213\n",
      "Epoch: 29, series: 180, nllk loss: -2.48610, kernel loss: 0.05630\n",
      "Epoch: 29, series: 181, nllk loss: -2.69236, kernel loss: 0.04691\n",
      "Epoch: 29, series: 182, nllk loss: -2.35667, kernel loss: 0.05707\n",
      "Epoch: 29, series: 183, nllk loss: -2.13203, kernel loss: 0.09658\n",
      "Epoch: 29, series: 184, nllk loss: -2.12480, kernel loss: 0.03268\n",
      "Epoch: 29, series: 185, nllk loss: -1.78361, kernel loss: 0.12877\n",
      "Epoch: 29, series: 186, nllk loss: -2.82463, kernel loss: 0.02340\n",
      "Epoch: 29, series: 187, nllk loss: -2.84674, kernel loss: 0.04124\n",
      "Epoch: 29, series: 188, nllk loss: -1.71029, kernel loss: 0.09726\n",
      "Epoch: 29, series: 189, nllk loss: -1.60211, kernel loss: 0.07176\n",
      "Epoch: 29, series: 190, nllk loss: -2.44980, kernel loss: 0.06215\n",
      "Epoch: 29, series: 191, nllk loss: -2.16971, kernel loss: 0.04094\n",
      "Epoch: 29, series: 192, nllk loss: -2.28228, kernel loss: 0.14608\n",
      "Epoch: 29, series: 193, nllk loss: -1.65536, kernel loss: 0.01940\n",
      "Epoch: 29, series: 194, nllk loss: -1.62376, kernel loss: 0.12422\n",
      "Epoch: 29, series: 195, nllk loss: -2.28158, kernel loss: 0.09006\n",
      "Epoch: 29, series: 196, nllk loss: -1.94476, kernel loss: 0.07680\n",
      "Epoch: 29, series: 197, nllk loss: -2.19352, kernel loss: 0.04107\n",
      "Epoch: 29, series: 198, nllk loss: -2.49664, kernel loss: 0.28905\n",
      "Epoch: 29, series: 199, nllk loss: -1.90437, kernel loss: 0.05782\n",
      "Epoch: 29, series: 200, nllk loss: -2.31975, kernel loss: 0.22336\n",
      "Epoch: 29, series: 201, nllk loss: -2.42562, kernel loss: 0.10996\n",
      "Epoch: 29, series: 202, nllk loss: -2.23764, kernel loss: 0.03590\n",
      "Epoch: 29, series: 203, nllk loss: -1.86186, kernel loss: 0.08109\n",
      "Epoch: 29, series: 204, nllk loss: -1.01193, kernel loss: 0.08022\n",
      "Epoch: 29, series: 205, nllk loss: -2.18964, kernel loss: 0.02043\n",
      "Epoch: 29, series: 206, nllk loss: -2.22050, kernel loss: 0.03726\n",
      "Epoch: 29, series: 207, nllk loss: -1.05307, kernel loss: 0.08668\n",
      "Epoch: 29, series: 208, nllk loss: -2.46523, kernel loss: 0.10025\n",
      "Epoch: 29, series: 209, nllk loss: -1.83965, kernel loss: 0.04885\n",
      "Epoch: 29, series: 210, nllk loss: -2.67998, kernel loss: 0.23257\n",
      "Epoch: 29, series: 211, nllk loss: -2.08149, kernel loss: 0.10427\n",
      "Epoch: 29, series: 212, nllk loss: -1.41185, kernel loss: 0.03418\n",
      "Epoch: 29, series: 213, nllk loss: -2.25363, kernel loss: 0.06350\n",
      "Epoch: 29, series: 214, nllk loss: -2.21574, kernel loss: 0.15479\n",
      "Epoch: 29, series: 215, nllk loss: -2.50630, kernel loss: 0.20437\n",
      "Epoch: 29, series: 216, nllk loss: -1.43773, kernel loss: 0.00000\n",
      "Epoch: 29, series: 217, nllk loss: -2.11767, kernel loss: 0.00738\n",
      "Epoch: 29, series: 218, nllk loss: -1.55571, kernel loss: 0.09977\n",
      "Epoch: 29, series: 219, nllk loss: -2.17297, kernel loss: 0.16550\n",
      "Epoch: 29, series: 220, nllk loss: -2.22396, kernel loss: 0.08250\n",
      "Epoch: 29, series: 221, nllk loss: -2.52670, kernel loss: 0.05194\n",
      "Epoch: 29, series: 222, nllk loss: -2.35817, kernel loss: 0.06816\n",
      "Epoch: 29, series: 223, nllk loss: -1.74953, kernel loss: 0.13684\n",
      "Epoch: 29, series: 224, nllk loss: -2.54098, kernel loss: 0.08845\n",
      "Epoch: 29, series: 225, nllk loss: -2.46433, kernel loss: 0.06728\n",
      "Epoch: 29, series: 226, nllk loss: -1.98661, kernel loss: 0.04711\n",
      "Epoch: 29, series: 227, nllk loss: -2.20778, kernel loss: 0.12882\n",
      "Epoch: 29, series: 228, nllk loss: -2.23001, kernel loss: 0.08725\n",
      "Epoch: 29, series: 229, nllk loss: -2.11306, kernel loss: 0.04948\n",
      "Epoch: 29, series: 230, nllk loss: -2.56994, kernel loss: 0.15367\n",
      "Epoch: 29, series: 231, nllk loss: -1.96143, kernel loss: 0.10448\n",
      "Epoch: 29, series: 232, nllk loss: -2.70902, kernel loss: 0.03025\n",
      "Epoch: 29, series: 233, nllk loss: -2.53173, kernel loss: 0.03775\n",
      "Epoch: 29, series: 234, nllk loss: -2.05027, kernel loss: 0.10244\n",
      "Epoch: 29, series: 235, nllk loss: -2.75593, kernel loss: 0.01755\n",
      "Epoch: 29, series: 236, nllk loss: -1.65659, kernel loss: 0.00945\n",
      "Epoch: 29, series: 237, nllk loss: -2.30539, kernel loss: 0.08741\n",
      "Epoch: 29, series: 238, nllk loss: -2.06332, kernel loss: 0.05165\n",
      "Epoch: 29, series: 239, nllk loss: -2.39572, kernel loss: 0.30990\n",
      "Epoch: 29, series: 240, nllk loss: -0.93988, kernel loss: 0.25292\n",
      "Epoch: 29, series: 241, nllk loss: -2.09878, kernel loss: 0.20868\n",
      "Epoch: 29, series: 242, nllk loss: -2.10967, kernel loss: 0.01734\n",
      "Epoch: 29, series: 243, nllk loss: -2.47850, kernel loss: 0.01873\n",
      "Epoch: 29, series: 244, nllk loss: -2.18441, kernel loss: 0.06298\n",
      "Epoch: 29, series: 245, nllk loss: -2.32783, kernel loss: 0.08146\n",
      "Epoch: 29, series: 246, nllk loss: -0.52541, kernel loss: 0.12142\n",
      "Epoch: 29, series: 247, nllk loss: -1.81691, kernel loss: 0.06955\n",
      "Epoch: 29, series: 248, nllk loss: -2.20712, kernel loss: 0.09418\n",
      "Epoch: 29, series: 249, nllk loss: -2.05865, kernel loss: 0.14135\n",
      "Epoch: 29, series: 250, nllk loss: -1.72461, kernel loss: 0.04220\n",
      "Epoch: 29, series: 251, nllk loss: -1.29801, kernel loss: 0.01002\n",
      "Epoch: 29, series: 252, nllk loss: -1.58097, kernel loss: 0.07589\n",
      "Epoch: 29, series: 253, nllk loss: -1.81279, kernel loss: 0.14313\n",
      "Epoch: 29, series: 254, nllk loss: -2.31989, kernel loss: 0.01333\n",
      "Epoch: 29, series: 255, nllk loss: -2.13167, kernel loss: 0.01441\n",
      "Epoch: 29, series: 256, nllk loss: -1.97268, kernel loss: 0.07212\n",
      "Epoch: 29, series: 257, nllk loss: -2.14412, kernel loss: 0.06303\n",
      "Epoch: 29, series: 258, nllk loss: -2.24931, kernel loss: 0.01230\n",
      "Epoch: 29, series: 259, nllk loss: -1.91414, kernel loss: 0.15327\n",
      "Epoch: 29, series: 260, nllk loss: -2.05050, kernel loss: 0.16254\n",
      "Epoch: 29, series: 261, nllk loss: -2.14993, kernel loss: 0.10001\n",
      "Epoch: 29, series: 262, nllk loss: -2.71697, kernel loss: 0.15259\n",
      "Epoch: 29, series: 263, nllk loss: -0.72067, kernel loss: 0.07090\n",
      "Epoch: 29, series: 264, nllk loss: -2.03065, kernel loss: 0.08668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29, series: 265, nllk loss: -1.96116, kernel loss: 0.01889\n",
      "Epoch: 29, series: 266, nllk loss: -2.36282, kernel loss: 0.08140\n",
      "Epoch: 29, series: 267, nllk loss: -2.18018, kernel loss: 0.06289\n",
      "Epoch: 29, series: 268, nllk loss: -2.20056, kernel loss: 0.10991\n",
      "Epoch: 29, series: 269, nllk loss: -1.98736, kernel loss: 0.11809\n",
      "Epoch: 29, series: 270, nllk loss: -1.97888, kernel loss: 0.06826\n",
      "Epoch: 29, series: 271, nllk loss: -2.16558, kernel loss: 0.01702\n",
      "Epoch: 29, series: 272, nllk loss: -2.05805, kernel loss: 0.07738\n",
      "Epoch: 29, series: 273, nllk loss: -2.12838, kernel loss: 0.15914\n",
      "Epoch: 29, series: 274, nllk loss: -1.62066, kernel loss: 0.13889\n",
      "Epoch: 29, series: 275, nllk loss: -2.03904, kernel loss: 0.06704\n",
      "Epoch: 29, series: 276, nllk loss: -1.34933, kernel loss: 0.03442\n",
      "Epoch: 29, series: 277, nllk loss: -2.37326, kernel loss: 0.03872\n",
      "Epoch: 29, series: 278, nllk loss: -2.11671, kernel loss: 0.08793\n",
      "Epoch: 29, series: 279, nllk loss: -2.50247, kernel loss: 0.21983\n",
      "Epoch: 29, series: 280, nllk loss: -2.21179, kernel loss: 0.02756\n",
      "Epoch: 29, series: 281, nllk loss: -2.44313, kernel loss: 0.01606\n",
      "Epoch: 29, series: 282, nllk loss: -2.30542, kernel loss: 0.07459\n",
      "Epoch: 29, series: 283, nllk loss: -2.34515, kernel loss: 0.05056\n",
      "Epoch: 29, series: 284, nllk loss: -1.71987, kernel loss: 0.00442\n",
      "Epoch: 29, series: 285, nllk loss: -2.00662, kernel loss: 0.21823\n",
      "Epoch: 29, series: 286, nllk loss: -2.30331, kernel loss: 0.04488\n",
      "Epoch: 29, series: 287, nllk loss: -2.58598, kernel loss: 0.09723\n",
      "Epoch: 29, series: 288, nllk loss: -1.36482, kernel loss: 0.11241\n",
      "Epoch: 29, series: 289, nllk loss: -1.22881, kernel loss: 0.09026\n",
      "Epoch: 29, series: 290, nllk loss: -2.39505, kernel loss: 0.02686\n",
      "Epoch: 29, series: 291, nllk loss: -2.52915, kernel loss: 0.04302\n",
      "Epoch: 29, series: 292, nllk loss: -2.39293, kernel loss: 0.03816\n",
      "Epoch: 29, series: 293, nllk loss: -2.54506, kernel loss: 0.05747\n",
      "Epoch: 29, series: 294, nllk loss: -1.48494, kernel loss: 0.16681\n",
      "Epoch: 29, series: 295, nllk loss: -1.31505, kernel loss: 0.17659\n",
      "Epoch: 29, series: 296, nllk loss: -2.65590, kernel loss: 0.11971\n",
      "Epoch: 29, series: 297, nllk loss: -2.69505, kernel loss: 0.25195\n",
      "Epoch: 29, series: 298, nllk loss: -0.42717, kernel loss: 0.21059\n",
      "Epoch: 29, series: 299, nllk loss: -0.93588, kernel loss: 0.09100\n",
      "Epoch: 29, series: 300, nllk loss: -2.38141, kernel loss: 0.09771\n",
      "Epoch: 29, series: 301, nllk loss: -2.71470, kernel loss: 0.04964\n",
      "Epoch: 29, series: 302, nllk loss: -2.47181, kernel loss: 0.12426\n",
      "Epoch: 29, series: 303, nllk loss: -2.17806, kernel loss: 0.09112\n",
      "Epoch: 29, series: 304, nllk loss: -0.47587, kernel loss: 0.11232\n",
      "Epoch: 29, series: 305, nllk loss: -2.14518, kernel loss: 0.03785\n",
      "Epoch: 29, series: 306, nllk loss: -2.66922, kernel loss: 0.21850\n",
      "Epoch: 29, series: 307, nllk loss: -1.91589, kernel loss: 0.08100\n",
      "Epoch: 29, series: 308, nllk loss: -2.72274, kernel loss: 0.00000\n",
      "Epoch: 29, series: 309, nllk loss: -1.99386, kernel loss: 0.21374\n",
      "Epoch: 29, series: 310, nllk loss: -2.61332, kernel loss: 0.21653\n",
      "Epoch: 29, series: 311, nllk loss: -2.05811, kernel loss: 0.10490\n",
      "Epoch: 29, series: 312, nllk loss: -2.26281, kernel loss: 0.09595\n",
      "Epoch: 29, series: 313, nllk loss: -2.23703, kernel loss: 0.25686\n",
      "Epoch: 29, series: 314, nllk loss: -2.92108, kernel loss: 0.06991\n",
      "Epoch: 29, series: 315, nllk loss: -0.95255, kernel loss: 0.08870\n",
      "Epoch: 29, series: 316, nllk loss: -2.22838, kernel loss: 0.15701\n",
      "Epoch: 29, series: 317, nllk loss: -0.05024, kernel loss: 0.01395\n",
      "Epoch: 29, series: 318, nllk loss: 0.36019, kernel loss: 0.10437\n",
      "Epoch: 29, series: 319, nllk loss: -0.98629, kernel loss: 0.01981\n",
      "Epoch: 29, series: 320, nllk loss: -0.83670, kernel loss: 0.08813\n",
      "Epoch: 29, total loss: -526.40448\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 0.003\n",
    "batch_size = 100\n",
    "\n",
    "input_size = 1\n",
    "hidden_size = 300\n",
    "num_layers = 2\n",
    "num_outputs = 2\n",
    "\n",
    "n_pairs = 100\n",
    "\n",
    "lstm = LSTM(num_outputs, input_size, hidden_size, num_layers).cuda()\n",
    "lstm.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i in range(len(train_ds)):\n",
    "        optimizer.zero_grad()\n",
    "        nllk_loss = 0\n",
    "        train_x, train_y = create_inout_sequences(train_ds[i], window_len)\n",
    "        train_x = train_x.cuda()\n",
    "        train_y = train_y.cuda()\n",
    "        num_batch = math.ceil(train_x.shape[0] / batch_size)\n",
    "        for j in range(num_batch):\n",
    "            outputs, _ = lstm(train_x[(j * batch_size) : ((j+1) * batch_size), :, :])\n",
    "            nllk_loss += NLLloss(train_y[(j * batch_size) : ((j+1) * batch_size), :].squeeze(1), outputs[:, 0], outputs[:, 1])\n",
    "        nllk_loss /= train_x.shape[0]\n",
    "        \n",
    "        index = [random.sample(range(len(train_ds)), 3) for _ in range(n_pairs)]\n",
    "        start = [random.sample(range(sample_len - pred_len - window_len), 3) for _ in range(n_pairs)]\n",
    "        kernel_x = create_kernel_sequences(train_ds, index, start, window_len).cuda()\n",
    "        _, feature = lstm(kernel_x)\n",
    "        kernel_x = kernel_x.squeeze(dim = 2).reshape([n_pairs, 3, -1])\n",
    "        feature = feature.reshape([n_pairs, 3, -1])\n",
    "        kernel_loss = contrastive_loss(kernel_x, feature)\n",
    "        \n",
    "        loss = nllk_loss + kernel_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        print(\"Epoch: %d, series: %d, nllk loss: %1.5f, kernel loss: %1.5f\" % (epoch, i, nllk_loss.item(), kernel_loss.item()))\n",
    "    print(\"Epoch: %d, total loss: %1.5f\" % (epoch, total_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a4a9b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.eval()\n",
    "\n",
    "pred_mean = np.empty([test_ds.shape[0], pred_len])\n",
    "pred_var = np.empty([test_ds.shape[0], pred_len])\n",
    "\n",
    "for i in range(len(test_ds)):\n",
    "    test_x, test_y = create_inout_sequences(test_ds[i], window_len)\n",
    "    test_x = test_x.cuda()\n",
    "    test_y = test_y.cuda()\n",
    "    outputs, _ = lstm(test_x)\n",
    "    pred_mean[i, :] = outputs[:, 0].cpu().detach().numpy()\n",
    "    pred_var[i, :] = outputs[:, 1].cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f97d06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_pred_kernel.npy', 'wb') as f:\n",
    "    np.save(f, pred_mean)\n",
    "    np.save(f, pred_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79f884a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAABwuElEQVR4nO19ebgdRZ32W919truvudlJAmEJO4Rd9lUEHcUNv8EZVBCXGfBz+RAUnRFxHFzHQQSdEUVcUEBlkVUQFAgGSCCBJCSQPbm5+3LWXur7o7r6dPfpc7r6nHPvzb2p93nuk5w+p05V9+l+6623fvUrQimFhISEhMT0hTLVDZCQkJCQqA2SyCUkJCSmOSSRS0hISExzSCKXkJCQmOaQRC4hISExzaFNRaVdXV100aJFU1G1hITE3oL169m/Bx00te2YRnjxxRf7KaXd/uNTQuSLFi3CypUrp6JqCQmJvQVnnMH+feqpqWzFtAIhZEvQcWmtSEhISExzTIkil5CQkMCXvjTVLZgxkEQuISExNTjnnKluwYyBtFYkJCSmBqtWsT+JmiEVuYSExNTgmmvYv3Kys2ZIRS4hISExzSGJXEJCQmKaQxK5hITEXos96T347drfTnUz9npIIpeQkNhrcfkfLsf7f/d+bB7ePNVN2ashJzslJCSmBjfdFPqR4dwwAOC1vtewqG3RxLZnGkMqcgkJianBySezvwrg5P1K7yuT0KDpC0nkEhISU4Nnn2V/FaAQRlGv7nl1Mlo0bSGtFQkJianBddexfyvEkY/mRwEAbw29NQkNmr6oWZETQhYQQp4khLxGCFlLCLm6Hg2TkJCQ4ES+ZSQw6Z+EjXpYKwaAz1JKlwE4EcCnCCHL6vC9EhIS+zg4ke8a24WCWYhU9ohbj8DFv7p4Ipq116FmIqeU7qKUvmT/fwzA6wDm1fq9EhISEpzIKSi2jWyLVPbVPa/igQ0PTESz9jrUdbKTELIIwNEAVgS8dyUhZCUhZGVfX189q5WQkJihGM2P4qBOtoNQtfYKpbSeTdorUTciJ4Q0AbgHwDWU0lH/+5TS2ymlyymly7u7S3YqkpCQ2Nfwve+xvwoYzY9iaedSAGyVpyhMy3T+35/pr6Z10wp1IXJCSAyMxO+ilN5bj++UkJCY4TjqKPYXgHX967Doe4uQM3LYv31/AEBfWnwkP5Ifcf7/xuAbtbRyWqAeUSsEwP8AeJ1S+p3amyQx3TGcKeDuv2/D9qHMVDdFYm/G44+zvwC82vuqY6WcMO8EEBD0ZcSJfCg75Pz/9b7XIzfthR0v4Id//2HkcgOZAby488XI5WpFPRT5KQAuA3AWIWSV/XdhHb5XYpri3pd24Av3vIKbHor+AEnsQ7jxRvYXAK6oV1+1Gpcefik6GzqFFblFLXzs/o85r1ftXhW5aSf85AR86qFPeSwaEZxz5zlY/uPlk+7L17wgiFL6VwCkDm2RmCHI6uzmH8sZU9wSiekKnmNlSfsSAEB3Q7ewIn+t7zU8tfkp5/Xq3tVVt2PX+C7Mb5kv/HneaQxkB9DV0FV1vVEhl+jvI0jnDeimNSl18XqsfSBaQGJiMJwbhkpUNMYaAQDdjeJE/tetf3X+f+rCUyMv73fHq28ZjhYpw1MK7BzbGalcrZBEvo/g0K88gv/zk5Ko0AmBYTIC1w1J5BLVYTg3jLZkG9gUnK3IBa2VZ7cV87csn7scw7lhDGYHheveOLjR+X/UkEfe8Ugil5gwvPCW+M1cC3SLKfK8Ec1flJDg4ETO0RRvQlpPC5Vd27cWB3UehBvPvBGn73c6AGDT4Cahsg9seMAzWRlVkTfGp4bIZdIsibrDtBV53pgcK0dimuK228q+5SdylahCE48WtbCufx2uOOYKXH/a9Vi7Zy0AprKPm3dcxbJj+bGSJf3bRqOtJp0qRS6JXKLuMCxJ5BICOOigsm+VELmiwqThRL5tZBsyegaHdB0CoDhZumkoXJG7LRUAWNy2GDvGdoSW4+399ZpfI2fkAGDSdzSSRL4PwLIm16vmk515XVorEhVw//3s34tLE1sN54ZxcNfBzmtRRf7SrpcAAIfNOgwAkIqloCkaMnr4mgY/kR/YeSB2jIoR+ecf/Tx+8vJPnNcrdqxAupB2rJaJhvTI9wEUJilahcOQ1oqECL79bfbnw8bBjXhr+C3MapzlHFOIAouG308PvvEgWhItOH7e8c4x0U7AvwJ0XvM8YUW+dXSr5/WaPWtw7O3HCpWtBySR7wOYbCLnk50FSeQSVeAXr/wCGT2DL5zyBeeYqLXyzNZncNbisxBTY5HLrh9Yj9lNs53X81vmo3e8F7qph5Z1q/kDOg5wvm+yIIl8H8BkE6pU5BK1IKNnkNSSns2WRVX1eGEcXSnvQhzRsi/seAHHzT0OT3z4CTz30ecwr2UeKCh2j++uWE43dbw59Kbz+qKlFwEADp91eGid9YIk8n0Ak07kXJGb1qT78xLTH3kjj4Sa8BwTVdU5I4eEFr3scG4Y6/rX4YR5J+CsxWfhxPknoiXRAoB1DpXAFypde8q1aIw14oOHfRDvPvjdoJi8e19Odu4DmGwi183iDVwwLSQVdVLrl5jeKJiFEjIW9cgDOwEBRf5a32sAgKNmH+WpE0Bovb3jvQCA4+cdj/HrGOmritgooF6QRL4PYPInO4v15XULyZgkcokA3Hln4OG8mUdcjXuOidojeTNflSLP6lkAbOGRu04AoWV704zIe5p6vO0VGEHUC5LI9wFMvrVSVORsdWes/Icl9l0sWBB4OG9WZ61Y1IJhGVUp8ryZBwBPJ6DaI8mwsnzDi55GF5FPsiKXHvk+gEmPWnErcjnhKVEOv/kN+/MhbwSoaqLColbF9LB5g5FxUkt6jitECe0EgsoKK3LbWnGHS0pFLlF3TFXUCiDzrUhUwK23sn8/8AHP4YJZKLFWuF9NQUHKZM0OUtUAU8dhPrdTVo2uyHvTvUhpKa8tI1BnPSEV+QzHzY+sw40PvjapdeouayWnS0UuEQ3lrBWgMqny5fGB1oqgInd3AuUmOwtmAd969ltOmZ1jOzGneY6TqREAFCjSWpGoH255chPW7CjZC3tCYVoWNIXd1NVaK1sG0sjJJf77JMpZK0BlmyOIjAExvzpQkZep8+erf47PP/Z5fOOv3wDAEmstbF1YWuckWiuSyCPCsii++fA6vLZzcsmxGkz2dlMchknRmGCuXTVkbFoUp9/8FC7/6d/r3TSJaYAga0VEkQeRMVC9Ii9XJ/fR1+xZAwDYOrIVC1q8E7eiUTb1wj5P5M+/OYA3eseEP/+XN/pw61ObcOF/PYPV24YnrmF1QN9YvuTYZJC7blpYOov5ha/vit7hDaRZu597c6Cu7ZKYHgiyVkRiustNdpZT5Gv2rMEVf7wCo/nRSIqcP0NbR7bCtEzsGN0hpMh3jO7AtY9fi3X968qeQ7WoC5ETQv6XELKHELKmHt83WbAsig/e/jzO/e7TwmX+8HIxic77bnsOb/WLJbufCmwZLM34Zk7CSkvDopjXnsKSrkY8uyk6Ge8ZLXZAQ+lChU9KVIO3+tN4dO3uSdv6ryx+9zv2B7bxAyfIqq2VcpOdZRT54bcejp+8/BOs2r0qkiLnKz23jmzFrvFdMKkppMg3Dm7EN//2TeGMilFQL0V+B4AL6vRdk4KcbuIbf4q+y/tb/WmcurQLv73qJBQMK5Kan2zsHM6WHHOvupwoGCaFpig4dr92vLJ9JHL53tGc8/+hjCTyeuKlrUM481tP4co7X8QjayvnEJlwdHUBXV3YMLABB/zgANz0zE0A7JWdgpOdL+96Gef/4nzc+/q9RTIOikGvYHNk9azTCcSU4pqHcqMATuR5M+/EkLuTbTl1+joPvpS/u7G7bFuqRV2InFL6NIDJ2UcsAK/vGo0UYrd9KIPT/vNJ/PiZtwAAXU2JkBJFbBnMYGFHA1qS7AefDGKsFqMBu9hPRky5blqIqQTz2lMYSOcjhz/2uhS5jEOvHyiluPLnL6KjkfnPQR39pOKOO4A77nDI8DvPfwdA+ZWdQCmp3vXqXXh006N4cMODxagVQUXOkdEzztJ+d+RJuVGAO/cKz4wYFC7pbyvfc7S7YS8lchEQQq4khKwkhKzs6xPbRDUM1933Kk76xhN4+/efwe1Pi+3JBwBPre/DnrE8rj57KQCgqykeUoJhJKtjOKNjv84GxFT2g0/58LQCxnKl6Tcno72GRaGpBLNbkqAU2DOWCy9kw7Iodo8UCUYSef3QN5ZH/3genzlnKRKaEjiHEoa/bOjDdfdF25W+LGwiH82zeRS+QXJQvhSujv2kystmjWz5yc4ARW5YRZHDywZFuwClo4CxAhuF54yc8z2a4l2SE2StcEXe1eDNzlgPTNqCIErp7QBuB4Dly5fXLGNHsjp+uaKYzP3P6/bg02ctFSq7fvcYmhMarjlnKbYOZrByi9hgYpvtOS/saEBMZTfW3k3kpYp8MtqrmxY0RcHsVjbp1Duaw/z2BqGy//TTF/DMG/3O6+mS05yNQvbu2IGt9v07v6MB3c0J9I+L21bbhzK48YHX8bBtx9xw0bK65dAZyXntN06qhmnhYz9fiTf70ki0sj0wy5EqV9VAwGRngCJ37xiU0TMsa2JAtAtQXpHnjBx0i4mlEiIPslbSfWhPtntypdcLe/edVwFrd7Af/0f/eAwuPX4BXt0x4knWVLHszhEcOLsZhBA0JlSk82JhQs/bURSHzm11Efnea62MBxG5Id7eh17dhevuexXHfu0xbOqrnMrTDcOkiKnEIfJdI+KKnJP4SUs6AYivDLUsip888yZe2zmKNTtGIkXnjOcN/GHVDnznsQ2458XtwuUA1knd9/J2LL3+T3jglcndcPePq3fi6Q3io9utLiHS3ZyIpMj/+ka/Q+IAMBBhEnowXcDnfrsaZ3/7Kdzxt7dK3h/ODTv/Ny3TCT/sHctj1fo3sf/w3/DSVqa8yynyjJ4JnOyklEIJUMfpQjFIgXvkoorcba3wDkH1ZfgMUuR7MnsmxB8HpjGRv2oT+QmLO7F0VjN0k2LzQBpbBipHkTzwyk68tHUYy/drBwA0xjWM50sJLwh/XrcHB/Y0YUHH1FgrKzcP4ncRiGYsp2NBRwp//uzp+H8XsP0PRT3y7UMZfPKul/DLFVsxkC5EIgzDsqCpCma3MCLfMZTFdx/bgNEAq8cNy6JQCHDk/FZ87ny2Ma+oIn9lxwhufPB1XPhfz+CiH/wVNz4oPpH9wyc34upfr8J/PfEGPvvb1aGfp5Q6JPj+257DZ37DyqzbFX3ieyyn40XBESHH1oEMbn1qE/71Vy/jn376gnC5bYPMsprXlkJ3UzQi58T9g0uPBgAMRlDz/37/Wtzz0nZs6kvjbwFRTCP5oiLPGlnHWhkcL+AL2m/w0/jNWESYj+72nccL49g1tguAV5En1ATyhomVmwfx9u8/g7U7x0o6gLRe5Am3R+7Gys3DJXXevfZu/GrNr4rfY3cIbkX+7MZ+/ODPm0BBPYKiL903If44UL/ww18BeA7AQYSQ7YSQj9bje8vhR3/ZhG/8aR3mt6fQ3hhHc5JdxHO+8zROv/mpimUfXduL9oYY/u95BwIAGhMaCoYlRMhv7BnH0QtYBxDTJtda+f3LO/DeHz2Hz/12tfADOJYz0JyIYUl3ExZ3MWtDtL2b+5nSuPbtB2N2SxIvbx0WKkcphW5SxBSC1lQMqkLwixVb8P0n3sC3Hqm89dVwVodFgX84eh4aE0zhiHrkbl8dAF7cMiRUDgC2DRXL9rSET3zftWIrjvv643h91yi2DGRw8OxmAIAZYRRAKcWT6/bg8K8+iktufQ4j2fDtxDi+/dh6fPNhFou8sEPMsgJY5zyrOYFkTGWKfDwCkY8X0BhXMbctBQDoT4uX3dSXxukHduO4Re2Bo0S3Ih/Pj8OkJhJaAv3pPDoI6xxPV5gv71a5s26ehZd3vwygVJHf8yJ7XtbtHkO2QEsmHv3WiluRD2cKOPvbT+HLv2epLdydwJX3Xxn4PW4iv+WpjeDUystSSvHW8FueVLf1RL2iVi6llM6hlMYopfMppf9Tj+8th//4E7uJD5nDdvBoTop7Tmt2juDY/TqQ0BhR8BWImRB7hVKKkYyOdnvGPz6J1spjr/Ximt+scl4/84aYOh7LG04nF9XT3zLIlMY7j5yLw+e34jXBhT08Tl1TFRBC0JTQsNu2VsLq7reJpasp4VxfUWuF2zdPfu4MnHlQd6QOtnckh+MXd+D/nLDQk/CrHJ5az9Qh79w+cNwCtKZiSAuO7ADg75uHcPkdxZWroxGIfPMAi5w655CeSL787tEc5th2V2sqFqnOgXQenU0JdNr3fxRFvmcsh1nNCbSmYhh21/nQQxi591f4/orvO4e4Oo+rcQyOF9BDWId8GGHzYW5SzRrFDpj73ABT5NuGMrgl9j38uPWngTaHx1pxjQIANtrf1JeGQ8ausg0xb8fpWCukaK3sGs6BwBu6+Jctf8Hm4c1454HvrHyxqsS0s1bcarQxzi5eS1JsznbHcBZv9adx2LwW51iTrfzGC5UfwqxuomBaaGtgnUa1k52U0sjbn3Fv/rV/Px+NcVU4NnssVz2Rbx3IIK4xe6Q5qSFbECNUwyFyZj01JzWnswsjHf7bdjUlkLAn0kStld2jOcQ1BYs6G5DQVOimhdd3jQqNXnaNZjGnNYmmhJjNxjsrHuPe3ZwQLsuxY5gRAI+cCpqYLoftgxmcckAn2htigQq3HPaM5jHLtrsa4ioMiwrfD4PpAjoa4+i0I7wGBT1y02I21KzmJFpTcW/n0dCAf336WoeAgSKRJxQNHRvvwdHKRhRaFqGBGPb3Bd+H/snOgdEs3qG+gHPzj0GFFW6tuBT55gGu1ksjZfjkprssUFTke8Zy2DmShb8T+OvWvwIA3rvsveUuVU2YdkTOSW1RZwM+ex7zUUUV+Vf/uBYNMRUXHj7HOdYQZz/AKf/xZ/z3n98oW3Y4w37AthSrS1UICIlG5I+s3Y3jvv44TvjGE9i4R3zy8LWdozhyQRsa4hoaEpqwSh3L6c614SRaEJjsfKN3DLc9/SYWdjRAUQjiqiJ8ng6R20mzmhLFTjaMyLki725OIKFxRS5Wb+9IDj0tLA44pinQTYq3f/8ZnP+9yqt2KaXoHc1jdksSjQkNecMKnTTnop2PNLqaEvakeTRSBYqjynSIkOBI5w0MpAuY396ApqQWqc7dozln3oJHnNzy5Ebc8uTGSsUAAP3jBXQ1xdGU0BBXFWFrZSCdh0WBWS22Incv8PrhD7Hst3/xfH40x0Z+if6NOPP1GwAAhSMvA6HsfrKohYHMgLM1G0dGz6Bgsu+OEw3nbvue895sDHs6gNtW3oavPPUVT1m3It86kMYVsYfxoyRLs8vLDmYH0Z/pxzFzjsFXT/8qgOKoQFPYyPP6b3wT38R/wd8J7Bzbic5UJxrjjULXLSqmFZFTSvH1B1/HAbOa8MhnTsMC2x9sFlTk63eP4axDenBgT7NzzE00tz5VPhbdIfKGYqcRUxVhayWdN/Cvv3oZrakY+sby+O2L24TKFQwLa3eOYNkc1ua4YJ2UUoxmdefaxDX2IPSO5vDwml0Vy/51I4sc4WoxFoHIf7uSndecVualtiS916sSnt7Qj7jKwhbjnMgF0uCO5nS88NagQ1IxlThKPkw5DmV0FAwLPTaRAwiNYuIjKp4CgRG5Jhz9BLDRRyqmOp68qLLebvv5Czoa2CigYAhF6OR0EyNZ3akvZY9mv/f4G7g5ZO5CNy1s7k+js5F1lG0NMYxkxGwZ3mFxayVdMJ17id59N055zrtcfbTAiDxuL565OnYDzOM/gV2UxV6b1MQ5d56DQ394qKdcRs8UQwFf+TXOHfs9a7uSwCKyB4ZZvL5XPXgVnt32rPOax5HzsMVdfQO4Xv05jqIbABTtkVd7mU9/01k34ewlZzv1AixqZcdwFj+OfwfvUp9FJ5hQ453AzrGdmNs8V+iaVYNpReSZgondozm879j5jscNiBG5blrYMZzFfr7JoUYXkWsViGY4ywihNVVcPBRFqa7ePoy8YeFL71iGUw7oxJPr9giVu3/1TozmDJx3KFsCHFOJUJ3PvzmI0ZyBw+a12uXYuV3zm1W46hcvVYwg2dA7jraGGC46Yo5TVqTz+Mkzb+Lf7n8NS7obccFhrL1Nrt8mrgZvCAAAa3aM4N6Xt+PyUxahKaE5ijwsyubRtbtxxFcfxc6RHC4/ZTEAIKEpwqOWZzexTmtpT5Owzcatlc12np3upujWyp6xPGa1JJx7V7Tsm3YY6OLORjQlNFDKnosw8OX4PXZnlxKMAR9KF3Ded59GVjdx7CI20Z+MqUKW1+Ov9eJDP34eADCrJemIID6xa1omDMvAp4/7NH75nl8CAAYybMSd270DW+ksjM87DbFEArvQ5ZRZtXtVSV1ZI4uCWYCmaCB/ZStEe+ML8ezB16EROox88BxPZ6qzqMiVGPCDY3HF9usAFMmRq+pXel8BABzec7jjlXNbSCMq8n2bMERZsrj9Sa+nrCRyFwbsCZZO35J6EWtlx1AWpkWxX6efyIs3dKwC0YwEKnKC7UMZfPPhdaG+N58YO3phGw6e3YIdQ9mKn+d4Yl0v5rWlcMaBLGxJE+w8Hnp1F5oSGt555Fy7rd6f2qxAzG/0juHAWc3OcuWYRkIJdc2OEfzHn9bhtAO7cd8nT3Hqc3ey5TpKSilufPA1tDfE8amzDgBQnEzOh6TB/fEzbwIA3nvsfMcyi6kKRrPhxHjDH9bgi/e8igUdKZy8f5djs4XZFTw6ZetgBglNQUtKQ2M8ms3RN5ZHt63kAXEi39A7DkKAA2Y1OZ2kSNlvPcpU9+HzWcfeEBcj8gdf3YW3+tP49vuOxPuXs8RQCU1BTqCj/P2qHRjNGbj0+AU4cn4bWlNeItct9jwfN+84HNDBfvf+LOtYFw+vw0a6ADe++zDEVQUGZQLKpCbmNM3xVwWAxYPHQIChzbjauBo/Pfq32Db37VAAWIVgK7OrocuxZeKZfmBgI440GGFvUZawOq0ikXemOjGnaY5D5HzTZu2FH+PkB85GO2H1XKy+4JS96Zmb8Pedf5dEzsF9uU7fkvq4pjgKDkAgqW6248v36/R6VI1xF9EolRR5sLXyyNpe3PrUJmexhR93rdiCLQNpPLJ2Nw6Z04K2hjjimiIcz/3azlEcMb+1SKqqIuRzv9Wfxv6zmhwv1E/k5ToDSik29I5haU9x2yo+8qg0hH/glV0gBPjBB492HljAa12VK75q2zCef3MQ15yz1LFiCCGIawryIdfJoizFwo3/cJhzLKaGX9/RnI6fP7cFY3kD/33pMVAV4rQ1jJDdOdYXdzXaC8vEiTydN/BWf9qZJBWpk+O1XSNY0N6AVFx1yoYRef94HtsGs/ji2w/GwbOZJy+6KvOx13qxuKsR7zlmnnMsEVOELK/Xd43i3GU9+MZ7joBqh6MCRSIv2HlKZjXOcohxMMNi6ucQA/S4j2BOawqaqsCyN/C2qIVFbYucOj5+7MfxjbPZBg9ZI4uYZaK3/Rj80TgOh8xphhZPAVBh2GQ87iP0roYuZHWm5hMDm0BjjB+2tJ2AV5LHAQBM27d/fsfzOGbOMSCEIKUx65ArcnXl/zrfme0+EvzqWtTC9X++np13XixIoRpMKyLniryrsTTW131j6lbpTcaJdlGJIndNxmnlFTnPyOcmKTc5BhHHrpEsrr9vDU6/+Sm8sn0E718+H0DR5w5T8eN5A1sGM1g2pxhlExe0Vt7qT2Ox61zjPiIvR3RbBjIYzRk43LZkeFlKK6fAHRjPo6MxjtYG7+jIPVoq124W6gWcfqB3sURCCyeM3tEcTl3a7fn9RULyuC1y+2XH4sgFbQAg7JG7I0z272YdXlNCFVbV1933KvaM5fDeY+c7QkIkauXhNbvxyNpeZ47HIfKQsquc0WC7c0zUWtnQO4ajF7Z5kkklNDV0EjpbMPFWf9qZzAWKvnzOtoJ0e3JyVuMspGKMGIeyLNyQ0mbEDz7fKWsRdq6mZaI5UZzjuv7U653d65kip1iRX4RD57XhnUfORVxTQFDcfJmnkH3H0nfg4gMvRnuqnSnywjji2WEMn3Ejjsj9GC8c/330x1jnZeaG0Z/px5o9a3D6fqcDKIYhOpOdZh5/XvxZ/NE8GZmLb8Mmi6lvk5o4Zs4xAIDPnfS5yhe7BkwzIg9W5EAxFBEIju3e3J9Byl4I4YYnqqKMIn/hrUF87/E3cPTCNmf4DXitmCDCeavPu8r0hMVs2XkiFu7/WhbFA6t3glI4PjerM9xayekmdo5kPaMPfydVzuNcvX0YgK9OZ/FTeSJn4WmlHazbWinX7u1DGRBSnCDlCCMMSqkdUuett5IXz8HzyC/uKl4jbrOFEbJ78c6S7ka7rIZ0wQydeOwdzeEPq3biqtP3x9mH9EBRCBrjYp0Aj9i64aJlTp0i7V21bRiqQjydc0rAWsnpbE5qvw7vKFZkDmJ97xgsCmeSHkBxAtu+D+699V9x5uU2kdsKdzg/DABQaBMWuUfPdnrZ3aNpjObSOGn+SXj9U69jQeuCIqkWxhGjwMaxGE5c3OmM6gAFpj1hefAtbIXzp4//NP546R/RmmjFYHYQBTOPGIDe1FKMohEd7R1QVDafYFkFZ3L0tP1OA1Ak8pxue+QAXmg4FV+JfQaxWQcgA9Z20zKR1bN477L34qQFJ4Vc8eoxvYjcjkDgaTjdaHcd0wMe/q2DaezX2eBRFgCQjBUvgRZAAOt2j+JSe8LmI/ZkGodXkZfe2G/6Np2Y185u1uJil/Ik9buXtuPae19FayqGty0tZksTIfKXtw6D0iLJ+NvK2lv6HZmCgZsfWY+mhOaJ7HFCFyvUO5AuOItF3HATebny24ey6GkuRqpwJDQFOd0sG8M+nNFRMC30NHuTJIko8rf60yAETuQTULTZKtkcPBqI4yB7VWdjQoNp0VClykcCJ9q5ZHhZEWvlTXsNxEJ7pCVqrby8bQiHzGn2kLeIR759KAtKgYWd/g5WCT1PvjPUsjnekR1QFBE8fW13Q7ejyEfzoyAAKGl1VpECACXs3vqXu1bgpW170JZsw8FdjJTbkm0AgLHcEGIA+q0mHLWQHYupCkAZkbvj1ec1M7W9uG0xto1uQ8HUEQfQa7A6e1qSgMr+bxo6Vu1eBQKCo+ewFAUNsQbMbpqNHeNM4avtS7BNb0V7QxxxVYFFiwm3hnPDaEu0VbxetWJaEXn/eB5NCS3Q33OTexDRbR7IlEx0AvAQe5BH/vquUZgWxWOfOQ0XH+mdrHATRqAi9xE5t2WciIwKD8OzdgjgLR86xlNPTFNQCIkg+eFTGzGrOYFzlxWXA5d45AE++5odo9g+lMV1Fx7iIdW4QF6ZwXQhcKTEPdlK5bcPZTC/PVVyPKEpuO/lHTjkhocDy+2w82nzSAyOmKvtpIw4f6s/jXltKc+91GAr8kyFCdZMwXRi5QHg1KXdTluB8Lh3d+IqjqakhrEQMl7x5gCe3tCHxV3FuQsuQirdR6ZFsXrbiJNaolg2nMiL2T79ilytaHnppoWfPbsZjXHV87vGfff9YT9/GNevSCKhJRxFPpAZQRNV0dY+C6ri+vFsIteggyLvED8AHDn7SADAnvHdiAEwEm04zbbp4poCaivy3nEWSfKeQ96Dw2axOZUDOg6ARS2byAn+98URKITlo1HtBUKmmcfq3tU4oOMANMXZ9SeE4MT5J+KtITbZntvvTGwfyqK1IcaIHEUraDg3jPaU9/rXG9OKyE9a0okrTl0S+J6byIOU387hLOa1Vc5LERS1MpRm6ito8wk3YQQ9wDuGsh5VzBEXCK1btW0Y5x/a41HjgO2RV3hwDdPCys1DuPDwOR4bqNQjLyUrvkjptAO9dYqsCuUr//w42lZGQPnMi5v7Mx5l7LTZdX2DLItbn9qEZExx1Je/vf7/e+tMe2wVAEio4atJ3WGbxy/qiNQ5AyyvCyHwqM1UTA2Nzvn0r1hOkVkuazCmhte5qW8c43nD8zvwOsPA74eS6xRTMJrTy66afWTtbqzbPYYl3U1QXGQc991Hx73ci3/c2mq/FwcBwVh+DG0giDd3eL/UtlY0FEBRcIgfYLvzzG2ei51j/YiB4B0nHOpMmidUBYAKSi3sGmfrJz5y1EccAbd/x/4AgLxlQIOCv2zJ4vxDZ6O9MQ7F7ixMS8crva84HQbHCfNOwICdQ/26F5qwetswTl3aDUUhoLann9WzyBpZZ9QwUZhWRH7eobNx9TnBOcfdN5s/X4ZpUWQKZmi8eVB43HBWByFASypW8l7MdZMGEXm6YDiTfW5l6FcmfuR0E5sHMjh0bmvJezFVgREwmcuxsW8cWd3EkQu8Zf22UVB7N/WNIxVTMdfnVTtEXoaI84aJ8bwRaK3EVAVfuZh5ukEdwe6RHHaP5jz+LYc7Eimo03t1xwjOWzYb89q87XV75P4ODLATGPWnvR4swn8XoOiP3/KhY3D3VUXPU6Szy+km7nlxO+a2pjydVEytbFVQSpGxFfuHT9qvtL0V6nx5K5s8dE90AhCyWVZvH8a8tlRJB53QFOwayeG4rz8euF0cXwT0nfd7ic9/fec1z3PsEUIIGmINSOtpdACgfgWruhQ58RI5ABzZcyRG9THEAJx6xIG+OlWYoE6mxDnNxfDF/dsZkRuwYCCOK05dgn97J1tsROw6+jID2Dy82fkshzt65tBF83HFqYvxyTPYZ7gVxGPeJ5rIJ21jiYnGJ87YH09v6MNLW4dLHqaMvcDDPbEZBE0pVeTDmQJakjHvMM+Gx1oJmPzJ6SYaYiqe+OzpnrrjIcqPRzC0NwR0HiGLc17bybxJPzH6zy3oOzb1jWNxV6NHRQHFkUc5wuCjlvYAIgeAy09ZjDuf3xJYnhPNMfuVDj3dZJPTLc8iMIDZHI0Bv6n7d/H77gAbPYzmDCzyKU0+IquoyO349FZfxy7SCdy/eid2DGdL5lrCFpbtGskhXTDx7+861DuBLdB5rN4+gtZUrCRaK+m6lkaZaKRXto/giPlBHWyx7LaAsFve2S3pbvIcD+t4FrYuxM7RXiwGheIncoWNRDLKhhJrBWCdgm7piAFQGovzD+waKTCohY2DLBWBOw69p6kHChRYsKBpKVz/jmXOe6o9ofm9N/4IACVx4LMaZzn/v+a8oxBbVCwLO/fKZb+/DMDEE/m0UuSVkNBUXHka6w39NwoPJwt66MMwnNEDCRUIt1YyBRMNcRX7dzd5fNywYTifvCpHUpXIgqcS8FtBhBCPOg36jsF0oSSqBwj3yHl7Ky3MKkdWb9jDd54K1o1u1yRmLsB6yBYMT7QSh9daKe2Aube+wOfLa6oCJSR/DiepskReoeyaHSNojKv40jsOKSkbZo8A8ExAe+qsUHZwvODkoHHD3VkHhZXqpoWtg5mSOoHwkdJIVkdzQisRP2HtPaT7EGSNtE3GfiJnImFb7I+wSLpEkfc09UCHyaLNXZ0A88hVDFEDX3j8C1CI4iFghSjOZg+K4v1O1ddZVCJyLenttLgi52hPSo9cGDyfiF9tFomxsi8Y9AAPZQpobQhWmu4hfBCRZwsmGgLI2AnDKhPCxSMYgkYQca1yHDkv6/bHOdykFvQd43kjsM4wL5aPeIJI1f0dQaOA8byBhKYETr65/WA/kVNKkdHNQFvA3cGqAbOdPO46yC4LW6zFI1ZaUt7rJOJXr9k5ikPntpaOeFS2cvY9P/wbHnylNA8O/01LOg+BaKKMbiIVcC8AwGHzWhBXFZgWLZmDKFcnUAyfBUptTIDNIwReW3+0VirF/mws61qGgpWHCkBtmecpSxSvwPArch5LTkGAmHeClaJ4j8xrnleymw/f7EFRvaMWEktCcZ1eOSJXKEDivjke4r3mE7UzEMeMIvJyQ01+UzaWuaE5goimoiIPUbiZArNW/AhTJtxaCSJVTak8DE8XTMRVJdBScBNcUN3pECIvVy8f8QR1HsXvCO6AynUegJ/IvWVzugVKEUhS7g5WD1Cb45U6SlVBOm/grhVbApVqLYr8zb5xz4pZd9mRrI6Xtg7j0796qeT9rN2J+ScoRTqPXMFEKhb8mD/wL6fiX+yUCH57pdI96LZWgn7T0WxlInfa+6c/sT8b3C/XAWhzDvOUJb7de/yKnJOqSbznyiJIiseWtJcGS3Q2MCtG0bxkrGpxuLtcf2qAzhQrRwDA1x5/x3P4rMNL6q0n9g0iL5S3KgDg4WtOLTv0H84WnNS1fmghHnmmYAQuvPAvjPDDUeQBk7NhHnk6b5QdeYR1POl8Zc+5HElxRV4pNrmcJZTOG4HnCXg996xPkVeq032eQSlpK90PcU3BXSu24vr71uC+l3eUvM+jVvw2khORUYFU0wWz7G/KU+IGEWe2wL7Tfy+pCoGqVB6hZXSjYgfL72F/p8WvUVB73SIh6F4cyepoTZWWUxQCTSmft2d2E0u0poMg1XOA5z1VC1Hk9s47ho/SEpqCrKuJ/o2ZAaA1zghZ8xG5Evd+1j1JCrCMhzFojMh97eFWULEd4TtP1YIZRuTB1gpXjOWU38GzW3DeoT2BN9h4zijr/Yat7MyWGfqXKBMfKhFNWAKrdMEo22F5PHLfd1gWRbpgOBkAPeXKWFYcPPteJesqrgV3lOM5o+xIye3F+q0VXmcYkQfaObnyVpv7GgWlUBjNshFEWf+3zG9jWhQFw0JDLJgYeTsDidw+9yD7KR4yZ5IpmBVXcfJJcP9vU7xGpe2xXDZMsCI3Ai0ZwD5X3t6vfY392ehqYGGvGcSQTHjLhylybq0Y8NtWCjKk2Ea/rQIATXG21kGLeSe/1RirM05UfOe87wR2AjFu2/h2DtJdlh7PBTORqAuRE0IuIISsJ4RsJIRcW4/vrAaxMqooLeCRx1Ql0O/TTVo2FjmuKs6D9/0n3nCWULNyFnSTBhJN2GRnpWFtWAKrdL48MbrXO/nrzugmKC0/wQqUV5tFdVzJWinvkZfrYPd3RT2UKvLydo6XyIPsnPIdu1ttJgN+u3IjHn+MtB+OPRIvvZfcnUdQm3JlrBWAW1blR2jMWil/3/MOya/IK9lP7nsnaMQzktU9eejd8MxBPPEE+7PBibwAtWRylocfcvgVObdW/EQe1xRkUGzjvxz/LyVtaiDsu4yYt45YLA4KYHasCZ856TOB56NR+7dTveebV1id1x55Oa5928RTYs1ETghRAdwC4O0AlgG4lBCyrHKpiUE5a6XSTVksGzxELZhW2WRa7z9uAa53RSD8+oWtzv850QR6uCFEXmmyMxaSwIqF5AU/uO7w89LInsqRMkC4R15pDqLc9U0Xylsrh81rdXZt9y+YqWStxLXKk7rpvAGFBBOjm8izAXnJy414wvxqnmYgrM6g784WTKgKCYzAiYfkoyk3IVxsN/tOv0de6Zlx1xe0yrjcZCfAOq2fP7clMGyRe9V60HJc35xPc9wbTcNXTvrLxjUFBbA27vq/u3DBAReUfHUjGIEXVN8Etl2nhuDn33mPoGQJsWG/fHrdAG5/uvyGNfVCPRT58QA2UkrfpJQWAPwawLvq8L2R4RCO76bMhHjkvOxYzih5EHXTClxUAgDHLGzHpccvdF63uaJbshWG/nyyqNwDOJ43QEhl26Bc7O94vry14rYn/Oq60oMr6pFXGsKXSy1bzpfnOHQuG/Y++lqv53il6+tW5FZApzduj1pKVJ+v7NbBTIniLDfiKUYiBY+WHFUdMoIoZ62kYgEqFWx0V8kjz4Yqcvt+KrEjy3vkYYq8nKUIFAXOZf+zouS9pJYEAZvs9IPY5zDHmoce81M4b//zPO8rRIFCAX/XqynEOZZSg33qBsvOyuh7zvlzr5XJ80AphQaCoCfRsq/r2HgBNz20LrB8PVEPIp8HwL1v2Xb7mAeEkCsJISsJISv7+sR2gY+KchNO43kTpIwC44ipCsbzBs75TnEPQRaWJZaECfCGs1VWjFy9BYcfjucNNJUlGnZsuMxWW5m8WVYZD7i2PYuiyLkVdPWvV+Gmh14veb9SpAxHucnksVywL8/BfeF7X9qBlZsHneOVrBV/zpygKKay8wiuc7jlyU0lD2G6zIiH33tX/3oVPvy/L5S8nxFU5H/d2O8Z2QGMGJNlIk/c29r5wZN4VfTIHUXu/Q7H3gu4vrNdayL815Y/M+Vy+/PnYkuZ/P2MyEupkcRYO7tpO5rNC0usFYCRmf+pIITAtB+jRBlhnbA/kFW89SZiKigApYxzZVgUMSCYyO1RYRwIXPFcb0zaZCel9HZK6XJK6fLu7omJqdTKLFzJ5A2kYmpJ/K4b/GFybxDBvycoK2IQ3HHUIg/uV+9/LXDvQxGiOfEbTwQukqmkyN3wE7mIIgdYDhg/MnnDSThVDjFVCVziX8nTB7zXzz2CSVcYBfhJyT96YfZIcHv9o6/HX/eOBMIUOQA880Z/yfuVPHK/ULj23lc9r3O6WTbJVaXFRJW8dQ6tjEdeXERXWvYjb1uMH394OZZ0N5aMfsOeGf5xSgF0drI/DkpBKKAHFCW2Rtqf7MFnyV2gdt7yYlFqE3npPWYSdux9tzwZ+Lyl7DZnifd5ak5ooADKXb2CYUEFYCEgFxCfAwXB/rNKQ07rjXoQ+Q4AC1yv59vHJh3lvNy8YXkiIIIQtDyfk105a8UPN2HwBzdIMbq/b93u0ZL3s3p5FeV+6O9fvbPk/Uok5Yb/4a8U2eP2ZoOuY7pQfhTgfEdAtI1pUWT14JA8DjeBuQcolawV/8ggaIRWbr7EX9b//eXTAlTu7IseefkRTznk9PL2SExlCayC5kwqRfZwqE7Uit9+0pGKqYH5h1SF4NxlPWyUFWBFAoLPzD33sD8OswACIENLN8xW7POfT4ZwlfYAzDef8bxfMEwQAAWUdmpcke/oH8IT63pL3td0lhsm7dPzyZgFEKBQMJ3wUG+dFjT7srlT5AIAnwONg4RuIFMP1IPI/w5gKSFkMSEkDuCDAP5Yh++NjOJKt1KVUGnYDwRPUnHfUNRacStG58ENVGDFhz4XUG/BMMs+CO7+Zk9A9rlMiOcMsBzhd63Y6unwnBWhAZ2A+2EOskcyBSM0v3VnYwJDmYJnFJEWyIFTLgSxEkkdPLsFt192rLMUfveo9yGrNOLxn5+/Qx0vF7UScn9l9fIjCJFOoFzHHtcUPLtpAJ//7erAcqzOynNDQNA8Qvh9xBK4ecvxZ0ZkFFvyzOVZKoI0Ctg8vNnzFlHt77VfWwXvb5pNj4ECyNPSUaplK/K3qasxli7dK9e0t38bN73Pk6qxDoVYFJ//Xen11U0LMXsE4N/GzbKjVhIojbiaCNRM5JRSA8CnATwC4HUAd1NK19b6vdWALx3mmeI4CkY4kQftKi9qrZxqp5p135ic1P2JngBvDvThTKn6qNTe3tHizTaU9pY1LYqCaYWmKOWTuo+uLaoTvqApaAjfGFdd8cZB9kjlyAiAbcBAaTE1KlAkmkq5sd12mHt1J7++5cqed+hsJ9vl27/vVW8sB04wSfnJpUSRC1grQOlQ21nUUyYWvBKyFawVrvbuDVi8VG5FqBtckfvtqLxR3pfn0AIikfhrEfFjXnst8MUvFuvMjDh6+i+b/+L5rBJj51kA0AcLpuG993PpUVAABRjOZskcnA2+GrsDyzb8sKQdus7uyRHdOzomCnvWVNBARZ43LHBqGMl5iZzaxnoC1vQgcgCglD5EKT2QUro/pfTr9fjOapC0t3LbNuSdSMlXiDzhCNp1nT/UYTflnR89AU0JzUMC/P/lCPl7HzgKQPCkZaHCCMKtnIZ8ZTkZlxuq3/nR4516AYC6/ESnvQHnqqkKNt50Ic48qDtQkecNE4mQzoMnX1q/e6ykzjBrgcOtyCu112l3mQm3gmGWrdMfSeS2QizLzu8SZK346vLbSEWrrXJumCBk9fKdc7rM7kmA2Ipb3kH7o1Z0k4Y+M0G7VXHPPGyUAQDqiueB555zXg8NDcCyi20Z2eL5LAEj7luIjllkHCv6vZPu+fEh527uTXvtE8NW5CYo2kbXl7SDK/LejHdugyiMvGOEIpkttWQKpgWtjCI37fM/T1mFZblVJWXrjRm1shNgmytvHvASecGwQsnYvQ8jRxS/jy10cBGN/f9y9V50BFvuG0TkukHLPggfP30JvnLxMhw8u7lEzYd1Hqcu7cY/HD0Pnz6TLX92b/ibFyDGcsvsCwJzEIs6GxBTCTb2FRV5PqS9HCuuOxuAd4haME1oCqk4gR2Uehjgi7yC3/OfnztBVNZeNBUUZeNvhz83DI9JL7c60w+3oq+0qIevwAya4+HXK1FBWXPbzG+R6ALPTNBiJB6OWK4TdcM/Pzg0zKLZkkrC2STZgeJ9TrZnvJFvenoE/O7YNrLN817B3q/TBErUOgBYBtvJa/e4N7e6BabIm5HD/foVJQ0uGBZi9hhiODfsec+0FXmPMoL/1r9SUme9MeOIfL/ORmwZ8G6xppvhRDO3rTScybDEPXL/UukwUtVUBc0JDcPZUmslb1qIB1gyAJs8vfyUxehsimPIR+SV7Bw3rrKT34+57CRnYrfCdYqViVkuCIx4NFXBrOYkel1+tagi5+TnJkcRu8y9g417wqlSWb8id/+maYEVrMXv8RJGMWpFzF/3zLfo5T1yPrcR1EGE2U+AW5GXWiTlFsJxsNXQZayVMtfXvUmF334aGWMro1tiTdg+tt3zHiXee90osVb6Qe3mbhv1ErlhU7wJwAy4fy2TCb+0nsZovmivZHXGI/xMaGHcU043LTSwfIv4/brfe7/Tbu/EmyoMM47IF3U2oHc079mwV+Sh//d3HYp5bSlPHm/+EItM3PjDwPiEayWCa2uMBVsrRjgxtjXE8dLWYWczX3d7w861Ma5CIV5FzkMDw2PBSz3yvB5+fQGgqznhIVdOdmFluVfrt1bCyrkVuXtPTN0srzb5Neyy9x/1TM6G5Oxxw597p5JHHtQW92bMlTzycUfpl36HiP1Ubol+ocI14tCU0v1j+f0RKzMa+vNnT8f1F7JJaH8wR2achRS2JlpKFLlJvR61afpsRVc44tYRbxy+Qdk1MgFQs/R5o2ZxAtSt5tM+Ik+PDLiLoaCbiMFEh9qAO1bd4ekETIsTOTtJK2BrxXpixhH5LHuxQv94kTBErJXGhIZzl/V4FGcUayXhy2MtQqptqXiZyU7Ts8w8CPzdD/34eeeYqFVBCEFTQvPsBl8wTSebXjlUSmMgQuTdTV4iLwiOIOKqAkJ8RC4wCrjspP1wygEsTtkz+qjQCfDf8L5PnoITl3QERiKFTQICpco+oxuIa0rF6+v5vEuIVLJWuKgNuoZFRV7JLgteol+ps+MIyo0fNtnZ1hDHgg42+i3MmQvMn++8R9PM2mhLdWF172oMuci5YIYQeXqY1atoeK3vNe9n7XBGA0CD4fWyAYBaxe/+2eqf4fYXb8eDGx506ue/2OiQ184x8mlYAHrircgaWVx414VY/P3F+P263+OpbQ8AgDN5mx8uDRWuJ2YckXMl5SFyQaLxr5KLZK34FbmAbdCS0rCxbxxPrt/jOS4y0cQz0O10zaaHTXZ66455FLnIKCBocouXFamzuzlR8rsAYh1PKqZ6iDwvoMhjqoJ/PIHtcemezK7UCfCcLs1JDUnfpsii7QVKszVWIuNyuew5mLVSuc6g619U5AJL9C0/IYffg5oSZK2Ehx/y52nL924DfvEL5zjJsAnFJZ0HAQCufvhq572s7g0bNE1vcIKeY6S7X8ti/O/L/4vH33wcw7lh5IwcLHuidBVMNFuDKIGt9i87/DLc/OzN+PgDH8dFv7oId75yJxSqgK9jHRv2KnIrNwoDQFusGSfMOwF/2/Y3bB7ejHf/5t3Fdtr/Fvo3l70e9cCMI/KORmaNDLqXowuQFFCaalWPaK3kA4i8UieQ0FRsG8zi8p/+XdjD5fjKxYfi4NnNUEhRKYpaKwDLpz3qJ3IBYiw32SmkyJsTGEgXnIdfZOjPkYypkT1yoJg3nCtySmnFjv2dR7FdYBoTGhKaUlIna2/4giu/Is9WWNQTmKfdtkx004Jh0bJlT1jcEVgfOyYw2WmPEO550WtlMEUe7pGXm+ysGE2kBnceSo4JmtP2Ow2XHHIJ/rTxT44q3p32TURaXkVu2uF/lx3xUSztXIpz7zwX7d9sxxce+wKorYsvIVn8hPaVzrJSJi5uPu9mHDPnGCyfuxwA8MimR9AWa3GiYbKjPiLPjsAAoKoxPPChB/Dji3/svPfFt7GwSofIs2OYSMw4Iud5DQbGvXlFxBQ5W+DASbUQMkx0I676iFzAqnCrqHTBpxhD2tvTksTVZy+FRYt7OuYFRgEczUnNEzsvUqc7b7YbrKMMJ7fu5gQoLeZ8EbWCACCpKd6oFcHOmW/JxkcfYflzvvauw7DqhnMRU9n2c+5Jy7COcv2NF+AXHz0BQNBkp1U2DFC3AhS57cdXykUOAHdcfjzOP7QnMF2DUIimTdYPvrqrZA5CLGqlnCIPt3PmfvU64JprnONqnoX/NcTiePsBb0d/ph8d/9mB21behkc2PYKYUpybMEzf5GeB+dOdjW245/3F1aI/eOEHOHXhqc7rFdDx2Oo3vQ2yrZfOhk68eOWLWPGxFThx/olQiIL9W2c79khuzKfm82MwQKFpCXQ1dOFjx3wM/3r8vwIAPnL0R1i7ePty3gCMemPmEbltrQxUocj9Wf50gQlLjiBrJaycm3C9E4/hDxFQzLbICTlKXHZLUisJPwy3VoI3tcgLdpR8pyXuzUdpbzKulnjkYh2WXSe/RiH2iKYqznVNar5RgFl5cjahqc6qz5e2eHOBZAtGWTJ+99HzcMkx83GQa6Nj3rHnnNWZwWVTcRULOxo8VgyH07ELKHIAnjkTFrUSPkLzZ3vknVKlUSy/z1KvvQqsWlVsi03kyVgCHzjsA/jamWzTiasevAoZPYMG18YP/jBC0ybyhlgCh806DOYNxfc/d/LnnP9TACvXu2LULQtsTyJAJewaK0TBM5c/g92f3Y14otlR1Xra+5siPwYTgOrKlf7t87+Nof835Gy2zFPoSiKPiIa4hmRMwWDaO6kmQjTOhg/2w86HiWFhWLxsCZGH1OmeoPKQqiAx8geU1ysafggALcmY8AQgR0xlG/W6IxwopZGvLyfHKFYQI9VoUSsAnNWd/Pry6ByRjjIRU4IVeYhdBgDfenQDtrsWplUKIWyIa/j2+49EV3OREHh7RVZnpuIasrpZktMj6qKpEQ+RC3jkKsFIVsdHf7ayWE5oFMDeW7dr1FOnZk9ExpQYmuJN+NJpX8IZi84AAJw0/yQ0xotEvmtozJOnyNKZdZG0t1RTiIIHP/Qgnrn8GWdvTYARuekiZJofYXuE+jaz0BQN3Y3dUGMpmIveBosSWBkvkZP8KHQAcdduRZqioS3Z5mzt9tahVwIAMmlprURGZ2PCY62I5FoBSnfC4YQusrjBv/t6waRCVgWHx8M1LCQE7RygSODRPHKvIq+Ud50jKCkZP2chVR3jedgZOeUjTB4mY6V+tVg5f51iIY+8bFBagEpl3eq333UPZgvhaQy+eckR+Afbo+cEJ0Lk/HtzPjunYFhQFVLR5nBbfyN+RR7ikas28f15XXGyngcIVJ7sLL7nXldgUd1+v5gO+tLDLgUA/OiiH4G4NngYSefwMVcHohWY7RF3qeMLl16Ity18W8l+mZZrOX1uuBcFMAIOgqZoMCwDGdIA6ifywhgj8nhDSTnejlvW/Qj3QseewaGSz9QTM5PIm+Il1opo5AlQpbUSsCCoGmvFqVOQ3HhdQLSolWZbkfNhsQgxBm1nFske8S3s4REhIiOIVFz1rewUs8t4u/L+UYDABHZCU5AzTOca8d+m0rm67RN3qGWmUD4WnGN+ewO+8/6jQAgwYoelOiGPFToBTvJ+eyVfIflaEEqJvHLZgXRp6KxIrhX+XitJo6lgL4unFCYncqVI5FcccwXS16VxRM8RUEjxOxXizbiZ1Pvs7y7dmSjh2lCCAoBrFWZ2aDcKoNBI8I5GCTWBl3a9hG8rFLGsN/xQyQygAIpkorGkHD8H3dJxCcliYEgSeWR0NsYxkK4m/JArctvXimStqL4FQQLWiku9cQ83StIhPsFYrSK3aDFXh+hkJ2tjQI6WSNZKsU738UpoS3lXsooqck0hUEhA5yzY8VBaLCNyru5zcavNSqlo3VAUgtZUDMMRFDm3bLKFUkUedp4LOhpw3YUHA/ASuUjZHUOlmQSLC4LCiTzWYaGjzY4EsUxn8YybjAkhaLA3NnYTOYGJpT12nm89h4TJiDKulm7i4N40mQKwMsP4wu9WY1PfOPIjvdABxALK8bJZI4uv0t1oKXgjZxrGtyAPBclEqSInhHg6kPGx0ZLP1BMzksg7GhMYtIe1lkWF/D4gSJHXYK0IqCF3pAdX5JGIsRaPPOUNyxONIweCrRXREEJ3O6OEH85tS2LncNY3ggg/T0KIJzQ0Sgghb28xvNMMba+byN1phiuFH/rRmoo5pCqyOUTKGen4FbnYhPD7jmXbCbhXGYs8M1x8uPPEO7lWKox4+ATrE+84GbjIJllLd7KBl7M53B624l78PrIdvIt3q3kOt7VCAVxQeBR3r9yG7zy6Acaoba1UIHKOTrrHc42bM9uQg5ewy9WrGKWdXj0xI4m8qymO/nTBiRkGxIiRD7cLjkceLWolH3Eyzq3IHSKP1F7ukVcTR84eFr5QRmyy03t9gKJlEcUKchS5YYUmvuKY25ZCTrec9QEiUTYcCa24sKc44gmvs72BkcKgPRIQ+W3c9skelyLPVMgp7kdbqpi6wVnaX6GsYx8F5IkR+V14p+5R5ALWyvc/yDbGdm9lJjKi5G0aow1IEh0wCoBZcEL1gsgYgMcjT2iujmt4i9MJBClyP9GeqLyOQ8kW7NfZAGtsD/IA4i7CdsNN5K1kBDv7ixZJe24bCoSUba+7XtXMBu7lWi/MSCLvaIyjYFhIF8zIGQyB4s0YxVppTmpIF8ziYhcRayVgslM0dS4QpMjDFWOxvV5FnheYR/BfHyBax8NHCnxSTlQxAsA8O6nZjuGsU69InbxtvJ1RYtd53h2+GlWko4ypCh6+5lQs6Wr0KPJchagVP1ob4pEmOxO+kQ6H6PVVFYLmhObUySOTwu6Hg2Y344pTFzvbBAIua0VAkZ/50HPA/VlYuTHA1J1t2oJ8bsCnyIlZnIjOjzlhfoEeuU+RA0ATsiyBV7oPGWhlVbWbyAsAhna9xV6YOtqMPhgI7jz87U3QXNnN1uuBGUvkADA4XoikUvmN+48/WYEn1++J5Fe327HHw1lxqyIo/DCKbxwUtUKImNr0h+WJxGXz6/DV+4u5LETzpQBFRe6eeBQlY56dkvuyomkBWNsUp84oHXt3M3u4+aQlv75BKWPdOHh2C2a1JJwUs7ppQTfLr870w22thC0IAkpHZhx5QfsJ4AncCk57ATEB05SIIadbjoARmuy0f7e2wTFgwEJ6fAgwC46qFlHkCkxo+WH2wtQdayVMkY8lZwMAmkkGhkVBsoNIQ0VcC7dWCqDI9W5kL+yUAQassh2PRYvEnULBE6dfb8xIIneUVDpflVUxljfw1Lo9jrUS9uACQJs9DB92huE0dEGFu03O8D2Cb6ypLAmTo8jtSA63EiiHFt9CGZEQTf5wPr2hr8SXjxIKmHNZQaJEvrCTTSjxXPNRyiaCPPIqFHmU69uUiDkZFyttKhEEZq2w+yFsQRBQHJmVKvLyG2j40d2UQJ99nlE6O77fKs8MKRR+yPO72PSTGRv2ErmAIu8yd+OOvvdjZM82wMxX7ATcilxvmQcAOJBsw/67HgQ1csiDIClA5HkA6N/AXpg6KChMmGU7HreVcr66EuPDfYGfqwdmJJG324p8KF2IZFW4420VhTixtCIPLh8F8F17ooYf8m3bohANwFMD2FaFLq5SW7hH7ppkFVnZyfGuW/6GG/6wJlLH4yhHrsgj2CMtyRhmtyTxRu9YsaygRx7XVIfkooyyOhrjUIhXkYu3V8N43p6wFNjSzo3u5gSGMjpyullU5AKRMv7UuVHa292cwK7hnDN6AMSuEd9kYyzvi7qqGLVip8616Sc3NgiYOrK28ZHSSvcGALyKnJ/ph777R1hGoaIid0e7JBLs/1+I3Y1z130Z0HMoAEhp4dbKHjQiOWwrcrPA0uKWqRPw7sClg6LlmX8L/Fw9UBORE0LeRwhZSwixCCHL69WoWtGaKqrNKMRouXpQw6Rs01vBh49bK0VCDldD7vf5JF4UogGYGitOzooPpZ0JLtdIQFSRA8Dru0bx8+e2COcUB1jnGLdjswGuGMXaCwAHzm7G+t4xx8ONpsijTwirCkFHY9zjkYt2lE1JzbFWeHy36L00v50R2c7hLNIFlv620qIefg396ROizEHMak7izf40Dv/qI5HuwaYEu4+4ItdNtghJZOcmk9re/vgIYBbA18G6V3C64RZU/EwvUF9AITPs+OvlSJUj60t/q+ppO/wwWFW7iXyb0oPWNPfI86EjCLciHwNg5jOBn6sHalXkawC8B8DTdWhL3eD2f/lD1CgwrF2+Xzu+ecnhaElqMCyr4m7rfnBrZcgV4RBlZSdfXCHiiXq+w5WsK11mh/cgJGMqZrcksamP5YAQIXL/jkS8HCC+76bbr87r4qoaAA6c1YSNe8YjdR68zrU7R7FrJBspERoALOluwuOv78FIRhfO2QOwzSfG8wYopcV7UPC3md/ObKTtQ1mk80boRhZFRV4aRy5O5EyR5nTLNYoNH4nyc7rjWUZwhklDrUhOyBt69gNmqyhkOJEz4uNx4364lTUn8n/Rfo/kk/9WDD8sQ6ocWV9ec81MQyflOwA3kQ/Eu9FW2MVemHqop+9W5GOgyCrB51UP1ETklNLXKaWlu5lOMYqhdbqz04oIIRNC8IHjFqIpocEw2Ua7opEGjiK3rRURkor7rBVKqdNekV1o+HfsGM7CMC0MZ3QnMZUIls1twWs7R0EpRU7goV86q7nkWM5+6EU2WwBY53rHs5vx8JpdSBfEOx4A6GiKI28UQxBFPee4pmAwXcDJ//HnyB3Pv5x1APrG8nhx62AkK6gpqUE3KfKG5STAEhUFXJEzIjdDr1G58MMoIx63cNAjzCsdPLsFAPDIWpZLPIrl9R9n/zNwQRK/emYtCoW8o8ijWCtOm+1/QxW5L6953MwIK/LxRDvarUHANGAUck6kTLk63ZOda60uwJUaoN6YNI+cEHIlIWQlIWRlX9/Emf4AG2omYwpGc4Yz4SRKjACgqgSGRZHJG8Jk0RBXEVcVx1rJFkw0hDyA7hvTsChGswbGI2wnBjDV9cwb/fjGn9ZhOKujtaHyjezGIXOasbFvHP3jBZgWdTqjcjhodjM2fv3tOOeQWc4xfr5hZf144JVdyBRMYXIDWOIsANhtb6bRJlgnJzP3Kk1RRc4nPPO2UhUl8mb7vMbzhtM5i+z1CbAUxZpCsH0og/G84VmKHgR+fn4iz0WYM2l1CYAo12h2axLXnLMUQ5mC7a9bQvn7AWAcjLCbkMXOgVFkQKERVWiy04Q3JtsJPyyjjjlyhleRJ8wMdEKFFHk20Q4VFjC2C9lcLpK10os4iG+D5noi9JcihDxOCFkT8PeuKBVRSm+nlC6nlC7v7u6uvsWC4LlEoihyjpjCNpjIFEzhh48QgsVdjVjfO8aUdSH8AaS+m3EwU8C4HUXCowHCwNXpU+v3YCRTiKTIF3Y0wLQo3tjDJhDbG8OJUVMVLHWlWx1MF0CIlwhEMKs5KURSbnDVuIsTuWCd7qE+n4AUHWm5V/tGIXL++4277T3B0YeqELQ1sBDETCHc3itGrXitlXTBEL6PLjl2Pua3p9CU0CLP0/S0JEEpmxQeyxnOGoUw3HT/f8O8N4cvxn6F/e5/PzIAEkrwpCNQWZFnKWtrqCL3rbBM0gzMCuU8USupNgCAObwd2WwmdBTgfr4zagqKa0/PeiP0l6KUnkMpPSzg7w8T1qo6oCWpYTRruIhcfAivqQSmRW0iFy939MI2vLx1GDndgkURqsg5uGpauXnQyX0i2l4e7tVmLyKJQqh8omrbIBvUdjSKlT1pCUsL2pzQMJguoDUVqzgZF4T2hhgyAraBG3y7M67IRUcB7qyAu0fyaIirTtROGNyx+lFsA35t3Yo8SqeViqvIFEyM58NHLbxN7hQGlFKM58TneFSF4B2Hz4FuWo6yF/HIAaCnhZFv72gOI1ndmS8Kw5yxfhRGWfsIKDKgSKrBKywBryLf2HCE572cTWWhHrnPWlFhQQctq+TdRG6kWgEAn7n9AaQz2YppAQCvtVLQGhDXp5DIpytaUjGM5nTHqmhOiBOcqrCdcDICqtqNoxa0YSSr43U7T3JY2R57o+grTl2C/bsbce9LOzCWMxBXlUjRHADruKI8REBRNW4bZDe3KDGedmA3Lj1+AZJxFYOZAjoi2ioAU7jpvCE84gGK1oqjyAXP1Z1MavdoFrNbk0IhpYArR71hCa1+5eDW2GiVo8LGuIa03Qk0hXR2PELkF89vxf/8lU065g22RVwUS5GvgOUx7KL3w6xmdh/3juYxnIkmJmKxYh0ZoCKRuyc71ycO87yXtX/PMGtFt3TgkyvwE+2DxWMQs1ZoYxsA4FTlFeT73wpdieq2Vox4A5LGxOUkrzX88N2EkO0ATgLwICHkkfo0q3Y0J2POZKdCxCfjAKZEDMti4YcRFPnsVvajc4Ubpub3727C4//3NHzm3AOxbG4rdo/mIkWeuKEqBBaNZnHwh3zbEFfk4oTM0/YOpQuRyv2/C1imvWzBZEP/KB65fT15VkFhItfdijyHOa3lycKPuIvIo9wPvG1fum+NM8qKMrprsBV5OqL99MwbLC0sXzbfLDjyAJiVQmkx2Zfo78oFyZ6xHEazuhPaKgaX/QBadqITADpSHYHlACAPBZqile2gH/3HR3H6fqfDsAxY3QdinXqQ855Zgcjdx7VEDGmawPu0p3Hwimsrxq6zFro2YEk0oomOg/p2NqoXao1auY9SOp9SmqCU9lBKz69Xw2oF38ps3A4hFFVgACNF06JIF0yhsEUO/tDwBSQiCuyAWc1QFYLGuIp0nrVX1Nd0g+edqIbIt9odj4hHzsG3thtMFyKV+8QZ+6OjMY6hjB7JfgLcijwLVSHCnYBHkY/kMLulPFn44fbId4/mMLtFrBM4qKcZRy5oQ+9oDpmCAVUhwhOPALt30oXi/SuKv2zowyW3PuukMoiqyIHiiIdvmxgGZzFcWsdwVixy6syDujG7NQm9occ5lgFFQwUi/+V7fombz70ZDbEGnLh/m+e9HEhFf/zc/c/F+fszetJNHZZLueuwQpU8AMRiFgZpi6ucfVzAWkGyCSqhGB/cFVpPNdgHrJVoqg8oTnYyBSZelvui3MONpsA02xONpsA49oyxOiMRuWOtZKDZiZNEwXZQZ0Qe1VpJxVQnX3yU34ar4d0jObSlYsKds1uR947lMbu1/ISaH9x/zuQN9I/nnVFXGBSF4LSlXcjqJtJ5NtcSRUykYioyebOqEdqLW4bwyvZhABEn+VU+B5FFKqYK216qQqApBHnDFJ6n+enlx2PRRedg9G0X4pfGWQCYtdJQZjEQAMxpnoPPnfw5qEQtGWEXoIROdPL3C2YBlmtSVYcVWhYANMWESor3UhRrZax5IQDAfOuvofVUgxlL5M2uyc4oNzPAJjuzOpvciqLIOTH2RlDkTtmEyhRYzog0HP7L588AUMwlHa1O9tn+cTZhGYVo4poCw6IYyerOTvWiSMYUZyu+SB65/fD2juUjdVjubI2mRSOV1VQFCgG2DWVBKSLZMsmYCouyhVRRxURjQsNAugCLRvtNOfioMErn7FbkUewygJ3rYJqFsQrP03zjGxi4/t+QBrumGVA0VSByDoUoXrULVEwny+Ehchf5GhWI3E3GyThFDMVMj1GslWzjPIzSBqibJ2bt5Iwl8pZkDAXTwkA6+kOkKsRJ7xrFI+cEzD3cSIo8oYFSlqApyoO7X2cjDp7d7CS/ijJ8d18X0ZWkHHHXIpSoZVNxFQPjXJFHt1ZMi0ayZP7nn47zvI46kRzXFGwZYCtgZ7eK2zJ8Sf7AeCHSvQCwe6d/PPqohaPP7iij2HQJtRgV1CVoqzhlNcW576N0lHFNQRasrgyApnhTaBlO5I8efKNzTCeVrRXAT+RMkVNQ6NQsq6qPnnO0839CTLS6qgizVq454ZpimzWCzbQHZExaK5HAJ1x2jWQjD01jquJsuBA10gAoEnkUi6TRNZEXVYEltOLGxFFISlWIQzBROizAmyQrKpEnNRX96eiK3N3GZITzPGxeKz76tsXFshEmvgF2rnweQdQjB4rtjdo5A977Lur15XX6vycMPG3t7ioUeUJTnEnSFsE4clxyCeZ+9B+Ro4xUM6BoTooT+Za578AKi02eFwgJDT10EzkU9n/D954fbck2jH9xHACQN/N45bibnffCVnb+57n/iQ2fZtkSVUKRpikgPzGRKzOXyG0lsmc0j1QsorXiUuRRHno+aeko8ggdCH/gRnNGJDsH8JK36IIVf72Ryc1VT5RRAMAIji+Vr2ZlJ1D9CAKoRpGr6B/nIXniapMr8sF0QThhlr8sUBuRR7JWVJ7JUHxRD0cipjo51IVFwcAAtOFBryJPlqaB8EMhCkzLhKYS5Km9yXFkRc7+L7K0311uaP6ZeNA83lO20kpUnkJXUSyMIwVSGA89v2owg4mcXVw29I92mppKnEURUZQfwIayXB1HUZvuz0Z96GshVf6gR63THU8dVc27iSlKvcm4exQQ7TwTNVwjT9ko7bU/O5zVI5OxexRZKYUtxz+fvMjzuipF7loAVM014hsnROkoCQiysBN2gSJZIWqFQ1VUWJTF9OfBlXW4R85JtWAWAJuc+R5OlcpqigYCgoJZQEwlTp1h1govCwBEMTGGFJSCVOSR4J6Ai/oQuTdbTkQkDLeSiUJSngc3siKvvr3cQ42scN3WSsTOzkPkEc6VberA/h+FUAFvZ1eLmo/ym/Jzi5KFkMPdsYuc61ffeajn9XDaVscR2huv4T5KaIqT2z5KWYUAWcqI0QKgltl42VuGWStxVUEe7HkrVMhgyMHfz5t5wN5IIsdzoMfKdyDEVvt5I886D3sUEDbZCRSJXFEspGkSqi4VeSRUS6iAd3cTkd3W3WhyKVxVYGchDo8nGpEY3Q9OVNugKVElkddAjKlYdcRICHGuTeRr5Pp8VFLlnZYiuI0eh/vcolte0RS5H2N5tkJYZGNrDs9vOknXlxCCnK3ITXhXb5YDJ/KYRpBzbBkrdKLUbZFQ2yPnC/YrLUTiZZkiL3YeeTv3SyVv3iFywqwV1UhXPrkqEX06fJrAPeES2Vpx3fzRFTm7pFEnWN0To7VMPEYljKY6WCtRr6/X/43ur2d1szZrJWpZ+/PJWPRY8GL9UaNWoinyIFTbYbE6q7tGrF7B9p59NgilyObYuTJFHl5WIQosMGslbavjDEx0RiByqIy4uSJ3L8UvVzZv5pntahN5joQn6nKsFWJhjKagWjpg5IEyOxJVixmryN3WSnRFXr2fyokxij/OPl+dbwzUpjaL1kr1xBg5asUdfVLlJGBt8wjVdZTRwyyrJ8aGePTOjse488nyqHXWco2quge//GWQG26AobB2W0RckZuWCU0peuQZaqI5UXmi1E3kqt1eR5FXsFb4+1kji5hSVOROoi4Rj5xYSNtpe5Gvv70yY4ncbW1EVTQxtyKPeENzRR41btgdK1wtSSkCO7yXq7cWYozaCTS4ooiidjw8rDQqqSZqaC8/16gWRzJWfQfrUeSC9+A9nzgZt112rLMaOeq9G6tBwHgVedTgAtZOC2JErhI22RnXCN6iswEAaZhoiokrcn6uooq8Kd6EdCGNmEZQsEcBvBMot6MR4CXyccqJvP5ZEGcskRNCnBDEqA+96prsjG5VsB85atywezVntZOdCS3a0B+o3iP3PvTVR2REbS9Xm9FHENXbHA6RR/xdarFWPB654LnObUvh/ENnOyOByNZKDaOsRBVq3jj/XOTPOwsDajcoqDCROx65quCX5tn458LnMU5IJI+cizxRj7wx1ojxwrg9CmDP+BgsEJCye4wCRSK3qIE0seuYgBDEGUvkQFG9Rfd/qw/DaqpSkbvtnGrVcdROB3B1ONH4tKaHPkoKAj/cfnWkcjV45I61EpGM3XMdUe+jxioUuVOvfW2i3g/xWhS5u6MUvL6bdq7Bi2/+DYOxHizJ3QkgOpFbUPCkdRSyZjYSkfNnPJIi19OeSJlRUDQnmiu2WSEKCAhMakJXbeU+AYuCZjSRN1fp/2o1EDmPy64m8RVHtWozSkQFBy9jWTTkk17Ea5jsrCZ3CAc/16h2WTWKkcNR5BHPM1kFuXGkqvDIi5+v7hrVGn7ofI9gznYCBZRSm5DZfagSwclOWswNT1GAFdEj1xQFD5vHCXvkjfFGpAtpe7KTfc8I0dAcD1/ApCkaDMuAwa0fSeTRwCNXarFWoj4MjkdeRU5xjur96uhEzmPm+T6NovAO/aPaBtUTeVEdR7t1W10rMqu1HKKep1LDXEstitwh8poUeXUhsFFCHgkhoJRvn8cW0QlPdlLTESEUbCV1FEWuqQSf1K/Gj9RLAIRbK03xJowXxj1x5MNERUuipWI5oEjkb2kH4EsH/hHY/+zQMlGxTxB5ZGtFcceRV2et1KbIq/NT3Vn+RMFHH2ZERT63rXjjR21vNUmgODipRonRB4A5rmRX1UYiVbNU3lnAFHmitPj5qOfK2xk5mqiGsFBO/FHsHIUQWKCIq4rtkAtOdrpWdgKARezc6yFEnlCLKzs1hcCCgu0a20g8zFppjDUiracRUwl0O2p7hJBIRB5PJDBgNQFq/aO+ZzSRc3UcdZjo9quj2hVO+GEtijyiv8632uK5LqKAk4QRkcg9ceRVEmM1cG+9FgXuHClRJ1h7IiTK8qM4ER3tGkVtoxtO+GEVOXA4oo8CWF1RWr3+xAPxwFL+fLL7L6pHDgDUNkjCbA6vIrcjvRS+AlZwslNV0EDYCGCMIBKRtyQ1J0tpvTGjibzayU53CF/UB4qvKK1FkUdtr+hmB0FY0M4mYJZ0heeBLoeoGy/XROQ2YRQijj5qIUZO5NV0lNV6+rWA5wOPSuRu1DLZKYoVH3wbbj7ZsjcmYb+n8IIgWsyhZJFo1srVD18NSlkZYhO5cPihStAGFnUyDivUlweKRN6ailV1D4lgZhN5lR65VsWkIUe1ceRA9QtPomx24MdpB3bj11ee6EnzKoorT1sSudMBavPID5nDFFAtKjkqZtdE5NUp8lrABUw1UUwc0e0y9vl8hA6WL23valFRjSLvbuY5xcWsFfcKzN35l1l7DUboodZKvBG6pYNSA3ebZ+Bh8zgMq/FIinyvJXJCyM2EkHWEkFcIIfcRQtrq1K66gK/ujE7k9jCxCj7vbIxDVYhzk0XBkQtaAUT3J7uaalvue+KSzkg5OTiuu/AQvP61CyKXq2ZzaY4PHb8Qd3/8JJy3rCf8wz4I71zjA98aju/CFAXJKkMBa0FbyiasaG6ZB1E7Hj4HEcXy+vDVP8WTPwU6GqN55HxlJx8FUDt9VZg9orkSci3uYPfPeCGLuBoPrZd3ElkjgxE04Sr9M8iaGbTEoxF5NfeQCGp13R8D8EVKqUEI+SaALwL4f7U3qz44akEbls1pQU9LNKLj1opaBZN3NiXw8NWnYnEVVsVPPnwcXt0xEnl5f9TJsKlGNcNwDkIIjl/cUVXZv3zuTKQLRvgHfZhlK/KcHn0H9KlQ5LzDylbRXo6ov5F78lsU3O5qb4wWtcJXdhZhOcdF6gOAjkYVgIGskUEqEd72xhh7nsftxTwUFFkjHc1aaYpjLGfAtGjdn9maiJxS+qjr5fMA3ltbc+qLoxe246GrT41cjhN5NSoVAJb2hP+4QWhtiOFtS7uqKvvli5bVZLFMBaLstlMPtDbEPGGIomhOaLji1MV4++FzIpflnn41RD6vLYWhTCH8gz7wXeyrIfKGuIpMwYwcIDCvCiJXbGI9/cAO3NGRxPZsNGuFg0bw1zlaG3jooh5qqwBFRZ7WefZCHRSWQ/CV4FbkADCW09EWccPy0Drq+F0fAfCbcm8SQq4EcCUALFy4sI7V1h98Mi5qZMRUohqPeyrxyDWnRd4XcqpACMH171hWVVmubKuIDHU21o4K7pFnC9GJfOmsJqzePhI5Z0/USCuALQgCgKYkwb2fPBlzvh1tQVDxi8TV/On7nY6/bPkL4horQ5EPtWSAIpGP2Yt5onQefiIfydafyEPPnBDyOCFkTcDfu1yfuR5s+7u7yn0PpfR2SulySuny7u7u+rR+gnDiks6pbsKMx0Gzm9FZo7c/HcDnO/JGdFLVVCVyRBCrk5FLrgoh8pN/Og7fft+RVf82B/aE77nJwa0O3dJhWuz6RFXkX3rHIWi158JEOoFvnfctAIBBDVx34cE4bnGzE19eCXxSc9RJeCVm5wClRD4RPnmoIqeUnlPpfULIPwO4CMDZlNIaplf2HrQ3xtGc1KoaLkpIuPEf7zkC3318A05YPHnioJqIKY7u5gQuOXZ+VWXXfe0Cxy4RwbbzT8Tdq9bjM6buEKIokesWI8OPnboEydZDcNl9YmV5ytmCWcCVp+2PR3Zr6MuFGxOtSRaIMJIfAZBAlCibIEVeb9RkrRBCLgDwBQCnU0oz9WnS3oGVXzon0k0pIRGEBR0N+M77j5rUOg/qacbHT1uCS4+fXAszanTY5g9diFvjP8OnzIITGii6sjNv5qGbOmJqzFHnIjaHZ3MJABa1hMq1JdsAAMO5YSzqXIxNA2PC7eVEvrirEV+5eFlVgRChddRY/r/BuqfH7GHS85TSq2pu1V6AWiIrJCSmEopC8MULD5nqZoQimbeQKjBrJQoZK0TBs9ueRfzGOPZ8bk8kW4YTuW4yVWxaplC51oStyHMj+N0nTkbGGMJ+34/mkXc3J3D5KRMzl1Vr1MoB9WqIhITEvoVTPvF1PNQL6J8sErmotcLRl+krdgICfjVfhLR9dDse2fgIU+QC5bhHPpIfQVdTAr3jRLi9mqKhP9MP0zIjRdZEwYxe2SkhIbH3gketFMwCTCquqokro4thGZHKckV+3Z+vwwV3XQDDMoTtnOZ4M4ZzwwAQqeNJ62m8vPtlfPnJL4d+tlpIIpeQkJgSuKNWohCjYRUXdelmNFvGv1GyKJEDbMKTTXYi0ihg28g2AMADGx4QqqcaSCKXkJCYEvBggoJZiETkeTPv/N+wjEgeuX+jZLbtm5jd0ZZscxR5lFFAf6YfANDTFD2thCgkkUtISEwJuLXiUdUCCjdnJ7oCfBOlAmVrUuSJVozkfIpcoBOgdqhiT6MkcgkJiRmGoQ+8E3ccFX1BkIfITT2SOuaTnU55S6/JWhEtCwCdqYlbSyCJXEJCYkow/qH34mdHR7dW3ER+1s/Pwku7XhIuyzdD5tBdi5HCwLd7AxCp4+HwJvqqLySRS0hITAkSw2PoTHutlahEDgB3vnInAPGkWdSV3zeKIm+MsQ2YgWiTnc999DkAXm+/3pBELiEhMSWY95Fr8Lu7oy8IyhvBhBhFHXPopjiRN8WbnOyHUeycE+efiIWtC53VpBMBSeQSEhJTAnfUShRi9CtyDlGLxA3d0oWVfJAiF+0EEmpCKnIJCYmZh6ColVqIfKIVOd/uze3pi3YCcTUuFbmEhMTMQ7ULgsop22qWvxfMQiSPHADShXTkyc6ElpBELiEhMfNQ7YKgcnBHo4jCsAxhS6YxbhO5no402QkwRV7O268HJJFLSEhMCehVV+HW4+xYcFvhVuNzA3ZYYRVpp6NGrQBMkUfteKS1IiEhMSOhfvBDuPuw+ijyasvpZoTJTpcijzI5C0z8ZGc99+yUkJCQEAbZvh1L00n8+9P/jgUtCwBUT8jVKvlqFTknfznZKSEhsW/jsstwxz1MiW8bZRkCRUj1oM6DSo5V2wFY1IoUtQLYijziZKckcgkJiRkLzadoRRTucx99Dq9+4tXI5cpBeLKzBo88oSUmdLJTWisSEhJTBlXxUpAIMban2p3NkKOU42iON2OsMBa5rFuRd9AOANGiVvZaRU4I+Roh5BVCyCpCyKOEkLn1apiEhMTMh58IRUnV/7koHvnOz+7Ez/7hZ5HrbIo3AbDjyKuY7NxriRzAzZTSIyilRwF4AMANtTdJQkJi3wH1vJqMqJWmeBPakm3Oa9FOoCHWAADI6JmqVnbutUv0KaWjrpeN8P8qEhISEuXw2c/iNxfM9xyarPBDN3mLlk1pKQBeIt9bJjtr9sgJIV8H8GEAIwDOrPC5KwFcCQALFy6stVoJCYnpjosvxt/6bwa2Fg9VG0YYdbLT/XlRMo6pMcSUGG546gacseiMSGUT6sROdoa2ghDyOCFkTcDfuwCAUno9pXQBgLsAfLrc91BKb6eULqeULu/u7q7fGUhISExPrF+PebvGPYcmS5G7Px+lE+D2ylObn2JlI0x26pYOSifGtAhV5JTScwS/6y4ADwH4Sk0tkpCQ2Dfw8Y/j87s34deXFg9N1oKgaqwVgBE53+4tSlm+V6hu6SX7htYDtUatLHW9fBeAdbU1R0JCYl9Cd4N3dD4lijxCJ5CKpaqqN6ElAJTfFKNW1Bq18h+2zfIKgPMAXF2HNklISOwjmN8yH/9w8D84r6td2DMZHnnQZ0XrbU2wuPeh3JBwXVFQ02QnpfSSejVEQkJi3wMB0JXqcl7vzVErQOkGyqJl5zazJTY7x3ZiYWv9gz3kEn0JCYkpheZa3TlZHnm1k508x0rUejmR7xrbJVxXFMgl+hISElODL30JAKAV/uAcmjRFXqW1Ug9FPhGQilxCQmJqcM45wDnn1EeRR/TI3fVMBpF3N3ZDJeqEEblU5BISElODVasAeEm4lh2CosBdT5Q6eY4Vp6xgB6IQBbObZmPH2A7huqJAErmEhMTU4JprAADal050DkUh5LZkG4ZzwwCqiCOfZGsFYFkb3THo9YS0ViQkJKYU1VorvZ/rxRE9R0Qu5//8ZBF5TIlBN3Xhz0eBJHIJCYkpRbVEHlfjSGpJAFXEkbutlUmIWgGKy/QnApLIJSQkphRuIo9KyLzsZCnydx38rrLfE4aYKhW5hITEDEW1i3PcZScr/PC2i27DkT1HBn5PGGJKbMIUuZzslJCQmBrcdBMAQKN/cw5VS8i1JM2Kao8saluE1b2rAURX5Bk9I97ICJBELiEhMTU4+WQAgPbcCufQZCnyaq0VoHo1LxW5hITEzMOzzwIANNXlkUdU1twjryVpVk0TpRHaO5EeuSRyCQmJqcF11wEA1Jvf7xyqVh1PVtIsd51Ry8aU2IRt9yYnOyUkJKYUtSzR54RcS9KsmlaFRlDzMvxQQkJixsJN5ISQSGWrVuQ1pAWoWpHL8EMJCYmZCjeRV1t2spJmAdXbMhM52SmJXEJCYkpRbaIsd9lJ9cirneycwCX6crJTQkJiavC97wEANGV91V9RdRx5LVErrs9HsYJi6l6uyAkhnyWEUEJIV/inJSQkJAAcdRRw1FF1sVYmNY68ylHAXq3ICSELwDZe3lp7cyQkJPYZPP44AECbXz0NOVErNcSCT9Zq0pi6d4cffhfAFwDQOnyXhITEvoIbbwRuvLEmRV6PlZ3VLu+PWmdcjcOkJiitP1XWROSEkHcB2EEpXV2n9khISOxjiKqmg8pOVgihp86I7Y4pMQCYEJ88tCskhDwOYHbAW9cDuA7MVgkFIeRKAFcCwMKFCyM0UUJCYiZjn/HIVZvITR1xNR6pbBhCryCl9Jyg44SQwwEsBrDanrmdD+AlQsjxlNLdAd9zO4DbAWD58uXShpGQkADgigWvIgyxWlL1fEeVUSvVTHYCU6TIy4FS+iqAWfw1IWQzgOWU0v46tEtCQmIfASfylkRL5LLVWituTFZaALcirzdkHLmEhMTU4LbbAAAqGQRQJZHXQ5FX6a9HTSewVypyPyili+r1XRISEvsADjoIAKDueAEA0JpsjfwVqVgKALB1tPro51pWdkYBV+QTEYIol+hLSEhMDe6/H7j/fuSNPACgOd4c+Ss+cvRHAACHdB1SdTOqjVqJGkbIJziltSIhITFz8O1vAwBGb/88gOqslUVti9D3+b6qynLUspgoCqaFtSIhISFRDY6fdzw0RcN1p15XVfmuhtoyg1StyCOugZSTnRISEjMW3Y3d0L88MTlIRFCtRx7VWplIRS49cgkJiX0a1Uat7E2KXBK5hITEPo1qFTlX2KKQHrmEhMTMw513TnULAFTvkSe0RKRyUpFLSEjMPCxYwP6mCCcvOBkAMJIfiVSOK/KEGo3IefihjCOXkJCYOfjNb9jfFOH2i27HMXOOwQnzTohUjivypJaMVO6IniOw5hNrcOp+p0YqJwJprUhISEwNbr2V/fuBD0xJ9YfOOhQvXvli5HKOIo9orTTEGnDorEMj1ycCqcglJCQkIqBaRT6RkEQuISEhEQHVeuQTCUnkEhISEhFQbdTKREISuYSEhEQEcEW+N1krcrJTQkJiavC73011C6qCYRkA9i5rRRK5hITE1KCrtmRXU4WckQOwdylyaa1ISEhMDe64g/1NM+RNlj99b1LkksglJCSmBtOVyO2NMORkp4SEhMQ0xYyzVgghXyWE7CCErLL/LqxXwyQkJCT2RvBNl6vZmm6iUI/Jzu9SSr9Vh++RkJCQ2OvxyeM+id7xXnz+lM9PdVMcyKgVCQkJiQhoiDXg5vNunupmeFAPIv80IeTDAFYC+CyldCjoQ4SQKwFcCQALFy6sQ7USEhLTGg89NNUtmDEgYfvOEUIeBzA74K3rATwPoB8ABfA1AHMopR8Jq3T58uV05cqV0VsrISEhsQ+DEPIipXS5/3ioIqeUniNYwY8BPFBF2yQkJPZF/PCH7N9PfnJq2zEDUGvUyhzXy3cDWFNbcyQkJPYZ3H03+5OoGbV65P9JCDkKzFrZDODjtTZIQkJCQiIaaiJySull9WqIhISEhER1kCs7JSQkJKY5JJFLSEhITHOEhh9OSKWE9AHYUmXxLrCQx30J8pz3Dchz3jdQyznvRynt9h+cEiKvBYSQlUFxlDMZ8pz3Dchz3jcwEecsrRUJCQmJaQ5J5BISEhLTHNORyG+f6gZMAeQ57xuQ57xvoO7nPO08cgkJCQkJL6ajIpeQkJCQcEESuYSEhMQ0x7QickLIBYSQ9YSQjYSQa6e6PfUCIeR/CSF7CCFrXMc6CCGPEULesP9tt48TQsh/2dfgFULIMVPX8upACFlACHmSEPIaIWQtIeRq+/iMPWcAIIQkCSEvEEJW2+f9b/bxxYSQFfb5/YYQErePJ+zXG+33F03pCVQJQohKCHmZEPKA/XpGny8AEEI2E0JetbfAXGkfm7D7e9oQOSFEBXALgLcDWAbgUkLIsqltVd1wB4ALfMeuBfAEpXQpgCfs1wA7/6X235UAbp2kNtYTBtgmJMsAnAjgU/ZvOZPPGQDyAM6ilB4J4CgAFxBCTgTwTbAtEw8AMATgo/bnPwpgyD7+Xftz0xFXA3jd9Xqmny/HmZTSo1wx4xN3f1NKp8UfgJMAPOJ6/UUAX5zqdtXx/BYBWON6vR5sow4AmANgvf3/2wBcGvS56foH4A8Azt3HzrkBwEsATgBb5afZx537HMAjAE6y/6/ZnyNT3faI5znfJq2zwPYrIDP5fF3nvRlAl+/YhN3f00aRA5gHYJvr9Xb72ExFD6V0l/3/3QB67P/PqOtgD5+PBrAC+8A52zbDKgB7ADwGYBOAYUqpYX/EfW7OedvvjwDonNQG147vAfgCAMt+3YmZfb4cFMCjhJAX7W0ugQm8v+Xmy9MAlFJKCJlxcaKEkCYA9wC4hlI6Sghx3pup50wpNQEcRQhpA3AfgIOntkUTB0LIRQD2UEpfJIScMcXNmWy8jVK6gxAyC8BjhJB17jfrfX9PJ0W+A8AC1+v59rGZil6+A5P97x77+Iy4DoSQGBiJ30Upvdc+PKPP2Q1K6TCAJ8GshTZCCBdV7nNzztt+vxXAwOS2tCacAuCdhJDNAH4NZq98HzP3fB1QSnfY/+4B67CPxwTe39OJyP8OYKk94x0H8EEAf5ziNk0k/gjgn+z//xOYj8yPf9ie6T4RwIhruDYtQJj0/h8Ar1NKv+N6a8aeMwAQQrptJQ5CSApsXuB1MEJ/r/0x/3nz6/FeAH+mtok6HUAp/SKldD6ldBHY8/pnSun/wQw9Xw5CSCMhpJn/H8B5YNtgTtz9PdWTAhEnEC4EsAHMV7x+qttTx/P6FYBdAHQwf+yjYN7gEwDeAPA4gA77swQsemcTgFcBLJ/q9ldxvm8D8xBfAbDK/rtwJp+zfR5HAHjZPu81AG6wjy8B8AKAjQB+CyBhH0/arzfa7y+Z6nOo4dzPAPDAvnC+9vmttv/Wcq6ayPtbLtGXkJCQmOaYTtaKhISEhEQAJJFLSEhITHNIIpeQkJCY5pBELiEhITHNIYlcQkJCYppDErmEhITENIckcgkJCYlpjv8PqiSfMaa0CiAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind = 45\n",
    "plt.plot(np.arange(test_ds.shape[1]), test_ds[ind].detach().numpy())\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind])\n",
    "# shows the 90% prediction interval\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] - 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] + 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.axvline(x=window_len, c='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "ind = 146\n",
    "plt.plot(np.arange(test_ds.shape[1]), test_ds[ind].detach().numpy())\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind])\n",
    "# shows the 90% prediction interval\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] - 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] + 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.axvline(x=window_len, c='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "ind = 199\n",
    "plt.plot(np.arange(test_ds.shape[1]), test_ds[ind].detach().numpy())\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind])\n",
    "# shows the 90% prediction interval\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] - 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] + 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.axvline(x=window_len, c='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "ind = 272\n",
    "plt.plot(np.arange(test_ds.shape[1]), test_ds[ind].detach().numpy())\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind])\n",
    "# shows the 90% prediction interval\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] - 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] + 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.axvline(x=window_len, c='r', linestyle='--')\n",
    "plt.show()\n",
    "\n",
    "ind = 304\n",
    "plt.plot(np.arange(test_ds.shape[1]), test_ds[ind].detach().numpy())\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind])\n",
    "# shows the 90% prediction interval\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] - 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.plot(np.arange(test_ds.shape[1] - pred_len, test_ds.shape[1]), pred_mean[ind] + 1.644854 * pred_mean[ind], color = 'green')\n",
    "plt.axvline(x=window_len, c='r', linestyle='--')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c137e91c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
