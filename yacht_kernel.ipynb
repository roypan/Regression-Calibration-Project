{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import uncertainty_toolbox as uct\n",
    "import uncertainty_toolbox.metrics as umetrics\n",
    "from uncertainty_toolbox.metrics_calibration import (\n",
    "    get_proportion_lists_vectorized,\n",
    ")\n",
    "import uncertainty_toolbox.viz as uviz\n",
    "from uncertainty_toolbox.recalibration import iso_recal\n",
    "\n",
    "from data import data_preprocess\n",
    "from evaluation import metrics\n",
    "from model import end2end_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = data_preprocess.data_preprocess('yacht')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = torch.mean(y_train)\n",
    "y_sd = torch.std(y_train)\n",
    "\n",
    "y_train = (y_train - y_mean) / y_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial loss:  10.583066940307617\n",
      "nllk loss:  tensor(1.2151, grad_fn=<MeanBackward0>) kernel loss: tensor(3.1226, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.9192, grad_fn=<MeanBackward0>) kernel loss: tensor(11.6139, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(1.4538, grad_fn=<MeanBackward0>) kernel loss: tensor(20.1540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(1.3994, grad_fn=<MeanBackward0>) kernel loss: tensor(18.3642, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(1.0128, grad_fn=<MeanBackward0>) kernel loss: tensor(7.8327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.7749, grad_fn=<MeanBackward0>) kernel loss: tensor(15.3147, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.7839, grad_fn=<MeanBackward0>) kernel loss: tensor(13.5132, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.4440, grad_fn=<MeanBackward0>) kernel loss: tensor(6.7940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.4619, grad_fn=<MeanBackward0>) kernel loss: tensor(5.4222, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.2164, grad_fn=<MeanBackward0>) kernel loss: tensor(2.8291, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.2571, grad_fn=<MeanBackward0>) kernel loss: tensor(4.8376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.0258, grad_fn=<MeanBackward0>) kernel loss: tensor(3.4140, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.1997, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7656, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.0779, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8395, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.0509, grad_fn=<MeanBackward0>) kernel loss: tensor(2.9589, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.1090, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1667, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.2840, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.2261, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.1196, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.2153, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9392, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.3662, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5970, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.4005, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.3307, grad_fn=<MeanBackward0>) kernel loss: tensor(3.8996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.2830, grad_fn=<MeanBackward0>) kernel loss: tensor(3.3443, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.0297, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.2541, grad_fn=<MeanBackward0>) kernel loss: tensor(2.4690, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.3662, grad_fn=<MeanBackward0>) kernel loss: tensor(2.9816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.2124, grad_fn=<MeanBackward0>) kernel loss: tensor(3.0204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.4318, grad_fn=<MeanBackward0>) kernel loss: tensor(2.7375, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5222, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6770, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5783, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5273, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5545, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9035, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.4048, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2712, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.4601, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6232, grad_fn=<MeanBackward0>) kernel loss: tensor(1.6776, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7152, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6488, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6956, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2610, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5623, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4128, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.3044, grad_fn=<MeanBackward0>) kernel loss: tensor(2.1790, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5418, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5702, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6743, grad_fn=<MeanBackward0>) kernel loss: tensor(4.5606, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.7896, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6192, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2652, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.2618, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7783, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.2947, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.7805, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.8445, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9514, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1729, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9880, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9574, grad_fn=<MeanBackward0>) kernel loss: tensor(2.0487, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6156, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6523, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.7721, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4440, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.8396, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.8910, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.7624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5951, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6585, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.2285, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6992, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.8714, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.0588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7732, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1805, grad_fn=<MeanBackward0>) kernel loss: tensor(2.2617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6465, grad_fn=<MeanBackward0>) kernel loss: tensor(2.9382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9094, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1406, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.0437, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.0253, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8014, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5851, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9622, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4497, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.0084, grad_fn=<MeanBackward0>) kernel loss: tensor(1.8798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1742, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.2168, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1530, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4290, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.0397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7849, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.6101, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.8538, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.2544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7111, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3197, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4666, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2864, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5096, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4923, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5876, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6292, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4250, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6720, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5106, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5452, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.2947, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.1848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.7271, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4727, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4388, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5808, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6463, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7357, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7196, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4065, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.1841, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.9813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8484, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.0293, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.2790, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8744, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4388, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4915, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6013, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6939, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0043, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-1.7845, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8379, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8871, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8213, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9432, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7325, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0378, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7079, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9569, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8270, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3719, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3140, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0749, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.5210, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2546, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(1.1062, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4033, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1169, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5860, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3113, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4283, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4975, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5811, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7321, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8216, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9612, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0989, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1333, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1535, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4132, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2386, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1670, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2738, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9224, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9340, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1833, grad_fn=<MeanBackward0>) kernel loss: tensor(1.3209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3515, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7882, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8771, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1123, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7926, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1699, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2405, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6982, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3157, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3093, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1119, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3303, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2603, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.6195, grad_fn=<MeanBackward0>) kernel loss: tensor(2.3472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.8726, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.0393, grad_fn=<MeanBackward0>) kernel loss: tensor(1.4647, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.2998, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4174, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3431, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8068, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4559, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8502, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2090, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8431, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2710, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9251, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8278, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0136, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1094, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2703, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0508, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0904, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1515, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4372, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3292, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1364, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1989, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5177, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3020, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5906, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5677, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2758, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4018, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2258, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(1.3574, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6268, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.8247, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7158, grad_fn=<MeanBackward0>) kernel loss: tensor(1.7454, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0394, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6589, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2086, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2363, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2705, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5105, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3631, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1926, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4655, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5029, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5087, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5748, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5182, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6622, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3574, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4881, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5421, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1577, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3960, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8674, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5728, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2856, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2565, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4285, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2751, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4799, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7731, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3244, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8058, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8871, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9294, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1272, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0389, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7196, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.0475, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4959, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.2165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.7466, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0257, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0007, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2472, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4331, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6503, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5075, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5992, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5855, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1411, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6748, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8308, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7410, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3091, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2624, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.8294, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0490, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1275, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3790, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1994, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2442, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2118, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8157, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.2461, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6926, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(1.7730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.6306, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5446, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5744, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5078, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6681, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3989, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4550, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4030, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9960, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3419, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5203, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1417, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4320, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0207, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3466, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1634, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4918, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2705, grad_fn=<MeanBackward0>) kernel loss: tensor(1.0557, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3809, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3743, grad_fn=<MeanBackward0>) kernel loss: tensor(1.1237, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6989, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0910, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5722, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3830, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7282, grad_fn=<MeanBackward0>) kernel loss: tensor(1.2532, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4718, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2924, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2670, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.2598, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6594, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5483, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9794, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0460, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6413, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1913, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1503, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2410, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0858, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4345, grad_fn=<MeanBackward0>) kernel loss: tensor(1.5209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6213, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2840, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.6971, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4932, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1938, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0682, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0036, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4196, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3737, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3139, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4269, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2558, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3399, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3373, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2275, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4442, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0552, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2294, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3811, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2170, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1578, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6772, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7226, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5662, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2889, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4078, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1920, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3975, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6248, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6408, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3310, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3900, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1296, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5507, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.3760, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6104, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.4093, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0250, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8282, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3661, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5671, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4987, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2158, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5806, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4667, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5540, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6652, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1945, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7591, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2106, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7831, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8455, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9392, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2610, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9379, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4736, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0479, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1444, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7915, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6449, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2296, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(2.1067, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.6957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0628, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5549, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0667, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8533, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0263, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6689, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1130, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4943, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1308, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2281, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3147, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4154, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3419, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4075, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4028, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4846, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4169, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5130, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0244, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1949, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5035, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6404, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6545, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4631, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7524, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3922, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8557, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8554, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2338, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-3.9245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6663, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6590, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8844, grad_fn=<MeanBackward0>) kernel loss: tensor(0.7000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0195, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0271, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4591, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0560, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1591, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0167, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2686, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1371, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2997, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.7953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1109, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.9825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2654, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4952, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5239, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6611, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5644, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6330, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2707, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4087, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8139, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2696, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8144, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0769, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8562, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0510, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9707, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5122, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9869, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4082, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0621, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2333, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0201, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5739, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0597, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1380, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1463, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3357, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1096, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3224, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.5791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.1934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6644, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1325, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8527, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9451, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2044, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9923, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1841, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1317, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2940, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2061, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2197, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3439, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4021, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0968, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4596, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2267, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1815, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(1.6641, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(6.7319, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.9883, grad_fn=<MeanBackward0>) kernel loss: tensor(1.9991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.4779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2978, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0349, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1956, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5547, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1799, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5907, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6428, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1652, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0686, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7200, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0895, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7549, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3058, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8211, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1447, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8886, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1187, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4371, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9530, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.9146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0273, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0250, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1065, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0648, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1476, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6399, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0339, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2300, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1818, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2463, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0212, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2780, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2127, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2763, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2873, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1613, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1367, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1213, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3031, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5495, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5549, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3182, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0016, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1207, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8844, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4122, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2374, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1237, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1519, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3182, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2096, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4548, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4831, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3578, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1200, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2555, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7279, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4222, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1461, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.6326, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.6197, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6753, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6604, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1359, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4699, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6192, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1613, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1270, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2976, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0278, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3606, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3041, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3988, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1470, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-4.2684, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2303, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1434, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2851, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3304, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3531, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1784, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1067, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9055, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0605, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9499, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5359, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5549, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1395, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4943, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3483, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2564, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7869, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0749, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2479, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2118, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4017, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2020, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4736, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4996, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1685, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3523, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1771, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9941, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7180, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2358, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0213, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2863, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1119, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.9640, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1081, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4467, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2878, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0337, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1313, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6108, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5020, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0101, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0586, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5395, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3870, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0823, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2136, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3099, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.3707, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2115, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3590, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0995, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0515, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4685, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1870, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1158, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5463, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2044, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5774, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2550, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6215, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6563, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7626, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5900, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6652, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5369, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7008, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6295, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2592, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3871, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2445, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0555, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0306, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.6418, grad_fn=<MeanBackward0>) kernel loss: tensor(0.6537, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4914, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1465, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4813, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2305, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3958, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5966, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3581, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1828, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6251, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6733, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1258, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6573, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6776, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0882, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2468, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2920, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8088, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1136, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4400, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.5582, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6507, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1002, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4318, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2058, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5773, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2425, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7135, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7040, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0875, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2429, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9018, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4136, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.0776, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0081, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2164, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4257, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0701, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2548, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6107, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2314, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6876, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0260, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7698, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8221, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8714, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9482, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0738, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3244, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9873, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1224, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0200, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1699, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0499, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1654, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0839, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1332, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1183, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8776, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3000, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3782, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1006, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(4.8539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3145, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(4.2934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.8777, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9216, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3929, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2102, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1634, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3547, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3793, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3815, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0772, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4398, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0228, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5079, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2451, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5617, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0965, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6101, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2973, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5524, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1843, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2949, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0305, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7420, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1575, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0641, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8064, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2044, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8363, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1192, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8514, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2589, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9061, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0553, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9079, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0790, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9126, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2487, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9269, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0337, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9182, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2911, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7961, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0616, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4152, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2686, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7619, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4125, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3397, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0077, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3519, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6716, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0080, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1571, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6879, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8192, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1406, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9297, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9664, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1906, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8674, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1699, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0461, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7703, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0135, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.3181, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1303, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.4070, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3333, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1935, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0352, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3800, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2687, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7784, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8819, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1930, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4255, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0401, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1527, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0930, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2174, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1460, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0696, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1663, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1249, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1458, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0332, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1865, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.7695, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2083, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2995, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1211, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0887, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8692, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9567, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1833, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0977, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0238, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0423, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1856, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2680, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0677, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1990, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1206, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1663, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1698, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2067, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1564, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2263, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0807, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1723, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0807, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6158, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2602, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.1449, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.9297, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2591, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(1.3709, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1500, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8352, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3251, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8797, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2250, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9320, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0262, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1485, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3754, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0228, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1083, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1251, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2949, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1485, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1046, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1874, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2280, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2338, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1711, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2373, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2176, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1589, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3139, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8174, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0445, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0163, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2917, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7274, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.4308, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8264, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4768, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9748, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1424, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0372, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1262, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1412, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1805, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0411, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1905, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-5.2338, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2208, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1976, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1175, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2688, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0421, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1332, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1469, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2406, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0510, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0783, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5894, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2335, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5090, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4287, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1832, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3348, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8557, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0257, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5297, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4883, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6570, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0936, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0273, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2320, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0099, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2422, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1164, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1564, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0782, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0147, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2143, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3146, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2663, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2798, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2701, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2905, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1861, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3117, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4027, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0680, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3981, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1265, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4063, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2291, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.0825, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0979, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.5618, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0392, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.4506, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9401, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1370, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0218, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1204, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0488, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0145, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0988, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1809, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1227, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1569, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1718, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1852, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2072, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0422, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2485, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2391, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2329, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2889, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3533, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1097, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3878, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0846, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4051, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0104, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0559, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4201, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2705, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4196, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2825, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5150, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5448, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5392, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1972, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5475, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2098, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1444, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3816, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1679, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0332, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.1819, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(3.1187, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2915, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8179, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8553, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1603, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1638, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1756, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2284, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1867, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2513, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1770, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2772, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3412, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3552, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3668, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3940, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1667, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0636, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1805, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4463, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0547, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4475, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1121, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4991, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3200, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5261, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1603, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4741, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5209, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5816, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5954, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2735, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1111, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5003, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0033, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0950, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.4117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1048, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0341, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-0.4458, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3385, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.4918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9616, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1683, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2498, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1081, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0902, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3250, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3679, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0308, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4009, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2079, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4068, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0622, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4692, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2084, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0012, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4944, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0141, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5295, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5458, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5882, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1325, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-5.5783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6283, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6475, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6281, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0433, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6296, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5203, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0410, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3160, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.3628, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.5919, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.1866, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6560, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0972, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1111, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2769, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0337, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4817, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2208, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4296, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0403, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5823, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6059, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6177, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2019, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6006, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0051, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2286, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6490, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0053, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7002, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0854, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7211, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7393, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0564, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7358, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0572, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7776, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1216, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7655, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7112, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5416, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1960, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9541, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5111, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0129, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(0.7356, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.3098, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1601, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.7646, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0766, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3794, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4453, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4934, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3440, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5183, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0945, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5435, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0641, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5654, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5776, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0924, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6167, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0284, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6334, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0526, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6510, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2884, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6500, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1662, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6714, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0272, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6809, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7090, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3953, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6560, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7297, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7497, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7212, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7430, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7496, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6882, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3577, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1689, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8968, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.5858, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0419, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8450, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2623, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.7716, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2933, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5366, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2716, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2574, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1129, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6315, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0210, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6633, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7050, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1347, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0434, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7568, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1818, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7787, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0395, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0891, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7979, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8211, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1404, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8299, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0750, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8467, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1494, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0400, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8332, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2007, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6701, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1714, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4238, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0976, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8134, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1669, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.8031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.9314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1823, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0298, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0712, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3682, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5473, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6632, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0903, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0265, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7309, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7592, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7799, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1342, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7283, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0620, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8174, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0473, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8184, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2411, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8574, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8224, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8081, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1369, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8008, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0937, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6706, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0152, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4628, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1038, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8802, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0577, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0915, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0913, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-2.6579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3893, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.0753, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1988, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3966, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7838, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1768, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0641, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7863, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0504, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8124, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0669, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8391, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0314, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8593, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8636, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1911, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1949, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0692, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8173, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2456, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8201, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2219, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1163, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0480, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2644, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0131, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0392, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0441, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.3613, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0121, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1546, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1088, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8310, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1804, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5951, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1291, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7289, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1485, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7179, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8023, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1241, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0063, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8341, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0811, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8988, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9152, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9249, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0041, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9219, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8913, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0719, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8066, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4721, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2161, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0946, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1145, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.2125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.1327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1235, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8603, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0134, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1676, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6389, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0664, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7510, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8628, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0214, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0713, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8511, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9072, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0272, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9272, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2230, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0580, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0640, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9474, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2082, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3240, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9130, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0776, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9931, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0013, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0316, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0986, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1706, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0125, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0178, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0266, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8469, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0292, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4917, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0071, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0862, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.6027, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.2274, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1295, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-2.8996, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0943, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8164, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4271, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1413, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0525, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9012, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9362, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9545, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1426, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9750, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9691, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1064, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9911, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0088, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0239, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0812, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2572, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1067, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0390, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0625, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3087, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0484, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0015, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0883, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2165, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0978, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1090, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1151, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1084, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1017, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0520, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0604, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6190, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0462, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.8670, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0663, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7469, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1461, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-1.8155, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.7651, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6412, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8675, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0942, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9480, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9853, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1410, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9967, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0122, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2217, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9978, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0048, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0308, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0525, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0663, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0445, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0935, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0711, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0508, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0788, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0965, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-6.0757, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0685, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0472, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0021, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0103, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0881, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7926, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0035, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5119, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2830, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3519, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7294, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5546, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0288, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0979, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8166, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0119, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0394, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0997, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0143, grad_fn=<MeanBackward0>) kernel loss: tensor(0.4467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9439, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0554, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0054, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0615, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0757, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2733, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0094, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0923, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0452, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0967, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0639, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9780, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0632, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9175, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8883, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7622, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0369, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1589, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1675, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1092, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0505, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2894, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3214, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0544, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6713, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0995, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0957, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9592, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1864, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2082, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0493, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0360, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0392, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1377, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1207, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2578, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1018, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2018, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1170, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0071, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1167, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1020, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1374, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0891, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9992, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0612, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1968, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1511, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1526, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9384, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1038, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.5104, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0996, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2483, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0374, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7006, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0859, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0391, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9803, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0614, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1561, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1098, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1251, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1691, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1653, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1801, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0587, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0650, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2229, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2311, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0036, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2399, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2424, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2139, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0194, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1767, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1083, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1575, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9603, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0541, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4563, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1162, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9436, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9669, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1293, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2888, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0991, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8566, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1773, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9866, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1322, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1601, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0224, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2019, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1482, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1737, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2150, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1086, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2274, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2556, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2681, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0235, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2582, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0984, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2689, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2845, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0353, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2938, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2689, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2119, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1418, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2293, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0258, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1668, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0805, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0457, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8937, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5743, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0238, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0444, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9648, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0258, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6656, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3099, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0330, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5399, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1258, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8312, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1505, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9193, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0814, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0872, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1400, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1576, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1673, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2256, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1947, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0428, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2948, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1659, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0795, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2927, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0781, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-6.3145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1193, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3100, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0921, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3042, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1179, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2619, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1047, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1272, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2005, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0083, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8433, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3995, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0898, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1364, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0082, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2257, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1780, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7837, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0135, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9799, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1384, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2267, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2732, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2102, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2973, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3227, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0179, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3347, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0439, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3575, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3679, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0382, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3833, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3841, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1001, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0525, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3965, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0774, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4026, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4083, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1867, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3914, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1730, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1225, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3220, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1275, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2603, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1425, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9729, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0545, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6612, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3294, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1564, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0912, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.6699, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0781, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-3.9973, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0089, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2226, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1037, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9324, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1654, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2598, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1326, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3159, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3531, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0323, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3517, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0083, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0266, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3870, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1520, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4093, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4198, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1444, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4197, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0625, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4219, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0113, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4396, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3807, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4215, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1064, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4418, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4523, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0379, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4549, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0980, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4268, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4027, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1160, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3870, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1044, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2056, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1435, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0696, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8910, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5070, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3279, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0119, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9499, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0970, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1514, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0045, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3262, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0321, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0257, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0759, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2424, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0415, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3319, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0927, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3853, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0894, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0562, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4392, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4522, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0393, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4547, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0019, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4602, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0490, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4759, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0264, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4837, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4933, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4861, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0079, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4964, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4786, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0526, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4657, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1715, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4451, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0259, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4663, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4072, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1182, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8473, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3344, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0546, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.1033, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0208, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7457, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3046, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5774, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0528, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2609, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1001, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4175, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0438, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4425, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0594, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4565, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1116, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4953, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1508, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1025, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5143, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5273, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0171, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5272, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1567, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5354, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0531, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5405, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0901, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-6.5479, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0327, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5602, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0111, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5586, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0344, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5564, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5607, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5602, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0762, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5626, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1244, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5452, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0158, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5141, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0202, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4447, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3310, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0298, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1409, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7649, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3837, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1932, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.7974, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0910, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-4.9588, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0003, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.0220, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0272, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7352, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0149, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3239, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1825, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4793, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2200, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5192, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1925, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5389, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5535, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0216, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5536, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0637, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5651, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0307, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5660, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1596, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5819, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5909, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1737, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5884, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0731, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5659, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0598, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5755, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0177, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5551, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0691, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5454, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0054, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1513, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5073, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0833, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1319, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4214, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2726, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1801, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0331, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8263, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0429, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4692, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.3630, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.2366, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3040, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8836, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1619, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3416, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1583, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4686, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1797, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5540, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5755, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2199, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5802, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0172, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1784, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6056, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0549, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6070, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2109, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6091, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6185, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2388, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6345, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0524, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6381, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0562, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6245, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0080, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2692, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6154, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6253, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6011, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0129, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1286, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5461, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0390, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4875, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0504, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4211, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3259, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0031, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1710, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0281, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9629, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1672, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7109, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1817, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8025, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1012, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0473, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2303, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0274, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3366, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4600, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1265, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5131, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0163, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5606, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5877, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0186, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6094, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2946, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5922, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1081, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6256, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6445, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0931, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6131, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6350, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0350, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6413, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0191, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6504, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6573, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0208, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6605, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6579, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6521, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6373, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2128, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5400, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0178, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4754, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1604, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2885, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0236, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1415, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0872, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8115, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1127, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6645, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.9425, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0474, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2895, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1521, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3816, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1629, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5548, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6068, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6312, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2171, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6586, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0691, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-6.6699, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0723, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6761, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6735, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0293, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6849, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6986, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1725, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7108, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7185, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7217, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0621, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0645, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0702, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7092, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0629, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7024, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2378, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7129, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7087, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0855, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0133, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6789, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6493, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1351, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6042, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5385, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0963, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1097, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3077, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0152, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0704, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8983, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1233, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.6606, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0106, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7765, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8465, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1781, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3521, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0323, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5226, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1499, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6088, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0247, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6629, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6920, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7009, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1064, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0788, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7215, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7414, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0559, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7437, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0471, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7542, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1950, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7593, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7636, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1105, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7661, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0090, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7624, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7655, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1233, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7634, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7639, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7700, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0527, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2081, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7556, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2182, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7606, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7642, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1644, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7307, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7209, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0620, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6979, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1323, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6650, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6173, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0234, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3248, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0105, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.0455, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8479, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0358, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.5918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0918, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7282, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8260, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0363, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2318, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3968, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0729, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6783, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7289, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7387, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0394, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7673, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7861, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2610, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7885, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0588, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8015, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1533, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7901, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7950, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0690, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8032, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8110, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0231, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8147, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1394, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8171, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2283, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8055, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8026, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1114, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7967, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8027, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0084, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8002, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0413, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7972, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7950, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7570, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7235, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0985, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6784, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0263, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5985, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1115, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5082, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0324, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4315, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3486, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1956, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0226, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0105, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1803, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1076, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2613, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0356, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3030, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0195, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4164, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5161, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0531, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6228, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6890, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7204, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0584, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7711, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0232, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0185, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0710, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8221, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2256, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8262, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0024, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8435, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0810, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8566, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0994, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8635, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8673, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0118, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8700, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1941, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8616, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0450, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8725, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1988, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8779, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0010, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8770, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8805, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8802, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0785, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-6.8828, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0381, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8801, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8804, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8665, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0896, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1354, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8585, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1346, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8346, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0573, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1828, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7565, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0206, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6605, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4498, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.1798, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2904, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8178, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1743, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.4751, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1417, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.7145, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-5.8534, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2734, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0156, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4856, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6899, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0075, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7736, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0879, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8404, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0423, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8657, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0906, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8796, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8918, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2173, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8859, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9015, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9071, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0361, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1585, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9089, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9151, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9095, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0504, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9043, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0858, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1610, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9021, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9225, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1031, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9205, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0566, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9278, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0216, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9283, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9332, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9351, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1897, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1130, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9314, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0867, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9111, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2436, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9209, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1569, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0138, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9004, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0145, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8791, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8522, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2717, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8063, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7670, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0269, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6842, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0182, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5724, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4239, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0785, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3364, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.2169, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3304, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1915, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.3378, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.4892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0727, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.5644, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0068, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6943, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7595, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1746, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8126, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0993, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8423, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1464, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8819, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1835, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9049, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0145, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9186, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0616, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9288, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9325, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0404, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9431, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0176, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9458, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0618, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9520, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9547, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9572, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1063, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9523, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1630, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9456, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9431, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0593, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9431, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1531, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9306, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9367, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9343, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0819, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9411, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1120, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1032, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8727, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0981, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8736, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1488, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8438, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0328, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8330, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7601, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7395, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0509, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6862, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0205, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0352, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6714, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0473, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7031, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0229, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7064, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1065, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7227, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7477, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0700, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7878, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0758, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8208, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0982, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8551, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0318, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8911, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0124, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9044, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9326, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9416, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0070, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9514, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1761, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9532, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9699, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9740, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0939, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9632, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9687, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0016, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1968, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9649, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0964, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9665, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9672, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9535, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1705, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9597, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0646, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9587, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0764, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9460, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-6.9415, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0481, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2414, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8571, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1473, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8191, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0813, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8055, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7615, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0880, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7491, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0188, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7028, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7135, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.6999, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7349, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0770, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7766, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8210, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8299, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0397, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9235, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1323, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9493, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0112, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9660, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0067, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9792, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1155, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9912, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0009, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0309, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0120, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0126, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0188, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1315, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0208, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0989, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0529, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0192, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0658, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0138, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0600, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0026, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0209, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9848, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2682, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0115, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9441, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0260, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9302, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0316, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9120, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1342, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9070, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8961, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0404, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8714, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8409, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8287, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0096, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7952, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7969, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7682, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0537, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7810, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0874, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8276, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8477, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0405, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1289, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9416, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9610, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0869, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9728, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9860, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0563, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9997, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0539, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0241, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1856, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0266, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0062, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0359, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0455, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0369, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0100, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0410, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1527, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0355, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0827, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0367, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2159, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0376, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1296, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0335, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0059, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0368, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1170, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0422, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1148, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0452, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0432, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0496, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0375, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0518, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0327, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0221, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0050, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0051, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9960, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9736, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1637, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9317, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8928, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0530, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7971, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0163, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7731, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0136, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.7821, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0396, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8055, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0217, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8531, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0223, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8960, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9494, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0200, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9846, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0171, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0252, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0443, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1089, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0485, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2549, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0630, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0448, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0664, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0060, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0854, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0534, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0924, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0973, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0115, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1006, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1681, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0993, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0649, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1057, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2143, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0996, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0848, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0378, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0959, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0227, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0772, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2080, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0775, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1023, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0801, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0898, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0674, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0088, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0561, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0427, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0470, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1695, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0395, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0518, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0357, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0390, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0236, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1506, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9893, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0290, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9584, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0624, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9426, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9064, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8921, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1627, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.8800, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0409, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9091, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0259, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9136, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0731, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-6.9319, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0056, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0376, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9471, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9690, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1183, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0066, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0591, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0306, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1486, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0585, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0294, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0039, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0925, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1045, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1123, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1177, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1233, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1181, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1125, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0724, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1272, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1006, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1237, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0870, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1288, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0768, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1289, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1260, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1275, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1242, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0073, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1117, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0924, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0730, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0983, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0544, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0699, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0355, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3449, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0116, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1001, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9720, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9868, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0180, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9993, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0098, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0184, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-6.9905, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0008, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0080, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0066, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0226, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0313, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0527, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0496, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1164, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0633, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0800, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0970, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1037, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0362, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1178, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1255, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0306, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1300, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2267, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1386, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0857, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1405, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0289, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1441, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1464, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1473, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0239, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1501, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1503, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0279, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1458, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0794, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1365, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1330, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1351, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2144, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1281, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0337, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1274, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0250, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1202, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0150, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1205, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0345, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0299, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1266, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1238, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1258, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0189, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1237, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0503, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1066, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1472, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.0990, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1297, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1143, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1084, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1118, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0802, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1154, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0166, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1074, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1512, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1035, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1061, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1093, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1022, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1108, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2560, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1116, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0998, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1172, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0349, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1267, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0261, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1299, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0577, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1361, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0639, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1384, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1734, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0540, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1152, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1207, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0198, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1195, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1263, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1221, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1277, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0317, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1377, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0899, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1379, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0905, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1446, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0721, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1465, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0642, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1463, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0767, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1491, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0192, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1466, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1535, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1445, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0763, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1519, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1170, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1371, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0919, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1545, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0027, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1578, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0485, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1502, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0071, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1550, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0542, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1652, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2111, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1702, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1404, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1764, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0055, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1739, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0047, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1717, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1049, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1753, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0120, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1777, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0401, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1679, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0684, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1671, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0683, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1539, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1573, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0420, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1620, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0581, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1659, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0757, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1558, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1607, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0569, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1598, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1604, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0470, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1680, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0085, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1778, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0380, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1774, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1268, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nllk loss:  tensor(-7.1758, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0157, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1820, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0034, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1816, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1727, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1801, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0280, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1812, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1617, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1957, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0290, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1983, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0398, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2001, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1914, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1958, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0432, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1963, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0057, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2007, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0876, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2045, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0322, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2042, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0507, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1972, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1657, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1910, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1939, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0306, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1911, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1916, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0125, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1945, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0285, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1920, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1903, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1334, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1797, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0816, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1745, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0695, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1774, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1766, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1734, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1762, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0477, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1942, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0885, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1869, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0826, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1951, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0069, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.1999, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1701, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2142, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1516, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2129, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0242, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2055, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1453, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2210, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2282, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0673, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2256, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0800, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2281, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2301, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2186, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2262, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0213, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2214, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0765, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2240, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0201, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2231, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2345, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2254, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0568, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2296, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0277, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2213, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0467, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2180, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0210, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2149, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0517, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2169, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0042, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2156, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0246, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2099, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2927, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2122, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0276, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2288, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0708, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2342, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0476, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2340, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2412, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2406, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2481, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1264, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2553, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2632, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2654, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0637, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2667, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1668, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2679, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0836, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2710, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2741, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2749, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2751, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0844, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2754, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2753, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0095, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2746, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0460, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2722, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2718, grad_fn=<MeanBackward0>) kernel loss: tensor(0.3003, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2549, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1862, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2463, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0783, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2357, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0601, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2223, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2204, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0388, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2119, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0546, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2017, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0253, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2085, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1978, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2046, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0168, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2103, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0301, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2124, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0218, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2195, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2284, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0491, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2460, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2387, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2551, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0002, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2613, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1021, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2689, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0654, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2837, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2892, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2151, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2940, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3034, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2197, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3105, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0123, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2359, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3114, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0153, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3153, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0837, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3185, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0523, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3187, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3204, grad_fn=<MeanBackward0>) kernel loss: tensor(0.2733, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3165, grad_fn=<MeanBackward0>) kernel loss: tensor(0.1572, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3166, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0752, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3137, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0890, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3087, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3082, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3088, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3064, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0443, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3092, grad_fn=<MeanBackward0>) kernel loss: tensor(0., grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.3076, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0314, grad_fn=<AddBackward0>)\n",
      "nllk loss:  tensor(-7.2940, grad_fn=<MeanBackward0>) kernel loss: tensor(0.0514, grad_fn=<AddBackward0>)\n",
      "final loss:  -7.2939839363098145\n"
     ]
    }
   ],
   "source": [
    "end2end_model = end2end_kernel.train_model_kernel(x_train, y_train, n_epoch = 2000, hidden_layers = [30, 30], learning_rate = 0.01, exp_decay = .998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End2end test MAPE:  0.24667867\n",
      "End2end test RMSE:  1.5080376\n",
      "End2end test NLLK:  4.589012\n",
      "End2end test CRPS:  tensor(0.6308)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End2end test calibration error when step size is 0.001:  15.765972255017711\n",
      "End2end test calibration error when step size is 0.01:  1.5528546129195482\n",
      "End2end test calibration error when step size is 0.1:  0.13082307303086527\n"
     ]
    }
   ],
   "source": [
    "mean_pred, var_pred, _ = end2end_model(x_test)\n",
    "mean_pred = mean_pred.detach().numpy() * y_sd.detach().numpy()+ y_mean.detach().numpy()\n",
    "var_pred = var_pred.detach().numpy() * torch.pow(y_sd, 2).detach().numpy()\n",
    "sd_pred = np.sqrt(var_pred)\n",
    "\n",
    "print('End2end test MAPE: ', metrics.mape(y_test.detach().numpy(), mean_pred))\n",
    "print('End2end test RMSE: ', metrics.rmse(y_test.detach().numpy(), mean_pred))\n",
    "print('End2end test NLLK: ', metrics.nllk(y_test.detach().numpy(), mean_pred, var_pred))\n",
    "print('End2end test CRPS: ', metrics.CRPSMetric(x = y_test.squeeze(dim = 1), loc = torch.tensor(mean_pred).squeeze(dim = 1), scale = torch.tensor(sd_pred).squeeze(dim = 1)).gaussian_crps().mean())\n",
    "\n",
    "pcdf = metrics.pcdf(mean_pred.squeeze(1), var_pred.squeeze(1), y_test.detach().numpy().squeeze(1))\n",
    "metrics.draw_pcdf(pcdf)\n",
    "print('End2end test calibration error when step size is 0.001: ', metrics.calibration_error(pcdf, step = 0.001))\n",
    "print('End2end test calibration error when step size is 0.01: ', metrics.calibration_error(pcdf, step = 0.01))\n",
    "print('End2end test calibration error when step size is 0.1: ', metrics.calibration_error(pcdf, step = 0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (1/n) Calculating accuracy metrics\n",
      " (2/n) Calculating average calibration metrics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|████████▌                                  | 2/10 [00:00<00:00, 11.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (3/n) Calculating adversarial group calibration metrics\n",
      "  [1/2] for mean absolute calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 11.42it/s]\n",
      " 20%|████████▌                                  | 2/10 [00:00<00:00, 11.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2/2] for root mean squared calibration error\n",
      "Measuring adversarial group calibration by spanning group size between 0.0 and 1.0, in 10 intervals\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 10/10 [00:00<00:00, 11.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " (4/n) Calculating sharpness metrics\n",
      " (n/n) Calculating proper scoring rule metrics\n",
      "**Finished Calculating All Metrics**\n",
      "\n",
      "\n",
      "===================== Accuracy Metrics =====================\n",
      "  MAE           0.771\n",
      "  RMSE          1.508\n",
      "  MDAE          0.296\n",
      "  MARPD         20.309\n",
      "  R2            0.992\n",
      "  Correlation   0.997\n",
      "=============== Average Calibration Metrics ================\n",
      "  Root-mean-squared Calibration Error   0.245\n",
      "  Mean-absolute Calibration Error       0.213\n",
      "  Miscalibration Area                   0.215\n",
      "========== Adversarial Group Calibration Metrics ===========\n",
      "  Mean-absolute Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.359\n",
      "     Group Size: 0.56 -- Calibration Error: 0.254\n",
      "     Group Size: 1.00 -- Calibration Error: 0.213\n",
      "  Root-mean-squared Adversarial Group Calibration Error\n",
      "     Group Size: 0.11 -- Calibration Error: 0.443\n",
      "     Group Size: 0.56 -- Calibration Error: 0.296\n",
      "     Group Size: 1.00 -- Calibration Error: 0.245\n",
      "==================== Sharpness Metrics =====================\n",
      "  Sharpness   0.708\n",
      "=================== Scoring Rule Metrics ===================\n",
      "  Negative-log-likelihood   3.213\n",
      "  CRPS                      0.631\n",
      "  Check Score               0.318\n",
      "  Interval Score            4.366\n",
      "{'accuracy': {'mae': 0.77075875, 'rmse': 1.5080376, 'mdae': 0.29552364, 'marpd': 20.308592915534973, 'r2': 0.992410015935136, 'corr': 0.9972078813122061}, 'avg_calibration': {'rms_cal': 0.24533897633294316, 'ma_cal': 0.21285714285714288, 'miscal_area': 0.21500721500721504}, 'adv_group_calibration': {'ma_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.48      , 0.35914141, 0.30936958, 0.29774204, 0.27877986,\n",
      "       0.25392436, 0.2525615 , 0.25198838, 0.23551471, 0.21285714]), 'adv_group_cali_stderr': array([2.65622958e-02, 5.18589188e-02, 2.78132019e-02, 2.74997228e-02,\n",
      "       2.67031556e-02, 1.37143565e-02, 1.08083603e-02, 1.56250684e-02,\n",
      "       1.06014465e-02, 2.92569456e-17])}, 'rms_adv_group_cal': {'group_sizes': array([0.        , 0.11111111, 0.22222222, 0.33333333, 0.44444444,\n",
      "       0.55555556, 0.66666667, 0.77777778, 0.88888889, 1.        ]), 'adv_group_cali_mean': array([0.55482764, 0.44280181, 0.35328592, 0.32038263, 0.31703188,\n",
      "       0.29600493, 0.28981315, 0.27377915, 0.26617397, 0.24533898]), 'adv_group_cali_stderr': array([0.03228641, 0.06439799, 0.02458586, 0.03418986, 0.0329126 ,\n",
      "       0.0136332 , 0.01062126, 0.01233247, 0.00785125, 0.        ])}}, 'sharpness': {'sharp': 0.7084626}, 'scoring_rule': {'nll': 3.2134446693208902, 'crps': 0.6308307580119545, 'check': 0.3177476502759452, 'interval': 4.365786182597366}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(uct.metrics.get_all_metrics(mean_pred.squeeze(1), sd_pred.squeeze(1), y_test.detach().numpy().squeeze(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lims is None. Setting lims now:\n",
      "min_max_true: (0.08, 62.42)\n",
      "min_max_pred: (-0.2740736, 57.145344)\n",
      "lims: (-0.2740736, 62.42)\n",
      "lims_ext: (-6.54348087310791, 68.68940544128418)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y = y_test.detach().numpy().squeeze(1)\n",
    "\n",
    "uviz.plot_intervals(mean_pred.squeeze(1), sd_pred.squeeze(1), y)\n",
    "uviz.plot_intervals_ordered(mean_pred.squeeze(1), sd_pred.squeeze(1), y)\n",
    "uviz.plot_parity(mean_pred.squeeze(1), y)\n",
    "uviz.plot_calibration(mean_pred.squeeze(1), sd_pred.squeeze(1), y)\n",
    "uviz.plot_sharpness(sd_pred.squeeze(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
